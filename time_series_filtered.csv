date_published,title,authors,summary,url,category
2023-11-02 17:58:09+00:00,Time Series Anomaly Detection using Diffusion-based Models,"['Ioana Pintilie', 'Andrei Manolache', 'Florin Brad']","Diffusion models have been recently used for anomaly detection (AD) in
images. In this paper we investigate whether they can also be leveraged for AD
on multivariate time series (MTS). We test two diffusion-based models and
compare them to several strong neural baselines. We also extend the PA%K
protocol, by computing a ROCK-AUC metric, which is agnostic to both the
detection threshold and the ratio K of correctly detected points. Our models
outperform the baselines on synthetic datasets and are competitive on
real-world datasets, illustrating the potential of diffusion-based methods for
AD in multivariate time series.",http://arxiv.org/pdf/2311.01452v1,cs.LG
2023-11-02 17:55:41+00:00,Deep Double Descent for Time Series Forecasting: Avoiding Undertrained Models,"['Valentino Assandri', 'Sam Heshmati', 'Burhaneddin Yaman', 'Anton Iakovlev', 'Ariel Emiliano Repetur']","Deep learning models, particularly Transformers, have achieved impressive
results in various domains, including time series forecasting. While existing
time series literature primarily focuses on model architecture modifications
and data augmentation techniques, this paper explores the training schema of
deep learning models for time series; how models are trained regardless of
their architecture. We perform extensive experiments to investigate the
occurrence of deep double descent in several Transformer models trained on
public time series data sets. We demonstrate epoch-wise deep double descent and
that overfitting can be reverted using more epochs. Leveraging these findings,
we achieve state-of-the-art results for long sequence time series forecasting
in nearly 70% of the 72 benchmarks tested. This suggests that many models in
the literature may possess untapped potential. Additionally, we introduce a
taxonomy for classifying training schema modifications, covering data
augmentation, model inputs, model targets, time series per model, and
computational budget.",http://arxiv.org/pdf/2311.01442v1,cs.LG
2023-11-02 17:26:49+00:00,Castor: Causal Temporal Regime Structure Learning,"['Abdellah Rahmani', 'Pascal Frossard']","The task of uncovering causal relationships among multivariate time series
data stands as an essential and challenging objective that cuts across a broad
array of disciplines ranging from climate science to healthcare. Such data
entails linear or non-linear relationships, and usually follow multiple a
priori unknown regimes. Existing causal discovery methods can infer summary
causal graphs from heterogeneous data with known regimes, but they fall short
in comprehensively learning both regimes and the corresponding causal graph. In
this paper, we introduce CASTOR, a novel framework designed to learn causal
relationships in heterogeneous time series data composed of various regimes,
each governed by a distinct causal graph. Through the maximization of a score
function via the EM algorithm, CASTOR infers the number of regimes and learns
linear or non-linear causal relationships in each regime. We demonstrate the
robust convergence properties of CASTOR, specifically highlighting its
proficiency in accurately identifying unique regimes. Empirical evidence,
garnered from exhaustive synthetic experiments and two real-world benchmarks,
confirm CASTOR's superior performance in causal discovery compared to baseline
methods. By learning a full temporal causal graph for each regime, CASTOR
establishes itself as a distinctly interpretable method for causal discovery in
heterogeneous time series.",http://arxiv.org/pdf/2311.01412v1,cs.LG
2023-11-01 13:44:45+00:00,Retrieval-Based Reconstruction For Time-series Contrastive Learning,"['Maxwell A. Xu', 'Alexander Moreno', 'Hui Wei', 'Benjamin M. Marlin', 'James M. Rehg']","The success of self-supervised contrastive learning hinges on identifying
positive data pairs that, when pushed together in embedding space, encode
useful information for subsequent downstream tasks. However, in time-series,
this is challenging because creating positive pairs via augmentations may break
the original semantic meaning. We hypothesize that if we can retrieve
information from one subsequence to successfully reconstruct another
subsequence, then they should form a positive pair. Harnessing this intuition,
we introduce our novel approach: REtrieval-BAsed Reconstruction (REBAR)
contrastive learning. First, we utilize a convolutional cross-attention
architecture to calculate the REBAR error between two different time-series.
Then, through validation experiments, we show that the REBAR error is a
predictor of mutual class membership, justifying its usage as a
positive/negative labeler. Finally, once integrated into a contrastive learning
framework, our REBAR method can learn an embedding that achieves
state-of-the-art performance on downstream tasks across various modalities.",http://arxiv.org/pdf/2311.00519v1,cs.LG
2023-11-01 01:23:59+00:00,WinNet:time series forecasting with a window-enhanced period extracting and interacting,"['Wenjie Ou', 'Dongyue Guo', 'Zheng Zhang', 'Zhishuo Zhao', 'Yi Lin']","Recently, Transformer-based methods have significantly improved
state-of-the-art time series forecasting results, but they suffer from high
computational costs and the inability to capture the long and short periodicity
of time series. We present a highly accurate and simply structured CNN-based
model for long-term time series forecasting tasks, called WinNet, including (i)
Inter-Intra Period Encoder (I2PE) to transform 1D sequence into 2D tensor with
long and short periodicity according to the predefined periodic window, (ii)
Two-Dimensional Period Decomposition (TDPD) to model period-trend and
oscillation terms, and (iii) Decomposition Correlation Block (DCB) to leverage
the correlations of the period-trend and oscillation terms to support the
prediction tasks by CNNs. Results on nine benchmark datasets show that the
WinNet can achieve SOTA performance and lower computational complexity over
CNN-, MLP-, Transformer-based approaches. The WinNet provides potential for the
CNN-based methods in the time series forecasting tasks, with perfect tradeoff
between performance and efficiency.",http://arxiv.org/pdf/2311.00214v1,cs.LG
2023-10-31 14:34:00+00:00,BasisFormer: Attention-based Time Series Forecasting with Learnable and Interpretable Basis,"['Zelin Ni', 'Hang Yu', 'Shizhan Liu', 'Jianguo Li', 'Weiyao Lin']","Bases have become an integral part of modern deep learning-based models for
time series forecasting due to their ability to act as feature extractors or
future references. To be effective, a basis must be tailored to the specific
set of time series data and exhibit distinct correlation with each time series
within the set. However, current state-of-the-art methods are limited in their
ability to satisfy both of these requirements simultaneously. To address this
challenge, we propose BasisFormer, an end-to-end time series forecasting
architecture that leverages learnable and interpretable bases. This
architecture comprises three components: First, we acquire bases through
adaptive self-supervised learning, which treats the historical and future
sections of the time series as two distinct views and employs contrastive
learning. Next, we design a Coef module that calculates the similarity
coefficients between the time series and bases in the historical view via
bidirectional cross-attention. Finally, we present a Forecast module that
selects and consolidates the bases in the future view based on the similarity
coefficients, resulting in accurate future predictions. Through extensive
experiments on six datasets, we demonstrate that BasisFormer outperforms
previous state-of-the-art methods by 11.04\% and 15.78\% respectively for
univariate and multivariate forecasting tasks. Code is available at:
\url{https://github.com/nzl5116190/Basisformer}",http://arxiv.org/pdf/2310.20496v1,cs.LG
2023-10-31 13:07:41+00:00,Raising the ClaSS of Streaming Time Series Segmentation,"['Arik Ermshaus', 'Patrick Schäfer', 'Ulf Leser']","Ubiquitous sensors today emit high frequency streams of numerical
measurements that reflect properties of human, animal, industrial, commercial,
and natural processes. Shifts in such processes, e.g. caused by external events
or internal state changes, manifest as changes in the recorded signals. The
task of streaming time series segmentation (STSS) is to partition the stream
into consecutive variable-sized segments that correspond to states of the
observed processes or entities. The partition operation itself must in
performance be able to cope with the input frequency of the signals. We
introduce ClaSS, a novel, efficient, and highly accurate algorithm for STSS.
ClaSS assesses the homogeneity of potential partitions using self-supervised
time series classification and applies statistical tests to detect significant
change points (CPs). In our experimental evaluation using two large benchmarks
and six real-world data archives, we found ClaSS to be significantly more
precise than eight state-of-the-art competitors. Its space and time complexity
is independent of segment sizes and linear only in the sliding window size. We
also provide ClaSS as a window operator with an average throughput of 538 data
points per second for the Apache Flink streaming engine.",http://arxiv.org/pdf/2310.20431v1,cs.LG
2023-10-31 08:50:52+00:00,AutoMixer for Improved Multivariate Time-Series Forecasting on Business and IT Observability Data,"['Santosh Palaskar', 'Vijay Ekambaram', 'Arindam Jati', 'Neelamadhav Gantayat', 'Avirup Saha', 'Seema Nagar', 'Nam H. Nguyen', 'Pankaj Dayama', 'Renuka Sindhgatta', 'Prateeti Mohapatra', 'Harshit Kumar', 'Jayant Kalagnanam', 'Nandyala Hemachandra', 'Narayan Rangaraj']","The efficiency of business processes relies on business key performance
indicators (Biz-KPIs), that can be negatively impacted by IT failures. Business
and IT Observability (BizITObs) data fuses both Biz-KPIs and IT event channels
together as multivariate time series data. Forecasting Biz-KPIs in advance can
enhance efficiency and revenue through proactive corrective measures. However,
BizITObs data generally exhibit both useful and noisy inter-channel
interactions between Biz-KPIs and IT events that need to be effectively
decoupled. This leads to suboptimal forecasting performance when existing
multivariate forecasting models are employed. To address this, we introduce
AutoMixer, a time-series Foundation Model (FM) approach, grounded on the novel
technique of channel-compressed pretrain and finetune workflows. AutoMixer
leverages an AutoEncoder for channel-compressed pretraining and integrates it
with the advanced TSMixer model for multivariate time series forecasting. This
fusion greatly enhances the potency of TSMixer for accurate forecasts and also
generalizes well across several downstream tasks. Through detailed experiments
and dashboard analytics, we show AutoMixer's capability to consistently improve
the Biz-KPI's forecasting accuracy (by 11-15\%) which directly translates to
actionable business insights.",http://arxiv.org/pdf/2310.20280v2,cs.LG
2023-10-31 06:37:51+00:00,A Systematic Review for Transformer-based Long-term Series Forecasting,"['Liyilei Su', 'Xumin Zuo', 'Rui Li', 'Xin Wang', 'Heng Zhao', 'Bingding Huang']","The emergence of deep learning has yielded noteworthy advancements in time
series forecasting (TSF). Transformer architectures, in particular, have
witnessed broad utilization and adoption in TSF tasks. Transformers have proven
to be the most successful solution to extract the semantic correlations among
the elements within a long sequence. Various variants have enabled transformer
architecture to effectively handle long-term time series forecasting (LTSF)
tasks. In this article, we first present a comprehensive overview of
transformer architectures and their subsequent enhancements developed to
address various LTSF tasks. Then, we summarize the publicly available LTSF
datasets and relevant evaluation metrics. Furthermore, we provide valuable
insights into the best practices and techniques for effectively training
transformers in the context of time-series analysis. Lastly, we propose
potential research directions in this rapidly evolving field.",http://arxiv.org/pdf/2310.20218v1,cs.LG
2023-10-31 03:16:32+00:00,Contrastive Difference Predictive Coding,"['Chongyi Zheng', 'Ruslan Salakhutdinov', 'Benjamin Eysenbach']","Predicting and reasoning about the future lie at the heart of many
time-series questions. For example, goal-conditioned reinforcement learning can
be viewed as learning representations to predict which states are likely to be
visited in the future. While prior methods have used contrastive predictive
coding to model time series data, learning representations that encode
long-term dependencies usually requires large amounts of data. In this paper,
we introduce a temporal difference version of contrastive predictive coding
that stitches together pieces of different time series data to decrease the
amount of data required to learn predictions of future events. We apply this
representation learning method to derive an off-policy algorithm for
goal-conditioned RL. Experiments demonstrate that, compared with prior RL
methods, ours achieves $2 \times$ median improvement in success rates and can
better cope with stochastic environments. In tabular settings, we show that our
method is about $20 \times$ more sample efficient than the successor
representation and $1500 \times$ more sample efficient than the standard (Monte
Carlo) version of contrastive predictive coding.",http://arxiv.org/pdf/2310.20141v1,cs.LG
2023-10-30 19:20:48+00:00,Topological Learning for Motion Data via Mixed Coordinates,"['Hengrui Luo', 'Jisu Kim', 'Alice Patania', 'Mikael Vejdemo-Johansson']","Topology can extract the structural information in a dataset efficiently. In
this paper, we attempt to incorporate topological information into a multiple
output Gaussian process model for transfer learning purposes. To achieve this
goal, we extend the framework of circular coordinates into a novel framework of
mixed valued coordinates to take linear trends in the time series into
consideration.
  One of the major challenges to learn from multiple time series effectively
via a multiple output Gaussian process model is constructing a functional
kernel. We propose to use topologically induced clustering to construct a
cluster based kernel in a multiple output Gaussian process model. This kernel
not only incorporates the topological structural information, but also allows
us to put forward a unified framework using topological information in time and
motion series.",http://arxiv.org/pdf/2310.19960v1,cs.LG
2023-10-30 06:10:00+00:00,AMLNet: Adversarial Mutual Learning Neural Network for Non-AutoRegressive Multi-Horizon Time Series Forecasting,['Yang Lin'],"Multi-horizon time series forecasting, crucial across diverse domains,
demands high accuracy and speed. While AutoRegressive (AR) models excel in
short-term predictions, they suffer speed and error issues as the horizon
extends. Non-AutoRegressive (NAR) models suit long-term predictions but
struggle with interdependence, yielding unrealistic results. We introduce
AMLNet, an innovative NAR model that achieves realistic forecasts through an
online Knowledge Distillation (KD) approach. AMLNet harnesses the strengths of
both AR and NAR models by training a deep AR decoder and a deep NAR decoder in
a collaborative manner, serving as ensemble teachers that impart knowledge to a
shallower NAR decoder. This knowledge transfer is facilitated through two key
mechanisms: 1) outcome-driven KD, which dynamically weights the contribution of
KD losses from the teacher models, enabling the shallow NAR decoder to
incorporate the ensemble's diversity; and 2) hint-driven KD, which employs
adversarial training to extract valuable insights from the model's hidden
states for distillation. Extensive experimentation showcases AMLNet's
superiority over conventional AR and NAR models, thereby presenting a promising
avenue for multi-horizon time series forecasting that enhances accuracy and
expedites computation.",http://arxiv.org/pdf/2310.19289v1,cs.LG
2023-10-28 12:08:03+00:00,Clairvoyance: A Pipeline Toolkit for Medical Time Series,"['Daniel Jarrett', 'Jinsung Yoon', 'Ioana Bica', 'Zhaozhi Qian', 'Ari Ercole', 'Mihaela van der Schaar']","Time-series learning is the bread and butter of data-driven *clinical
decision support*, and the recent explosion in ML research has demonstrated
great potential in various healthcare settings. At the same time, medical
time-series problems in the wild are challenging due to their highly
*composite* nature: They entail design choices and interactions among
components that preprocess data, impute missing values, select features, issue
predictions, estimate uncertainty, and interpret models. Despite exponential
growth in electronic patient data, there is a remarkable gap between the
potential and realized utilization of ML for clinical research and decision
support. In particular, orchestrating a real-world project lifecycle poses
challenges in engineering (i.e. hard to build), evaluation (i.e. hard to
assess), and efficiency (i.e. hard to optimize). Designed to address these
issues simultaneously, Clairvoyance proposes a unified, end-to-end,
autoML-friendly pipeline that serves as a (i) software toolkit, (ii) empirical
standard, and (iii) interface for optimization. Our ultimate goal lies in
facilitating transparent and reproducible experimentation with complex
inference workflows, providing integrated pathways for (1) personalized
prediction, (2) treatment-effect estimation, and (3) information acquisition.
Through illustrative examples on real-world data in outpatient, general wards,
and intensive-care settings, we illustrate the applicability of the pipeline
paradigm on core tasks in the healthcare journey. To the best of our knowledge,
Clairvoyance is the first to demonstrate viability of a comprehensive and
automatable pipeline for clinical time-series ML.",http://arxiv.org/pdf/2310.18688v1,cs.LG
2023-10-28 09:47:02+00:00,Causal discovery in a complex industrial system: A time series benchmark,"['Søren Wengel Mogensen', 'Karin Rathsman', 'Per Nilsson']","Causal discovery outputs a causal structure, represented by a graph, from
observed data. For time series data, there is a variety of methods, however, it
is difficult to evaluate these on real data as realistic use cases very rarely
come with a known causal graph to which output can be compared. In this paper,
we present a dataset from an industrial subsystem at the European Spallation
Source along with its causal graph which has been constructed from expert
knowledge. This provides a testbed for causal discovery from time series
observations of complex systems, and we believe this can help inform the
development of causal discovery methodology.",http://arxiv.org/pdf/2310.18654v1,stat.ML
2023-10-26 20:07:25+00:00,Novel Models for Multiple Dependent Heteroskedastic Time Series,"['Fangyijie Wang', 'Michael Salter-Townshend']","Functional magnetic resonance imaging or functional MRI (fMRI) is a very
popular tool used for differing brain regions by measuring brain activity. It
is affected by physiological noise, such as head and brain movement in the
scanner from breathing, heart beats, or the subject fidgeting. The purpose of
this paper is to propose a novel approach to handling fMRI data for infants
with high volatility caused by sudden head movements. Another purpose is to
evaluate the volatility modelling performance of multiple dependent fMRI time
series data. The models examined in this paper are AR and GARCH and the
modelling performance is evaluated by several statistical performance measures.
The conclusions of this paper are that multiple dependent fMRI series data can
be fitted with AR + GARCH model if the multiple fMRI data have many sudden head
movements. The GARCH model can capture the shared volatility clustering caused
by head movements across brain regions. However, the multiple fMRI data without
many head movements have fitted AR + GARCH model with different performance.
The conclusions are supported by statistical tests and measures. This paper
highlights the difference between the proposed approach from traditional
approaches when estimating model parameters and modelling conditional variances
on multiple dependent time series. In the future, the proposed approach can be
applied to other research fields, such as financial economics, and signal
processing. Code is available at \url{https://github.com/13204942/STAT40710}.",http://arxiv.org/pdf/2310.17760v1,stat.ME
2023-10-26 19:43:16+00:00,Making the End-User a Priority in Benchmarking: OrionBench for Unsupervised Time Series Anomaly Detection,"['Sarah Alnegheimish', 'Laure Berti-Equille', 'Kalyan Veeramachaneni']","Time series anomaly detection is a prevalent problem in many application
domains such as patient monitoring in healthcare, forecasting in finance, or
predictive maintenance in energy. This has led to the emergence of a plethora
of anomaly detection methods, including more recently, deep learning based
methods. Although several benchmarks have been proposed to compare newly
developed models, they usually rely on one-time execution over a limited set of
datasets and the comparison is restricted to a few models. We propose
OrionBench -- a user centric continuously maintained benchmark for unsupervised
time series anomaly detection. The framework provides universal abstractions to
represent models, extensibility to add new pipelines and datasets,
hyperparameter standardization, pipeline verification, and frequent releases
with published benchmarks. We demonstrate the usage of OrionBench, and the
progression of pipelines across 15 releases published over the course of three
years. Moreover, we walk through two real scenarios we experienced with
OrionBench that highlight the importance of continuous benchmarks in
unsupervised time series anomaly detection.",http://arxiv.org/pdf/2310.17748v1,cs.LG
2023-10-26 02:09:39+00:00,MIM-GAN-based Anomaly Detection for Multivariate Time Series Data,"['Shan Lu', 'Zhicheng Dong', 'Donghong Cai', 'Fang Fang', 'Dongcai Zhao']","The loss function of Generative adversarial network(GAN) is an important
factor that affects the quality and diversity of the generated samples for
anomaly detection. In this paper, we propose an unsupervised multiple time
series anomaly detection algorithm based on the GAN with message importance
measure(MIM-GAN). In particular, the time series data is divided into
subsequences using a sliding window. Then a generator and a discriminator
designed based on the Long Short-Term Memory (LSTM) are employed to capture the
temporal correlations of the time series data. To avoid the local optimal
solution of loss function and the model collapse, we introduce an exponential
information measure into the loss function of GAN. Additionally, a discriminant
reconstruction score consisting on discrimination and reconstruction loss is
taken into account. The global optimal solution for the loss function is
derived and the model collapse is proved to be avoided in our proposed
MIM-GAN-based anomaly detection algorithm. Experimental results show that the
proposed MIM-GAN-based anomaly detection algorithm has superior performance in
terms of precision, recall, and F1 score.",http://arxiv.org/pdf/2310.18257v1,cs.LG
2023-10-25 15:06:57+00:00,Interpretable time series neural representation for classification purposes,"['Etienne Le Naour', 'Ghislain Agoua', 'Nicolas Baskiotis', 'Vincent Guigue']","Deep learning has made significant advances in creating efficient
representations of time series data by automatically identifying complex
patterns. However, these approaches lack interpretability, as the time series
is transformed into a latent vector that is not easily interpretable. On the
other hand, Symbolic Aggregate approximation (SAX) methods allow the creation
of symbolic representations that can be interpreted but do not capture complex
patterns effectively. In this work, we propose a set of requirements for a
neural representation of univariate time series to be interpretable. We propose
a new unsupervised neural architecture that meets these requirements. The
proposed model produces consistent, discrete, interpretable, and visualizable
representations. The model is learned independently of any downstream tasks in
an unsupervised setting to ensure robustness. As a demonstration of the
effectiveness of the proposed model, we propose experiments on classification
tasks using UCR archive datasets. The obtained results are extensively compared
to other interpretable models and state-of-the-art neural representation
learning models. The experiments show that the proposed model yields, on
average better results than other interpretable approaches on multiple
datasets. We also present qualitative experiments to asses the interpretability
of the approach.",http://arxiv.org/pdf/2310.16696v1,cs.LG
2023-10-25 09:13:19+00:00,A Comprehensive Python Library for Deep Learning-Based Event Detection in Multivariate Time Series Data and Information Retrieval in NLP,"['Menouar Azib', 'Benjamin Renard', 'Philippe Garnier', 'Vincent Génot', 'Nicolas André']","Event detection in time series data is crucial in various domains, including
finance, healthcare, cybersecurity, and science. Accurately identifying events
in time series data is vital for making informed decisions, detecting
anomalies, and predicting future trends. Despite extensive research exploring
diverse methods for event detection in time series, with deep learning
approaches being among the most advanced, there is still room for improvement
and innovation in this field. In this paper, we present a new deep learning
supervised method for detecting events in multivariate time series data. Our
method combines four distinct novelties compared to existing deep-learning
supervised methods. Firstly, it is based on regression instead of binary
classification. Secondly, it does not require labeled datasets where each point
is labeled; instead, it only requires reference events defined as time points
or intervals of time. Thirdly, it is designed to be robust by using a stacked
ensemble learning meta-model that combines deep learning models, ranging from
classic feed-forward neural networks (FFNs) to state-of-the-art architectures
like transformers. This ensemble approach can mitigate individual model
weaknesses and biases, resulting in more robust predictions. Finally, to
facilitate practical implementation, we have developed a Python package to
accompany our proposed method. The package, called eventdetector-ts, can be
installed through the Python Package Index (PyPI). In this paper, we present
our method and provide a comprehensive guide on the usage of the package. We
showcase its versatility and effectiveness through different real-world use
cases from natural language processing (NLP) to financial security domains.",http://arxiv.org/pdf/2310.16485v1,cs.LG
2023-10-24 22:59:56+00:00,Attention-Based Ensemble Pooling for Time Series Forecasting,"['Dhruvit Patel', 'Alexander Wikner']","A common technique to reduce model bias in time-series forecasting is to use
an ensemble of predictive models and pool their output into an ensemble
forecast. In cases where each predictive model has different biases, however,
it is not always clear exactly how each model forecast should be weighed during
this pooling. We propose a method for pooling that performs a weighted average
over candidate model forecasts, where the weights are learned by an
attention-based ensemble pooling model. We test this method on two time-series
forecasting problems: multi-step forecasting of the dynamics of the
non-stationary Lorenz `63 equation, and one-step forecasting of the weekly
incident deaths due to COVID-19. We find that while our model achieves
excellent valid times when forecasting the non-stationary Lorenz `63 equation,
it does not consistently perform better than the existing ensemble pooling when
forecasting COVID-19 weekly incident deaths.",http://arxiv.org/pdf/2310.16231v1,cs.LG
2023-10-24 16:26:38+00:00,Graph Deep Learning for Time Series Forecasting,"['Andrea Cini', 'Ivan Marisca', 'Daniele Zambon', 'Cesare Alippi']","Graph-based deep learning methods have become popular tools to process
collections of correlated time series. Differently from traditional
multivariate forecasting methods, neural graph-based predictors take advantage
of pairwise relationships by conditioning forecasts on a (possibly dynamic)
graph spanning the time series collection. The conditioning can take the form
of an architectural inductive bias on the neural forecasting architecture,
resulting in a family of deep learning models called spatiotemporal graph
neural networks. Such relational inductive biases enable the training of global
forecasting models on large time-series collections, while at the same time
localizing predictions w.r.t. each element in the set (i.e., graph nodes) by
accounting for local correlations among them (i.e., graph edges). Indeed,
recent theoretical and practical advances in graph neural networks and deep
learning for time series forecasting make the adoption of such processing
frameworks appealing and timely. However, most of the studies in the literature
focus on proposing variations of existing neural architectures by taking
advantage of modern deep learning practices, while foundational and
methodological aspects have not been subject to systematic investigation. To
fill the gap, this paper aims to introduce a comprehensive methodological
framework that formalizes the forecasting problem and provides design
principles for graph-based predictive models and methods to assess their
performance. At the same time, together with an overview of the field, we
provide design guidelines, recommendations, and best practices, as well as an
in-depth discussion of open challenges and future research directions.",http://arxiv.org/pdf/2310.15978v1,cs.LG
2023-10-24 06:54:50+00:00,Transfer learning for day-ahead load forecasting: a case study on European national electricity demand time series,"['Alexandros-Menelaos Tzortzis', 'Sotiris Pelekis', 'Evangelos Spiliotis', 'Spiros Mouzakitis', 'John Psarras', 'Dimitris Askounis']","Short-term load forecasting (STLF) is crucial for the daily operation of
power grids. However, the non-linearity, non-stationarity, and randomness
characterizing electricity demand time series renders STLF a challenging task.
Various forecasting approaches have been proposed for improving STLF, including
neural network (NN) models which are trained using data from multiple
electricity demand series that may not necessary include the target series. In
the present study, we investigate the performance of this special case of STLF,
called transfer learning (TL), by considering a set of 27 time series that
represent the national day-ahead electricity demand of indicative European
countries. We employ a popular and easy-to-implement NN model and perform a
clustering analysis to identify similar patterns among the series and assist
TL. In this context, two different TL approaches, with and without the
clustering step, are compiled and compared against each other as well as a
typical NN training setup. Our results demonstrate that TL can outperform the
conventional approach, especially when clustering techniques are considered.",http://arxiv.org/pdf/2310.15555v1,cs.LG
2023-10-24 00:14:57+00:00,Nominality Score Conditioned Time Series Anomaly Detection by Point/Sequential Reconstruction,"['Chih-Yu Lai', 'Fan-Keng Sun', 'Zhengqi Gao', 'Jeffrey H. Lang', 'Duane S. Boning']","Time series anomaly detection is challenging due to the complexity and
variety of patterns that can occur. One major difficulty arises from modeling
time-dependent relationships to find contextual anomalies while maintaining
detection accuracy for point anomalies. In this paper, we propose a framework
for unsupervised time series anomaly detection that utilizes point-based and
sequence-based reconstruction models. The point-based model attempts to
quantify point anomalies, and the sequence-based model attempts to quantify
both point and contextual anomalies. Under the formulation that the observed
time point is a two-stage deviated value from a nominal time point, we
introduce a nominality score calculated from the ratio of a combined value of
the reconstruction errors. We derive an induced anomaly score by further
integrating the nominality score and anomaly score, then theoretically prove
the superiority of the induced anomaly score over the original anomaly score
under certain conditions. Extensive studies conducted on several public
datasets show that the proposed framework outperforms most state-of-the-art
baselines for time series anomaly detection.",http://arxiv.org/pdf/2310.15416v1,cs.LG
2023-10-23 14:00:02+00:00,XTSC-Bench: Quantitative Benchmarking for Explainers on Time Series Classification,"['Jacqueline Höllig', 'Steffen Thoma', 'Florian Grimm']","Despite the growing body of work on explainable machine learning in time
series classification (TSC), it remains unclear how to evaluate different
explainability methods. Resorting to qualitative assessment and user studies to
evaluate explainers for TSC is difficult since humans have difficulties
understanding the underlying information contained in time series data.
Therefore, a systematic review and quantitative comparison of explanation
methods to confirm their correctness becomes crucial. While steps to
standardized evaluations were taken for tabular, image, and textual data,
benchmarking explainability methods on time series is challenging due to a)
traditional metrics not being directly applicable, b) implementation and
adaption of traditional metrics for time series in the literature vary, and c)
varying baseline implementations. This paper proposes XTSC-Bench, a
benchmarking tool providing standardized datasets, models, and metrics for
evaluating explanation methods on TSC. We analyze 3 perturbation-, 6 gradient-
and 2 example-based explanation methods to TSC showing that improvements in the
explainers' robustness and reliability are necessary, especially for
multivariate data.",http://arxiv.org/pdf/2310.14957v1,cs.LG
2023-10-23 08:56:01+00:00,Extended Deep Adaptive Input Normalization for Preprocessing Time Series Data for Neural Networks,"['Marcus A. K. September', 'Francesco Sanna Passino', 'Leonie Goldmann', 'Anton Hinel']","Data preprocessing is a crucial part of any machine learning pipeline, and it
can have a significant impact on both performance and training efficiency. This
is especially evident when using deep neural networks for time series
prediction and classification: real-world time series data often exhibit
irregularities such as multi-modality, skewness and outliers, and the model
performance can degrade rapidly if these characteristics are not adequately
addressed. In this work, we propose the EDAIN (Extended Deep Adaptive Input
Normalization) layer, a novel adaptive neural layer that learns how to
appropriately normalize irregular time series data for a given task in an
end-to-end fashion, instead of using a fixed normalization scheme. This is
achieved by optimizing its unknown parameters simultaneously with the deep
neural network using back-propagation. Our experiments, conducted using
synthetic data, a credit default prediction dataset, and a large-scale limit
order book benchmark dataset, demonstrate the superior performance of the EDAIN
layer when compared to conventional normalization methods and existing adaptive
time series preprocessing layers.",http://arxiv.org/pdf/2310.14720v1,cs.LG
2023-10-22 16:17:24+00:00,Pyramidal Hidden Markov Model For Multivariate Time Series Forecasting,['YeXin Huang'],"The Hidden Markov Model (HMM) can predict the future value of a time series
based on its current and previous values, making it a powerful algorithm for
handling various types of time series. Numerous studies have explored the
improvement of HMM using advanced techniques, leading to the development of
several variations of HMM. Despite these studies indicating the increased
competitiveness of HMM compared to other advanced algorithms, few have
recognized the significance and impact of incorporating multistep stochastic
states into its performance. In this work, we propose a Pyramidal Hidden Markov
Model (PHMM) that can capture multiple multistep stochastic states. Initially,
a multistep HMM is designed for extracting short multistep stochastic states.
Next, a novel time series forecasting structure is proposed based on PHMM,
which utilizes pyramid-like stacking to adaptively identify long multistep
stochastic states. By employing these two schemes, our model can effectively
handle non-stationary and noisy data, while also establishing long-term
dependencies for more accurate and comprehensive forecasting. The experimental
results on diverse multivariate time series datasets convincingly demonstrate
the superior performance of our proposed PHMM compared to its competitive peers
in time series forecasting.",http://arxiv.org/pdf/2310.14341v1,cs.LG
2023-10-21 13:59:31+00:00,Contrast Everything: A Hierarchical Contrastive Framework for Medical Time-Series,"['Yihe Wang', 'Yu Han', 'Haishuai Wang', 'Xiang Zhang']","Contrastive representation learning is crucial in medical time series
analysis as it alleviates dependency on labor-intensive, domain-specific, and
scarce expert annotations. However, existing contrastive learning methods
primarily focus on one single data level, which fails to fully exploit the
intricate nature of medical time series. To address this issue, we present
COMET, an innovative hierarchical framework that leverages data consistencies
at all inherent levels in medical time series. Our meticulously designed model
systematically captures data consistency from four potential levels:
observation, sample, trial, and patient levels. By developing contrastive loss
at multiple levels, we can learn effective representations that preserve
comprehensive data consistency, maximizing information utilization in a
self-supervised manner. We conduct experiments in the challenging
patient-independent setting. We compare COMET against six baselines using three
diverse datasets, which include ECG signals for myocardial infarction and EEG
signals for Alzheimer's and Parkinson's diseases. The results demonstrate that
COMET consistently outperforms all baselines, particularly in setup with 10%
and 1% labeled data fractions across all datasets. These results underscore the
significant impact of our framework in advancing contrastive representation
learning techniques for medical time series. The source code is available at
https://github.com/DL4mHealth/COMET.",http://arxiv.org/pdf/2310.14017v3,cs.LG
2023-10-20 12:14:38+00:00,Testing for the extent of instability in nearly unstable processes,"['Marie Badreau', 'Frédéric Proïa']","This paper deals with unit root issues in time series analysis. It has been
known for a long time that unit root tests may be flawed when a series although
stationary has a root close to unity. That motivated recent papers dedicated to
autoregressive processes where the bridge between stability and instability is
expressed by means of time-varying coefficients. In this vein the process we
consider has a companion matrix $A_{n}$ with spectral radius $\rho(A_{n}) < 1$
satisfying $\rho(A_{n}) \rightarrow 1$, a situation that we describe as `nearly
unstable'. The question we investigate is the following: given an observed path
supposed to come from a nearly-unstable process, is it possible to test for the
`extent of instability', \textit{i.e.} to test how close we are to the unit
root? In this regard, we develop a strategy to evaluate $\alpha$ and to test
for $\mathcal{H}_0 : ""\alpha = \alpha_0""$ against $\mathcal{H}_1 : ""\alpha >
\alpha_0""$ when $\rho(A_{n})$ lies in an inner $O(n^{-\alpha})$-neighborhood of
the unity, for some $0 < \alpha < 1$. Empirical evidence is given (on
simulations and real time series) about the advantages of the flexibility
induced by such a procedure compared to the usual unit root tests and their
binary responses. As a by-product, we also build a symmetric procedure for the
usually left out situation where the dominant root lies around $-1$.",http://arxiv.org/pdf/2310.13444v1,math.ST
2023-10-19 14:42:42+00:00,Continuous Time Locally Stationary Wavelet Processes,"['Henry Antonio Palasciano', 'Marina I. Knight', 'Guy P. Nason']","This article introduces the class of continuous time locally stationary
wavelet processes. Continuous time models enable us to properly provide
scale-based time series models for irregularly-spaced observations for the
first time. We derive results for both the theoretical setting, where we assume
access to the entire process sample path, and a more practical one, which
develops methods for estimating the quantities of interest from sampled time
series. The latter estimates are accurately computable in reasonable time by
solving the relevant linear integral equation using the iterative thresholding
method due to Daubechies, Defrise and De~Mol. We exemplify our new methods by
computing spectral and autocovariance estimates on irregularly-spaced
heart-rate data obtained from a recent sleep-state study.",http://arxiv.org/pdf/2310.12788v2,math.ST
2023-10-19 07:51:39+00:00,Neural Likelihood Approximation for Integer Valued Time Series Data,"[""Luke O'Loughlin"", 'John Maclean', 'Andrew Black']","Stochastic processes defined on integer valued state spaces are popular
within the physical and biological sciences. These models are necessary for
capturing the dynamics of small systems where the individual nature of the
populations cannot be ignored and stochastic effects are important. The
inference of the parameters of such models, from time series data, is difficult
due to intractability of the likelihood; current methods, based on simulations
of the underlying model, can be so computationally expensive as to be
prohibitive. In this paper we construct a neural likelihood approximation for
integer valued time series data using causal convolutions, which allows us to
evaluate the likelihood of the whole time series in parallel. We demonstrate
our method by performing inference on a number of ecological and
epidemiological models, showing that we can accurately approximate the true
posterior while achieving significant computational speed ups in situations
where current methods struggle.",http://arxiv.org/pdf/2310.12544v1,stat.ML
2023-10-19 04:08:19+00:00,MTS-LOF: Medical Time-Series Representation Learning via Occlusion-Invariant Features,"['Huayu Li', 'Ana S. Carreon-Rascon', 'Xiwen Chen', 'Geng Yuan', 'Ao Li']","Medical time series data are indispensable in healthcare, providing critical
insights for disease diagnosis, treatment planning, and patient management. The
exponential growth in data complexity, driven by advanced sensor technologies,
has presented challenges related to data labeling. Self-supervised learning
(SSL) has emerged as a transformative approach to address these challenges,
eliminating the need for extensive human annotation. In this study, we
introduce a novel framework for Medical Time Series Representation Learning,
known as MTS-LOF. MTS-LOF leverages the strengths of contrastive learning and
Masked Autoencoder (MAE) methods, offering a unique approach to representation
learning for medical time series data. By combining these techniques, MTS-LOF
enhances the potential of healthcare applications by providing more
sophisticated, context-rich representations. Additionally, MTS-LOF employs a
multi-masking strategy to facilitate occlusion-invariant feature learning. This
approach allows the model to create multiple views of the data by masking
portions of it. By minimizing the discrepancy between the representations of
these masked patches and the fully visible patches, MTS-LOF learns to capture
rich contextual information within medical time series datasets. The results of
experiments conducted on diverse medical time series datasets demonstrate the
superiority of MTS-LOF over other methods. These findings hold promise for
significantly enhancing healthcare applications by improving representation
learning. Furthermore, our work delves into the integration of joint-embedding
SSL and MAE techniques, shedding light on the intricate interplay between
temporal and structural dependencies in healthcare data. This understanding is
crucial, as it allows us to grasp the complexities of healthcare data analysis.",http://arxiv.org/pdf/2310.12451v1,cs.LG
2023-10-18 15:24:34+00:00,Is Channel Independent strategy optimal for Time Series Forecasting?,"['Yuan Peiwen', 'Zhu Changsheng']","There has been an emergence of various models for long-term time series
forecasting. Recent studies have demonstrated that a single linear layer, using
Channel Dependent (CD) or Channel Independent (CI) modeling, can even
outperform a large number of sophisticated models. However, current research
primarily considers CD and CI as two complementary yet mutually exclusive
approaches, unable to harness these two extremes simultaneously. And it is also
a challenging issue that both CD and CI are static strategies that cannot be
determined to be optimal for a specific dataset without extensive experiments.
In this paper, we reconsider whether the current CI strategy is the best
solution for time series forecasting. First, we propose a simple yet effective
strategy called CSC, which stands for $\mathbf{C}$hannel
$\mathbf{S}$elf-$\mathbf{C}$lustering strategy, for linear models. Our Channel
Self-Clustering (CSC) enhances CI strategy's performance improvements while
reducing parameter size, for exmpale by over 10 times on electricity dataset,
and significantly cutting training time. Second, we further propose Channel
Rearrangement (CR), a method for deep models inspired by the self-clustering.
CR attains competitive performance against baselines. Finally, we also discuss
whether it is best to forecast the future values using the historical values of
the same channel as inputs. We hope our findings and methods could inspire new
solutions beyond CD/CI.",http://arxiv.org/pdf/2310.17658v1,cs.LG
2023-10-18 13:39:07+00:00,A Multi-Scale Decomposition MLP-Mixer for Time Series Analysis,"['Shuhan Zhong', 'Sizhe Song', 'Guanyao Li', 'Weipeng Zhuo', 'Yang Liu', 'S. -H. Gary Chan']","Time series data, often characterized by unique composition and complex
multi-scale temporal variations, requires special consideration of
decomposition and multi-scale modeling in its analysis. Existing deep learning
methods on this best fit to only univariate time series, and have not
sufficiently accounted for sub-series level modeling and decomposition
completeness. To address this, we propose MSD-Mixer, a Multi-Scale
Decomposition MLP-Mixer which learns to explicitly decompose the input time
series into different components, and represents the components in different
layers. To handle multi-scale temporal patterns and inter-channel dependencies,
we propose a novel temporal patching approach to model the time series as
multi-scale sub-series, i.e., patches, and employ MLPs to mix intra- and
inter-patch variations and channel-wise correlations. In addition, we propose a
loss function to constrain both the magnitude and autocorrelation of the
decomposition residual for decomposition completeness. Through extensive
experiments on various real-world datasets for five common time series analysis
tasks (long- and short-term forecasting, imputation, anomaly detection, and
classification), we demonstrate that MSD-Mixer consistently achieves
significantly better performance in comparison with other state-of-the-art
task-general and task-specific approaches.",http://arxiv.org/pdf/2310.11959v1,cs.LG
2023-10-17 20:30:16+00:00,When Rigidity Hurts: Soft Consistency Regularization for Probabilistic Hierarchical Time Series Forecasting,"['Harshavardhan Kamarthi', 'Lingkai Kong', 'Alexander Rodríguez', 'Chao Zhang', 'B. Aditya Prakash']","Probabilistic hierarchical time-series forecasting is an important variant of
time-series forecasting, where the goal is to model and forecast multivariate
time-series that have underlying hierarchical relations. Most methods focus on
point predictions and do not provide well-calibrated probabilistic forecasts
distributions. Recent state-of-art probabilistic forecasting methods also
impose hierarchical relations on point predictions and samples of distribution
which does not account for coherency of forecast distributions. Previous works
also silently assume that datasets are always consistent with given
hierarchical relations and do not adapt to real-world datasets that show
deviation from this assumption. We close both these gap and propose PROFHiT,
which is a fully probabilistic hierarchical forecasting model that jointly
models forecast distribution of entire hierarchy. PROFHiT uses a flexible
probabilistic Bayesian approach and introduces a novel Distributional Coherency
regularization to learn from hierarchical relations for entire forecast
distribution that enables robust and calibrated forecasts as well as adapt to
datasets of varying hierarchical consistency. On evaluating PROFHiT over wide
range of datasets, we observed 41-88% better performance in accuracy and
significantly better calibration. Due to modeling the coherency over full
distribution, we observed that PROFHiT can robustly provide reliable forecasts
even if up to 10% of input time-series data is missing where other methods'
performance severely degrade by over 70%.",http://arxiv.org/pdf/2310.11569v2,cs.LG
2023-10-17 11:37:40+00:00,MST-GAT: A Multimodal Spatial-Temporal Graph Attention Network for Time Series Anomaly Detection,"['Chaoyue Ding', 'Shiliang Sun', 'Jing Zhao']","Multimodal time series (MTS) anomaly detection is crucial for maintaining the
safety and stability of working devices (e.g., water treatment system and
spacecraft), whose data are characterized by multivariate time series with
diverse modalities. Although recent deep learning methods show great potential
in anomaly detection, they do not explicitly capture spatial-temporal
relationships between univariate time series of different modalities, resulting
in more false negatives and false positives. In this paper, we propose a
multimodal spatial-temporal graph attention network (MST-GAT) to tackle this
problem. MST-GAT first employs a multimodal graph attention network (M-GAT) and
a temporal convolution network to capture the spatial-temporal correlation in
multimodal time series. Specifically, M-GAT uses a multi-head attention module
and two relational attention modules (i.e., intra- and inter-modal attention)
to model modal correlations explicitly. Furthermore, MST-GAT optimizes the
reconstruction and prediction modules simultaneously. Experimental results on
four multimodal benchmarks demonstrate that MST-GAT outperforms the
state-of-the-art baselines. Further analysis indicates that MST-GAT strengthens
the interpretability of detected anomalies by locating the most anomalous
univariate time series.",http://arxiv.org/pdf/2310.11169v1,cs.LG
2023-10-17 06:29:09+00:00,Compatible Transformer for Irregularly Sampled Multivariate Time Series,"['Yuxi Wei', 'Juntong Peng', 'Tong He', 'Chenxin Xu', 'Jian Zhang', 'Shirui Pan', 'Siheng Chen']","To analyze multivariate time series, most previous methods assume regular
subsampling of time series, where the interval between adjacent measurements
and the number of samples remain unchanged. Practically, data collection
systems could produce irregularly sampled time series due to sensor failures
and interventions. However, existing methods designed for regularly sampled
multivariate time series cannot directly handle irregularity owing to
misalignment along both temporal and variate dimensions. To fill this gap, we
propose Compatible Transformer (CoFormer), a transformer-based encoder to
achieve comprehensive temporal-interaction feature learning for each individual
sample in irregular multivariate time series. In CoFormer, we view each sample
as a unique variate-time point and leverage intra-variate/inter-variate
attentions to learn sample-wise temporal/interaction features based on
intra-variate/inter-variate neighbors. With CoFormer as the core, we can
analyze irregularly sampled multivariate time series for many downstream tasks,
including classification and prediction. We conduct extensive experiments on 3
real-world datasets and validate that the proposed CoFormer significantly and
consistently outperforms existing methods.",http://arxiv.org/pdf/2310.11022v1,cs.LG
2023-10-16 21:35:23+00:00,A Machine Learning-based Algorithm for Automated Detection of Frequency-based Events in Recorded Time Series of Sensor Data,"['Bahareh Medghalchi', 'Andreas Vogel']","Automated event detection has emerged as one of the fundamental practices to
monitor the behavior of technical systems by means of sensor data. In the
automotive industry, these methods are in high demand for tracing events in
time series data. For assessing the active vehicle safety systems, a diverse
range of driving scenarios is conducted. These scenarios involve the recording
of the vehicle's behavior using external sensors, enabling the evaluation of
operational performance. In such setting, automated detection methods not only
accelerate but also standardize and objectify the evaluation by avoiding
subjective, human-based appraisals in the data inspection. This work proposes a
novel event detection method that allows to identify frequency-based events in
time series data. To this aim, the time series data is mapped to
representations in the time-frequency domain, known as scalograms. After
filtering scalograms to enhance relevant parts of the signal, an object
detection model is trained to detect the desired event objects in the
scalograms. For the analysis of unseen time series data, events can be detected
in their scalograms with the trained object detection model and are thereafter
mapped back to the time series data to mark the corresponding time interval.
The algorithm, evaluated on unseen datasets, achieves a precision rate of 0.97
in event detection, providing sharp time interval boundaries whose accurate
indication by human visual inspection is challenging. Incorporating this method
into the vehicle development process enhances the accuracy and reliability of
event detection, which holds major importance for rapid testing analysis.",http://arxiv.org/pdf/2310.10841v1,cs.LG
2023-10-16 21:18:51+00:00,Gaussian processes based data augmentation and expected signature for time series classification,"['Marco Romito', 'Francesco Triggiano']","The signature is a fundamental object that describes paths (that is,
continuous functions from an interval to a Euclidean space). Likewise, the
expected signature provides a statistical description of the law of stochastic
processes. We propose a feature extraction model for time series built upon the
expected signature. This is computed through a Gaussian processes based data
augmentation. One of the main features is that an optimal feature extraction is
learnt through the supervised task that uses the model.",http://arxiv.org/pdf/2310.10836v1,cs.LG
2023-10-16 19:58:37+00:00,Poisson Count Time Series,"['Jiajie Kong', 'Robert Lund']","This paper reviews and compares popular methods, some old and some very
recent, that produce time series having Poisson marginal distributions. The
paper begins by narrating ways where time series with Poisson marginal
distributions can be produced. Modeling nonstationary series with covariates
motivates consideration of methods where the Poisson parameter depends on time.
Here, estimation methods are developed for some of the more flexible methods.
The results are used in the analysis of 1) a count sequence of tropical
cyclones occurring in the North Atlantic Basin since 1970, and 2) the number of
no-hitter games pitched in major league baseball since 1893. Tests for whether
the Poisson marginal distribution is appropriate are included.",http://arxiv.org/pdf/2310.10798v1,stat.ME
2023-10-16 12:15:39+00:00,Specifications tests for count time series models with covariates,"['Šárka Hudecová', 'Marie Hušková', 'Simos G. Meintanis']","We propose a goodness-of-fit test for a class of count time series models
with covariates which includes the Poisson autoregressive model with covariates
(PARX) as a special case. The test criteria are derived from a specific
characterization for the conditional probability generating function and the
test statistic is formulated as a $L_2$ weighting norm of the corresponding
sample counterpart. The asymptotic properties of the proposed test statistic
are provided under the null hypothesis as well as under specific alternatives.
A bootstrap version of the test is explored in a Monte--Carlo study and
illustrated on a real data set on road safety.",http://arxiv.org/pdf/2310.10331v1,stat.ME
2023-10-16 09:06:00+00:00,Large Models for Time Series and Spatio-Temporal Data: A Survey and Outlook,"['Ming Jin', 'Qingsong Wen', 'Yuxuan Liang', 'Chaoli Zhang', 'Siqiao Xue', 'Xue Wang', 'James Zhang', 'Yi Wang', 'Haifeng Chen', 'Xiaoli Li', 'Shirui Pan', 'Vincent S. Tseng', 'Yu Zheng', 'Lei Chen', 'Hui Xiong']","Temporal data, notably time series and spatio-temporal data, are prevalent in
real-world applications. They capture dynamic system measurements and are
produced in vast quantities by both physical and virtual sensors. Analyzing
these data types is vital to harnessing the rich information they encompass and
thus benefits a wide range of downstream tasks. Recent advances in large
language and other foundational models have spurred increased use of these
models in time series and spatio-temporal data mining. Such methodologies not
only enable enhanced pattern recognition and reasoning across diverse domains
but also lay the groundwork for artificial general intelligence capable of
comprehending and processing common temporal data. In this survey, we offer a
comprehensive and up-to-date review of large models tailored (or adapted) for
time series and spatio-temporal data, spanning four key facets: data types,
model categories, model scopes, and application areas/tasks. Our objective is
to equip practitioners with the knowledge to develop applications and further
research in this underexplored domain. We primarily categorize the existing
literature into two major clusters: large models for time series analysis
(LM4TS) and spatio-temporal data mining (LM4STD). On this basis, we further
classify research based on model scopes (i.e., general vs. domain-specific) and
application areas/tasks. We also provide a comprehensive collection of
pertinent resources, including datasets, model assets, and useful tools,
categorized by mainstream applications. This survey coalesces the latest
strides in large model-centric research on time series and spatio-temporal
data, underscoring the solid foundations, current advances, practical
applications, abundant resources, and future research opportunities.",http://arxiv.org/pdf/2310.10196v2,cs.LG
2023-10-15 06:30:22+00:00,UniTime: A Language-Empowered Unified Model for Cross-Domain Time Series Forecasting,"['Xu Liu', 'Junfeng Hu', 'Yuan Li', 'Shizhe Diao', 'Yuxuan Liang', 'Bryan Hooi', 'Roger Zimmermann']","Multivariate time series forecasting plays a pivotal role in contemporary web
technologies. In contrast to conventional methods that involve creating
dedicated models for specific time series application domains, this research
advocates for a unified model paradigm that transcends domain boundaries.
However, learning an effective cross-domain model presents the following
challenges. First, various domains exhibit disparities in data characteristics,
e.g., the number of variables, posing hurdles for existing models that impose
inflexible constraints on these factors. Second, the model may encounter
difficulties in distinguishing data from various domains, leading to suboptimal
performance in our assessments. Third, the diverse convergence rates of time
series domains can also result in compromised empirical performance. To address
these issues, we propose UniTime for effective cross-domain time series
learning. Concretely, UniTime can flexibly adapt to data with varying
characteristics. It also uses domain instructions and a Language-TS Transformer
to offer identification information and align two modalities. In addition,
UniTime employs masking to alleviate domain convergence speed imbalance issues.
Our extensive experiments demonstrate the effectiveness of UniTime in advancing
state-of-the-art forecasting performance and zero-shot transferability.",http://arxiv.org/pdf/2310.09751v2,cs.LG
2023-10-14 04:37:38+00:00,ARM: Refining Multivariate Forecasting with Adaptive Temporal-Contextual Learning,"['Jiecheng Lu', 'Xu Han', 'Shihao Yang']","Long-term time series forecasting (LTSF) is important for various domains but
is confronted by challenges in handling the complex temporal-contextual
relationships. As multivariate input models underperforming some recent
univariate counterparts, we posit that the issue lies in the inefficiency of
existing multivariate LTSF Transformers to model series-wise relationships: the
characteristic differences between series are often captured incorrectly. To
address this, we introduce ARM: a multivariate temporal-contextual adaptive
learning method, which is an enhanced architecture specifically designed for
multivariate LTSF modelling. ARM employs Adaptive Univariate Effect Learning
(AUEL), Random Dropping (RD) training strategy, and Multi-kernel Local
Smoothing (MKLS), to better handle individual series temporal patterns and
correctly learn inter-series dependencies. ARM demonstrates superior
performance on multiple benchmarks without significantly increasing
computational costs compared to vanilla Transformer, thereby advancing the
state-of-the-art in LTSF. ARM is also generally applicable to other LTSF
architecture beyond vanilla Transformer.",http://arxiv.org/pdf/2310.09488v1,stat.ML
2023-10-13 04:22:21+00:00,Semi-Supervised End-To-End Contrastive Learning For Time Series Classification,"['Huili Cai', 'Xiang Zhang', 'Xiaofeng Liu']","Time series classification is a critical task in various domains, such as
finance, healthcare, and sensor data analysis. Unsupervised contrastive
learning has garnered significant interest in learning effective
representations from time series data with limited labels. The prevalent
approach in existing contrastive learning methods consists of two separate
stages: pre-training the encoder on unlabeled datasets and fine-tuning the
well-trained model on a small-scale labeled dataset. However, such two-stage
approaches suffer from several shortcomings, such as the inability of
unsupervised pre-training contrastive loss to directly affect downstream
fine-tuning classifiers, and the lack of exploiting the classification loss
which is guided by valuable ground truth. In this paper, we propose an
end-to-end model called SLOTS (Semi-supervised Learning fOr Time
clasSification). SLOTS receives semi-labeled datasets, comprising a large
number of unlabeled samples and a small proportion of labeled samples, and maps
them to an embedding space through an encoder. We calculate not only the
unsupervised contrastive loss but also measure the supervised contrastive loss
on the samples with ground truth. The learned embeddings are fed into a
classifier, and the classification loss is calculated using the available true
labels. The unsupervised, supervised contrastive losses and classification loss
are jointly used to optimize the encoder and classifier. We evaluate SLOTS by
comparing it with ten state-of-the-art methods across five datasets. The
results demonstrate that SLOTS is a simple yet effective framework. When
compared to the two-stage framework, our end-to-end SLOTS utilizes the same
input data, consumes a similar computational cost, but delivers significantly
improved performance. We release code and datasets at
https://anonymous.4open.science/r/SLOTS-242E.",http://arxiv.org/pdf/2310.08848v1,cs.LG
2023-10-13 01:50:43+00:00,A Nonlinear Method for time series forecasting using VMD-GARCH-LSTM model,"['Zhengtao Gui', 'Haoyuan Li', 'Sijie Xu', 'Yu Chen']","Time series forecasting represents a significant and challenging task across
various fields. Recently, methods based on mode decomposition have dominated
the forecasting of complex time series because of the advantages of capturing
local characteristics and extracting intrinsic modes from data. Unfortunately,
most models fail to capture the implied volatilities that contain significant
information. To enhance the forecasting of current, rapidly evolving, and
volatile time series, we propose a novel decomposition-ensemble paradigm, the
VMD-LSTM-GARCH model. The Variational Mode Decomposition algorithm is employed
to decompose the time series into K sub-modes. Subsequently, the GARCH model
extracts the volatility information from these sub-modes, which serve as the
input for the LSTM. The numerical and volatility information of each sub-mode
is utilized to train a Long Short-Term Memory network. This network predicts
the sub-mode, and then we aggregate the predictions from all sub-modes to
produce the output. By integrating econometric and artificial intelligence
methods, and taking into account both the numerical and volatility information
of the time series, our proposed model demonstrates superior performance in
time series forecasting, as evidenced by the significant decrease in MSE, RMSE,
and MAPE in our comparative experimental results.",http://arxiv.org/pdf/2310.08812v1,stat.ME
2023-10-13 01:18:41+00:00,DDMT: Denoising Diffusion Mask Transformer Models for Multivariate Time Series Anomaly Detection,"['Chaocheng Yang', 'Tingyin Wang', 'Xuanhui Yan']","Anomaly detection in multivariate time series has emerged as a crucial
challenge in time series research, with significant research implications in
various fields such as fraud detection, fault diagnosis, and system state
estimation. Reconstruction-based models have shown promising potential in
recent years for detecting anomalies in time series data. However, due to the
rapid increase in data scale and dimensionality, the issues of noise and Weak
Identity Mapping (WIM) during time series reconstruction have become
increasingly pronounced. To address this, we introduce a novel Adaptive Dynamic
Neighbor Mask (ADNM) mechanism and integrate it with the Transformer and
Denoising Diffusion Model, creating a new framework for multivariate time
series anomaly detection, named Denoising Diffusion Mask Transformer (DDMT).
The ADNM module is introduced to mitigate information leakage between input and
output features during data reconstruction, thereby alleviating the problem of
WIM during reconstruction. The Denoising Diffusion Transformer (DDT) employs
the Transformer as an internal neural network structure for Denoising Diffusion
Model. It learns the stepwise generation process of time series data to model
the probability distribution of the data, capturing normal data patterns and
progressively restoring time series data by removing noise, resulting in a
clear recovery of anomalies. To the best of our knowledge, this is the first
model that combines Denoising Diffusion Model and the Transformer for
multivariate time series anomaly detection. Experimental evaluations were
conducted on five publicly available multivariate time series anomaly detection
datasets. The results demonstrate that the model effectively identifies
anomalies in time series data, achieving state-of-the-art performance in
anomaly detection.",http://arxiv.org/pdf/2310.08800v2,cs.LG
2023-10-12 12:29:32+00:00,Lag-Llama: Towards Foundation Models for Time Series Forecasting,"['Kashif Rasul', 'Arjun Ashok', 'Andrew Robert Williams', 'Arian Khorasani', 'George Adamopoulos', 'Rishika Bhagwatkar', 'Marin Biloš', 'Hena Ghonia', 'Nadhir Vincent Hassen', 'Anderson Schneider', 'Sahil Garg', 'Alexandre Drouin', 'Nicolas Chapados', 'Yuriy Nevmyvaka', 'Irina Rish']","Aiming to build foundation models for time-series forecasting and study their
scaling behavior, we present here our work-in-progress on Lag-Llama, a
general-purpose univariate probabilistic time-series forecasting model trained
on a large collection of time-series data. The model shows good zero-shot
prediction capabilities on unseen ""out-of-distribution"" time-series datasets,
outperforming supervised baselines. We use smoothly broken power-laws to fit
and predict model scaling behavior. The open source code is made available at
https://github.com/kashif/pytorch-transformer-ts.",http://arxiv.org/pdf/2310.08278v1,cs.LG
2023-10-12 09:17:46+00:00,On Extreme Value Asymptotics of Projected Sample Covariances in High Dimensions with Applications in Finance and Convolutional Networks,['Ansgar Steland'],"Maximum-type statistics of certain functions of the sample covariance matrix
of high-dimensional vector time series are studied to statistically confirm or
reject the null hypothesis that a data set has been collected under normal
conditions. The approach generalizes the case of the maximal deviation of the
sample autocovariances function from its assumed values. Within a linear time
series framework it is shown that Gumbel-type extreme value asymptotics holds
true. As applications we discuss long-only mimimal-variance portfolio
optimization and subportfolio analysis with respect to idiosyncratic risks, ETF
index tracking by sparse tracking portfolios, convolutional deep learners for
image analysis and the analysis of array-of-sensors data.",http://arxiv.org/pdf/2310.08150v1,math.ST
2023-10-12 08:51:59+00:00,Counterfactual Explanations for Time Series Forecasting,"['Zhendong Wang', 'Ioanna Miliou', 'Isak Samsten', 'Panagiotis Papapetrou']","Among recent developments in time series forecasting methods, deep
forecasting models have gained popularity as they can utilize hidden feature
patterns in time series to improve forecasting performance. Nevertheless, the
majority of current deep forecasting models are opaque, hence making it
challenging to interpret the results. While counterfactual explanations have
been extensively employed as a post-hoc approach for explaining classification
models, their application to forecasting models still remains underexplored. In
this paper, we formulate the novel problem of counterfactual generation for
time series forecasting, and propose an algorithm, called ForecastCF, that
solves the problem by applying gradient-based perturbations to the original
time series. ForecastCF guides the perturbations by applying constraints to the
forecasted values to obtain desired prediction outcomes. We experimentally
evaluate ForecastCF using four state-of-the-art deep model architectures and
compare to two baselines. Our results show that ForecastCF outperforms the
baseline in terms of counterfactual validity and data manifold closeness.
Overall, our findings suggest that ForecastCF can generate meaningful and
relevant counterfactual explanations for various forecasting tasks.",http://arxiv.org/pdf/2310.08137v1,cs.LG
2023-10-11 21:07:04+00:00,Precise localization within the GI tract by combining classification of CNNs and time-series analysis of HMMs,"['Julia Werner', 'Christoph Gerum', 'Moritz Reiber', 'Jörg Nick', 'Oliver Bringmann']","This paper presents a method to efficiently classify the gastroenterologic
section of images derived from Video Capsule Endoscopy (VCE) studies by
exploring the combination of a Convolutional Neural Network (CNN) for
classification with the time-series analysis properties of a Hidden Markov
Model (HMM). It is demonstrated that successive time-series analysis identifies
and corrects errors in the CNN output. Our approach achieves an accuracy of
$98.04\%$ on the Rhode Island (RI) Gastroenterology dataset. This allows for
precise localization within the gastrointestinal (GI) tract while requiring
only approximately 1M parameters and thus, provides a method suitable for low
power devices",http://arxiv.org/pdf/2310.07895v1,cs.LG
2023-10-11 19:01:28+00:00,Large Language Models Are Zero-Shot Time Series Forecasters,"['Nate Gruver', 'Marc Finzi', 'Shikai Qiu', 'Andrew Gordon Wilson']","By encoding time series as a string of numerical digits, we can frame time
series forecasting as next-token prediction in text. Developing this approach,
we find that large language models (LLMs) such as GPT-3 and LLaMA-2 can
surprisingly zero-shot extrapolate time series at a level comparable to or
exceeding the performance of purpose-built time series models trained on the
downstream tasks. To facilitate this performance, we propose procedures for
effectively tokenizing time series data and converting discrete distributions
over tokens into highly flexible densities over continuous values. We argue the
success of LLMs for time series stems from their ability to naturally represent
multimodal distributions, in conjunction with biases for simplicity, and
repetition, which align with the salient features in many time series, such as
repeated seasonal trends. We also show how LLMs can naturally handle missing
data without imputation through non-numerical text, accommodate textual side
information, and answer questions to help explain predictions. While we find
that increasing model size generally improves performance on time series, we
show GPT-4 can perform worse than GPT-3 because of how it tokenizes numbers,
and poor uncertainty calibration, which is likely the result of alignment
interventions such as RLHF.",http://arxiv.org/pdf/2310.07820v1,cs.LG
2023-10-11 12:48:45+00:00,ProbTS: A Unified Toolkit to Probe Deep Time-series Forecasting,"['Jiawen Zhang', 'Xumeng Wen', 'Shun Zheng', 'Jia Li', 'Jiang Bian']","Time-series forecasting serves as a linchpin in a myriad of applications,
spanning various domains. With the growth of deep learning, this arena has
bifurcated into two salient branches: one focuses on crafting specific neural
architectures tailored for time series, and the other harnesses advanced deep
generative models for probabilistic forecasting. While both branches have made
significant progress, their differences across data scenarios, methodological
focuses, and decoding schemes pose profound, yet unexplored, research
questions. To bridge this knowledge chasm, we introduce ProbTS, a pioneering
toolkit developed to synergize and compare these two distinct branches. Endowed
with a unified data module, a modularized model module, and a comprehensive
evaluator module, ProbTS allows us to revisit and benchmark leading methods
from both branches. The scrutiny with ProbTS highlights their distinct
characteristics, relative strengths and weaknesses, and areas that need further
exploration. Our analyses point to new avenues for research, aiming for more
effective time-series forecasting.",http://arxiv.org/pdf/2310.07446v1,cs.LG
2023-10-11 12:36:42+00:00,Generalized Mixture Model for Extreme Events Forecasting in Time Series Data,"['Jincheng Wang', 'Yue Gao']","Time Series Forecasting (TSF) is a widely researched topic with broad
applications in weather forecasting, traffic control, and stock price
prediction. Extreme values in time series often significantly impact human and
natural systems, but predicting them is challenging due to their rare
occurrence. Statistical methods based on Extreme Value Theory (EVT) provide a
systematic approach to modeling the distribution of extremes, particularly the
Generalized Pareto (GP) distribution for modeling the distribution of
exceedances beyond a threshold. To overcome the subpar performance of deep
learning in dealing with heavy-tailed data, we propose a novel framework to
enhance the focus on extreme events. Specifically, we propose a Deep Extreme
Mixture Model with Autoencoder (DEMMA) for time series prediction. The model
comprises two main modules: 1) a generalized mixture distribution based on the
Hurdle model and a reparameterized GP distribution form independent of the
extreme threshold, 2) an Autoencoder-based LSTM feature extractor and a
quantile prediction module with a temporal attention mechanism. We demonstrate
the effectiveness of our approach on multiple real-world rainfall datasets.",http://arxiv.org/pdf/2310.07435v1,cs.LG
2023-10-11 12:28:52+00:00,Quantum-Enhanced Forecasting: Leveraging Quantum Gramian Angular Field and CNNs for Stock Return Predictions,"['Zhengmeng Xu', 'Hai Lin']","We propose a time series forecasting method named Quantum Gramian Angular
Field (QGAF). This approach merges the advantages of quantum computing
technology with deep learning, aiming to enhance the precision of time series
classification and forecasting. We successfully transformed stock return time
series data into two-dimensional images suitable for Convolutional Neural
Network (CNN) training by designing specific quantum circuits. Distinct from
the classical Gramian Angular Field (GAF) approach, QGAF's uniqueness lies in
eliminating the need for data normalization and inverse cosine calculations,
simplifying the transformation process from time series data to two-dimensional
images. To validate the effectiveness of this method, we conducted experiments
on datasets from three major stock markets: the China A-share market, the Hong
Kong stock market, and the US stock market. Experimental results revealed that
compared to the classical GAF method, the QGAF approach significantly improved
time series prediction accuracy, reducing prediction errors by an average of
25% for Mean Absolute Error (MAE) and 48% for Mean Squared Error (MSE). This
research confirms the potential and promising prospects of integrating quantum
computing with deep learning techniques in financial time series forecasting.",http://arxiv.org/pdf/2310.07427v2,cs.LG
2023-10-11 10:27:24+00:00,Statistical inference of high-dimensional vector autoregressive time series with non-i.i.d. innovations,['Yunyi Zhang'],"Independent or i.i.d. innovations is an essential assumption in the
literature for analyzing a vector time series. However, this assumption is
either too restrictive for a real-life time series to satisfy or is hard to
verify through a hypothesis test. This paper performs statistical inference on
a sparse high-dimensional vector autoregressive time series, allowing its white
noise innovations to be dependent, even non-stationary. To achieve this goal,
it adopts a post-selection estimator to fit the vector autoregressive model and
derives the asymptotic distribution of the post-selection estimator. The
innovations in the autoregressive time series are not assumed to be
independent, thus making the covariance matrices of the autoregressive
coefficient estimators complex and difficult to estimate. Our work develops a
bootstrap algorithm to facilitate practitioners in performing statistical
inference without having to engage in sophisticated calculations. Simulations
and real-life data experiments reveal the validity of the proposed methods and
theoretical results.
  Real-life data is rarely considered to exactly satisfy an autoregressive
model with independent or i.i.d. innovations, so our work should better reflect
the reality compared to the literature that assumes i.i.d. innovations.",http://arxiv.org/pdf/2310.07364v1,math.ST
2023-10-10 13:44:09+00:00,iTransformer: Inverted Transformers Are Effective for Time Series Forecasting,"['Yong Liu', 'Tengge Hu', 'Haoran Zhang', 'Haixu Wu', 'Shiyu Wang', 'Lintao Ma', 'Mingsheng Long']","The recent boom of linear forecasting models questions the ongoing passion
for architectural modifications of Transformer-based forecasters. These
forecasters leverage Transformers to model the global dependencies over
temporal tokens of time series, with each token formed by multiple variates of
the same timestamp. However, Transformer is challenged in forecasting series
with larger lookback windows due to performance degradation and computation
explosion. Besides, the unified embedding for each temporal token fuses
multiple variates with potentially unaligned timestamps and distinct physical
measurements, which may fail in learning variate-centric representations and
result in meaningless attention maps. In this work, we reflect on the competent
duties of Transformer components and repurpose the Transformer architecture
without any adaptation on the basic components. We propose iTransformer that
simply inverts the duties of the attention mechanism and the feed-forward
network. Specifically, the time points of individual series are embedded into
variate tokens which are utilized by the attention mechanism to capture
multivariate correlations; meanwhile, the feed-forward network is applied for
each variate token to learn nonlinear representations. The iTransformer model
achieves consistent state-of-the-art on several real-world datasets, which
further empowers the Transformer family with promoted performance,
generalization ability across different variates, and better utilization of
arbitrary lookback windows, making it a nice alternative as the fundamental
backbone of time series forecasting.",http://arxiv.org/pdf/2310.06625v1,cs.LG
2023-10-10 05:13:10+00:00,Discovering Mixtures of Structural Causal Models from Time Series Data,"['Sumanth Varambally', 'Yi-An Ma', 'Rose Yu']","In fields such as finance, climate science, and neuroscience, inferring
causal relationships from time series data poses a formidable challenge. While
contemporary techniques can handle nonlinear relationships between variables
and flexible noise distributions, they rely on the simplifying assumption that
data originates from the same underlying causal model. In this work, we relax
this assumption and perform causal discovery from time series data originating
from mixtures of different causal models. We infer both the underlying
structural causal models and the posterior probability for each sample
belonging to a specific mixture component. Our approach employs an end-to-end
training process that maximizes an evidence-lower bound for data likelihood.
Through extensive experimentation on both synthetic and real-world datasets, we
demonstrate that our method surpasses state-of-the-art benchmarks in causal
discovery tasks, particularly when the data emanates from diverse underlying
causal graphs. Theoretically, we prove the identifiability of such a model
under some mild assumptions.",http://arxiv.org/pdf/2310.06312v1,cs.LG
2023-10-09 18:34:29+00:00,Performative Time-Series Forecasting,"['Zhiyuan Zhao', 'Alexander Rodriguez', 'B. Aditya Prakash']","Time-series forecasting is a critical challenge in various domains and has
witnessed substantial progress in recent years. Many real-life scenarios, such
as public health, economics, and social applications, involve feedback loops
where predictions can influence the predicted outcome, subsequently altering
the target variable's distribution. This phenomenon, known as performativity,
introduces the potential for 'self-negating' or 'self-fulfilling' predictions.
Despite extensive studies in classification problems across domains,
performativity remains largely unexplored in the context of time-series
forecasting from a machine-learning perspective.
  In this paper, we formalize performative time-series forecasting (PeTS),
addressing the challenge of accurate predictions when performativity-induced
distribution shifts are possible. We propose a novel approach, Feature
Performative-Shifting (FPS), which leverages the concept of delayed response to
anticipate distribution shifts and subsequently predicts targets accordingly.
We provide theoretical insights suggesting that FPS can potentially lead to
reduced generalization error. We conduct comprehensive experiments using
multiple time-series models on COVID-19 and traffic forecasting tasks. The
results demonstrate that FPS consistently outperforms conventional time-series
forecasting methods, highlighting its efficacy in handling
performativity-induced challenges.",http://arxiv.org/pdf/2310.06077v1,cs.LG
2023-10-09 08:45:06+00:00,Projecting infinite time series graphs to finite marginal graphs using number theory,"['Andreas Gerhardus', 'Jonas Wahl', 'Sofia Faltenbacher', 'Urmi Ninad', 'Jakob Runge']","In recent years, a growing number of method and application works have
adapted and applied the causal-graphical-model framework to time series data.
Many of these works employ time-resolved causal graphs that extend infinitely
into the past and future and whose edges are repetitive in time, thereby
reflecting the assumption of stationary causal relationships. However, most
results and algorithms from the causal-graphical-model framework are not
designed for infinite graphs. In this work, we develop a method for projecting
infinite time series graphs with repetitive edges to marginal graphical models
on a finite time window. These finite marginal graphs provide the answers to
$m$-separation queries with respect to the infinite graph, a task that was
previously unresolved. Moreover, we argue that these marginal graphs are useful
for causal discovery and causal effect estimation in time series, effectively
enabling to apply results developed for finite graphs to the infinite graphs.
The projection procedure relies on finding common ancestors in the
to-be-projected graph and is, by itself, not new. However, the projection
procedure has not yet been algorithmically implemented for time series graphs
since in these infinite graphs there can be infinite sets of paths that might
give rise to common ancestors. We solve the search over these possibly infinite
sets of paths by an intriguing combination of path-finding techniques for
finite directed graphs and solution theory for linear Diophantine equations. By
providing an algorithm that carries out the projection, our paper makes an
important step towards a theoretically-grounded and method-agnostic
generalization of a range of causal inference methods and results to time
series.",http://arxiv.org/pdf/2310.05526v1,math.ST
2023-10-08 22:58:44+00:00,Successive Data Injection in Conditional Quantum GAN Applied to Time Series Anomaly Detection,"['Benjamin Kalfon', 'Soumaya Cherkaoui', 'Jean-Frédéric Laprade', 'Ola Ahmad', 'Shengrui Wang']","Classical GAN architectures have shown interesting results for solving
anomaly detection problems in general and for time series anomalies in
particular, such as those arising in communication networks. In recent years,
several quantum GAN architectures have been proposed in the literature. When
detecting anomalies in time series using QGANs, huge challenges arise due to
the limited number of qubits compared to the size of the data. To address these
challenges, we propose a new high-dimensional encoding approach, named
Successive Data Injection (SuDaI). In this approach, we explore a larger
portion of the quantum state than that in the conventional angle encoding, the
method used predominantly in the literature, through repeated data injections
into the quantum state. SuDaI encoding allows us to adapt the QGAN for anomaly
detection with network data of a much higher dimensionality than with the
existing known QGANs implementations. In addition, SuDaI encoding applies to
other types of high-dimensional time series and can be used in contexts beyond
anomaly detection and QGANs, opening up therefore multiple fields of
application.",http://arxiv.org/pdf/2310.05307v1,cs.LG
2023-10-08 08:09:51+00:00,Pushing the Limits of Pre-training for Time Series Forecasting in the CloudOps Domain,"['Gerald Woo', 'Chenghao Liu', 'Akshat Kumar', 'Doyen Sahoo']","Time series has been left behind in the era of pre-training and transfer
learning. While research in the fields of natural language processing and
computer vision are enjoying progressively larger datasets to train massive
models, the most popular time series datasets consist of only tens of thousands
of time steps, limiting our ability to study the effectiveness of pre-training
and scaling. Recent studies have also cast doubt on the need for expressive
models and scale. To alleviate these issues, we introduce three large-scale
time series forecasting datasets from the cloud operations (CloudOps) domain,
the largest having billions of observations, enabling further study into
pre-training and scaling of time series models. We build the empirical
groundwork for studying pre-training and scaling of time series models and pave
the way for future research by identifying a promising candidate architecture.
We show that it is a strong zero-shot baseline and benefits from further
scaling, both in model and dataset size. Accompanying these datasets and
results is a suite of comprehensive benchmark results comparing classical and
deep learning baselines to our pre-trained method - achieving a 27% reduction
in error on the largest dataset. Code and datasets will be released.",http://arxiv.org/pdf/2310.05063v2,cs.LG
2023-10-08 00:02:25+00:00,TEMPO: Prompt-based Generative Pre-trained Transformer for Time Series Forecasting,"['Defu Cao', 'Furong Jia', 'Sercan O Arik', 'Tomas Pfister', 'Yixiang Zheng', 'Wen Ye', 'Yan Liu']","The past decade has witnessed significant advances in time series modeling
with deep learning. While achieving state-of-the-art results, the
best-performing architectures vary highly across applications and domains.
Meanwhile, for natural language processing, the Generative Pre-trained
Transformer (GPT) has demonstrated impressive performance via training one
general-purpose model across various textual datasets. It is intriguing to
explore whether GPT-type architectures can be effective for time series,
capturing the intrinsic dynamic attributes and leading to significant accuracy
improvements. In this paper, we propose a novel framework, TEMPO, that can
effectively learn time series representations. We focus on utilizing two
essential inductive biases of the time series task for pre-trained models: (i)
decomposition of the complex interaction between trend, seasonal and residual
components; and (ii) introducing the selection-based prompts to facilitate
distribution adaptation in non-stationary time series. TEMPO expands the
capability for dynamically modeling real-world temporal phenomena from data
within diverse domains. Our experiments demonstrate the superior performance of
TEMPO over state-of-the-art methods on a number of time series benchmark
datasets. This performance gain is observed not only in standard supervised
learning settings but also in scenarios involving previously unseen datasets as
well as in scenarios with multi-modal inputs. This compelling finding
highlights TEMPO's potential to constitute a foundational model-building
framework.",http://arxiv.org/pdf/2310.04948v2,cs.LG
2023-10-06 15:45:28+00:00,T-Rep: Representation Learning for Time Series using Time-Embeddings,"['Archibald Fraikin', 'Adrien Bennetot', 'Stéphanie Allassonnière']","Multivariate time series present challenges to standard machine learning
techniques, as they are often unlabeled, high dimensional, noisy, and contain
missing data. To address this, we propose T-Rep, a self-supervised method to
learn time series representations at a timestep granularity. T-Rep learns
vector embeddings of time alongside its feature extractor, to extract temporal
features such as trend, periodicity, or distribution shifts from the signal.
These time-embeddings are leveraged in pretext tasks, to incorporate smooth and
fine-grained temporal dependencies in the representations, as well as reinforce
robustness to missing data. We evaluate T-Rep on downstream classification,
forecasting, and anomaly detection tasks. It is compared to existing
self-supervised algorithms for time series, which it outperforms in all three
tasks. We test T-Rep in missing data regimes, where it proves more resilient
than its counterparts. Finally, we provide latent space visualisation
experiments, highlighting the interpretability of the learned representations.",http://arxiv.org/pdf/2310.04486v1,cs.LG
2023-10-06 11:48:26+00:00,Introducing the Attribution Stability Indicator: a Measure for Time Series XAI Attributions,"['Udo Schlegel', 'Daniel A. Keim']","Given the increasing amount and general complexity of time series data in
domains such as finance, weather forecasting, and healthcare, there is a
growing need for state-of-the-art performance models that can provide
interpretable insights into underlying patterns and relationships. Attribution
techniques enable the extraction of explanations from time series models to
gain insights but are hard to evaluate for their robustness and
trustworthiness. We propose the Attribution Stability Indicator (ASI), a
measure to incorporate robustness and trustworthiness as properties of
attribution techniques for time series into account. We extend a perturbation
analysis with correlations of the original time series to the perturbed
instance and the attributions to include wanted properties in the measure. We
demonstrate the wanted properties based on an analysis of the attributions in a
dimension-reduced space and the ASI scores distribution over three whole time
series classification datasets.",http://arxiv.org/pdf/2310.04178v1,cs.LG
2023-10-05 22:00:17+00:00,Multitask Learning for Time Series Data with 2D Convolution,"['Chin-Chia Michael Yeh', 'Xin Dai', 'Yan Zheng', 'Junpeng Wang', 'Huiyuan Chen', 'Yujie Fan', 'Audrey Der', 'Zhongfang Zhuang', 'Liang Wang', 'Wei Zhang']","Multitask learning (MTL) aims to develop a unified model that can handle a
set of closely related tasks simultaneously. By optimizing the model across
multiple tasks, MTL generally surpasses its non-MTL counterparts in terms of
generalizability. Although MTL has been extensively researched in various
domains such as computer vision, natural language processing, and
recommendation systems, its application to time series data has received
limited attention. In this paper, we investigate the application of MTL to the
time series classification (TSC) problem. However, when we integrate the
state-of-the-art 1D convolution-based TSC model with MTL, the performance of
the TSC model actually deteriorates. By comparing the 1D convolution-based
models with the Dynamic Time Warping (DTW) distance function, it appears that
the underwhelming results stem from the limited expressive power of the 1D
convolutional layers. To overcome this challenge, we propose a novel design for
a 2D convolution-based model that enhances the model's expressiveness.
Leveraging this advantage, our proposed method outperforms competing approaches
on both the UCR Archive and an industrial transaction TSC dataset.",http://arxiv.org/pdf/2310.03925v2,cs.LG
2023-10-05 21:44:50+00:00,Toward a Foundation Model for Time Series Data,"['Chin-Chia Michael Yeh', 'Xin Dai', 'Huiyuan Chen', 'Yan Zheng', 'Yujie Fan', 'Audrey Der', 'Vivian Lai', 'Zhongfang Zhuang', 'Junpeng Wang', 'Liang Wang', 'Wei Zhang']","A foundation model is a machine learning model trained on a large and diverse
set of data, typically using self-supervised learning-based pre-training
techniques, that can be adapted to various downstream tasks. However, current
research on time series pre-training has mostly focused on models pre-trained
solely on data from a single domain, resulting in a lack of knowledge about
other types of time series. However, current research on time series
pre-training has predominantly focused on models trained exclusively on data
from a single domain. As a result, these models possess domain-specific
knowledge that may not be easily transferable to time series from other
domains. In this paper, we aim to develop an effective time series foundation
model by leveraging unlabeled samples from multiple domains. To achieve this,
we repurposed the publicly available UCR Archive and evaluated four existing
self-supervised learning-based pre-training methods, along with a novel method,
on the datasets. We tested these methods using four popular neural network
architectures for time series to understand how the pre-training methods
interact with different network designs. Our experimental results show that
pre-training improves downstream classification tasks by enhancing the
convergence of the fine-tuning process. Furthermore, we found that the proposed
pre-training method, when combined with the Transformer model, outperforms the
alternatives.",http://arxiv.org/pdf/2310.03916v1,cs.LG
2023-10-05 15:36:47+00:00,Comparing Time-Series Analysis Approaches Utilized in Research Papers to Forecast COVID-19 Cases in Africa: A Literature Review,"['Ali Ebadi', 'Ebrahim Sahafizadeh']","This literature review aimed to compare various time-series analysis
approaches utilized in forecasting COVID-19 cases in Africa. The study involved
a methodical search for English-language research papers published between
January 2020 and July 2023, focusing specifically on papers that utilized
time-series analysis approaches on COVID-19 datasets in Africa. A variety of
databases including PubMed, Google Scholar, Scopus, and Web of Science were
utilized for this process. The research papers underwent an evaluation process
to extract relevant information regarding the implementation and performance of
the time-series analysis models. The study highlighted the different
methodologies employed, evaluating their effectiveness and limitations in
forecasting the spread of the virus. The result of this review could contribute
deeper insights into the field, and future research should consider these
insights to improve time series analysis models and explore the integration of
different approaches for enhanced public health decision-making.",http://arxiv.org/pdf/2310.03606v1,cs.LG
2023-10-05 15:14:00+00:00,TimeGPT-1,"['Azul Garza', 'Max Mergenthaler-Canseco']","In this paper, we introduce TimeGPT, the first foundation model for time
series, capable of generating accurate predictions for diverse datasets not
seen during training. We evaluate our pre-trained model against established
statistical, machine learning, and deep learning methods, demonstrating that
TimeGPT zero-shot inference excels in performance, efficiency, and simplicity.
Our study provides compelling evidence that insights from other domains of
artificial intelligence can be effectively applied to time series analysis. We
conclude that large-scale time series models offer an exciting opportunity to
democratize access to precise predictions and reduce uncertainty by leveraging
the capabilities of contemporary advancements in deep learning.",http://arxiv.org/pdf/2310.03589v1,cs.LG
2023-10-05 01:26:13+00:00,Sparse Deep Learning for Time Series Data: Theory and Applications,"['Mingxuan Zhang', 'Yan Sun', 'Faming Liang']","Sparse deep learning has become a popular technique for improving the
performance of deep neural networks in areas such as uncertainty
quantification, variable selection, and large-scale network compression.
However, most existing research has focused on problems where the observations
are independent and identically distributed (i.i.d.), and there has been little
work on the problems where the observations are dependent, such as time series
data and sequential data in natural language processing. This paper aims to
address this gap by studying the theory for sparse deep learning with dependent
data. We show that sparse recurrent neural networks (RNNs) can be consistently
estimated, and their predictions are asymptotically normally distributed under
appropriate assumptions, enabling the prediction uncertainty to be correctly
quantified. Our numerical results show that sparse deep learning outperforms
state-of-the-art methods, such as conformal predictions, in prediction
uncertainty quantification for time series data. Furthermore, our results
indicate that the proposed method can consistently identify the autoregressive
order for time series data and outperform existing methods in large-scale model
compression. Our proposed method has important practical implications in fields
such as finance, healthcare, and energy, where both accurate point estimates
and prediction uncertainty quantification are of concern.",http://arxiv.org/pdf/2310.03243v1,stat.ML
2023-10-04 13:37:34+00:00,Time-Series Classification in Smart Manufacturing Systems: An Experimental Evaluation of State-of-the-Art Machine Learning Algorithms,"['Mojtaba A. Farahani', 'M. R. McCormick', 'Ramy Harik', 'Thorsten Wuest']","Manufacturing is gathering extensive amounts of diverse data, thanks to the
growing number of sensors and rapid advances in sensing technologies. Among the
various data types available in SMS settings, time-series data plays a pivotal
role. Hence, TSC emerges is crucial in this domain. The objective of this study
is to fill this gap by providing a rigorous experimental evaluation of the SoTA
ML and DL algorithms for TSC tasks in manufacturing and industrial settings. We
first explored and compiled a comprehensive list of more than 92 SoTA
algorithms from both TSC and manufacturing literature. Following, we selected
the 36 most representative algorithms from this list. To evaluate their
performance across various manufacturing classification tasks, we curated a set
of 22 manufacturing datasets, representative of different characteristics that
cover diverse manufacturing problems. Subsequently, we implemented and
evaluated the algorithms on the manufacturing benchmark datasets, and analyzed
the results for each dataset. Based on the results, ResNet, DrCIF,
InceptionTime, and ARSENAL are the top-performing algorithms, boasting an
average accuracy of over 96.6% across all 22 manufacturing TSC datasets. These
findings underscore the robustness, efficiency, scalability, and effectiveness
of convolutional kernels in capturing temporal features in time-series data, as
three out of the top four performing algorithms leverage these kernels for
feature extraction. Additionally, LSTM, BiLSTM, and TS-LSTM algorithms deserve
recognition for their effectiveness in capturing features within time-series
data using RNN-based structures.",http://arxiv.org/pdf/2310.02812v1,cs.LG
2023-10-04 12:43:38+00:00,Graph Neural Networks and Time Series as Directed Graphs for Quality Recognition,"['Angelica Simonetti', 'Ferdinando Zanchetta']","Graph Neural Networks (GNNs) are becoming central in the study of time
series, coupled with existing algorithms as Temporal Convolutional Networks and
Recurrent Neural Networks. In this paper, we see time series themselves as
directed graphs, so that their topology encodes time dependencies and we start
to explore the effectiveness of GNNs architectures on them. We develop two
distinct Geometric Deep Learning models, a supervised classifier and an
autoencoder-like model for signal reconstruction. We apply these models on a
quality recognition problem.",http://arxiv.org/pdf/2310.02774v1,cs.LG
2023-10-04 08:25:03+00:00,A Study of Quantisation-aware Training on Time Series Transformer Models for Resource-constrained FPGAs,"['Tianheng Ling', 'Chao Qian', 'Lukas Einhaus', 'Gregor Schiele']","This study explores the quantisation-aware training (QAT) on time series
Transformer models. We propose a novel adaptive quantisation scheme that
dynamically selects between symmetric and asymmetric schemes during the QAT
phase. Our approach demonstrates that matching the quantisation scheme to the
real data distribution can reduce computational overhead while maintaining
acceptable precision. Moreover, our approach is robust when applied to
real-world data and mixed-precision quantisation, where most objects are
quantised to 4 bits. Our findings inform model quantisation and deployment
decisions while providing a foundation for advancing quantisation techniques.",http://arxiv.org/pdf/2310.02654v1,cs.LG
2023-10-04 07:14:43+00:00,Generative Modeling of Regular and Irregular Time Series Data via Koopman VAEs,"['Ilan Naiman', 'N. Benjamin Erichson', 'Pu Ren', 'Michael W. Mahoney', 'Omri Azencot']","Generating realistic time series data is important for many engineering and
scientific applications. Existing work tackles this problem using generative
adversarial networks (GANs). However, GANs are often unstable during training,
and they can suffer from mode collapse. While variational autoencoders (VAEs)
are known to be more robust to these issues, they are (surprisingly) less often
considered for time series generation. In this work, we introduce Koopman VAE
(KVAE), a new generative framework that is based on a novel design for the
model prior, and that can be optimized for either regular and irregular
training data. Inspired by Koopman theory, we represent the latent conditional
prior dynamics using a linear map. Our approach enhances generative modeling
with two desired features: (i) incorporating domain knowledge can be achieved
by leverageing spectral tools that prescribe constraints on the eigenvalues of
the linear map; and (ii) studying the qualitative behavior and stablity of the
system can be performed using tools from dynamical systems theory. Our results
show that KVAE outperforms state-of-the-art GAN and VAE methods across several
challenging synthetic and real-world time series generation benchmarks. Whether
trained on regular or irregular data, KVAE generates time series that improve
both discriminative and predictive metrics. We also present visual evidence
suggesting that KVAE learns probability density functions that better
approximate empirical ground truth distributions.",http://arxiv.org/pdf/2310.02619v1,cs.LG
2023-10-03 02:29:19+00:00,CausalTime: Realistically Generated Time-series for Benchmarking of Causal Discovery,"['Yuxiao Cheng', 'Ziqian Wang', 'Tingxiong Xiao', 'Qin Zhong', 'Jinli Suo', 'Kunlun He']","Time-series causal discovery (TSCD) is a fundamental problem of machine
learning. However, existing synthetic datasets cannot properly evaluate or
predict the algorithms' performance on real data. This study introduces the
CausalTime pipeline to generate time-series that highly resemble the real data
and with ground truth causal graphs for quantitative performance evaluation.
The pipeline starts from real observations in a specific scenario and produces
a matching benchmark dataset. Firstly, we harness deep neural networks along
with normalizing flow to accurately capture realistic dynamics. Secondly, we
extract hypothesized causal graphs by performing importance analysis on the
neural network or leveraging prior knowledge. Thirdly, we derive the ground
truth causal graphs by splitting the causal model into causal term, residual
term, and noise term. Lastly, using the fitted network and the derived causal
graph, we generate corresponding versatile time-series proper for algorithm
assessment. In the experiments, we validate the fidelity of the generated data
through qualitative and quantitative experiments, followed by a benchmarking of
existing TSCD algorithms using these generated datasets. CausalTime offers a
feasible solution to evaluating TSCD algorithms in real applications and can be
generalized to a wide range of fields. For easy use of the proposed approach,
we also provide a user-friendly website, hosted on www.causaltime.cc.",http://arxiv.org/pdf/2310.01753v1,cs.LG
2023-10-03 01:31:25+00:00,Time-LLM: Time Series Forecasting by Reprogramming Large Language Models,"['Ming Jin', 'Shiyu Wang', 'Lintao Ma', 'Zhixuan Chu', 'James Y. Zhang', 'Xiaoming Shi', 'Pin-Yu Chen', 'Yuxuan Liang', 'Yuan-Fang Li', 'Shirui Pan', 'Qingsong Wen']","Time series forecasting holds significant importance in many real-world
dynamic systems and has been extensively studied. Unlike natural language
process (NLP) and computer vision (CV), where a single large model can tackle
multiple tasks, models for time series forecasting are often specialized,
necessitating distinct designs for different tasks and applications. While
pre-trained foundation models have made impressive strides in NLP and CV, their
development in time series domains has been constrained by data sparsity.
Recent studies have revealed that large language models (LLMs) possess robust
pattern recognition and reasoning abilities over complex sequences of tokens.
However, the challenge remains in effectively aligning the modalities of time
series data and natural language to leverage these capabilities. In this work,
we present Time-LLM, a reprogramming framework to repurpose LLMs for general
time series forecasting with the backbone language models kept intact. We begin
by reprogramming the input time series with text prototypes before feeding it
into the frozen LLM to align the two modalities. To augment the LLM's ability
to reason with time series data, we propose Prompt-as-Prefix (PaP), which
enriches the input context and directs the transformation of reprogrammed input
patches. The transformed time series patches from the LLM are finally projected
to obtain the forecasts. Our comprehensive evaluations demonstrate that
Time-LLM is a powerful time series learner that outperforms state-of-the-art,
specialized forecasting models. Moreover, Time-LLM excels in both few-shot and
zero-shot learning scenarios.",http://arxiv.org/pdf/2310.01728v1,cs.LG
2023-10-03 01:13:17+00:00,PrACTiS: Perceiver-Attentional Copulas for Time Series,"['Cat P. Le', 'Chris Cannella', 'Ali Hasan', 'Yuting Ng', 'Vahid Tarokh']","Transformers incorporating copula structures have demonstrated remarkable
performance in time series prediction. However, their heavy reliance on
self-attention mechanisms demands substantial computational resources, thus
limiting their practical utility across a wide range of tasks. In this work, we
present a model that combines the perceiver architecture with a copula
structure to enhance time-series forecasting. By leveraging the perceiver as
the encoder, we efficiently transform complex, high-dimensional, multimodal
data into a compact latent space, thereby significantly reducing computational
demands. To further reduce complexity, we introduce midpoint inference and
local attention mechanisms, enabling the model to capture dependencies within
imputed samples effectively. Subsequently, we deploy the copula-based attention
and output variance testing mechanism to capture the joint distribution of
missing data, while simultaneously mitigating error propagation during
prediction. Our experimental results on the unimodal and multimodal benchmarks
showcase a consistent 20\% improvement over the state-of-the-art methods, while
utilizing less than half of available memory resources.",http://arxiv.org/pdf/2310.01720v1,cs.LG
2023-10-02 16:45:19+00:00,"TACTiS-2: Better, Faster, Simpler Attentional Copulas for Multivariate Time Series","['Arjun Ashok', 'Étienne Marcotte', 'Valentina Zantedeschi', 'Nicolas Chapados', 'Alexandre Drouin']","We introduce a new model for multivariate probabilistic time series
prediction, designed to flexibly address a range of tasks including
forecasting, interpolation, and their combinations. Building on copula theory,
we propose a simplified objective for the recently-introduced transformer-based
attentional copulas (TACTiS), wherein the number of distributional parameters
now scales linearly with the number of variables instead of factorially. The
new objective requires the introduction of a training curriculum, which goes
hand-in-hand with necessary changes to the original architecture. We show that
the resulting model has significantly better training dynamics and achieves
state-of-the-art performance across diverse real-world forecasting tasks, while
maintaining the flexibility of prior work, such as seamless handling of
unaligned and unevenly-sampled time series.",http://arxiv.org/pdf/2310.01327v1,cs.LG
2023-10-02 14:22:41+00:00,Modality-aware Transformer for Time series Forecasting,"['Hajar Emami', 'Xuan-Hong Dang', 'Yousaf Shah', 'Petros Zerfos']","Time series forecasting presents a significant challenge, particularly when
its accuracy relies on external data sources rather than solely on historical
values. This issue is prevalent in the financial sector, where the future
behavior of time series is often intricately linked to information derived from
various textual reports and a multitude of economic indicators. In practice,
the key challenge lies in constructing a reliable time series forecasting model
capable of harnessing data from diverse sources and extracting valuable
insights to predict the target time series accurately. In this work, we tackle
this challenging problem and introduce a novel multimodal transformer-based
model named the Modality-aware Transformer. Our model excels in exploring the
power of both categorical text and numerical timeseries to forecast the target
time series effectively while providing insights through its neural attention
mechanism. To achieve this, we develop feature-level attention layers that
encourage the model to focus on the most relevant features within each data
modality. By incorporating the proposed feature-level attention, we develop a
novel Intra-modal multi-head attention (MHA), Inter-modal MHA and
Modality-target MHA in a way that both feature and temporal attentions are
incorporated in MHAs. This enables the MHAs to generate temporal attentions
with consideration of modality and feature importance which leads to more
informative embeddings. The proposed modality-aware structure enables the model
to effectively exploit information within each modality as well as foster
cross-modal understanding. Our extensive experiments on financial datasets
demonstrate that Modality-aware Transformer outperforms existing methods,
offering a novel and practical solution to the complex challenges of
multi-modality time series forecasting.",http://arxiv.org/pdf/2310.01232v1,cs.LG
2023-10-01 23:33:37+00:00,Determining the Optimal Number of Clusters for Time Series Datasets with Symbolic Pattern Forest,['Md Nishat Raihan'],"Clustering algorithms are among the most widely used data mining methods due
to their exploratory power and being an initial preprocessing step that paves
the way for other techniques. But the problem of calculating the optimal number
of clusters (say k) is one of the significant challenges for such methods. The
most widely used clustering algorithms like k-means and k-shape in time series
data mining also need the ground truth for the number of clusters that need to
be generated. In this work, we extended the Symbolic Pattern Forest algorithm,
another time series clustering algorithm, to determine the optimal number of
clusters for the time series datasets. We used SPF to generate the clusters
from the datasets and chose the optimal number of clusters based on the
Silhouette Coefficient, a metric used to calculate the goodness of a clustering
technique. Silhouette was calculated on both the bag of word vectors and the
tf-idf vectors generated from the SAX words of each time series. We tested our
approach on the UCR archive datasets, and our experimental results so far
showed significant improvement over the baseline.",http://arxiv.org/pdf/2310.00820v1,cs.LG
2023-10-01 12:47:59+00:00,PatchMixer: A Patch-Mixing Architecture for Long-Term Time Series Forecasting,"['Zeying Gong', 'Yujin Tang', 'Junwei Liang']","Although the Transformer has been the dominant architecture for time series
forecasting tasks in recent years, a fundamental challenge remains: the
permutation-invariant self-attention mechanism within Transformers leads to a
loss of temporal information. To tackle these challenges, we propose
PatchMixer, a novel CNN-based model. It introduces a permutation-variant
convolutional structure to preserve temporal information. Diverging from
conventional CNNs in this field, which often employ multiple scales or numerous
branches, our method relies exclusively on depthwise separable convolutions.
This allows us to extract both local features and global correlations using a
single-scale architecture. Furthermore, we employ dual forecasting heads that
encompass both linear and nonlinear components to better model future curve
trends and details. Our experimental results on seven time-series forecasting
benchmarks indicate that compared with the state-of-the-art method and the
best-performing CNN, PatchMixer yields $3.9\%$ and $21.2\%$ relative
improvements, respectively, while being 2-3x faster than the most advanced
method. We will release our code and model.",http://arxiv.org/pdf/2310.00655v1,cs.LG
2023-09-30 07:46:47+00:00,Mathematical structure of perfect predictive reservoir computing for autoregressive type of time series data,['Tsuyoshi Yoneda'],"Reservoir Computing (RC) is a type of recursive neural network (RNN), and
there can be no doubt that the RC will be more and more widely used for
building future prediction models for time-series data, with low training cost,
high speed and high computational power. However, research into the
mathematical structure of RC neural networks has only recently begun. Bollt
(2021) clarified the necessity of the autoregressive (AR) model for gaining the
insight into the mathematical structure of RC neural networks, and indicated
that the Wold decomposition theorem is the milestone for understanding of
these. Keeping this celebrated result in mind, in this paper, we clarify hidden
structures of input and recurrent weight matrices in RC neural networks, and
show that such structures attain perfect prediction for the AR type of time
series data.",http://arxiv.org/pdf/2310.00290v2,cs.LG
2023-09-30 06:08:37+00:00,Unravel Anomalies: An End-to-end Seasonal-Trend Decomposition Approach for Time Series Anomaly Detection,"['Zhenwei Zhang', 'Ruiqi Wang', 'Ran Ding', 'Yuantao Gu']","Traditional Time-series Anomaly Detection (TAD) methods often struggle with
the composite nature of complex time-series data and a diverse array of
anomalies. We introduce TADNet, an end-to-end TAD model that leverages
Seasonal-Trend Decomposition to link various types of anomalies to specific
decomposition components, thereby simplifying the analysis of complex
time-series and enhancing detection performance. Our training methodology,
which includes pre-training on a synthetic dataset followed by fine-tuning,
strikes a balance between effective decomposition and precise anomaly
detection. Experimental validation on real-world datasets confirms TADNet's
state-of-the-art performance across a diverse range of anomalies.",http://arxiv.org/pdf/2310.00268v1,cs.LG
2023-09-29 11:42:59+00:00,Efficient Interpretable Nonlinear Modeling for Multiple Time Series,"['Kevin Roy', 'Luis Miguel Lopez-Ramos', 'Baltasar Beferull-Lozano']","Predictive linear and nonlinear models based on kernel machines or deep
neural networks have been used to discover dependencies among time series. This
paper proposes an efficient nonlinear modeling approach for multiple time
series, with a complexity comparable to linear vector autoregressive (VAR)
models while still incorporating nonlinear interactions among different
time-series variables. The modeling assumption is that the set of time series
is generated in two steps: first, a linear VAR process in a latent space, and
second, a set of invertible and Lipschitz continuous nonlinear mappings that
are applied per sensor, that is, a component-wise mapping from each latent
variable to a variable in the measurement space. The VAR coefficient
identification provides a topology representation of the dependencies among the
aforementioned variables. The proposed approach models each component-wise
nonlinearity using an invertible neural network and imposes sparsity on the VAR
coefficients to reflect the parsimonious dependencies usually found in real
applications. To efficiently solve the formulated optimization problems, a
custom algorithm is devised combining proximal gradient descent, stochastic
primal-dual updates, and projection to enforce the corresponding constraints.
Experimental results on both synthetic and real data sets show that the
proposed algorithm improves the identification of the support of the VAR
coefficients in a parsimonious manner while also improving the time-series
prediction, as compared to the current state-of-the-art methods.",http://arxiv.org/pdf/2309.17154v1,cs.LG
2023-09-28 23:50:11+00:00,Algorithmic Recourse for Anomaly Detection in Multivariate Time Series,"['Xiao Han', 'Lu Zhang', 'Yongkai Wu', 'Shuhan Yuan']","Anomaly detection in multivariate time series has received extensive study
due to the wide spectrum of applications. An anomaly in multivariate time
series usually indicates a critical event, such as a system fault or an
external attack. Therefore, besides being effective in anomaly detection,
recommending anomaly mitigation actions is also important in practice yet
under-investigated. In this work, we focus on algorithmic recourse in time
series anomaly detection, which is to recommend fixing actions on abnormal time
series with a minimum cost so that domain experts can understand how to fix the
abnormal behavior. To this end, we propose an algorithmic recourse framework,
called RecAD, which can recommend recourse actions to flip the abnormal time
steps. Experiments on two synthetic and one real-world datasets show the
effectiveness of our framework.",http://arxiv.org/pdf/2309.16896v1,cs.LG
2023-09-28 23:03:12+00:00,Sourcing Investment Targets for Venture and Growth Capital Using Multivariate Time Series Transformer,"['Lele Cao', 'Gustaf Halvardsson', 'Andrew McCornack', 'Vilhelm von Ehrenheim', 'Pawel Herman']","This paper addresses the growing application of data-driven approaches within
the Private Equity (PE) industry, particularly in sourcing investment targets
(i.e., companies) for Venture Capital (VC) and Growth Capital (GC). We present
a comprehensive review of the relevant approaches and propose a novel approach
leveraging a Transformer-based Multivariate Time Series Classifier (TMTSC) for
predicting the success likelihood of any candidate company. The objective of
our research is to optimize sourcing performance for VC and GC investments by
formally defining the sourcing problem as a multivariate time series
classification task. We consecutively introduce the key components of our
implementation which collectively contribute to the successful application of
TMTSC in VC/GC sourcing: input features, model architecture, optimization
target, and investor-centric data augmentation and split. Our extensive
experiments on four datasets, benchmarked towards three popular baselines,
demonstrate the effectiveness of our approach in improving decision making
within the VC and GC industry.",http://arxiv.org/pdf/2309.16888v1,cs.LG
2023-09-28 22:38:18+00:00,Message Propagation Through Time: An Algorithm for Sequence Dependency Retention in Time Series Modeling,"['Shaoming Xu', 'Ankush Khandelwal', 'Arvind Renganathan', 'Vipin Kumar']","Time series modeling, a crucial area in science, often encounters challenges
when training Machine Learning (ML) models like Recurrent Neural Networks
(RNNs) using the conventional mini-batch training strategy that assumes
independent and identically distributed (IID) samples and initializes RNNs with
zero hidden states. The IID assumption ignores temporal dependencies among
samples, resulting in poor performance. This paper proposes the Message
Propagation Through Time (MPTT) algorithm to effectively incorporate long
temporal dependencies while preserving faster training times relative to the
stateful solutions. MPTT utilizes two memory modules to asynchronously manage
initial hidden states for RNNs, fostering seamless information exchange between
samples and allowing diverse mini-batches throughout epochs. MPTT further
implements three policies to filter outdated and preserve essential information
in the hidden states to generate informative initial hidden states for RNNs,
facilitating robust training. Experimental results demonstrate that MPTT
outperforms seven strategies on four climate datasets with varying levels of
temporal dependencies.",http://arxiv.org/pdf/2309.16882v1,cs.LG
2023-09-28 15:27:28+00:00,Generating Personalized Insulin Treatments Strategies with Deep Conditional Generative Time Series Models,"['Manuel Schürch', 'Xiang Li', 'Ahmed Allam', 'Giulia Rathmes', 'Amina Mollaysa', 'Claudia Cavelti-Weder', 'Michael Krauthammer']","We propose a novel framework that combines deep generative time series models
with decision theory for generating personalized treatment strategies. It
leverages historical patient trajectory data to jointly learn the generation of
realistic personalized treatment and future outcome trajectories through deep
generative time series models. In particular, our framework enables the
generation of novel multivariate treatment strategies tailored to the
personalized patient history and trained for optimal expected future outcomes
based on conditional expected utility maximization. We demonstrate our
framework by generating personalized insulin treatment strategies and blood
glucose predictions for hospitalized diabetes patients, showcasing the
potential of our approach for generating improved personalized treatment
strategies. Keywords: deep generative model, probabilistic decision support,
personalized treatment generation, insulin and blood glucose prediction",http://arxiv.org/pdf/2309.16521v1,stat.ML
2023-09-28 11:25:02+00:00,ShapeDBA: Generating Effective Time Series Prototypes using ShapeDTW Barycenter Averaging,"['Ali Ismail-Fawaz', 'Hassan Ismail Fawaz', 'François Petitjean', 'Maxime Devanne', 'Jonathan Weber', 'Stefano Berretti', 'Geoffrey I. Webb', 'Germain Forestier']","Time series data can be found in almost every domain, ranging from the
medical field to manufacturing and wireless communication. Generating realistic
and useful exemplars and prototypes is a fundamental data analysis task. In
this paper, we investigate a novel approach to generating realistic and useful
exemplars and prototypes for time series data. Our approach uses a new form of
time series average, the ShapeDTW Barycentric Average. We therefore turn our
attention to accurately generating time series prototypes with a novel
approach. The existing time series prototyping approaches rely on the Dynamic
Time Warping (DTW) similarity measure such as DTW Barycentering Average (DBA)
and SoftDBA. These last approaches suffer from a common problem of generating
out-of-distribution artifacts in their prototypes. This is mostly caused by the
DTW variant used and its incapability of detecting neighborhood similarities,
instead it detects absolute similarities. Our proposed method, ShapeDBA, uses
the ShapeDTW variant of DTW, that overcomes this issue. We chose time series
clustering, a popular form of time series analysis to evaluate the outcome of
ShapeDBA compared to the other prototyping approaches. Coupled with the k-means
clustering algorithm, and evaluated on a total of 123 datasets from the UCR
archive, our proposed averaging approach is able to achieve new
state-of-the-art results in terms of Adjusted Rand Index.",http://arxiv.org/pdf/2309.16353v1,cs.LG
2023-09-28 08:08:08+00:00,Multi-Modal Financial Time-Series Retrieval Through Latent Space Projections,"['Tom Bamford', 'Andrea Coletta', 'Elizabeth Fons', 'Sriram Gopalakrishnan', 'Svitlana Vyetrenko', 'Tucker Balch', 'Manuela Veloso']","Financial firms commonly process and store billions of time-series data,
generated continuously and at a high frequency. To support efficient data
storage and retrieval, specialized time-series databases and systems have
emerged. These databases support indexing and querying of time-series by a
constrained Structured Query Language(SQL)-like format to enable queries like
""Stocks with monthly price returns greater than 5%"", and expressed in rigid
formats. However, such queries do not capture the intrinsic complexity of high
dimensional time-series data, which can often be better described by images or
language (e.g., ""A stock in low volatility regime""). Moreover, the required
storage, computational time, and retrieval complexity to search in the
time-series space are often non-trivial. In this paper, we propose and
demonstrate a framework to store multi-modal data for financial time-series in
a lower-dimensional latent space using deep encoders, such that the latent
space projections capture not only the time series trends but also other
desirable information or properties of the financial time-series data (such as
price volatility). Moreover, our approach allows user-friendly query
interfaces, enabling natural language text or sketches of time-series, for
which we have developed intuitive interfaces. We demonstrate the advantages of
our method in terms of computational efficiency and accuracy on real historical
data as well as synthetic data, and highlight the utility of latent-space
projections in the storage and retrieval of financial time-series data with
intuitive query modalities.",http://arxiv.org/pdf/2309.16741v1,cs.LG
2023-09-27 18:59:00+00:00,Unified Long-Term Time-Series Forecasting Benchmark,"['Jacek Cyranka', 'Szymon Haponiuk']","In order to support the advancement of machine learning methods for
predicting time-series data, we present a comprehensive dataset designed
explicitly for long-term time-series forecasting. We incorporate a collection
of datasets obtained from diverse, dynamic systems and real-life records. Each
dataset is standardized by dividing it into training and test trajectories with
predetermined lookback lengths. We include trajectories of length up to $2000$
to ensure a reliable evaluation of long-term forecasting capabilities. To
determine the most effective model in diverse scenarios, we conduct an
extensive benchmarking analysis using classical and state-of-the-art models,
namely LSTM, DeepAR, NLinear, N-Hits, PatchTST, and LatentODE. Our findings
reveal intriguing performance comparisons among these models, highlighting the
dataset-dependent nature of model effectiveness. Notably, we introduce a custom
latent NLinear model and enhance DeepAR with a curriculum learning phase. Both
consistently outperform their vanilla counterparts.",http://arxiv.org/pdf/2309.15946v1,cs.LG
2023-09-26 22:42:25+00:00,Telescope: An Automated Hybrid Forecasting Approach on a Level-Playing Field,"['André Bauer', 'Mark Leznik', 'Michael Stenger', 'Robert Leppich', 'Nikolas Herbst', 'Samuel Kounev', 'Ian Foster']","In many areas of decision-making, forecasting is an essential pillar.
Consequently, many different forecasting methods have been proposed. From our
experience, recently presented forecasting methods are computationally
intensive, poorly automated, tailored to a particular data set, or they lack a
predictable time-to-result. To this end, we introduce Telescope, a novel
machine learning-based forecasting approach that automatically retrieves
relevant information from a given time series and splits it into parts,
handling each of them separately. In contrast to deep learning methods, our
approach doesn't require parameterization or the need to train and fit a
multitude of parameters. It operates with just one time series and provides
forecasts within seconds without any additional setup. Our experiments show
that Telescope outperforms recent methods by providing accurate and reliable
forecasts while making no assumptions about the analyzed time series.",http://arxiv.org/pdf/2309.15871v1,cs.LG
2023-09-26 19:10:00+00:00,Balancing Computational Efficiency and Forecast Error in Machine Learning-based Time-Series Forecasting: Insights from Live Experiments on Meteorological Nowcasting,"['Elin Törnquist', 'Wagner Costa Santos', 'Timothy Pogue', 'Nicholas Wingle', 'Robert A. Caulk']","Machine learning for time-series forecasting remains a key area of research.
Despite successful application of many machine learning techniques, relating
computational efficiency to forecast error remains an under-explored domain.
This paper addresses this topic through a series of real-time experiments to
quantify the relationship between computational cost and forecast error using
meteorological nowcasting as an example use-case. We employ a variety of
popular regression techniques (XGBoost, FC-MLP, Transformer, and LSTM) for
multi-horizon, short-term forecasting of three variables (temperature, wind
speed, and cloud cover) for multiple locations. During a 5-day live experiment,
4000 data sources were streamed for training and inferencing 144 models per
hour. These models were parameterized to explore forecast error for two
computational cost minimization methods: a novel auto-adaptive data reduction
technique (Variance Horizon) and a performance-based concept drift-detection
mechanism. Forecast error of all model variations were benchmarked in real-time
against a state-of-the-art numerical weather prediction model. Performance was
assessed using classical and novel evaluation metrics. Results indicate that
using the Variance Horizon reduced computational usage by more than 50\%, while
increasing between 0-15\% in error. Meanwhile, performance-based retraining
reduced computational usage by up to 90\% while \emph{also} improving forecast
error by up to 10\%. Finally, the combination of both the Variance Horizon and
performance-based retraining outperformed other model configurations by up to
99.7\% when considering error normalized to computational usage.",http://arxiv.org/pdf/2309.15207v1,cs.LG
2023-09-26 18:05:19+00:00,Revealing the Power of Spatial-Temporal Masked Autoencoders in Multivariate Time Series Forecasting,"['Jiarui Sun', 'Yujie Fan', 'Chin-Chia Michael Yeh', 'Wei Zhang', 'Girish Chowdhary']","Multivariate time series (MTS) forecasting involves predicting future time
series data based on historical observations. Existing research primarily
emphasizes the development of complex spatial-temporal models that capture
spatial dependencies and temporal correlations among time series variables
explicitly. However, recent advances have been impeded by challenges relating
to data scarcity and model robustness. To address these issues, we propose
Spatial-Temporal Masked Autoencoders (STMAE), an MTS forecasting framework that
leverages masked autoencoders to enhance the performance of spatial-temporal
baseline models. STMAE consists of two learning stages. In the pretraining
stage, an encoder-decoder architecture is employed. The encoder processes the
partially visible MTS data produced by a novel dual-masking strategy, including
biased random walk-based spatial masking and patch-based temporal masking.
Subsequently, the decoders aim to reconstruct the masked counterparts from both
spatial and temporal perspectives. The pretraining stage establishes a
challenging pretext task, compelling the encoder to learn robust
spatial-temporal patterns. In the fine-tuning stage, the pretrained encoder is
retained, and the original decoder from existing spatial-temporal models is
appended for forecasting. Extensive experiments are conducted on multiple MTS
benchmarks. The promising results demonstrate that integrating STMAE into
various spatial-temporal models can largely enhance their MTS forecasting
capability.",http://arxiv.org/pdf/2309.15169v1,cs.LG
2023-09-25 10:51:47+00:00,Diffeomorphic Transformations for Time Series Analysis: An Efficient Approach to Nonlinear Warping,['Iñigo Martinez'],"The proliferation and ubiquity of temporal data across many disciplines has
sparked interest for similarity, classification and clustering methods
specifically designed to handle time series data. A core issue when dealing
with time series is determining their pairwise similarity, i.e., the degree to
which a given time series resembles another. Traditional distance measures such
as the Euclidean are not well-suited due to the time-dependent nature of the
data. Elastic metrics such as dynamic time warping (DTW) offer a promising
approach, but are limited by their computational complexity,
non-differentiability and sensitivity to noise and outliers. This thesis
proposes novel elastic alignment methods that use parametric \& diffeomorphic
warping transformations as a means of overcoming the shortcomings of DTW-based
metrics. The proposed method is differentiable \& invertible, well-suited for
deep learning architectures, robust to noise and outliers, computationally
efficient, and is expressive and flexible enough to capture complex patterns.
Furthermore, a closed-form solution was developed for the gradient of these
diffeomorphic transformations, which allows an efficient search in the
parameter space, leading to better solutions at convergence. Leveraging the
benefits of these closed-form diffeomorphic transformations, this thesis
proposes a suite of advancements that include: (a) an enhanced temporal
transformer network for time series alignment and averaging, (b) a
deep-learning based time series classification model to simultaneously align
and classify signals with high accuracy, (c) an incremental time series
clustering algorithm that is warping-invariant, scalable and can operate under
limited computational and time resources, and finally, (d) a normalizing flow
model that enhances the flexibility of affine transformations in coupling and
autoregressive layers.",http://arxiv.org/pdf/2309.14029v1,cs.LG
2023-09-25 08:31:50+00:00,Local and Global Trend Bayesian Exponential Smoothing Models,"['Slawek Smyl', 'Christoph Bergmeir', 'Alexander Dokumentov', 'Erwin Wibowo', 'Daniel Schmidt']","This paper describes a family of seasonal and non-seasonal time series models
that can be viewed as generalisations of additive and multiplicative
exponential smoothing models. Their development is motivated by fast-growing,
volatile time series, and facilitated by state-of-the-art Bayesian fitting
techniques. When applied to the M3 competition data set, they outperform the
best algorithms in the competition as well as other benchmarks, thus achieving
to the best of our knowledge the best results of univariate methods on this
dataset in the literature.",http://arxiv.org/pdf/2309.13950v1,cs.LG
2023-09-25 01:23:02+00:00,Forecasting large collections of time series: feature-based methods,"['Li Li', 'Feng Li', 'Yanfei Kang']","In economics and many other forecasting domains, the real world problems are
too complex for a single model that assumes a specific data generation process.
The forecasting performance of different methods changes depending on the
nature of the time series. When forecasting large collections of time series,
two lines of approaches have been developed using time series features, namely
feature-based model selection and feature-based model combination. This chapter
discusses the state-of-the-art feature-based methods, with reference to
open-source software implementations.",http://arxiv.org/pdf/2309.13807v1,cs.LG
2023-09-23 18:40:10+00:00,Monotonic Neural Ordinary Differential Equation: Time-series Forecasting for Cumulative Data,"['Zhichao Chen', 'Leilei Ding', 'Zhixuan Chu', 'Yucheng Qi', 'Jianmin Huang', 'Hao Wang']","Time-Series Forecasting based on Cumulative Data (TSFCD) is a crucial problem
in decision-making across various industrial scenarios. However, existing
time-series forecasting methods often overlook two important characteristics of
cumulative data, namely monotonicity and irregularity, which limit their
practical applicability. To address this limitation, we propose a principled
approach called Monotonic neural Ordinary Differential Equation (MODE) within
the framework of neural ordinary differential equations. By leveraging MODE, we
are able to effectively capture and represent the monotonicity and irregularity
in practical cumulative data. Through extensive experiments conducted in a
bonus allocation scenario, we demonstrate that MODE outperforms
state-of-the-art methods, showcasing its ability to handle both monotonicity
and irregularity in cumulative data and delivering superior forecasting
performance.",http://arxiv.org/pdf/2309.13452v1,cs.LG
2023-09-23 17:42:13+00:00,Finding Order in Chaos: A Novel Data Augmentation Method for Time Series in Contrastive Learning,"['Berken Utku Demirel', 'Christian Holz']","The success of contrastive learning is well known to be dependent on data
augmentation. Although the degree of data augmentations has been well
controlled by utilizing pre-defined techniques in some domains like vision,
time-series data augmentation is less explored and remains a challenging
problem due to the complexity of the data generation mechanism, such as the
intricate mechanism involved in the cardiovascular system. Moreover, there is
no widely recognized and general time-series augmentation method that can be
applied across different tasks. In this paper, we propose a novel data
augmentation method for quasi-periodic time-series tasks that aims to connect
intra-class samples together, and thereby find order in the latent space. Our
method builds upon the well-known mixup technique by incorporating a novel
approach that accounts for the periodic nature of non-stationary time-series.
Also, by controlling the degree of chaos created by data augmentation, our
method leads to improved feature representations and performance on downstream
tasks. We evaluate our proposed method on three time-series tasks, including
heart rate estimation, human activity recognition, and cardiovascular disease
detection. Extensive experiments against state-of-the-art methods show that the
proposed approach outperforms prior works on optimal data generation and known
data augmentation techniques in the three tasks, reflecting the effectiveness
of the presented method. Source code:
https://github.com/eth-siplab/Finding_Order_in_Chaos",http://arxiv.org/pdf/2309.13439v1,cs.LG
2023-09-23 15:42:54+00:00,Time-Series Forecasting: Unleashing Long-Term Dependencies with Fractionally Differenced Data,"['Sarit Maitra', 'Vivek Mishra', 'Srashti Dwivedi', 'Sukanya Kundu', 'Goutam Kumar Kundu']","This study introduces a novel forecasting strategy that leverages the power
of fractional differencing (FD) to capture both short- and long-term
dependencies in time series data. Unlike traditional integer differencing
methods, FD preserves memory in series while stabilizing it for modeling
purposes. By applying FD to financial data from the SPY index and incorporating
sentiment analysis from news reports, this empirical analysis explores the
effectiveness of FD in conjunction with binary classification of target
variables. Supervised classification algorithms were employed to validate the
performance of FD series. The results demonstrate the superiority of FD over
integer differencing, as confirmed by Receiver Operating Characteristic/Area
Under the Curve (ROCAUC) and Mathews Correlation Coefficient (MCC) evaluations.",http://arxiv.org/pdf/2309.13409v2,cs.LG
2023-09-22 06:59:14+00:00,OneNet: Enhancing Time Series Forecasting Models under Concept Drift by Online Ensembling,"['Yi-Fan Zhang', 'Qingsong Wen', 'Xue Wang', 'Weiqi Chen', 'Liang Sun', 'Zhang Zhang', 'Liang Wang', 'Rong Jin', 'Tieniu Tan']","Online updating of time series forecasting models aims to address the concept
drifting problem by efficiently updating forecasting models based on streaming
data. Many algorithms are designed for online time series forecasting, with
some exploiting cross-variable dependency while others assume independence
among variables. Given every data assumption has its own pros and cons in
online time series modeling, we propose \textbf{On}line \textbf{e}nsembling
\textbf{Net}work (OneNet). It dynamically updates and combines two models, with
one focusing on modeling the dependency across the time dimension and the other
on cross-variate dependency. Our method incorporates a reinforcement
learning-based approach into the traditional online convex programming
framework, allowing for the linear combination of the two models with
dynamically adjusted weights. OneNet addresses the main shortcoming of
classical online learning methods that tend to be slow in adapting to the
concept drift. Empirical results show that OneNet reduces online forecasting
error by more than $\mathbf{50\%}$ compared to the State-Of-The-Art (SOTA)
method. The code is available at \url{https://github.com/yfzhang114/OneNet}.",http://arxiv.org/pdf/2309.12659v1,cs.LG
2023-09-21 10:34:50+00:00,Generating Hierarchical Structures for Improved Time Series Classification Using Stochastic Splitting Functions,['Celal Alagoz'],"This study introduces a novel hierarchical divisive clustering approach with
stochastic splitting functions (SSFs) to enhance classification performance in
multi-class datasets through hierarchical classification (HC). The method has
the unique capability of generating hierarchy without requiring explicit
information, making it suitable for datasets lacking prior knowledge of
hierarchy. By systematically dividing classes into two subsets based on their
discriminability according to the classifier, the proposed approach constructs
a binary tree representation of hierarchical classes. The approach is evaluated
on 46 multi-class time series datasets using popular classifiers (svm and
rocket) and SSFs (potr, srtr, and lsoo). The results reveal that the approach
significantly improves classification performance in approximately half and a
third of the datasets when using rocket and svm as the classifier,
respectively. The study also explores the relationship between dataset features
and HC performance. While the number of classes and flat classification (FC)
score show consistent significance, variations are observed with different
splitting functions. Overall, the proposed approach presents a promising
strategy for enhancing classification by generating hierarchical structure in
multi-class time series datasets. Future research directions involve exploring
different splitting functions, classifiers, and hierarchy structures, as well
as applying the approach to diverse domains beyond time series data. The source
code is made openly available to facilitate reproducibility and further
exploration of the method.",http://arxiv.org/pdf/2309.11963v1,cs.LG
2023-09-20 16:01:45+00:00,Generative Pre-Training of Time-Series Data for Unsupervised Fault Detection in Semiconductor Manufacturing,"['Sewoong Lee', 'JinKyou Choi', 'Min Su Kim']","This paper introduces TRACE-GPT, which stands for Time-seRies
Anomaly-detection with Convolutional Embedding and Generative Pre-trained
Transformers. TRACE-GPT is designed to pre-train univariate time-series sensor
data and detect faults on unlabeled datasets in semiconductor manufacturing. In
semiconductor industry, classifying abnormal time-series sensor data from
normal data is important because it is directly related to wafer defect.
However, small, unlabeled, and even mixed training data without enough
anomalies make classification tasks difficult. In this research, we capture
features of time-series data with temporal convolutional embedding and
Generative Pre-trained Transformer (GPT) to classify abnormal sequences from
normal sequences using cross entropy loss. We prove that our model shows better
performance than previous unsupervised models with both an open dataset, the
University of California Riverside (UCR) time-series classification archive,
and the process log of our Chemical Vapor Deposition (CVD) equipment. Our model
has the highest F1 score at Equal Error Rate (EER) across all datasets and is
only 0.026 below the supervised state-of-the-art baseline on the open dataset.",http://arxiv.org/pdf/2309.11427v1,cs.LG
2023-09-20 14:54:48+00:00,Learning Patient Static Information from Time-series EHR and an Approach for Safeguarding Privacy and Fairness,"['Wei Liao', 'Joel Voldman']","Recent work in machine learning for healthcare has raised concerns about
patient privacy and algorithmic fairness. For example, previous work has shown
that patient self-reported race can be predicted from medical data that does
not explicitly contain racial information. However, the extent of data
identification is unknown, and we lack ways to develop models whose outcomes
are minimally affected by such information. Here we systematically investigated
the ability of time-series electronic health record data to predict patient
static information. We found that not only the raw time-series data, but also
learned representations from machine learning models, can be trained to predict
a variety of static information with area under the receiver operating
characteristic curve as high as 0.851 for biological sex, 0.869 for binarized
age and 0.810 for self-reported race. Such high predictive performance can be
extended to a wide range of comorbidity factors and exists even when the model
was trained for different tasks, using different cohorts, using different model
architectures and databases. Given the privacy and fairness concerns these
findings pose, we develop a variational autoencoder-based approach that learns
a structured latent space to disentangle patient-sensitive attributes from
time-series data. Our work thoroughly investigates the ability of machine
learning models to encode patient static information from time-series
electronic health records and introduces a general approach to protect
patient-sensitive attribute information for downstream tasks.",http://arxiv.org/pdf/2309.11373v1,cs.LG
2023-09-20 13:44:18+00:00,WFTNet: Exploiting Global and Local Periodicity in Long-term Time Series Forecasting,"['Peiyuan Liu', 'Beiliang Wu', 'Naiqi Li', 'Tao Dai', 'Fengmao Lei', 'Jigang Bao', 'Yong Jiang', 'Shu-Tao Xia']","Recent CNN and Transformer-based models tried to utilize frequency and
periodicity information for long-term time series forecasting. However, most
existing work is based on Fourier transform, which cannot capture fine-grained
and local frequency structure. In this paper, we propose a Wavelet-Fourier
Transform Network (WFTNet) for long-term time series forecasting. WFTNet
utilizes both Fourier and wavelet transforms to extract comprehensive
temporal-frequency information from the signal, where Fourier transform
captures the global periodic patterns and wavelet transform captures the local
ones. Furthermore, we introduce a Periodicity-Weighted Coefficient (PWC) to
adaptively balance the importance of global and local frequency patterns.
Extensive experiments on various time series datasets show that WFTNet
consistently outperforms other state-of-the-art baseline.",http://arxiv.org/pdf/2309.11319v1,cs.LG
2023-09-19 14:40:13+00:00,Implementing a new fully stepwise decomposition-based sampling technique for the hybrid water level forecasting model in real-world application,"['Ziqian Zhang', 'Nana Bao', 'Xingting Yan', 'Aokai Zhu', 'Chenyang Li', 'Mingyu Liu']","Various time variant non-stationary signals need to be pre-processed properly
in hydrological time series forecasting in real world, for example, predictions
of water level. Decomposition method is a good candidate and widely used in
such a pre-processing problem. However, decomposition methods with an
inappropriate sampling technique may introduce future data which is not
available in practical applications, and result in incorrect
decomposition-based forecasting models. In this work, a novel Fully Stepwise
Decomposition-Based (FSDB) sampling technique is well designed for the
decomposition-based forecasting model, strictly avoiding introducing future
information. This sampling technique with decomposition methods, such as
Variational Mode Decomposition (VMD) and Singular spectrum analysis (SSA), is
applied to predict water level time series in three different stations of
Guoyang and Chaohu basins in China. Results of VMD-based hybrid model using
FSDB sampling technique show that Nash-Sutcliffe Efficiency (NSE) coefficient
is increased by 6.4%, 28.8% and 7.0% in three stations respectively, compared
with those obtained from the currently most advanced sampling technique. In the
meantime, for series of SSA-based experiments, NSE is increased by 3.2%, 3.1%
and 1.1% respectively. We conclude that the newly developed FSDB sampling
technique can be used to enhance the performance of decomposition-based hybrid
model in water level time series forecasting in real world.",http://arxiv.org/pdf/2309.10658v1,cs.LG
2023-09-19 13:41:15+00:00,"An overview of time series point and interval forecasting based on similarity of trajectories, with an experimental study on traffic flow forecasting","['İlker Arslan', 'Can Hakan Dağıdır', 'Ümit Işlak']","The purpose of this paper is to give an overview of the time series
forecasting problem based on similarity of trajectories. Various methodologies
are introduced and studied, and detailed discussions on hyperparameter
optimization, outlier handling and distance measures are provided. The
suggested new approaches involve variations in both the selection of similar
trajectories and assembling the candidate forecasts. After forming a general
framework, an experimental study is conducted to compare the methods that use
similar trajectories along with some other standard models (such as ARIMA and
Random Forest) from the literature. Lastly, the forecasting setting is extended
to interval forecasts, and the prediction intervals resulting from the similar
trajectories approach are compared with the existing models from the
literature, such as historical simulation and quantile regression. Throughout
the paper, the experimentations and comparisons are conducted via the time
series of traffic flow from the California PEMS dataset.",http://arxiv.org/pdf/2309.10613v1,stat.ME
2023-09-19 12:00:28+00:00,Hybrid State Space-based Learning for Sequential Data Prediction with Joint Optimization,"['Mustafa E. Aydın', 'Arda Fazla', 'Suleyman S. Kozat']","We investigate nonlinear prediction/regression in an online setting and
introduce a hybrid model that effectively mitigates, via a joint mechanism
through a state space formulation, the need for domain-specific feature
engineering issues of conventional nonlinear prediction models and achieves an
efficient mix of nonlinear and linear components. In particular, we use
recursive structures to extract features from raw sequential sequences and a
traditional linear time series model to deal with the intricacies of the
sequential data, e.g., seasonality, trends. The state-of-the-art ensemble or
hybrid models typically train the base models in a disjoint manner, which is
not only time consuming but also sub-optimal due to the separation of modeling
or independent training. In contrast, as the first time in the literature, we
jointly optimize an enhanced recurrent neural network (LSTM) for automatic
feature extraction from raw data and an ARMA-family time series model (SARIMAX)
for effectively addressing peculiarities associated with time series data. We
achieve this by introducing novel state space representations for the base
models, which are then combined to provide a full state space representation of
the hybrid or the ensemble. Hence, we are able to jointly optimize both models
in a single pass via particle filtering, for which we also provide the update
equations. The introduced architecture is generic so that one can use other
recurrent architectures, e.g., GRUs, traditional time series-specific models,
e.g., ETS or other optimization methods, e.g., EKF, UKF. Due to such novel
combination and joint optimization, we demonstrate significant improvements in
widely publicized real life competition datasets. We also openly share our code
for further research and replicability of our results.",http://arxiv.org/pdf/2309.10553v1,stat.ML
2023-09-18 22:25:12+00:00,Graph-enabled Reinforcement Learning for Time Series Forecasting with Adaptive Intelligence,"['Thanveer Shaik', 'Xiaohui Tao', 'Haoran Xie', 'Lin Li', 'Jianming Yong', 'Yuefeng Li']","Reinforcement learning is well known for its ability to model sequential
tasks and learn latent data patterns adaptively. Deep learning models have been
widely explored and adopted in regression and classification tasks. However,
deep learning has its limitations such as the assumption of equally spaced and
ordered data, and the lack of ability to incorporate graph structure in terms
of time-series prediction. Graphical neural network (GNN) has the ability to
overcome these challenges and capture the temporal dependencies in time-series
data. In this study, we propose a novel approach for predicting time-series
data using GNN and monitoring with Reinforcement Learning (RL). GNNs are able
to explicitly incorporate the graph structure of the data into the model,
allowing them to capture temporal dependencies in a more natural way. This
approach allows for more accurate predictions in complex temporal structures,
such as those found in healthcare, traffic and weather forecasting. We also
fine-tune our GraphRL model using a Bayesian optimisation technique to further
improve performance. The proposed framework outperforms the baseline models in
time-series forecasting and monitoring. The contributions of this study include
the introduction of a novel GraphRL framework for time-series prediction and
the demonstration of the effectiveness of GNNs in comparison to traditional
deep learning models such as RNNs and LSTMs. Overall, this study demonstrates
the potential of GraphRL in providing accurate and efficient predictions in
dynamic RL environments.",http://arxiv.org/pdf/2309.10186v1,cs.LG
2023-09-18 18:17:07+00:00,Transformed-Linear Innovations Algorithm for Modeling and Forecasting of Time Series Extremes,"['Nehali Mhatre', 'Daniel Cooley']","The innovations algorithm is a classical recursive forecasting algorithm used
in time series analysis. We develop the innovations algorithm for a class of
nonnegative regularly varying time series models constructed via
transformed-linear arithmetic. In addition to providing the best linear
predictor, the algorithm also enables us to estimate parameters of
transformed-linear regularly-varying moving average (MA) models, thus providing
a tool for modeling.
  We first construct an inner product space of transformed-linear combinations
of nonnegative regularly-varying random variables and prove its link to a
Hilbert space which allows us to employ the projection theorem, from which we
develop the transformed-linear innovations algorithm. Turning our attention to
the class of transformed linear MA($\infty$) models, we give results on
parameter estimation and also show that this class of models is dense in the
class of possible tail pairwise dependence functions (TPDFs). We also develop
an extremes analogue of the classical Wold decomposition. Simulation study
shows that our class of models captures tail dependence for the GARCH(1,1)
model and a Markov time series model, both of which are outside our class of
models.",http://arxiv.org/pdf/2309.10061v1,math.ST
2023-09-18 17:51:47+00:00,Empirical Study of Mix-based Data Augmentation Methods in Physiological Time Series Data,"['Peikun Guo', 'Huiyuan Yang', 'Akane Sano']","Data augmentation is a common practice to help generalization in the
procedure of deep model training. In the context of physiological time series
classification, previous research has primarily focused on label-invariant data
augmentation methods. However, another class of augmentation techniques
(\textit{i.e., Mixup}) that emerged in the computer vision field has yet to be
fully explored in the time series domain. In this study, we systematically
review the mix-based augmentations, including mixup, cutmix, and manifold
mixup, on six physiological datasets, evaluating their performance across
different sensory data and classification tasks. Our results demonstrate that
the three mix-based augmentations can consistently improve the performance on
the six datasets. More importantly, the improvement does not rely on expert
knowledge or extensive parameter tuning. Lastly, we provide an overview of the
unique properties of the mix-based augmentation methods and highlight the
potential benefits of using the mix-based augmentation in physiological time
series data.",http://arxiv.org/pdf/2309.09970v1,cs.LG
2023-09-18 14:50:46+00:00,Clustering of Urban Traffic Patterns by K-Means and Dynamic Time Warping: Case Study,"['Sadegh Etemad', 'Raziyeh Mosayebi', 'Tadeh Alexani Khodavirdian', 'Elahe Dastan', 'Amir Salari Telmadarreh', 'Mohammadreza Jafari', 'Sepehr Rafiei']","Clustering of urban traffic patterns is an essential task in many different
areas of traffic management and planning. In this paper, two significant
applications in the clustering of urban traffic patterns are described. The
first application estimates the missing speed values using the speed of road
segments with similar traffic patterns to colorify map tiles. The second one is
the estimation of essential road segments for generating addresses for a local
point on the map, using the similarity patterns of different road segments. The
speed time series extracts the traffic pattern in different road segments. In
this paper, we proposed the time series clustering algorithm based on K-Means
and Dynamic Time Warping. The case study of our proposed algorithm is based on
the Snapp application's driver speed time series data. The results of the two
applications illustrate that the proposed method can extract similar urban
traffic patterns.",http://arxiv.org/pdf/2309.09830v1,cs.LG
2023-09-16 18:46:34+00:00,Test-Time Compensated Representation Learning for Extreme Traffic Forecasting,"['Zhiwei Zhang', 'Weizhong Zhang', 'Yaowei Huang', 'Kani Chen']","Traffic forecasting is a challenging task due to the complex spatio-temporal
correlations among traffic series. In this paper, we identify an underexplored
problem in multivariate traffic series prediction: extreme events. Road
congestion and rush hours can result in low correlation in vehicle speeds at
various intersections during adjacent time periods. Existing methods generally
predict future series based on recent observations and entirely discard
training data during the testing phase, rendering them unreliable for
forecasting highly nonlinear multivariate time series. To tackle this issue, we
propose a test-time compensated representation learning framework comprising a
spatio-temporal decomposed data bank and a multi-head spatial transformer model
(CompFormer). The former component explicitly separates all training data along
the temporal dimension according to periodicity characteristics, while the
latter component establishes a connection between recent observations and
historical series in the data bank through a spatial attention matrix. This
enables the CompFormer to transfer robust features to overcome anomalous events
while using fewer computational resources. Our modules can be flexibly
integrated with existing forecasting methods through end-to-end training, and
we demonstrate their effectiveness on the METR-LA and PEMS-BAY benchmarks.
Extensive experimental results show that our method is particularly important
in extreme events, and can achieve significant improvements over six strong
baselines, with an overall improvement of up to 28.2%.",http://arxiv.org/pdf/2309.09074v1,cs.LG
2023-09-15 16:03:23+00:00,P-ROCKET: Pruning Random Convolution Kernels for Time Series Classification,"['Shaowu Chen', 'Weize Sun', 'Lei Huang', 'Xiaopeng Li', 'Qingyuan Wang', 'Deepu John']","In recent years, two time series classification models, ROCKET and
MINIROCKET, have attracted much attention for their low training cost and
state-of-the-art accuracy. Utilizing random 1-D convolutional kernels without
training, ROCKET and MINIROCKET can rapidly extract features from time series
data, allowing for the efficient fitting of linear classifiers. However, to
comprehensively capture useful features, a large number of random kernels are
required, which is incompatible for resource-constrained devices. Therefore, a
heuristic evolutionary algorithm named S-ROCKET is devised to recognize and
prune redundant kernels. Nevertheless, the inherent nature of evolutionary
algorithms renders the evaluation of kernels within S-ROCKET an unacceptable
time-consuming process. In this paper, diverging from S-ROCKET, which directly
evaluates random kernels with nonsignificant differences, we remove kernels
from a feature selection perspective by eliminating associating connections in
the sequential classification layer. To this end, we start by formulating the
pruning challenge as a Group Elastic Net classification problem and employ the
ADMM method to arrive at a solution. Sequentially, we accelerate the
aforementioned time-consuming solving process by bifurcating the $l_{2,1}$ and
$l_2$ regularizations into two sequential stages and solve them separately,
which ultimately forms our core algorithm, named P-ROCKET. Stage 1 of P-ROCKET
employs group-wise regularization similarly to our initial ADMM-based
Algorithm, but introduces dynamically varying penalties to greatly accelerate
the process. To mitigate overfitting, Stage 2 of P-ROCKET implements
element-wise regularization to refit a linear classifier, utilizing the
retained features.",http://arxiv.org/pdf/2309.08499v1,cs.LG
2023-09-15 15:47:08+00:00,A Random Graph-based Autoregressive Model for Networked Time Series,"['Weichi Wu', 'Chenlei Leng']","Contemporary time series data often feature objects connected by a social
network that naturally induces temporal dependence involving connected
neighbours. The network vector autoregressive model is useful for describing
the influence of linked neighbours, while recent generalizations aim to
separate influence and homophily. Existing approaches, however, require either
correct specification of a time series model or accurate estimation of a
network model or both, and rely exclusively on least-squares for parameter
estimation. This paper proposes a new autoregressive model incorporating a
flexible form for latent variables used to depict homophily. We develop a
first-order differencing method for the estimation of influence requiring only
the influence part of the model to be correctly specified. When the part
including homophily is correctly specified admitting a semiparametric form, we
leverage and generalize the recent notion of neighbour smoothing for parameter
estimation, bypassing the need to specify the generative mechanism of the
network. We develop new theory to show that all the estimated parameters are
consistent and asymptotically normal. The efficacy of our approach is confirmed
via extensive simulations and an analysis of a social media dataset.",http://arxiv.org/pdf/2309.08488v1,stat.ME
2023-09-14 08:49:35+00:00,Learning Beyond Similarities: Incorporating Dissimilarities between Positive Pairs in Self-Supervised Time Series Learning,"['Adrian Atienza', 'Jakob Bardram', 'Sadasivan Puthusserypady']","By identifying similarities between successive inputs, Self-Supervised
Learning (SSL) methods for time series analysis have demonstrated their
effectiveness in encoding the inherent static characteristics of temporal data.
However, an exclusive emphasis on similarities might result in representations
that overlook the dynamic attributes critical for modeling cardiovascular
diseases within a confined subject cohort. Introducing Distilled Encoding
Beyond Similarities (DEBS), this paper pioneers an SSL approach that transcends
mere similarities by integrating dissimilarities among positive pairs. The
framework is applied to electrocardiogram (ECG) signals, leading to a notable
enhancement of +10\% in the detection accuracy of Atrial Fibrillation (AFib)
across diverse subjects. DEBS underscores the potential of attaining a more
refined representation by encoding the dynamic characteristics of time series
data, tapping into dissimilarities during the optimization process. Broadly,
the strategy delineated in this study holds the promise of unearthing novel
avenues for advancing SSL methodologies tailored to temporal data.",http://arxiv.org/pdf/2309.07526v1,cs.LG
2023-09-14 05:34:59+00:00,Uncertainty Intervals for Prediction Errors in Time Series Forecasting,"['Hui Xu', 'Song Mei', 'Stephen Bates', 'Jonathan Taylor', 'Robert Tibshirani']","Inference for prediction errors is critical in time series forecasting
pipelines. However, providing statistically meaningful uncertainty intervals
for prediction errors remains relatively under-explored. Practitioners often
resort to forward cross-validation (FCV) for obtaining point estimators and
constructing confidence intervals based on the Central Limit Theorem (CLT). The
naive version assumes independence, a condition that is usually invalid due to
time correlation. These approaches lack statistical interpretations and
theoretical justifications even under stationarity.
  This paper systematically investigates uncertainty intervals for prediction
errors in time series forecasting. We first distinguish two key inferential
targets: the stochastic test error over near future data points, and the
expected test error as the expectation of the former. The stochastic test error
is often more relevant in applications needing to quantify uncertainty over
individual time series instances. To construct prediction intervals for the
stochastic test error, we propose the quantile-based forward cross-validation
(QFCV) method. Under an ergodicity assumption, QFCV intervals have
asymptotically valid coverage and are shorter than marginal empirical
quantiles. In addition, we also illustrate why naive CLT-based FCV intervals
fail to provide valid uncertainty intervals, even with certain corrections. For
non-stationary time series, we further provide rolling intervals by combining
QFCV with adaptive conformal prediction to give time-average coverage
guarantees. Overall, we advocate the use of QFCV procedures and demonstrate
their coverage and efficiency through simulations and real data examples.",http://arxiv.org/pdf/2309.07435v1,stat.ME
2023-09-13 11:15:56+00:00,Spatial autoregressive fractionally integrated moving average model,"['Philipp Otto', 'Philipp Sibbertsen']","In this paper, we introduce the concept of fractional integration for spatial
autoregressive models. We show that the range of the dependence can be
spatially extended or diminished by introducing a further fractional
integration parameter to spatial autoregressive moving average models (SARMA).
This new model is called the spatial autoregressive fractionally integrated
moving average model, briefly sp-ARFIMA. We show the relation to time-series
ARFIMA models and also to (higher-order) spatial autoregressive models.
Moreover, an estimation procedure based on the maximum-likelihood principle is
introduced and analysed in a series of simulation studies. Eventually, the use
of the model is illustrated by an empirical example of atmospheric fine
particles, so-called aerosol optical thickness, which is important in weather,
climate and environmental science.",http://arxiv.org/pdf/2309.06880v1,stat.ME
2023-09-13 06:15:37+00:00,MCNS: Mining Causal Natural Structures Inside Time Series via A Novel Internal Causality Scheme,"['Yuanhao Liu', 'Dehui Du', 'Zihan Jiang', 'Anyan Huang', 'Yiyang Li']","Causal inference permits us to discover covert relationships of various
variables in time series. However, in most existing works, the variables
mentioned above are the dimensions. The causality between dimensions could be
cursory, which hinders the comprehension of the internal relationship and the
benefit of the causal graph to the neural networks (NNs). In this paper, we
find that causality exists not only outside but also inside the time series
because it reflects a succession of events in the real world. It inspires us to
seek the relationship between internal subsequences. However, the challenges
are the hardship of discovering causality from subsequences and utilizing the
causal natural structures to improve NNs. To address these challenges, we
propose a novel framework called Mining Causal Natural Structure (MCNS), which
is automatic and domain-agnostic and helps to find the causal natural
structures inside time series via the internal causality scheme. We evaluate
the MCNS framework and impregnation NN with MCNS on time series classification
tasks. Experimental results illustrate that our impregnation, by refining
attention, shape selection classification, and pruning datasets, drives NN,
even the data itself preferable accuracy and interpretability. Besides, MCNS
provides an in-depth, solid summary of the time series and datasets.",http://arxiv.org/pdf/2309.06739v1,cs.LG
2023-09-12 10:07:31+00:00,Pseudo-variance quasi-maximum likelihood estimation of semi-parametric time series models,"['Mirko Armillotta', 'Paolo Gorgi']","We propose a novel estimation approach for a general class of semi-parametric
time series models where the conditional expectation is modeled through a
parametric function. The proposed class of estimators is based on a Gaussian
quasi-likelihood function and it relies on the specification of a parametric
pseudo-variance that can contain parametric restrictions with respect to the
conditional expectation. The specification of the pseudo-variance and the
parametric restrictions follow naturally in observation-driven models with
bounds in the support of the observable process, such as count processes and
double-bounded time series. We derive the asymptotic properties of the
estimators and a validity test for the parameter restrictions. We show that the
results remain valid irrespective of the correct specification of the
pseudo-variance. The key advantage of the restricted estimators is that they
can achieve higher efficiency compared to alternative quasi-likelihood methods
that are available in the literature. Furthermore, the testing approach can be
used to build specification tests for parametric time series models. We
illustrate the practical use of the methodology in a simulation study and two
empirical applications featuring integer-valued autoregressive processes, where
assumptions on the dispersion of the thinning operator are formally tested, and
autoregressions for double-bounded data with application to a realized
correlation time series.",http://arxiv.org/pdf/2309.06100v1,stat.ME
2023-09-11 22:08:09+00:00,Effective Abnormal Activity Detection on Multivariate Time Series Healthcare Data,"['Mengjia Niu', 'Yuchen Zhao', 'Hamed Haddadi']","Multivariate time series (MTS) data collected from multiple sensors provide
the potential for accurate abnormal activity detection in smart healthcare
scenarios. However, anomalies exhibit diverse patterns and become unnoticeable
in MTS data. Consequently, achieving accurate anomaly detection is challenging
since we have to capture both temporal dependencies of time series and
inter-relationships among variables. To address this problem, we propose a
Residual-based Anomaly Detection approach, Rs-AD, for effective representation
learning and abnormal activity detection. We evaluate our scheme on a
real-world gait dataset and the experimental results demonstrate an F1 score of
0.839.",http://arxiv.org/pdf/2309.05845v1,cs.LG
2023-09-11 06:26:57+00:00,Examining the Effect of Pre-training on Time Series Classification,"['Jiashu Pu', 'Shiwei Zhao', 'Ling Cheng', 'Yongzhu Chang', 'Runze Wu', 'Tangjie Lv', 'Rongsheng Zhang']","Although the pre-training followed by fine-tuning paradigm is used
extensively in many fields, there is still some controversy surrounding the
impact of pre-training on the fine-tuning process. Currently, experimental
findings based on text and image data lack consensus. To delve deeper into the
unsupervised pre-training followed by fine-tuning paradigm, we have extended
previous research to a new modality: time series. In this study, we conducted a
thorough examination of 150 classification datasets derived from the Univariate
Time Series (UTS) and Multivariate Time Series (MTS) benchmarks. Our analysis
reveals several key conclusions. (i) Pre-training can only help improve the
optimization process for models that fit the data poorly, rather than those
that fit the data well. (ii) Pre-training does not exhibit the effect of
regularization when given sufficient training time. (iii) Pre-training can only
speed up convergence if the model has sufficient ability to fit the data. (iv)
Adding more pre-training data does not improve generalization, but it can
strengthen the advantage of pre-training on the original data volume, such as
faster convergence. (v) While both the pre-training task and the model
structure determine the effectiveness of the paradigm on a given dataset, the
model structure plays a more significant role.",http://arxiv.org/pdf/2309.05256v1,cs.LG
2023-09-09 09:33:25+00:00,TCGAN: Convolutional Generative Adversarial Network for Time Series Classification and Clustering,"['Fanling Huang', 'Yangdong Deng']","Recent works have demonstrated the superiority of supervised Convolutional
Neural Networks (CNNs) in learning hierarchical representations from time
series data for successful classification. These methods require sufficiently
large labeled data for stable learning, however acquiring high-quality labeled
time series data can be costly and potentially infeasible. Generative
Adversarial Networks (GANs) have achieved great success in enhancing
unsupervised and semi-supervised learning. Nonetheless, to our best knowledge,
it remains unclear how effectively GANs can serve as a general-purpose solution
to learn representations for time series recognition, i.e., classification and
clustering. The above considerations inspire us to introduce a Time-series
Convolutional GAN (TCGAN). TCGAN learns by playing an adversarial game between
two one-dimensional CNNs (i.e., a generator and a discriminator) in the absence
of label information. Parts of the trained TCGAN are then reused to construct a
representation encoder to empower linear recognition methods. We conducted
comprehensive experiments on synthetic and real-world datasets. The results
demonstrate that TCGAN is faster and more accurate than existing time-series
GANs. The learned representations enable simple classification and clustering
methods to achieve superior and stable performance. Furthermore, TCGAN retains
high efficacy in scenarios with few-labeled and imbalanced-labeled data. Our
work provides a promising path to effectively utilize abundant unlabeled time
series data.",http://arxiv.org/pdf/2309.04732v1,cs.LG
2023-09-07 09:18:12+00:00,DTW+S: Shape-based Comparison of Time-series with Ordered Local Trend,['Ajitesh Srivastava'],"Measuring distance or similarity between time-series data is a fundamental
aspect of many applications including classification and clustering. Existing
measures may fail to capture similarities due to local trends (shapes) and may
even produce misleading results. Our goal is to develop a measure that looks
for similar trends occurring around similar times and is easily interpretable
for researchers in applied domains. This is particularly useful for
applications where time-series have a sequence of meaningful local trends that
are ordered, such as in epidemics (a surge to an increase to a peak to a
decrease). We propose a novel measure, DTW+S, which creates an interpretable
""closeness-preserving"" matrix representation of the time-series, where each
column represents local trends, and then it applies Dynamic Time Warping to
compute distances between these matrices. We present a theoretical analysis
that supports the choice of this representation. We demonstrate the utility of
DTW+S in ensemble building and clustering of epidemic curves. We also
demonstrate that our approach results in better classification compared to
Dynamic Time Warping for a class of datasets, particularly when local trends
rather than scale play a decisive role.",http://arxiv.org/pdf/2309.03579v1,cs.LG
2023-09-06 02:52:21+00:00,Denoising and Multilinear Dimension-Reduction of High-Dimensional Matrix-Variate Time Series via a Factor Model,"['Zhaoxing Gao', 'Ruey S. Tsay']","This paper proposes a new multilinear projection method for
dimension-reduction in modeling high-dimensional matrix-variate time series. It
assumes that a $p_1\times p_2$ matrix-variate time series consists of a
dynamically dependent, lower-dimensional matrix-variate factor process and a
$p_1\times p_2$ matrix white noise series. Covariance matrix of the vectorized
white noises assumes a Kronecker structure such that the row and column
covariances of the noise all have diverging/spiked eigenvalues to accommodate
the case of low signal-to-noise ratio often encountered in applications, such
as in finance and economics. We use an iterative projection procedure to
{reduce the dimensions and noise effects in estimating} front and back loading
matrices and {to} obtain faster convergence rates than those of the traditional
methods available in the literature. Furthermore, we introduce a two-way
projected Principal Component Analysis to mitigate the diverging noise effects,
and implement a high-dimensional white-noise testing procedure to estimate the
dimension of the factor matrix. Asymptotic properties of the proposed method
are established as the dimensions and sample size go to infinity. Simulated and
real examples are used to assess the performance of the proposed method. We
also compared the proposed method with some existing ones in the literature
concerning the forecasting ability of the identified factors and found that the
proposed approach fares well in out-of-sample forecasting.",http://arxiv.org/pdf/2309.02674v1,stat.ME
2023-09-05 13:58:59+00:00,Encoding Seasonal Climate Predictions for Demand Forecasting with Modular Neural Network,"['Smit Marvaniya', 'Jitendra Singh', 'Nicolas Galichet', 'Fred Ochieng Otieno', 'Geeth De Mel', 'Kommy Weldemariam']","Current time-series forecasting problems use short-term weather attributes as
exogenous inputs. However, in specific time-series forecasting solutions (e.g.,
demand prediction in the supply chain), seasonal climate predictions are
crucial to improve its resilience. Representing mid to long-term seasonal
climate forecasts is challenging as seasonal climate predictions are uncertain,
and encoding spatio-temporal relationship of climate forecasts with demand is
complex.
  We propose a novel modeling framework that efficiently encodes seasonal
climate predictions to provide robust and reliable time-series forecasting for
supply chain functions. The encoding framework enables effective learning of
latent representations -- be it uncertain seasonal climate prediction or other
time-series data (e.g., buyer patterns) -- via a modular neural network
architecture. Our extensive experiments indicate that learning such
representations to model seasonal climate forecast results in an error
reduction of approximately 13\% to 17\% across multiple real-world data sets
compared to existing demand forecasting methods.",http://arxiv.org/pdf/2309.02248v1,cs.LG
2023-09-05 06:51:39+00:00,sasdim: self-adaptive noise scaling diffusion model for spatial time series imputation,"['Shunyang Zhang', 'Senzhang Wang', 'Xianzhen Tan', 'Ruochen Liu', 'Jian Zhang', 'Jianxin Wang']","Spatial time series imputation is critically important to many real
applications such as intelligent transportation and air quality monitoring.
Although recent transformer and diffusion model based approaches have achieved
significant performance gains compared with conventional statistic based
methods, spatial time series imputation still remains as a challenging issue
due to the complex spatio-temporal dependencies and the noise uncertainty of
the spatial time series data. Especially, recent diffusion process based models
may introduce random noise to the imputations, and thus cause negative impact
on the model performance. To this end, we propose a self-adaptive noise scaling
diffusion model named SaSDim to more effectively perform spatial time series
imputation. Specially, we propose a new loss function that can scale the noise
to the similar intensity, and propose the across spatial-temporal global
convolution module to more effectively capture the dynamic spatial-temporal
dependencies. Extensive experiments conducted on three real world datasets
verify the effectiveness of SaSDim by comparison with current state-of-the-art
baselines.",http://arxiv.org/pdf/2309.01988v1,cs.LG
2023-09-04 09:08:22+00:00,On the Consistency and Robustness of Saliency Explanations for Time Series Classification,"['Chiara Balestra', 'Bin Li', 'Emmanuel Müller']","Interpretable machine learning and explainable artificial intelligence have
become essential in many applications. The trade-off between interpretability
and model performance is the traitor to developing intrinsic and model-agnostic
interpretation methods. Although model explanation approaches have achieved
significant success in vision and natural language domains, explaining time
series remains challenging. The complex pattern in the feature domain, coupled
with the additional temporal dimension, hinders efficient interpretation.
Saliency maps have been applied to interpret time series windows as images.
However, they are not naturally designed for sequential data, thus suffering
various issues.
  This paper extensively analyzes the consistency and robustness of saliency
maps for time series features and temporal attribution. Specifically, we
examine saliency explanations from both perturbation-based and gradient-based
explanation models in a time series classification task. Our experimental
results on five real-world datasets show that they all lack consistent and
robust performances to some extent. By drawing attention to the flawed saliency
explanation models, we motivate to develop consistent and robust explanations
for time series classification.",http://arxiv.org/pdf/2309.01457v1,cs.LG
2023-09-04 00:30:25+00:00,Communication-Efficient Design of Learning System for Energy Demand Forecasting of Electrical Vehicles,"['Jiacong Xu', 'Riley Kilfoyle', 'Zixiang Xiong', 'Ligang Lu']","Machine learning (ML) applications to time series energy utilization
forecasting problems are a challenging assignment due to a variety of factors.
Chief among these is the non-homogeneity of the energy utilization datasets and
the geographical dispersion of energy consumers. Furthermore, these ML models
require vast amounts of training data and communications overhead in order to
develop an effective model. In this paper, we propose a communication-efficient
time series forecasting model combining the most recent advancements in
transformer architectures implemented across a geographically dispersed series
of EV charging stations and an efficient variant of federated learning (FL) to
enable distributed training. The time series prediction performance and
communication overhead cost of our FL are compared against their counterpart
models and shown to have parity in performance while consuming significantly
lower data rates during training. Additionally, the comparison is made across
EV charging as well as other time series datasets to demonstrate the
flexibility of our proposed model in generalized time series prediction beyond
energy demand. The source code for this work is available at
https://github.com/XuJiacong/LoGTST_PSGF",http://arxiv.org/pdf/2309.01297v1,cs.LG
2023-08-31 18:37:43+00:00,Locally Adaptive Shrinkage Priors for Trends and Breaks in Count Time Series,"['Toryn L. J. Schafer', 'David S. Matteson']","Non-stationary count time series characterized by features such as abrupt
changes and fluctuations about the trend arise in many scientific domains
including biophysics, ecology, energy, epidemiology, and social science
domains. Current approaches for integer-valued time series lack the flexibility
to capture local transient features while more flexible models for continuous
data types are inadequate for universal applications to integer-valued
responses such as settings with small counts. We present a modeling framework,
the negative binomial Bayesian trend filter (NB-BTF), that offers an adaptive
model-based solution to capturing multiscale features with valid integer-valued
inference for trend filtering. The framework is a hierarchical Bayesian model
with a dynamic global-local shrinkage process. The flexibility of the
global-local process allows for the necessary local regularization while the
temporal dependence induces a locally smooth trend. In simulation, the NB-BTF
outperforms a number of alternative trend filtering methods. Then, we
demonstrate the method on weekly power outage frequency in Massachusetts
townships. Power outage frequency is characterized by a nominal low level with
occasional spikes. These illustrations show the estimation of a smooth,
non-stationary trend with adequate uncertainty quantification.",http://arxiv.org/pdf/2309.00080v1,stat.ME
2023-08-30 19:13:10+00:00,Classification of Anomalies in Telecommunication Network KPI Time Series,"['Korantin Bordeau-Aubert', 'Justin Whatley', 'Sylvain Nadeau', 'Tristan Glatard', 'Brigitte Jaumard']","The increasing complexity and scale of telecommunication networks have led to
a growing interest in automated anomaly detection systems. However, the
classification of anomalies detected on network Key Performance Indicators
(KPI) has received less attention, resulting in a lack of information about
anomaly characteristics and classification processes. To address this gap, this
paper proposes a modular anomaly classification framework. The framework
assumes separate entities for the anomaly classifier and the detector, allowing
for a distinct treatment of anomaly detection and classification tasks on time
series. The objectives of this study are (1) to develop a time series simulator
that generates synthetic time series resembling real-world network KPI
behavior, (2) to build a detection model to identify anomalies in the time
series, (3) to build classification models that accurately categorize detected
anomalies into predefined classes (4) to evaluate the classification framework
performance on simulated and real-world network KPI time series. This study has
demonstrated the good performance of the anomaly classification models trained
on simulated anomalies when applied to real-world network time series data.",http://arxiv.org/pdf/2308.16279v1,cs.LG
2023-08-29 11:24:12+00:00,Evaluating Explanation Methods for Multivariate Time Series Classification,"['Davide Italo Serramazza', 'Thu Trang Nguyen', 'Thach Le Nguyen', 'Georgiana Ifrim']","Multivariate time series classification is an important computational task
arising in applications where data is recorded over time and over multiple
channels. For example, a smartwatch can record the acceleration and orientation
of a person's motion, and these signals are recorded as multivariate time
series. We can classify this data to understand and predict human movement and
various properties such as fitness levels. In many applications classification
alone is not enough, we often need to classify but also understand what the
model learns (e.g., why was a prediction given, based on what information in
the data). The main focus of this paper is on analysing and evaluating
explanation methods tailored to Multivariate Time Series Classification (MTSC).
We focus on saliency-based explanation methods that can point out the most
relevant channels and time series points for the classification decision. We
analyse two popular and accurate multivariate time series classifiers, ROCKET
and dResNet, as well as two popular explanation methods, SHAP and dCAM. We
study these methods on 3 synthetic datasets and 2 real-world datasets and
provide a quantitative and qualitative analysis of the explanations provided.
We find that flattening the multivariate datasets by concatenating the channels
works as well as using multivariate classifiers directly and adaptations of
SHAP for MTSC work quite well. Additionally, we also find that the popular
synthetic datasets we used are not suitable for time series analysis.",http://arxiv.org/pdf/2308.15223v2,cs.LG
2023-08-29 07:04:50+00:00,MadSGM: Multivariate Anomaly Detection with Score-based Generative Models,"['Haksoo Lim', 'Sewon Park', 'Minjung Kim', 'Jaehoon Lee', 'Seonkyu Lim', 'Noseong Park']","The time-series anomaly detection is one of the most fundamental tasks for
time-series. Unlike the time-series forecasting and classification, the
time-series anomaly detection typically requires unsupervised (or
self-supervised) training since collecting and labeling anomalous observations
are difficult. In addition, most existing methods resort to limited forms of
anomaly measurements and therefore, it is not clear whether they are optimal in
all circumstances. To this end, we present a multivariate time-series anomaly
detector based on score-based generative models, called MadSGM, which considers
the broadest ever set of anomaly measurement factors: i) reconstruction-based,
ii) density-based, and iii) gradient-based anomaly measurements. We also design
a conditional score network and its denoising score matching loss for the
time-series anomaly detection. Experiments on five real-world benchmark
datasets illustrate that MadSGM achieves the most robust and accurate
predictions.",http://arxiv.org/pdf/2308.15069v1,cs.LG
2023-08-29 02:53:10+00:00,The projected dynamic linear model for time series on the sphere,"['John Zito', 'Daniel Kowal']","Time series on the unit n-sphere arise in directional statistics,
compositional data analysis, and many scientific fields. There are few models
for such data, and the ones that exist suffer from several limitations: they
are often challenging to fit computationally, many of them apply only to the
circular case of n = 2, and they are usually based on families of distributions
that are not flexible enough to capture the complexities observed in real data.
Furthermore, there is little work on Bayesian methods for spherical time
series. To address these shortcomings, we propose a state space model based on
the projected normal distribution that can be applied to spherical time series
of arbitrary dimension. We describe how to perform fully Bayesian offline
inference for this model using a simple and efficient Gibbs sampling algorithm,
and we develop a Rao-Blackwellized particle filter to perform online inference
for streaming data. In an analysis of wind direction time series, we show that
the proposed model outperforms competitors in terms of point, interval, and
density forecasting.",http://arxiv.org/pdf/2308.14996v1,stat.ME
2023-08-28 21:17:12+00:00,BayOTIDE: Bayesian Online Multivariate Time series Imputation with functional decomposition,"['Shikai Fang', 'Qingsong Wen', 'Yingtao Luo', 'Shandian Zhe', 'Liang Sun']","In real-world scenarios like traffic and energy, massive time-series data
with missing values and noises are widely observed, even sampled irregularly.
While many imputation methods have been proposed, most of them work with a
local horizon, which means models are trained by splitting the long sequence
into batches of fit-sized patches. This local horizon can make models ignore
global trends or periodic patterns. More importantly, almost all methods assume
the observations are sampled at regular time stamps, and fail to handle complex
irregular sampled time series arising from different applications. Thirdly,
most existing methods are learned in an offline manner. Thus, it is not
suitable for many applications with fast-arriving streaming data. To overcome
these limitations, we propose BayOTIDE: Bayesian Online Multivariate Time
series Imputation with functional decomposition. We treat the multivariate time
series as the weighted combination of groups of low-rank temporal factors with
different patterns. We apply a group of Gaussian Processes (GPs) with different
kernels as functional priors to fit the factors. For computational efficiency,
we further convert the GPs into a state-space prior by constructing an
equivalent stochastic differential equation (SDE), and developing a scalable
algorithm for online inference. The proposed method can not only handle
imputation over arbitrary time stamps, but also offer uncertainty
quantification and interpretability for the downstream application. We evaluate
our method on both synthetic and real-world datasets.",http://arxiv.org/pdf/2308.14906v2,cs.LG
2023-08-26 22:47:46+00:00,Multivariate time series classification with dual attention network,"['Mojtaba A. Farahani', 'Tara Eslaminokandeh']","One of the topics in machine learning that is becoming more and more relevant
is multivariate time series classification. Current techniques concentrate on
identifying the local important sequence segments or establishing the global
long-range dependencies. They frequently disregard the merged data from both
global and local features, though. Using dual attention, we explore a novel
network (DA-Net) in this research to extract local and global features for
multivariate time series classification. The two distinct layers that make up
DA-Net are the Squeeze-Excitation Window Attention (SEWA) layer and the Sparse
Self-Attention within Windows (SSAW) layer. DA- Net can mine essential local
sequence fragments that are necessary for establishing global long-range
dependencies based on the two expanded layers.",http://arxiv.org/pdf/2308.13968v1,cs.LG
2023-08-26 07:45:41+00:00,DeLELSTM: Decomposition-based Linear Explainable LSTM to Capture Instantaneous and Long-term Effects in Time Series,"['Chaoqun Wang', 'Yijun Li', 'Xiangqian Sun', 'Qi Wu', 'Dongdong Wang', 'Zhixiang Huang']","Time series forecasting is prevalent in various real-world applications.
Despite the promising results of deep learning models in time series
forecasting, especially the Recurrent Neural Networks (RNNs), the explanations
of time series models, which are critical in high-stakes applications, have
received little attention. In this paper, we propose a Decomposition-based
Linear Explainable LSTM (DeLELSTM) to improve the interpretability of LSTM.
Conventionally, the interpretability of RNNs only concentrates on the variable
importance and time importance. We additionally distinguish between the
instantaneous influence of new coming data and the long-term effects of
historical data. Specifically, DeLELSTM consists of two components, i.e.,
standard LSTM and tensorized LSTM. The tensorized LSTM assigns each variable
with a unique hidden state making up a matrix $\mathbf{h}_t$, and the standard
LSTM models all the variables with a shared hidden state $\mathbf{H}_t$. By
decomposing the $\mathbf{H}_t$ into the linear combination of past information
$\mathbf{h}_{t-1}$ and the fresh information $\mathbf{h}_{t}-\mathbf{h}_{t-1}$,
we can get the instantaneous influence and the long-term effect of each
variable. In addition, the advantage of linear regression also makes the
explanation transparent and clear. We demonstrate the effectiveness and
interpretability of DeLELSTM on three empirical datasets. Extensive experiments
show that the proposed method achieves competitive performance against the
baseline methods and provides a reliable explanation relative to domain
knowledge.",http://arxiv.org/pdf/2308.13797v1,cs.LG
2023-08-26 04:51:51+00:00,Limit theorems for non-degenerate U-statistics of block maxima for time series,"['Axel Bücher', 'Torben Staud']","The block maxima method is a classical and widely applied statistical method
for time series extremes. It has recently been found that respective estimators
whose asymptotics are driven by empirical means can be improved by using
sliding rather than disjoint block maxima. Similar results are derived for
general non-degenerate U-statistics of arbitrary order, in the multivariate
time series case. Details are worked out for selected examples: the empirical
variance, the probability weighted moment estimator and Kendall's tau
statistic. The results are also extended to the case where the underlying
sample is piecewise stationary. The finite-sample properties are illustrated by
a Monte Carlo simulation study.",http://arxiv.org/pdf/2308.13761v1,math.ST
2023-08-26 01:15:32+00:00,Time-to-Pattern: Information-Theoretic Unsupervised Learning for Scalable Time Series Summarization,"['Alireza Ghods', 'Trong Nghia Hoang', 'Diane Cook']","Data summarization is the process of generating interpretable and
representative subsets from a dataset. Existing time series summarization
approaches often search for recurring subsequences using a set of manually
devised similarity functions to summarize the data. However, such approaches
are fraught with limitations stemming from an exhaustive search coupled with a
heuristic definition of series similarity. Such approaches affect the diversity
and comprehensiveness of the generated data summaries. To mitigate these
limitations, we introduce an approach to time series summarization, called
Time-to-Pattern (T2P), which aims to find a set of diverse patterns that
together encode the most salient information, following the notion of minimum
description length. T2P is implemented as a deep generative model that learns
informative embeddings of the discrete time series on a latent space
specifically designed to be interpretable. Our synthetic and real-world
experiments reveal that T2P discovers informative patterns, even in noisy and
complex settings. Furthermore, our results also showcase the improved
performance of T2P over previous work in pattern diversity and processing
scalability, which conclusively demonstrate the algorithm's effectiveness for
time series summarization.",http://arxiv.org/pdf/2308.13722v1,cs.LG
2023-08-25 23:21:53+00:00,PAITS: Pretraining and Augmentation for Irregularly-Sampled Time Series,"['Nicasia Beebe-Wang', 'Sayna Ebrahimi', 'Jinsung Yoon', 'Sercan O. Arik', 'Tomas Pfister']","Real-world time series data that commonly reflect sequential human behavior
are often uniquely irregularly sampled and sparse, with highly nonuniform
sampling over time and entities. Yet, commonly-used pretraining and
augmentation methods for time series are not specifically designed for such
scenarios. In this paper, we present PAITS (Pretraining and Augmentation for
Irregularly-sampled Time Series), a framework for identifying suitable
pretraining strategies for sparse and irregularly sampled time series datasets.
PAITS leverages a novel combination of NLP-inspired pretraining tasks and
augmentations, and a random search to identify an effective strategy for a
given dataset. We demonstrate that different datasets benefit from different
pretraining choices. Compared with prior methods, our approach is better able
to consistently improve pretraining across multiple datasets and domains. Our
code is available at
\url{https://github.com/google-research/google-research/tree/master/irregular_timeseries_pretraining}.",http://arxiv.org/pdf/2308.13703v1,cs.LG
2023-08-25 14:01:43+00:00,TFDNet: Time-Frequency Enhanced Decomposed Network for Long-term Time Series Forecasting,"['Yuxiao Luo', 'Ziyu Lyu', 'Xingyu Huang']","Long-term time series forecasting is a vital task and has a wide range of
real applications. Recent methods focus on capturing the underlying patterns
from one single domain (e.g. the time domain or the frequency domain), and have
not taken a holistic view to process long-term time series from the
time-frequency domains. In this paper, we propose a Time-Frequency Enhanced
Decomposed Network (TFDNet) to capture both the long-term underlying patterns
and temporal periodicity from the time-frequency domain. In TFDNet, we devise a
multi-scale time-frequency enhanced encoder backbone and develop two separate
trend and seasonal time-frequency blocks to capture the distinct patterns
within the decomposed trend and seasonal components in multi-resolutions.
Diverse kernel learning strategies of the kernel operations in time-frequency
blocks have been explored, by investigating and incorporating the potential
different channel-wise correlation patterns of multivariate time series.
Experimental evaluation of eight datasets from five benchmark domains
demonstrated that TFDNet is superior to state-of-the-art approaches in both
effectiveness and efficiency.",http://arxiv.org/pdf/2308.13386v1,cs.LG
2023-08-24 16:58:30+00:00,Low-count Time Series Anomaly Detection,"['Philipp Renz', 'Kurt Cutajar', 'Niall Twomey', 'Gavin K. C. Cheung', 'Hanting Xie']","Low-count time series describe sparse or intermittent events, which are
prevalent in large-scale online platforms that capture and monitor diverse data
types. Several distinct challenges surface when modelling low-count time
series, particularly low signal-to-noise ratios (when anomaly signatures are
provably undetectable), and non-uniform performance (when average metrics are
not representative of local behaviour). The time series anomaly detection
community currently lacks explicit tooling and processes to model and reliably
detect anomalies in these settings. We address this gap by introducing a novel
generative procedure for creating benchmark datasets comprising of low-count
time series with anomalous segments. Via a mixture of theoretical and empirical
analysis, our work explains how widely-used algorithms struggle with the
distribution overlap between normal and anomalous segments. In order to
mitigate this shortcoming, we then leverage our findings to demonstrate how
anomaly score smoothing consistently improves performance. The practical
utility of our analysis and recommendation is validated on a real-world dataset
containing sales data for retail stores.",http://arxiv.org/pdf/2308.12925v1,cs.LG
2023-08-24 09:57:11+00:00,Match-And-Deform: Time Series Domain Adaptation through Optimal Transport and Temporal Alignment,"['François Painblanc', 'Laetitia Chapel', 'Nicolas Courty', 'Chloé Friguet', 'Charlotte Pelletier', 'Romain Tavenard']","While large volumes of unlabeled data are usually available, associated
labels are often scarce. The unsupervised domain adaptation problem aims at
exploiting labels from a source domain to classify data from a related, yet
different, target domain. When time series are at stake, new difficulties arise
as temporal shifts may appear in addition to the standard feature distribution
shift. In this paper, we introduce the Match-And-Deform (MAD) approach that
aims at finding correspondences between the source and target time series while
allowing temporal distortions. The associated optimization problem
simultaneously aligns the series thanks to an optimal transport loss and the
time stamps through dynamic time warping. When embedded into a deep neural
network, MAD helps learning new representations of time series that both align
the domains and maximize the discriminative power of the network. Empirical
studies on benchmark datasets and remote sensing data demonstrate that MAD
makes meaningful sample-to-sample pairing and time shift estimation, reaching
similar or better classification performance than state-of-the-art deep time
series domain adaptation strategies.",http://arxiv.org/pdf/2308.12686v2,cs.LG
2023-08-24 04:33:30+00:00,A Co-training Approach for Noisy Time Series Learning,"['Weiqi Zhang', 'Jianfeng Zhang', 'Jia Li', 'Fugee Tsung']","In this work, we focus on robust time series representation learning. Our
assumption is that real-world time series is noisy and complementary
information from different views of the same time series plays an important
role while analyzing noisy input. Based on this, we create two views for the
input time series through two different encoders. We conduct co-training based
contrastive learning iteratively to learn the encoders. Our experiments
demonstrate that this co-training approach leads to a significant improvement
in performance. Especially, by leveraging the complementary information from
different views, our proposed TS-CoT method can mitigate the impact of data
noise and corruption. Empirical evaluations on four time series benchmarks in
unsupervised and semi-supervised settings reveal that TS-CoT outperforms
existing methods. Furthermore, the representations learned by TS-CoT can
transfer well to downstream tasks through fine-tuning.",http://arxiv.org/pdf/2308.12551v1,cs.LG
2023-08-21 06:45:28+00:00,Adaptive Thresholding Heuristic for KPI Anomaly Detection,"['Ebenezer R. H. P. Isaac', 'Akshat Sharma']","A plethora of outlier detectors have been explored in the time series domain,
however, in a business sense, not all outliers are anomalies of interest.
Existing anomaly detection solutions are confined to certain outlier detectors
limiting their applicability to broader anomaly detection use cases. Network
KPIs (Key Performance Indicators) tend to exhibit stochastic behaviour
producing statistical outliers, most of which do not adversely affect business
operations. Thus, a heuristic is required to capture the business definition of
an anomaly for time series KPI. This article proposes an Adaptive Thresholding
Heuristic (ATH) to dynamically adjust the detection threshold based on the
local properties of the data distribution and adapt to changes in time series
patterns. The heuristic derives the threshold based on the expected periodicity
and the observed proportion of anomalies minimizing false positives and
addressing concept drift. ATH can be used in conjunction with any underlying
seasonality decomposition method and an outlier detector that yields an outlier
score. This method has been tested on EON1-Cell-U, a labeled KPI anomaly
dataset produced by Ericsson, to validate our hypothesis. Experimental results
show that ATH is computationally efficient making it scalable for near real
time anomaly detection and flexible with multiple forecasters and outlier
detectors.",http://arxiv.org/pdf/2308.10504v1,cs.LG
2023-08-19 02:30:35+00:00,A Transformer-based Framework For Multi-variate Time Series: A Remaining Useful Life Prediction Use Case,"['Oluwaseyi Ogunfowora', 'Homayoun Najjaran']","In recent times, Large Language Models (LLMs) have captured a global
spotlight and revolutionized the field of Natural Language Processing. One of
the factors attributed to the effectiveness of LLMs is the model architecture
used for training, transformers. Transformer models excel at capturing
contextual features in sequential data since time series data are sequential,
transformer models can be leveraged for more efficient time series data
prediction. The field of prognostics is vital to system health management and
proper maintenance planning. A reliable estimation of the remaining useful life
(RUL) of machines holds the potential for substantial cost savings. This
includes avoiding abrupt machine failures, maximizing equipment usage, and
serving as a decision support system (DSS). This work proposed an
encoder-transformer architecture-based framework for multivariate time series
prediction for a prognostics use case. We validated the effectiveness of the
proposed framework on all four sets of the C-MAPPS benchmark dataset for the
remaining useful life prediction task. To effectively transfer the knowledge
and application of transformers from the natural language domain to time
series, three model-specific experiments were conducted. Also, to enable the
model awareness of the initial stages of the machine life and its degradation
path, a novel expanding window method was proposed for the first time in this
work, it was compared with the sliding window method, and it led to a large
improvement in the performance of the encoder transformer model. Finally, the
performance of the proposed encoder-transformer model was evaluated on the test
dataset and compared with the results from 13 other state-of-the-art (SOTA)
models in the literature and it outperformed them all with an average
performance increase of 137.65% over the next best model across all the
datasets.",http://arxiv.org/pdf/2308.09884v2,cs.LG
2023-08-18 18:30:33+00:00,Time Series Predictions in Unmonitored Sites: A Survey of Machine Learning Techniques in Water Resources,"['Jared D. Willard', 'Charuleka Varadharajan', 'Xiaowei Jia', 'Vipin Kumar']","Prediction of dynamic environmental variables in unmonitored sites remains a
long-standing challenge for water resources science. The majority of the
world's freshwater resources have inadequate monitoring of critical
environmental variables needed for management. Yet, the need to have widespread
predictions of hydrological variables such as river flow and water quality has
become increasingly urgent due to climate and land use change over the past
decades, and their associated impacts on water resources. Modern machine
learning methods increasingly outperform their process-based and empirical
model counterparts for hydrologic time series prediction with their ability to
extract information from large, diverse data sets. We review relevant
state-of-the art applications of machine learning for streamflow, water
quality, and other water resources prediction and discuss opportunities to
improve the use of machine learning with emerging methods for incorporating
watershed characteristics into deep learning models, transfer learning, and
incorporating process knowledge into machine learning models. The analysis here
suggests most prior efforts have been focused on deep learning learning
frameworks built on many sites for predictions at daily time scales in the
United States, but that comparisons between different classes of machine
learning methods are few and inadequate. We identify several open questions for
time series predictions in unmonitored sites that include incorporating dynamic
inputs and site characteristics, mechanistic understanding and spatial context,
and explainable AI techniques in modern machine learning frameworks.",http://arxiv.org/pdf/2308.09766v1,cs.LG
2023-08-18 15:53:40+00:00,Development of a Neural Network-based Method for Improved Imputation of Missing Values in Time Series Data by Repurposing DataWig,['Daniel Zhang'],"Time series data are observations collected over time intervals. Successful
analysis of time series data captures patterns such as trends, cyclicity and
irregularity, which are crucial for decision making in research, business, and
governance. However, missing values in time series data occur often and present
obstacles to successful analysis, thus they need to be filled with alternative
values, a process called imputation. Although various approaches have been
attempted for robust imputation of time series data, even the most advanced
methods still face challenges including limited scalability, poor capacity to
handle heterogeneous data types and inflexibility due to requiring strong
assumptions of data missing mechanisms. Moreover, the imputation accuracy of
these methods still has room for improvement. In this study, I developed
tsDataWig (time-series DataWig) by modifying DataWig, a neural network-based
method that possesses the capacity to process large datasets and heterogeneous
data types but was designed for non-time series data imputation. Unlike the
original DataWig, tsDataWig can directly handle values of time variables and
impute missing values in complex time series datasets. Using one simulated and
three different complex real-world time series datasets, I demonstrated that
tsDataWig outperforms the original DataWig and the current state-of-the-art
methods for time series data imputation and potentially has broad application
due to not requiring strong assumptions of data missing mechanisms. This study
provides a valuable solution for robustly imputing missing values in
challenging time series datasets, which often contain millions of samples, high
dimensional variables, and heterogeneous data types.",http://arxiv.org/pdf/2308.09635v1,cs.LG
2023-08-18 05:19:18+00:00,Path Signatures for Seizure Forecasting,"['Jonas F. Haderlein', 'Andre D. H. Peterson', 'Parvin Zarei Eskikand', 'Mark J. Cook', 'Anthony N. Burkitt', 'Iven M. Y. Mareels', 'David B. Grayden']","Predicting future system behaviour from past observed behaviour (time series)
is fundamental to science and engineering. In computational neuroscience, the
prediction of future epileptic seizures from brain activity measurements, using
EEG data, remains largely unresolved despite much dedicated research effort.
Based on a longitudinal and state-of-the-art data set using intercranial EEG
measurements from people with epilepsy, we consider the automated discovery of
predictive features (or biomarkers) to forecast seizures in a patient-specific
way. To this end, we use the path signature, a recent development in the
analysis of data streams, to map from measured time series to seizure
prediction. The predictor is based on linear classification, here augmented
with sparsity constraints, to discern time series with and without an impending
seizure. This approach may be seen as a step towards a generic pattern
recognition pipeline where the main advantages are simplicity and ease of
customisation, while maintaining forecasting performance on par with modern
machine learning. Nevertheless, it turns out that although the path signature
method has some powerful theoretical guarantees, appropriate time series
statistics can achieve essentially the same results in our context of seizure
prediction. This suggests that, due to their inherent complexity and
non-stationarity, the brain's dynamics are not identifiable from the available
EEG measurement data, and, more concretely, epileptic episode prediction is not
reliably achieved using EEG measurement data alone.",http://arxiv.org/pdf/2308.09312v2,stat.ML
2023-08-18 04:45:56+00:00,CARLA: A Self-supervised Contrastive Representation Learning Approach for Time Series Anomaly Detection,"['Zahra Zamanzadeh Darban', 'Geoffrey I. Webb', 'Shirui Pan', 'Mahsa Salehi']","We introduce a Self-supervised Contrastive Representation Learning Approach
for Time Series Anomaly Detection (CARLA), an innovative end-to-end
self-supervised framework carefully developed to identify anomalous patterns in
both univariate and multivariate time series data. By taking advantage of
contrastive representation learning, We introduce an innovative end-to-end
self-supervised deep learning framework carefully developed to identify
anomalous patterns in both univariate and multivariate time series data. By
taking advantage of contrastive representation learning, CARLA effectively
generates robust representations for time series windows. It achieves this by
1) learning similar representations for temporally close windows and dissimilar
representations for windows and their equivalent anomalous windows and 2)
employing a self-supervised approach to classify normal/anomalous
representations of windows based on their nearest/furthest neighbours in the
representation space. Most of the existing models focus on learning normal
behaviour. The normal boundary is often tightly defined, which can result in
slight deviations being classified as anomalies, resulting in a high false
positive rate and limited ability to generalise normal patterns. CARLA's
contrastive learning methodology promotes the production of highly consistent
and discriminative predictions, thereby empowering us to adeptly address the
inherent challenges associated with anomaly detection in time series data.
Through extensive experimentation on 7 standard real-world time series anomaly
detection benchmark datasets, CARLA demonstrates F1 and AU-PR superior to
existing state-of-the-art results. Our research highlights the immense
potential of contrastive representation learning in advancing the field of time
series anomaly detection, thus paving the way for novel applications and
in-depth exploration in this domain.",http://arxiv.org/pdf/2308.09296v1,cs.LG
2023-08-17 09:54:42+00:00,Mixed causality graphs for continuous-time stationary processes,"['Vicky Fasen-Hartmann', 'Lea Schenk']","In this paper, we introduce different concepts of Granger non-causality and
contemporaneous uncorrelation for stationary continuous-time processes to model
the different dependencies between the component series of multivariate time
series models. Several equivalent characterisations for the different
definitions are given, in particular by linear projections. We then define two
mixed graphs based on different definitions of causality and contemporaneous
uncorrelation, the (mixed) causality graph and the local (mixed) causality
graph, to visualise and to analyse the different dependencies in stationary
continuous-time processes. In these graphs, the components of the process are
represented by vertices, directed edges between the vertices indicate causal
influences and undirected edges indicate contemporaneous uncorrelation between
the component processes. Further, we introduce various notions of causal Markov
properties in analogy to Eichler (2012), which relate the different dependence
structures of subprocesses, and we derive sufficient criteria for the (local)
causality graph to satisfy them. Finally, as an example, the popular
multivariate continuous-time AR (MCAR) processes satisfy our assumptions. For
MCAR processes we show that the (local) causality graphs can be characterised
explicitly by the model parameters.",http://arxiv.org/pdf/2308.08890v1,math.ST
2023-08-16 16:19:50+00:00,LLM4TS: Two-Stage Fine-Tuning for Time-Series Forecasting with Pre-Trained LLMs,"['Ching Chang', 'Wen-Chih Peng', 'Tien-Fu Chen']","In this work, we leverage pre-trained Large Language Models (LLMs) to enhance
time-series forecasting. Mirroring the growing interest in unifying models for
Natural Language Processing and Computer Vision, we envision creating an
analogous model for long-term time-series forecasting. Due to limited
large-scale time-series data for building robust foundation models, our
approach LLM4TS focuses on leveraging the strengths of pre-trained LLMs. By
combining time-series patching with temporal encoding, we have enhanced the
capability of LLMs to handle time-series data effectively. Inspired by the
supervised fine-tuning in chatbot domains, we prioritize a two-stage
fine-tuning process: first conducting supervised fine-tuning to orient the LLM
towards time-series data, followed by task-specific downstream fine-tuning.
Furthermore, to unlock the flexibility of pre-trained LLMs without extensive
parameter adjustments, we adopt several Parameter-Efficient Fine-Tuning (PEFT)
techniques. Drawing on these innovations, LLM4TS has yielded state-of-the-art
results in long-term forecasting. Our model has also shown exceptional
capabilities as both a robust representation learner and an effective few-shot
learner, thanks to the knowledge transferred from the pre-trained LLM.",http://arxiv.org/pdf/2308.08469v3,cs.LG
2023-08-15 17:23:18+00:00,Back to Basics: A Sanity Check on Modern Time Series Classification Algorithms,"['Bhaskar Dhariyal', 'Thach Le Nguyen', 'Georgiana Ifrim']","The state-of-the-art in time series classification has come a long way, from
the 1NN-DTW algorithm to the ROCKET family of classifiers. However, in the
current fast-paced development of new classifiers, taking a step back and
performing simple baseline checks is essential. These checks are often
overlooked, as researchers are focused on establishing new state-of-the-art
results, developing scalable algorithms, and making models explainable.
Nevertheless, there are many datasets that look like time series at first
glance, but classic algorithms such as tabular methods with no time ordering
may perform better on such problems. For example, for spectroscopy datasets,
tabular methods tend to significantly outperform recent time series methods. In
this study, we compare the performance of tabular models using classic machine
learning approaches (e.g., Ridge, LDA, RandomForest) with the ROCKET family of
classifiers (e.g., Rocket, MiniRocket, MultiRocket). Tabular models are simple
and very efficient, while the ROCKET family of classifiers are more complex and
have state-of-the-art accuracy and efficiency among recent time series
classifiers. We find that tabular models outperform the ROCKET family of
classifiers on approximately 19% of univariate and 28% of multivariate datasets
in the UCR/UEA benchmark and achieve accuracy within 10 percentage points on
about 50% of datasets. Our results suggest that it is important to consider
simple tabular models as baselines when developing time series classifiers.
These models are very fast, can be as effective as more complex methods and may
be easier to understand and deploy.",http://arxiv.org/pdf/2308.07886v1,cs.LG
2023-08-13 10:04:13+00:00,Probabilistic Imputation for Time-series Classification with Missing Data,"['SeungHyun Kim', 'Hyunsu Kim', 'EungGu Yun', 'Hwangrae Lee', 'Jaehun Lee', 'Juho Lee']","Multivariate time series data for real-world applications typically contain a
significant amount of missing values. The dominant approach for classification
with such missing values is to impute them heuristically with specific values
(zero, mean, values of adjacent time-steps) or learnable parameters. However,
these simple strategies do not take the data generative process into account,
and more importantly, do not effectively capture the uncertainty in prediction
due to the multiple possibilities for the missing values. In this paper, we
propose a novel probabilistic framework for classification with multivariate
time series data with missing values. Our model consists of two parts; a deep
generative model for missing value imputation and a classifier. Extending the
existing deep generative models to better capture structures of time-series
data, our deep generative model part is trained to impute the missing values in
multiple plausible ways, effectively modeling the uncertainty of the
imputation. The classifier part takes the time series data along with the
imputed missing values and classifies signals, and is trained to capture the
predictive uncertainty due to the multiple possibilities of imputations.
Importantly, we show that na\""ively combining the generative model and the
classifier could result in trivial solutions where the generative model does
not produce meaningful imputations. To resolve this, we present a novel
regularization technique that can promote the model to produce useful
imputation values that help classification. Through extensive experiments on
real-world time series data with missing values, we demonstrate the
effectiveness of our method.",http://arxiv.org/pdf/2308.06738v1,cs.LG
2023-08-13 02:17:19+00:00,ALGAN: Time Series Anomaly Detection with Adjusted-LSTM GAN,"['Md Abul Bashar', 'Richi Nayak']","Anomaly detection in time series data, to identify points that deviate from
normal behaviour, is a common problem in various domains such as manufacturing,
medical imaging, and cybersecurity. Recently, Generative Adversarial Networks
(GANs) are shown to be effective in detecting anomalies in time series data.
The neural network architecture of GANs (i.e. Generator and Discriminator) can
significantly improve anomaly detection accuracy. In this paper, we propose a
new GAN model, named Adjusted-LSTM GAN (ALGAN), which adjusts the output of an
LSTM network for improved anomaly detection in both univariate and multivariate
time series data in an unsupervised setting. We evaluate the performance of
ALGAN on 46 real-world univariate time series datasets and a large multivariate
dataset that spans multiple domains. Our experiments demonstrate that ALGAN
outperforms traditional, neural network-based, and other GAN-based methods for
anomaly detection in time series data.",http://arxiv.org/pdf/2308.06663v2,cs.LG
2023-08-09 00:23:04+00:00,Sparse Binary Transformers for Multivariate Time Series Modeling,"['Matt Gorbett', 'Hossein Shirazi', 'Indrakshi Ray']","Compressed Neural Networks have the potential to enable deep learning across
new applications and smaller computational environments. However, understanding
the range of learning tasks in which such models can succeed is not well
studied. In this work, we apply sparse and binary-weighted Transformers to
multivariate time series problems, showing that the lightweight models achieve
accuracy comparable to that of dense floating-point Transformers of the same
structure. Our model achieves favorable results across three time series
learning tasks: classification, anomaly detection, and single-step forecasting.
Additionally, to reduce the computational complexity of the attention
mechanism, we apply two modifications, which show little to no decline in model
performance: 1) in the classification task, we apply a fixed mask to the query,
key, and value activations, and 2) for forecasting and anomaly detection, which
rely on predicting outputs at a single point in time, we propose an attention
mask to allow computation only at the current time step. Together, each
compression technique and attention modification substantially reduces the
number of non-zero operations necessary in the Transformer. We measure the
computational savings of our approach over a range of metrics including
parameter count, bit size, and floating point operation (FLOPs) count, showing
up to a 53x reduction in storage size and up to 10.5x reduction in FLOPs.",http://arxiv.org/pdf/2308.04637v1,cs.LG
2023-08-07 04:44:12+00:00,DOMINO: Domain-invariant Hyperdimensional Classification for Multi-Sensor Time Series Data,"['Junyao Wang', 'Luke Chen', 'Mohammad Abdullah Al Faruque']","With the rapid evolution of the Internet of Things, many real-world
applications utilize heterogeneously connected sensors to capture time-series
information. Edge-based machine learning (ML) methodologies are often employed
to analyze locally collected data. However, a fundamental issue across
data-driven ML approaches is distribution shift. It occurs when a model is
deployed on a data distribution different from what it was trained on, and can
substantially degrade model performance. Additionally, increasingly
sophisticated deep neural networks (DNNs) have been proposed to capture spatial
and temporal dependencies in multi-sensor time series data, requiring intensive
computational resources beyond the capacity of today's edge devices. While
brain-inspired hyperdimensional computing (HDC) has been introduced as a
lightweight solution for edge-based learning, existing HDCs are also vulnerable
to the distribution shift challenge. In this paper, we propose DOMINO, a novel
HDC learning framework addressing the distribution shift problem in noisy
multi-sensor time-series data. DOMINO leverages efficient and parallel matrix
operations on high-dimensional space to dynamically identify and filter out
domain-variant dimensions. Our evaluation on a wide range of multi-sensor time
series classification tasks shows that DOMINO achieves on average 2.04% higher
accuracy than state-of-the-art (SOTA) DNN-based domain generalization
techniques, and delivers 16.34x faster training and 2.89x faster inference.
More importantly, DOMINO performs notably better when learning from partially
labeled and highly imbalanced data, providing 10.93x higher robustness against
hardware noises than SOTA DNNs.",http://arxiv.org/pdf/2308.03295v2,cs.LG
2023-08-07 03:32:39+00:00,DSformer: A Double Sampling Transformer for Multivariate Time Series Long-term Prediction,"['Chengqing Yu', 'Fei Wang', 'Zezhi Shao', 'Tao Sun', 'Lin Wu', 'Yongjun Xu']","Multivariate time series long-term prediction, which aims to predict the
change of data in a long time, can provide references for decision-making.
Although transformer-based models have made progress in this field, they
usually do not make full use of three features of multivariate time series:
global information, local information, and variables correlation. To
effectively mine the above three features and establish a high-precision
prediction model, we propose a double sampling transformer (DSformer), which
consists of the double sampling (DS) block and the temporal variable attention
(TVA) block. Firstly, the DS block employs down sampling and piecewise sampling
to transform the original series into feature vectors that focus on global
information and local information respectively. Then, TVA block uses temporal
attention and variable attention to mine these feature vectors from different
dimensions and extract key information. Finally, based on a parallel structure,
DSformer uses multiple TVA blocks to mine and integrate different features
obtained from DS blocks respectively. The integrated feature information is
passed to the generative decoder based on a multi-layer perceptron to realize
multivariate time series long-term prediction. Experimental results on nine
real-world datasets show that DSformer can outperform eight existing baselines.",http://arxiv.org/pdf/2308.03274v1,cs.LG
2023-08-06 21:10:30+00:00,Time-Parameterized Convolutional Neural Networks for Irregularly Sampled Time Series,"['Chrysoula Kosma', 'Giannis Nikolentzos', 'Michalis Vazirgiannis']","Irregularly sampled multivariate time series are ubiquitous in several
application domains, leading to sparse, not fully-observed and non-aligned
observations across different variables. Standard sequential neural network
architectures, such as recurrent neural networks (RNNs) and convolutional
neural networks (CNNs), consider regular spacing between observation times,
posing significant challenges to irregular time series modeling. While most of
the proposed architectures incorporate RNN variants to handle irregular time
intervals, convolutional neural networks have not been adequately studied in
the irregular sampling setting. In this paper, we parameterize convolutional
layers by employing time-explicitly initialized kernels. Such general functions
of time enhance the learning process of continuous-time hidden dynamics and can
be efficiently incorporated into convolutional kernel weights. We, thus,
propose the time-parameterized convolutional neural network (TPCNN), which
shares similar properties with vanilla convolutions but is carefully designed
for irregularly sampled time series. We evaluate TPCNN on both interpolation
and classification tasks involving real-world irregularly sampled multivariate
time series datasets. Our experimental results indicate the competitive
performance of the proposed TPCNN model which is also significantly more
efficient than other state-of-the-art methods. At the same time, the proposed
architecture allows the interpretability of the input series by leveraging the
combination of learnable time functions that improve the network performance in
subsequent tasks and expedite the inaugural application of convolutions in this
field.",http://arxiv.org/pdf/2308.03210v2,cs.LG
2023-08-06 17:51:22+00:00,Detection of Anomalies in Multivariate Time Series Using Ensemble Techniques,"['Anastasios Iliopoulos', 'John Violos', 'Christos Diou', 'Iraklis Varlamis']","Anomaly Detection in multivariate time series is a major problem in many
fields. Due to their nature, anomalies sparsely occur in real data, thus making
the task of anomaly detection a challenging problem for classification
algorithms to solve. Methods that are based on Deep Neural Networks such as
LSTM, Autoencoders, Convolutional Autoencoders etc., have shown positive
results in such imbalanced data. However, the major challenge that algorithms
face when applied to multivariate time series is that the anomaly can arise
from a small subset of the feature set. To boost the performance of these base
models, we propose a feature-bagging technique that considers only a subset of
features at a time, and we further apply a transformation that is based on
nested rotation computed from Principal Component Analysis (PCA) to improve the
effectiveness and generalization of the approach. To further enhance the
prediction performance, we propose an ensemble technique that combines multiple
base models toward the final decision. In addition, a semi-supervised approach
using a Logistic Regressor to combine the base models' outputs is proposed. The
proposed methodology is applied to the Skoltech Anomaly Benchmark (SKAB)
dataset, which contains time series data related to the flow of water in a
closed circuit, and the experimental results show that the proposed ensemble
technique outperforms the basic algorithms. More specifically, the performance
improvement in terms of anomaly detection accuracy reaches 2% for the
unsupervised and at least 10% for the semi-supervised models.",http://arxiv.org/pdf/2308.03171v1,cs.LG
2023-08-04 12:27:11+00:00,DIVERSIFY: A General Framework for Time Series Out-of-distribution Detection and Generalization,"['Wang Lu', 'Jindong Wang', 'Xinwei Sun', 'Yiqiang Chen', 'Xiangyang Ji', 'Qiang Yang', 'Xing Xie']","Time series remains one of the most challenging modalities in machine
learning research. The out-of-distribution (OOD) detection and generalization
on time series tend to suffer due to its non-stationary property, i.e., the
distribution changes over time. The dynamic distributions inside time series
pose great challenges to existing algorithms to identify invariant
distributions since they mainly focus on the scenario where the domain
information is given as prior knowledge. In this paper, we attempt to exploit
subdomains within a whole dataset to counteract issues induced by
non-stationary for generalized representation learning. We propose DIVERSIFY, a
general framework, for OOD detection and generalization on dynamic
distributions of time series. DIVERSIFY takes an iterative process: it first
obtains the ""worst-case"" latent distribution scenario via adversarial training,
then reduces the gap between these latent distributions. We implement DIVERSIFY
via combining existing OOD detection methods according to either extracted
features or outputs of models for detection while we also directly utilize
outputs for classification. In addition, theoretical insights illustrate that
DIVERSIFY is theoretically supported. Extensive experiments are conducted on
seven datasets with different OOD settings across gesture recognition, speech
commands recognition, wearable stress and affect detection, and sensor-based
human activity recognition. Qualitative and quantitative results demonstrate
that DIVERSIFY learns more generalized features and significantly outperforms
other baselines.",http://arxiv.org/pdf/2308.02282v1,cs.LG
2023-08-03 07:28:06+00:00,Unsupervised Representation Learning for Time Series: A Review,"['Qianwen Meng', 'Hangwei Qian', 'Yong Liu', 'Yonghui Xu', 'Zhiqi Shen', 'Lizhen Cui']","Unsupervised representation learning approaches aim to learn discriminative
feature representations from unlabeled data, without the requirement of
annotating every sample. Enabling unsupervised representation learning is
extremely crucial for time series data, due to its unique annotation bottleneck
caused by its complex characteristics and lack of visual cues compared with
other data modalities. In recent years, unsupervised representation learning
techniques have advanced rapidly in various domains. However, there is a lack
of systematic analysis of unsupervised representation learning approaches for
time series. To fill the gap, we conduct a comprehensive literature review of
existing rapidly evolving unsupervised representation learning approaches for
time series. Moreover, we also develop a unified and standardized library,
named ULTS (i.e., Unsupervised Learning for Time Series), to facilitate fast
implementations and unified evaluations on various models. With ULTS, we
empirically evaluate state-of-the-art approaches, especially the rapidly
evolving contrastive learning methods, on 9 diverse real-world datasets. We
further discuss practical considerations as well as open research challenges on
unsupervised representation learning for time series to facilitate future
research in this field.",http://arxiv.org/pdf/2308.01578v1,cs.LG
2023-08-02 10:46:42+00:00,Automatic Feature Engineering for Time Series Classification: Evaluation and Discussion,"['Aurélien Renault', 'Alexis Bondu', 'Vincent Lemaire', 'Dominique Gay']","Time Series Classification (TSC) has received much attention in the past two
decades and is still a crucial and challenging problem in data science and
knowledge engineering. Indeed, along with the increasing availability of time
series data, many TSC algorithms have been suggested by the research community
in the literature. Besides state-of-the-art methods based on similarity
measures, intervals, shapelets, dictionaries, deep learning methods or hybrid
ensemble methods, several tools for extracting unsupervised informative summary
statistics, aka features, from time series have been designed in the recent
years. Originally designed for descriptive analysis and visualization of time
series with informative and interpretable features, very few of these feature
engineering tools have been benchmarked for TSC problems and compared with
state-of-the-art TSC algorithms in terms of predictive performance. In this
article, we aim at filling this gap and propose a simple TSC process to
evaluate the potential predictive performance of the feature sets obtained with
existing feature engineering tools. Thus, we present an empirical study of 11
feature engineering tools branched with 9 supervised classifiers over 112 time
series data sets. The analysis of the results of more than 10000 learning
experiments indicate that feature-based methods perform as accurately as
current state-of-the-art TSC algorithms, and thus should rightfully be
considered further in the TSC literature.",http://arxiv.org/pdf/2308.01071v1,cs.LG
2023-08-02 08:37:45+00:00,Enhancing Representation Learning for Periodic Time Series with Floss: A Frequency Domain Regularization Approach,"['Chunwei Yang', 'Xiaoxu Chen', 'Lijun Sun', 'Hongyu Yang', 'Yuankai Wu']","Time series analysis is a fundamental task in various application domains,
and deep learning approaches have demonstrated remarkable performance in this
area. However, many real-world time series data exhibit significant periodic or
quasi-periodic dynamics that are often not adequately captured by existing deep
learning-based solutions. This results in an incomplete representation of the
underlying dynamic behaviors of interest. To address this gap, we propose an
unsupervised method called Floss that automatically regularizes learned
representations in the frequency domain. The Floss method first automatically
detects major periodicities from the time series. It then employs periodic
shift and spectral density similarity measures to learn meaningful
representations with periodic consistency. In addition, Floss can be easily
incorporated into both supervised, semi-supervised, and unsupervised learning
frameworks. We conduct extensive experiments on common time series
classification, forecasting, and anomaly detection tasks to demonstrate the
effectiveness of Floss. We incorporate Floss into several representative deep
learning solutions to justify our design choices and demonstrate that it is
capable of automatically discovering periodic dynamics and improving
state-of-the-art deep learning models.",http://arxiv.org/pdf/2308.01011v4,cs.LG
2023-08-02 04:06:16+00:00,QUANT: A Minimalist Interval Method for Time Series Classification,"['Angus Dempster', 'Daniel F. Schmidt', 'Geoffrey I. Webb']","We show that it is possible to achieve the same accuracy, on average, as the
most accurate existing interval methods for time series classification on a
standard set of benchmark datasets using a single type of feature (quantiles),
fixed intervals, and an 'off the shelf' classifier. This distillation of
interval-based approaches represents a fast and accurate method for time series
classification, achieving state-of-the-art accuracy on the expanded set of 142
datasets in the UCR archive with a total compute time (training and inference)
of less than 15 minutes using a single CPU core.",http://arxiv.org/pdf/2308.00928v1,cs.LG
2023-08-01 09:13:57+00:00,A Survey of Time Series Anomaly Detection Methods in the AIOps Domain,"['Zhenyu Zhong', 'Qiliang Fan', 'Jiacheng Zhang', 'Minghua Ma', 'Shenglin Zhang', 'Yongqian Sun', 'Qingwei Lin', 'Yuzhi Zhang', 'Dan Pei']","Internet-based services have seen remarkable success, generating vast amounts
of monitored key performance indicators (KPIs) as univariate or multivariate
time series. Monitoring and analyzing these time series are crucial for
researchers, service operators, and on-call engineers to detect outliers or
anomalies indicating service failures or significant events. Numerous advanced
anomaly detection methods have emerged to address availability and performance
issues. This review offers a comprehensive overview of time series anomaly
detection in Artificial Intelligence for IT operations (AIOps), which uses AI
capabilities to automate and optimize operational workflows. Additionally, it
explores future directions for real-world and next-generation time-series
anomaly detection based on recent advancements.",http://arxiv.org/pdf/2308.00393v1,cs.LG
2023-07-31 17:59:16+00:00,Conformal PID Control for Time Series Prediction,"['Anastasios N. Angelopoulos', 'Emmanuel J. Candes', 'Ryan J. Tibshirani']","We study the problem of uncertainty quantification for time series
prediction, with the goal of providing easy-to-use algorithms with formal
guarantees. The algorithms we present build upon ideas from conformal
prediction and control theory, are able to prospectively model conformal scores
in an online setting, and adapt to the presence of systematic errors due to
seasonality, trends, and general distribution shifts. Our theory both
simplifies and strengthens existing analyses in online conformal prediction.
Experiments on 4-week-ahead forecasting of statewide COVID-19 death counts in
the U.S. show an improvement in coverage over the ensemble forecaster used in
official CDC communications. We also run experiments on predicting electricity
demand, market returns, and temperature using autoregressive, Theta, Prophet,
and Transformer models. We provide an extendable codebase for testing our
methods and for the integration of new algorithms, data sets, and forecasting
rules.",http://arxiv.org/pdf/2307.16895v1,cs.LG
2023-07-30 10:30:38+00:00,Shuffled Differentially Private Federated Learning for Time Series Data Analytics,"['Chenxi Huang', 'Chaoyang Jiang', 'Zhenghua Chen']","Trustworthy federated learning aims to achieve optimal performance while
ensuring clients' privacy. Existing privacy-preserving federated learning
approaches are mostly tailored for image data, lacking applications for time
series data, which have many important applications, like machine health
monitoring, human activity recognition, etc. Furthermore, protective noising on
a time series data analytics model can significantly interfere with
temporal-dependent learning, leading to a greater decline in accuracy. To
address these issues, we develop a privacy-preserving federated learning
algorithm for time series data. Specifically, we employ local differential
privacy to extend the privacy protection trust boundary to the clients. We also
incorporate shuffle techniques to achieve a privacy amplification, mitigating
the accuracy decline caused by leveraging local differential privacy. Extensive
experiments were conducted on five time series datasets. The evaluation results
reveal that our algorithm experienced minimal accuracy loss compared to
non-private federated learning in both small and large client scenarios. Under
the same level of privacy protection, our algorithm demonstrated improved
accuracy compared to the centralized differentially private federated learning
in both scenarios.",http://arxiv.org/pdf/2307.16196v1,cs.LG
2023-07-28 22:32:08+00:00,A Distance Correlation-Based Approach to Characterize the Effectiveness of Recurrent Neural Networks for Time Series Forecasting,"['Christopher Salazar', 'Ashis G. Banerjee']","Time series forecasting has received a lot of attention with recurrent neural
networks (RNNs) being one of the widely used models due to their ability to
handle sequential data. Prior studies of RNNs for time series forecasting yield
inconsistent results with limited insights as to why the performance varies for
different datasets. In this paper, we provide an approach to link the
characteristics of time series with the components of RNNs via the versatile
metric of distance correlation. This metric allows us to examine the
information flow through the RNN activation layers to be able to interpret and
explain their performance. We empirically show that the RNN activation layers
learn the lag structures of time series well. However, they gradually lose this
information over a span of a few consecutive layers, thereby worsening the
forecast quality for series with large lag structures. We also show that the
activation layers cannot adequately model moving average and heteroskedastic
time series processes. Last, we generate heatmaps for visual comparisons of the
activation layers for different choices of the network hyperparameters to
identify which of them affect the forecast performance. Our findings can,
therefore, aid practitioners in assessing the effectiveness of RNNs for given
time series data without actually training and evaluating the networks.",http://arxiv.org/pdf/2307.15830v1,cs.LG
2023-07-28 17:40:58+00:00,Universal Recurrent Event Memories for Streaming Data,"['Ran Dou', 'Jose Principe']","In this paper, we propose a new event memory architecture (MemNet) for
recurrent neural networks, which is universal for different types of time
series data such as scalar, multivariate or symbolic. Unlike other external
neural memory architectures, it stores key-value pairs, which separate the
information for addressing and for content to improve the representation, as in
the digital archetype. Moreover, the key-value pairs also avoid the compromise
between memory depth and resolution that applies to memories constructed by the
model state. One of the MemNet key characteristics is that it requires only
linear adaptive mapping functions while implementing a nonlinear operation on
the input data. MemNet architecture can be applied without modifications to
scalar time series, logic operators on strings, and also to natural language
processing, providing state-of-the-art results in all application domains such
as the chaotic time series, the symbolic operation tasks, and the
question-answering tasks (bAbI). Finally, controlled by five linear layers,
MemNet requires a much smaller number of training parameters than other
external memory networks as well as the transformer network. The space
complexity of MemNet equals a single self-attention layer. It greatly improves
the efficiency of the attention mechanism and opens the door for IoT
applications.",http://arxiv.org/pdf/2307.15694v1,cs.LG
2023-07-28 17:13:00+00:00,Case Studies of Causal Discovery from IT Monitoring Time Series,"['Ali Aït-Bachir', 'Charles K. Assaad', 'Christophe de Bignicourt', 'Emilie Devijver', 'Simon Ferreira', 'Eric Gaussier', 'Hosein Mohanna', 'Lei Zan']","Information technology (IT) systems are vital for modern businesses, handling
data storage, communication, and process automation. Monitoring these systems
is crucial for their proper functioning and efficiency, as it allows collecting
extensive observational time series data for analysis. The interest in causal
discovery is growing in IT monitoring systems as knowing causal relations
between different components of the IT system helps in reducing downtime,
enhancing system performance and identifying root causes of anomalies and
incidents. It also allows proactive prediction of future issues through
historical data analysis. Despite its potential benefits, applying causal
discovery algorithms on IT monitoring data poses challenges, due to the
complexity of the data. For instance, IT monitoring data often contains
misaligned time series, sleeping time series, timestamp errors and missing
values. This paper presents case studies on applying causal discovery
algorithms to different IT monitoring datasets, highlighting benefits and
ongoing challenges.",http://arxiv.org/pdf/2307.15678v1,cs.LG
2023-07-27 08:10:19+00:00,TimeGNN: Temporal Dynamic Graph Learning for Time Series Forecasting,"['Nancy Xu', 'Chrysoula Kosma', 'Michalis Vazirgiannis']","Time series forecasting lies at the core of important real-world applications
in many fields of science and engineering. The abundance of large time series
datasets that consist of complex patterns and long-term dependencies has led to
the development of various neural network architectures. Graph neural network
approaches, which jointly learn a graph structure based on the correlation of
raw values of multivariate time series while forecasting, have recently seen
great success. However, such solutions are often costly to train and difficult
to scale. In this paper, we propose TimeGNN, a method that learns dynamic
temporal graph representations that can capture the evolution of inter-series
patterns along with the correlations of multiple series. TimeGNN achieves
inference times 4 to 80 times faster than other state-of-the-art graph-based
methods while achieving comparable forecasting performance",http://arxiv.org/pdf/2307.14680v1,cs.LG
2023-07-26 16:51:18+00:00,Unraveling the Complexity of Splitting Sequential Data: Tackling Challenges in Video and Time Series Analysis,"['Diego Botache', 'Kristina Dingel', 'Rico Huhnstock', 'Arno Ehresmann', 'Bernhard Sick']","Splitting of sequential data, such as videos and time series, is an essential
step in various data analysis tasks, including object tracking and anomaly
detection. However, splitting sequential data presents a variety of challenges
that can impact the accuracy and reliability of subsequent analyses. This
concept article examines the challenges associated with splitting sequential
data, including data acquisition, data representation, split ratio selection,
setting up quality criteria, and choosing suitable selection strategies. We
explore these challenges through two real-world examples: motor test benches
and particle tracking in liquids.",http://arxiv.org/pdf/2307.14294v1,cs.LG
2023-07-26 02:15:11+00:00,Robustness Verification of Deep Neural Networks using Star-Based Reachability Analysis with Variable-Length Time Series Input,"['Neelanjana Pal', 'Diego Manzanas Lopez', 'Taylor T Johnson']","Data-driven, neural network (NN) based anomaly detection and predictive
maintenance are emerging research areas. NN-based analytics of time-series data
offer valuable insights into past behaviors and estimates of critical
parameters like remaining useful life (RUL) of equipment and state-of-charge
(SOC) of batteries. However, input time series data can be exposed to
intentional or unintentional noise when passing through sensors, necessitating
robust validation and verification of these NNs. This paper presents a case
study of the robustness verification approach for time series regression NNs
(TSRegNN) using set-based formal methods. It focuses on utilizing
variable-length input data to streamline input manipulation and enhance network
architecture generalizability. The method is applied to two data sets in the
Prognostics and Health Management (PHM) application areas: (1) SOC estimation
of a Lithium-ion battery and (2) RUL estimation of a turbine engine. The NNs'
robustness is checked using star-based reachability analysis, and several
performance measures evaluate the effect of bounded perturbations in the input
on network outputs, i.e., future outcomes. Overall, the paper offers a
comprehensive case study for validating and verifying NN-based analytics of
time-series data in real-world applications, emphasizing the importance of
robustness testing for accurate and reliable predictions, especially
considering the impact of noise on future outcomes.",http://arxiv.org/pdf/2307.13907v1,cs.LG
2023-07-25 17:36:34+00:00,RED CoMETS: An ensemble classifier for symbolically represented multivariate time series,"['Luca A. Bennett', 'Zahraa S. Abdallah']","Multivariate time series classification is a rapidly growing research field
with practical applications in finance, healthcare, engineering, and more. The
complexity of classifying multivariate time series data arises from its high
dimensionality, temporal dependencies, and varying lengths. This paper
introduces a novel ensemble classifier called RED CoMETS (Random Enhanced
Co-eye for Multivariate Time Series), which addresses these challenges. RED
CoMETS builds upon the success of Co-eye, an ensemble classifier specifically
designed for symbolically represented univariate time series, and extends its
capabilities to handle multivariate data. The performance of RED CoMETS is
evaluated on benchmark datasets from the UCR archive, where it demonstrates
competitive accuracy when compared to state-of-the-art techniques in
multivariate settings. Notably, it achieves the highest reported accuracy in
the literature for the 'HandMovementDirection' dataset. Moreover, the proposed
method significantly reduces computation time compared to Co-eye, making it an
efficient and effective choice for multivariate time series classification.",http://arxiv.org/pdf/2307.13679v2,cs.LG
2023-07-25 13:54:00+00:00,Continuous Time Evidential Distributions for Irregular Time Series,"['Taylor W. Killian', 'Haoran Zhang', 'Thomas Hartvigsen', 'Ava P. Amini']","Prevalent in many real-world settings such as healthcare, irregular time
series are challenging to formulate predictions from. It is difficult to infer
the value of a feature at any given time when observations are sporadic, as it
could take on a range of values depending on when it was last observed. To
characterize this uncertainty we present EDICT, a strategy that learns an
evidential distribution over irregular time series in continuous time. This
distribution enables well-calibrated and flexible inference of partially
observed features at any time of interest, while expanding uncertainty
temporally for sparse, irregular observations. We demonstrate that EDICT
attains competitive performance on challenging time series classification tasks
and enabling uncertainty-guided inference when encountering noisy data.",http://arxiv.org/pdf/2307.13503v1,cs.LG
2023-07-25 12:00:48+00:00,Network Traffic Classification based on Single Flow Time Series Analysis,"['Josef Koumar', 'Karel Hynek', 'Tomáš Čejka']","Network traffic monitoring using IP flows is used to handle the current
challenge of analyzing encrypted network communication. Nevertheless, the
packet aggregation into flow records naturally causes information loss;
therefore, this paper proposes a novel flow extension for traffic features
based on the time series analysis of the Single Flow Time series, i.e., a time
series created by the number of bytes in each packet and its timestamp. We
propose 69 universal features based on the statistical analysis of data points,
time domain analysis, packet distribution within the flow timespan, time series
behavior, and frequency domain analysis. We have demonstrated the usability and
universality of the proposed feature vector for various network traffic
classification tasks using 15 well-known publicly available datasets. Our
evaluation shows that the novel feature vector achieves classification
performance similar or better than related works on both binary and multiclass
classification tasks. In more than half of the evaluated tasks, the
classification performance increased by up to 5\%.",http://arxiv.org/pdf/2307.13434v1,cs.LG
2023-07-24 10:14:51+00:00,"TransFusion: Generating Long, High Fidelity Time Series using Diffusion Models with Transformers","['Md Fahim Sikder', 'Resmi Ramachandranpillai', 'Fredrik Heintz']","The generation of high-quality, long-sequenced time-series data is essential
due to its wide range of applications. In the past, standalone Recurrent and
Convolutional Neural Network-based Generative Adversarial Networks (GAN) were
used to synthesize time-series data. However, they are inadequate for
generating long sequences of time-series data due to limitations in the
architecture. Furthermore, GANs are well known for their training instability
and mode collapse problem. To address this, we propose TransFusion, a
diffusion, and transformers-based generative model to generate high-quality
long-sequence time-series data. We have stretched the sequence length to 384,
and generated high-quality synthetic data. To the best of our knowledge, this
is the first study that has been done with this long-sequence length. Also, we
introduce two evaluation metrics to evaluate the quality of the synthetic data
as well as its predictive characteristics. We evaluate TransFusion with a wide
variety of visual and empirical metrics, and TransFusion outperforms the
previous state-of-the-art by a significant margin.",http://arxiv.org/pdf/2307.12667v1,cs.LG
2023-07-21 10:56:36+00:00,"Predict, Refine, Synthesize: Self-Guiding Diffusion Models for Probabilistic Time Series Forecasting","['Marcel Kollovieh', 'Abdul Fatir Ansari', 'Michael Bohlke-Schneider', 'Jasper Zschiegner', 'Hao Wang', 'Yuyang Wang']","Diffusion models have achieved state-of-the-art performance in generative
modeling tasks across various domains. Prior works on time series diffusion
models have primarily focused on developing conditional models tailored to
specific forecasting or imputation tasks. In this work, we explore the
potential of task-agnostic, unconditional diffusion models for several time
series applications. We propose TSDiff, an unconditionally trained diffusion
model for time series. Our proposed self-guidance mechanism enables
conditioning TSDiff for downstream tasks during inference, without requiring
auxiliary networks or altering the training procedure. We demonstrate the
effectiveness of our method on three different time series tasks: forecasting,
refinement, and synthetic data generation. First, we show that TSDiff is
competitive with several task-specific conditional forecasting methods
(predict). Second, we leverage the learned implicit probability density of
TSDiff to iteratively refine the predictions of base forecasters with reduced
computational overhead over reverse diffusion (refine). Notably, the generative
performance of the model remains intact -- downstream forecasters trained on
synthetic samples from TSDiff outperform forecasters that are trained on
samples from other state-of-the-art generative time series models, occasionally
even outperforming models trained on real data (synthesize).",http://arxiv.org/pdf/2307.11494v1,cs.LG
2023-07-21 10:45:08+00:00,A New Deep State-Space Analysis Framework for Patient Latent State Estimation and Classification from EHR Time Series Data,"['Aya Nakamura', 'Ryosuke Kojima', 'Yuji Okamoto', 'Eiichiro Uchino', 'Yohei Mineharu', 'Yohei Harada', 'Mayumi Kamada', 'Manabu Muto', 'Motoko Yanagita', 'Yasushi Okuno']","Many diseases, including cancer and chronic conditions, require extended
treatment periods and long-term strategies. Machine learning and AI research
focusing on electronic health records (EHRs) have emerged to address this need.
Effective treatment strategies involve more than capturing sequential changes
in patient test values. It requires an explainable and clinically interpretable
model by capturing the patient's internal state over time.
  In this study, we propose the ""deep state-space analysis framework,"" using
time-series unsupervised learning of EHRs with a deep state-space model. This
framework enables learning, visualizing, and clustering of temporal changes in
patient latent states related to disease progression.
  We evaluated our framework using time-series laboratory data from 12,695
cancer patients. By estimating latent states, we successfully discover latent
states related to prognosis. By visualization and cluster analysis, the
temporal transition of patient status and test items during state transitions
characteristic of each anticancer drug were identified. Our framework surpasses
existing methods in capturing interpretable latent space. It can be expected to
enhance our comprehension of disease progression from EHRs, aiding treatment
adjustments and prognostic determinations.",http://arxiv.org/pdf/2307.11487v1,cs.LG
2023-07-20 14:49:58+00:00,Sequential Multi-Dimensional Self-Supervised Learning for Clinical Time Series,"['Aniruddh Raghu', 'Payal Chandak', 'Ridwan Alam', 'John Guttag', 'Collin M. Stultz']","Self-supervised learning (SSL) for clinical time series data has received
significant attention in recent literature, since these data are highly rich
and provide important information about a patient's physiological state.
However, most existing SSL methods for clinical time series are limited in that
they are designed for unimodal time series, such as a sequence of structured
features (e.g., lab values and vitals signs) or an individual high-dimensional
physiological signal (e.g., an electrocardiogram). These existing methods
cannot be readily extended to model time series that exhibit multimodality,
with structured features and high-dimensional data being recorded at each
timestep in the sequence. In this work, we address this gap and propose a new
SSL method -- Sequential Multi-Dimensional SSL -- where a SSL loss is applied
both at the level of the entire sequence and at the level of the individual
high-dimensional data points in the sequence in order to better capture
information at both scales. Our strategy is agnostic to the specific form of
loss function used at each level -- it can be contrastive, as in SimCLR, or
non-contrastive, as in VICReg. We evaluate our method on two real-world
clinical datasets, where the time series contains sequences of (1)
high-frequency electrocardiograms and (2) structured data from lab values and
vitals signs. Our experimental results indicate that pre-training with our
method and then fine-tuning on downstream tasks improves performance over
baselines on both datasets, and in several settings, can lead to improvements
across different self-supervised loss functions.",http://arxiv.org/pdf/2307.10923v1,cs.LG
2023-07-20 07:33:36+00:00,Refining the Optimization Target for Automatic Univariate Time Series Anomaly Detection in Monitoring Services,"['Manqing Dong', 'Zhanxiang Zhao', 'Yitong Geng', 'Wentao Li', 'Wei Wang', 'Huai Jiang']","Time series anomaly detection is crucial for industrial monitoring services
that handle a large volume of data, aiming to ensure reliability and optimize
system performance. Existing methods often require extensive labeled resources
and manual parameter selection, highlighting the need for automation. This
paper proposes a comprehensive framework for automatic parameter optimization
in time series anomaly detection models. The framework introduces three
optimization targets: prediction score, shape score, and sensitivity score,
which can be easily adapted to different model backbones without prior
knowledge or manual labeling efforts. The proposed framework has been
successfully applied online for over six months, serving more than 50,000 time
series every minute. It simplifies the user's experience by requiring only an
expected sensitive value, offering a user-friendly interface, and achieving
desired detection results. Extensive evaluations conducted on public datasets
and comparison with other methods further confirm the effectiveness of the
proposed framework.",http://arxiv.org/pdf/2307.10653v1,cs.LG
2023-07-19 20:48:44+00:00,Latent Gaussian dynamic factor modeling and forecasting for multivariate count time series,"['Younghoon Kim', 'Zachary F. Fisher', 'Vladas Pipiras']","This work considers estimation and forecasting in a multivariate count time
series model based on a copula-type transformation of a Gaussian dynamic factor
model. The estimation is based on second-order properties of the count and
underlying Gaussian models and applies to the case where the model dimension is
larger than the sample length. In addition, novel cross-validation schemes are
suggested for model selection. The forecasting is carried out through a
particle-based sequential Monte Carlo, leveraging Kalman filtering techniques.
A simulation study and an application are also considered.",http://arxiv.org/pdf/2307.10454v1,stat.ME
2023-07-19 13:23:52+00:00,"Correlation networks, dynamic factor models and community detection","['Shankar Bhamidi', 'Dhruv Patel', 'Vladas Pipiras', 'Guorong Wu']","A dynamic factor model with a mixture distribution of the loadings is
introduced and studied for multivariate, possibly high-dimensional time series.
The correlation matrix of the model exhibits a block structure, reminiscent of
correlation patterns for many real multivariate time series. A standard
$k$-means algorithm on the loadings estimated through principal components is
used to cluster component time series into communities with accompanying bounds
on the misclustering rate. This is one standard method of community detection
applied to correlation matrices viewed as weighted networks. This work puts a
mixture model, a dynamic factor model and network community detection in one
interconnected framework. Performance of the proposed methodology is
illustrated on simulated and real data.",http://arxiv.org/pdf/2307.09970v1,stat.ME
2023-07-19 05:58:21+00:00,Sig-Splines: universal approximation and convex calibration of time series generative models,"['Magnus Wiese', 'Phillip Murray', 'Ralf Korn']","We propose a novel generative model for multivariate discrete-time time
series data. Drawing inspiration from the construction of neural spline flows,
our algorithm incorporates linear transformations and the signature transform
as a seamless substitution for traditional neural networks. This approach
enables us to achieve not only the universality property inherent in neural
networks but also introduces convexity in the model's parameters.",http://arxiv.org/pdf/2307.09767v1,cs.LG
2023-07-18 11:15:28+00:00,Optimal Short-Term Forecast for Locally Stationary Functional Time Series,"['Yan Cui', 'Zhou Zhou']","Accurate curve forecasting is of vital importance for policy planning,
decision making and resource allocation in many engineering and industrial
applications. In this paper we establish a theoretical foundation for the
optimal short-term linear prediction of non-stationary functional or curve time
series with smoothly time-varying data generating mechanisms. The core of this
work is to establish a unified functional auto-regressive approximation result
for a general class of locally stationary functional time series. A double
sieve expansion method is proposed and theoretically verified for the
asymptotic optimal forecasting. A telecommunication traffic data set is used to
illustrate the usefulness of the proposed theory and methodology.",http://arxiv.org/pdf/2307.09148v1,stat.ME
2023-07-18 07:15:26+00:00,U-shaped Transformer: Retain High Frequency Context in Time Series Analysis,"['Qingkui Chen', 'Yiqin Zhang']","Time series prediction plays a crucial role in various industrial fields. In
recent years, neural networks with a transformer backbone have achieved
remarkable success in many domains, including computer vision and NLP. In time
series analysis domain, some studies have suggested that even the simplest MLP
networks outperform advanced transformer-based networks on time series forecast
tasks. However, we believe these findings indicate there to be low-rank
properties in time series sequences. In this paper, we consider the low-pass
characteristics of transformers and try to incorporate the advantages of MLP.
We adopt skip-layer connections inspired by Unet into traditional transformer
backbone, thus preserving high-frequency context from input to output, namely
U-shaped Transformer. We introduce patch merge and split operation to extract
features with different scales and use larger datasets to fully make use of the
transformer backbone. Our experiments demonstrate that the model performs at an
advanced level across multiple datasets with relatively low cost.",http://arxiv.org/pdf/2307.09019v2,cs.LG
2023-07-17 11:04:27+00:00,Correlation-aware Spatial-Temporal Graph Learning for Multivariate Time-series Anomaly Detection,"['Yu Zheng', 'Huan Yee Koh', 'Ming Jin', 'Lianhua Chi', 'Khoa T. Phan', 'Shirui Pan', 'Yi-Ping Phoebe Chen', 'Wei Xiang']","Multivariate time-series anomaly detection is critically important in many
applications, including retail, transportation, power grid, and water treatment
plants. Existing approaches for this problem mostly employ either statistical
models which cannot capture the non-linear relations well or conventional deep
learning models (e.g., CNN and LSTM) that do not explicitly learn the pairwise
correlations among variables. To overcome these limitations, we propose a novel
method, correlation-aware spatial-temporal graph learning (termed CST-GL), for
time series anomaly detection. CST-GL explicitly captures the pairwise
correlations via a multivariate time series correlation learning module based
on which a spatial-temporal graph neural network (STGNN) can be developed.
Then, by employing a graph convolution network that exploits one- and multi-hop
neighbor information, our STGNN component can encode rich spatial information
from complex pairwise dependencies between variables. With a temporal module
that consists of dilated convolutional functions, the STGNN can further capture
long-range dependence over time. A novel anomaly scoring component is further
integrated into CST-GL to estimate the degree of an anomaly in a purely
unsupervised manner. Experimental results demonstrate that CST-GL can detect
anomalies effectively in general settings as well as enable early detection
across different time delays.",http://arxiv.org/pdf/2307.08390v1,cs.LG
2023-07-17 07:55:21+00:00,GBT: Two-stage transformer framework for non-stationary time series forecasting,"['Li Shen', 'Yuning Wei', 'Yangzhu Wang']","This paper shows that time series forecasting Transformer (TSFT) suffers from
severe over-fitting problem caused by improper initialization method of unknown
decoder inputs, esp. when handling non-stationary time series. Based on this
observation, we propose GBT, a novel two-stage Transformer framework with Good
Beginning. It decouples the prediction process of TSFT into two stages,
including Auto-Regression stage and Self-Regression stage to tackle the problem
of different statistical properties between input and prediction
sequences.Prediction results of Auto-Regression stage serve as a Good
Beginning, i.e., a better initialization for inputs of Self-Regression stage.
We also propose Error Score Modification module to further enhance the
forecasting capability of the Self-Regression stage in GBT. Extensive
experiments on seven benchmark datasets demonstrate that GBT outperforms SOTA
TSFTs (FEDformer, Pyraformer, ETSformer, etc.) and many other forecasting
models (SCINet, N-HiTS, etc.) with only canonical attention and convolution
while owning less time and space complexity. It is also general enough to
couple with these models to strengthen their forecasting capability. The source
code is available at: https://github.com/OrigamiSL/GBT",http://arxiv.org/pdf/2307.08302v1,cs.LG
2023-07-15 02:11:40+00:00,Learning Subjective Time-Series Data via Utopia Label Distribution Approximation,"['Wenxin Xu', 'Hexin Jiang', 'Xuefeng Liang', 'Ying Zhou', 'Yin Zhao', 'Jie Zhang']","Subjective time-series regression (STR) tasks have gained increasing
attention recently. However, most existing methods overlook the label
distribution bias in STR data, which results in biased models. Emerging studies
on imbalanced regression tasks, such as age estimation and depth estimation,
hypothesize that the prior label distribution of the dataset is uniform.
However, we observe that the label distributions of training and test sets in
STR tasks are likely to be neither uniform nor identical. This distinct feature
calls for new approaches that estimate more reasonable distributions to train a
fair model. In this work, we propose Utopia Label Distribution Approximation
(ULDA) for time-series data, which makes the training label distribution closer
to real-world but unknown (utopia) label distribution. This would enhance the
model's fairness. Specifically, ULDA first convolves the training label
distribution by a Gaussian kernel. After convolution, the required sample
quantity at each regression label may change. We further devise the Time-slice
Normal Sampling (TNS) to generate new samples when the required sample quantity
is greater than the initial sample quantity, and the Convolutional Weighted
Loss (CWL) to lower the sample weight when the required sample quantity is less
than the initial quantity. These two modules not only assist the model training
on the approximated utopia label distribution, but also maintain the sample
continuity in temporal context space. To the best of our knowledge, ULDA is the
first method to address the label distribution bias in time-series data.
Extensive experiments demonstrate that ULDA lifts the state-of-the-art
performance on two STR tasks and three benchmark datasets.",http://arxiv.org/pdf/2307.07682v1,cs.LG
2023-07-13 19:03:06+00:00,Multi-view self-supervised learning for multivariate variable-channel time series,"['Thea Brüsch', 'Mikkel N. Schmidt', 'Tommy S. Alstrøm']","Labeling of multivariate biomedical time series data is a laborious and
expensive process. Self-supervised contrastive learning alleviates the need for
large, labeled datasets through pretraining on unlabeled data. However, for
multivariate time series data, the set of input channels often varies between
applications, and most existing work does not allow for transfer between
datasets with different sets of input channels. We propose learning one encoder
to operate on all input channels individually. We then use a message passing
neural network to extract a single representation across channels. We
demonstrate the potential of this method by pretraining our model on a dataset
with six EEG channels and then fine-tuning it on a dataset with two different
EEG channels. We compare models with and without the message passing neural
network across different contrastive loss functions. We show that our method,
combined with the TS2Vec loss, outperforms all other methods in most settings.",http://arxiv.org/pdf/2307.09614v2,stat.ML
2023-07-13 16:38:01+00:00,Sequential Monte Carlo Learning for Time Series Structure Discovery,"['Feras A. Saad', 'Brian J. Patton', 'Matthew D. Hoffman', 'Rif A. Saurous', 'Vikash K. Mansinghka']","This paper presents a new approach to automatically discovering accurate
models of complex time series data. Working within a Bayesian nonparametric
prior over a symbolic space of Gaussian process time series models, we present
a novel structure learning algorithm that integrates sequential Monte Carlo
(SMC) and involutive MCMC for highly effective posterior inference. Our method
can be used both in ""online"" settings, where new data is incorporated
sequentially in time, and in ""offline"" settings, by using nested subsets of
historical data to anneal the posterior. Empirical measurements on real-world
time series show that our method can deliver 10x--100x runtime speedups over
previous MCMC and greedy-search structure learning algorithms targeting the
same model family. We use our method to perform the first large-scale
evaluation of Gaussian process time series structure learning on a prominent
benchmark of 1,428 econometric datasets. The results show that our method
discovers sensible models that deliver more accurate point forecasts and
interval forecasts over multiple horizons as compared to widely used
statistical and neural baselines that struggle on this challenging data.",http://arxiv.org/pdf/2307.09607v1,cs.LG
2023-07-13 13:16:01+00:00,MPR-Net:Multi-Scale Pattern Reproduction Guided Universality Time Series Interpretable Forecasting,"['Tianlong Zhao', 'Xiang Ma', 'Xuemei Li', 'Caiming Zhang']","Time series forecasting has received wide interest from existing research due
to its broad applications and inherent challenging. The research challenge lies
in identifying effective patterns in historical series and applying them to
future forecasting. Advanced models based on point-wise connected MLP and
Transformer architectures have strong fitting power, but their secondary
computational complexity limits practicality. Additionally, those structures
inherently disrupt the temporal order, reducing the information utilization and
making the forecasting process uninterpretable. To solve these problems, this
paper proposes a forecasting model, MPR-Net. It first adaptively decomposes
multi-scale historical series patterns using convolution operation, then
constructs a pattern extension forecasting method based on the prior knowledge
of pattern reproduction, and finally reconstructs future patterns into future
series using deconvolution operation. By leveraging the temporal dependencies
present in the time series, MPR-Net not only achieves linear time complexity,
but also makes the forecasting process interpretable. By carrying out
sufficient experiments on more than ten real data sets of both short and long
term forecasting tasks, MPR-Net achieves the state of the art forecasting
performance, as well as good generalization and robustness performance.",http://arxiv.org/pdf/2307.06736v1,cs.LG
2023-07-11 08:26:08+00:00,A Deep Dive into Perturbations as Evaluation Technique for Time Series XAI,"['Udo Schlegel', 'Daniel A. Keim']","Explainable Artificial Intelligence (XAI) has gained significant attention
recently as the demand for transparency and interpretability of machine
learning models has increased. In particular, XAI for time series data has
become increasingly important in finance, healthcare, and climate science.
However, evaluating the quality of explanations, such as attributions provided
by XAI techniques, remains challenging. This paper provides an in-depth
analysis of using perturbations to evaluate attributions extracted from time
series models. A perturbation analysis involves systematically modifying the
input data and evaluating the impact on the attributions generated by the XAI
method. We apply this approach to several state-of-the-art XAI techniques and
evaluate their performance on three time series classification datasets. Our
results demonstrate that the perturbation analysis approach can effectively
evaluate the quality of attributions and provide insights into the strengths
and limitations of XAI techniques. Such an approach can guide the selection of
XAI methods for time series data, e.g., focusing on return time rather than
precision, and facilitate the development of more reliable and interpretable
machine learning models for time series analysis.",http://arxiv.org/pdf/2307.05104v1,cs.LG
2023-07-10 09:53:14+00:00,Learning Behavioral Representations of Routines From Large-scale Unlabeled Wearable Time-series Data Streams using Hawkes Point Process,"['Tiantian Feng', 'Brandon M Booth', 'Shrikanth Narayanan']","Continuously-worn wearable sensors enable researchers to collect copious
amounts of rich bio-behavioral time series recordings of real-life activities
of daily living, offering unprecedented opportunities to infer novel human
behavior patterns during daily routines. Existing approaches to routine
discovery through bio-behavioral data rely either on pre-defined notions of
activities or use additional non-behavioral measurements as contexts, such as
GPS location or localization within the home, presenting risks to user privacy.
In this work, we propose a novel wearable time-series mining framework, Hawkes
point process On Time series clusters for ROutine Discovery (HOT-ROD), for
uncovering behavioral routines from completely unlabeled wearable recordings.
We utilize a covariance-based method to generate time-series clusters and
discover routines via the Hawkes point process learning algorithm. We
empirically validate our approach for extracting routine behaviors using a
completely unlabeled time-series collected continuously from over 100
individuals both in and outside of the workplace during a period of ten weeks.
Furthermore, we demonstrate this approach intuitively captures daily
transitional relationships between physical activity states without using prior
knowledge. We also show that the learned behavioral patterns can assist in
illuminating an individual's personality and affect.",http://arxiv.org/pdf/2307.04445v1,cs.LG
2023-07-10 03:20:08+00:00,Two-Sample and Change-Point Inference for Non-Euclidean Valued Time Series,"['Feiyu Jiang', 'Changbo Zhu', 'Xiaofeng Shao']","Data objects taking value in a general metric space have become increasingly
common in modern data analysis. In this paper, we study two important
statistical inference problems, namely, two-sample testing and change-point
detection, for such non-Euclidean data under temporal dependence. Typical
examples of non-Euclidean valued time series include yearly mortality
distributions, time-varying networks, and covariance matrix time series. To
accommodate unknown temporal dependence, we advance the self-normalization (SN)
technique (Shao, 2010) to the inference of non-Euclidean time series, which is
substantially different from the existing SN-based inference for functional
time series that reside in Hilbert space (Zhang et al., 2011). Theoretically,
we propose new regularity conditions that could be easier to check than those
in the recent literature, and derive the limiting distributions of the proposed
test statistics under both null and local alternatives. For change-point
detection problem, we also derive the consistency for the change-point location
estimator, and combine our proposed change-point test with wild binary
segmentation to perform multiple change-point estimation. Numerical simulations
demonstrate the effectiveness and robustness of our proposed tests compared
with existing methods in the literature. Finally, we apply our tests to
two-sample inference in mortality data and change-point detection in
cryptocurrency data.",http://arxiv.org/pdf/2307.04318v1,stat.ME
2023-07-07 13:38:16+00:00,GEANN: Scalable Graph Augmentations for Multi-Horizon Time Series Forecasting,"['Sitan Yang', 'Malcolm Wolff', 'Shankar Ramasubramanian', 'Vincent Quenneville-Belair', 'Ronak Metha', 'Michael W. Mahoney']","Encoder-decoder deep neural networks have been increasingly studied for
multi-horizon time series forecasting, especially in real-world applications.
However, to forecast accurately, these sophisticated models typically rely on a
large number of time series examples with substantial history. A rapidly
growing topic of interest is forecasting time series which lack sufficient
historical data -- often referred to as the ``cold start'' problem. In this
paper, we introduce a novel yet simple method to address this problem by
leveraging graph neural networks (GNNs) as a data augmentation for enhancing
the encoder used by such forecasters. These GNN-based features can capture
complex inter-series relationships, and their generation process can be
optimized end-to-end with the forecasting task. We show that our architecture
can use either data-driven or domain knowledge-defined graphs, scaling to
incorporate information from multiple very large graphs with millions of nodes.
In our target application of demand forecasting for a large e-commerce
retailer, we demonstrate on both a small dataset of 100K products and a large
dataset with over 2 million products that our method improves overall
performance over competitive baseline models. More importantly, we show that it
brings substantially more gains to ``cold start'' products such as those newly
launched or recently out-of-stock.",http://arxiv.org/pdf/2307.03595v1,cs.LG
2023-07-07 08:05:03+00:00,"A Survey on Graph Neural Networks for Time Series: Forecasting, Classification, Imputation, and Anomaly Detection","['Ming Jin', 'Huan Yee Koh', 'Qingsong Wen', 'Daniele Zambon', 'Cesare Alippi', 'Geoffrey I. Webb', 'Irwin King', 'Shirui Pan']","Time series are the primary data type used to record dynamic system
measurements and generated in great volume by both physical sensors and online
processes (virtual sensors). Time series analytics is therefore crucial to
unlocking the wealth of information implicit in available data. With the recent
advancements in graph neural networks (GNNs), there has been a surge in
GNN-based approaches for time series analysis. These approaches can explicitly
model inter-temporal and inter-variable relationships, which traditional and
other deep neural network-based methods struggle to do. In this survey, we
provide a comprehensive review of graph neural networks for time series
analysis (GNN4TS), encompassing four fundamental dimensions: forecasting,
classification, anomaly detection, and imputation. Our aim is to guide
designers and practitioners to understand, build applications, and advance
research of GNN4TS. At first, we provide a comprehensive task-oriented taxonomy
of GNN4TS. Then, we present and discuss representative research works and
introduce mainstream applications of GNN4TS. A comprehensive discussion of
potential future research directions completes the survey. This survey, for the
first time, brings together a vast array of knowledge on GNN-based time series
research, highlighting foundations, practical applications, and opportunities
of graph neural networks for time series analysis.",http://arxiv.org/pdf/2307.03759v2,cs.LG
2023-07-06 15:01:58+00:00,FITS: Modeling Time Series with $10k$ Parameters,"['Zhijian Xu', 'Ailing Zeng', 'Qiang Xu']","In this paper, we introduce FITS, a lightweight yet powerful model for time
series analysis. Unlike existing models that directly process raw time-domain
data, FITS operates on the principle that time series can be manipulated
through interpolation in the complex frequency domain. By discarding
high-frequency components with negligible impact on time series data, FITS
achieves performance comparable to state-of-the-art models for time series
forecasting and anomaly detection tasks, while having a remarkably compact size
of only approximately $10k$ parameters. Such a lightweight model can be easily
trained and deployed in edge devices, creating opportunities for various
applications. The anonymous code repo is available in:
\url{https://anonymous.4open.science/r/FITS}",http://arxiv.org/pdf/2307.03756v2,cs.LG
2023-07-05 12:50:48+00:00,Multivariate Time Series Classification: A Deep Learning Approach,"['Mohamed Abouelnaga', 'Julien Vitay', 'Aida Farahani']","This paper investigates different methods and various neural network
architectures applicable in the time series classification domain. The data is
obtained from a fleet of gas sensors that measure and track quantities such as
oxygen and sound. With the help of this data, we can detect events such as
occupancy in a specific environment. At first, we analyze the time series data
to understand the effect of different parameters, such as the sequence length,
when training our models. These models employ Fully Convolutional Networks
(FCN) and Long Short-Term Memory (LSTM) for supervised learning and Recurrent
Autoencoders for semisupervised learning. Throughout this study, we spot the
differences between these methods based on metrics such as precision and recall
identifying which technique best suits this problem.",http://arxiv.org/pdf/2307.02253v1,cs.LG
2023-07-05 09:56:22+00:00,Noise reduction for functional time series,"['Cees Diks', 'Bram Wouters']","A novel method for noise reduction in the setting of curve time series with
error contamination is proposed, based on extending the framework of functional
principal component analysis (FPCA). We employ the underlying,
finite-dimensional dynamics of the functional time series to separate the
serially dependent dynamical part of the observed curves from the noise. Upon
identifying the subspaces of the signal and idiosyncratic components, we
construct a projection of the observed curve time series along the noise
subspace, resulting in an estimate of the underlying denoised curves. This
projection is optimal in the sense that it minimizes the mean integrated
squared error. By applying our method to similated and real data, we show the
denoising estimator is consistent and outperforms existing denoising
techniques. Furthermore, we show it can be used as a pre-processing step to
improve forecasting.",http://arxiv.org/pdf/2307.02154v1,stat.ME
2023-07-04 13:43:05+00:00,On the Constrained Time-Series Generation Problem,"['Andrea Coletta', 'Sriram Gopalakrishan', 'Daniel Borrajo', 'Svitlana Vyetrenko']","Synthetic time series are often used in practical applications to augment the
historical time series dataset for better performance of machine learning
algorithms, amplify the occurrence of rare events, and also create
counterfactual scenarios described by the time series.
Distributional-similarity (which we refer to as realism) as well as the
satisfaction of certain numerical constraints are common requirements in
counterfactual time series scenario generation requests. For instance, the US
Federal Reserve publishes synthetic market stress scenarios given by the
constrained time series for financial institutions to assess their performance
in hypothetical recessions. Existing approaches for generating constrained time
series usually penalize training loss to enforce constraints, and reject
non-conforming samples. However, these approaches would require re-training if
we change constraints, and rejection sampling can be computationally expensive,
or impractical for complex constraints. In this paper, we propose a novel set
of methods to tackle the constrained time series generation problem and provide
efficient sampling while ensuring the realism of generated time series. In
particular, we frame the problem using a constrained optimization framework and
then we propose a set of generative methods including ""GuidedDiffTime"", a
guided diffusion model to generate realistic time series. Empirically, we
evaluate our work on several datasets for financial and energy data, where
incorporating constraints is critical. We show that our approaches outperform
existing work both qualitatively and quantitatively. Most importantly, we show
that our ""GuidedDiffTime"" model is the only solution where re-training is not
necessary for new constraints, resulting in a significant carbon footprint
reduction, up to 92% w.r.t. existing deep learning methods.",http://arxiv.org/pdf/2307.01717v2,cs.LG
2023-07-04 10:08:25+00:00,SageFormer: Series-Aware Framework for Long-term Multivariate Time Series Forecasting,"['Zhenwei Zhang', 'Linghang Meng', 'Yuantao Gu']","In the burgeoning ecosystem of Internet of Things, multivariate time series
(MTS) data has become ubiquitous, highlighting the fundamental role of time
series forecasting across numerous applications. The crucial challenge of
long-term MTS forecasting requires adept models capable of capturing both
intra- and inter-series dependencies. Recent advancements in deep learning,
notably Transformers, have shown promise. However, many prevailing methods
either marginalize inter-series dependencies or overlook them entirely. To
bridge this gap, this paper introduces a novel series-aware framework,
explicitly designed to emphasize the significance of such dependencies. At the
heart of this framework lies our specific implementation: the SageFormer. As a
Series-aware Graph-enhanced Transformer model, SageFormer proficiently discerns
and models the intricate relationships between series using graph structures.
Beyond capturing diverse temporal patterns, it also curtails redundant
information across series. Notably, the series-aware framework seamlessly
integrates with existing Transformer-based models, enriching their ability to
comprehend inter-series relationships. Extensive experiments on real-world and
synthetic datasets validate the superior performance of SageFormer against
contemporary state-of-the-art approaches.",http://arxiv.org/pdf/2307.01616v2,cs.LG
2023-07-04 09:40:30+00:00,Prototypes as Explanation for Time Series Anomaly Detection,"['Bin Li', 'Carsten Jentsch', 'Emmanuel Müller']","Detecting abnormal patterns that deviate from a certain regular repeating
pattern in time series is essential in many big data applications. However, the
lack of labels, the dynamic nature of time series data, and unforeseeable
abnormal behaviors make the detection process challenging. Despite the success
of recent deep anomaly detection approaches, the mystical mechanisms in such
black-box models have become a new challenge in safety-critical applications.
The lack of model transparency and prediction reliability hinders further
breakthroughs in such domains. This paper proposes ProtoAD, using prototypes as
the example-based explanation for the state of regular patterns during anomaly
detection. Without significant impact on the detection performance, prototypes
shed light on the deep black-box models and provide intuitive understanding for
domain experts and stakeholders. We extend the widely used prototype learning
in classification problems into anomaly detection. By visualizing both the
latent space and input space prototypes, we intuitively demonstrate how regular
data are modeled and why specific patterns are considered abnormal.",http://arxiv.org/pdf/2307.01601v1,cs.LG
2023-07-04 09:38:38+00:00,Unlocking the Potential of Deep Learning in Peak-Hour Series Forecasting,"['Zhenwei Zhang', 'Xin Wang', 'Jingyuan Xie', 'Heling Zhang', 'Yuantao Gu']","Unlocking the potential of deep learning in Peak-Hour Series Forecasting
(PHSF) remains a critical yet underexplored task in various domains. While
state-of-the-art deep learning models excel in regular Time Series Forecasting
(TSF), they struggle to achieve comparable results in PHSF. This can be
attributed to the challenges posed by the high degree of non-stationarity in
peak-hour series, which makes direct forecasting more difficult than standard
TSF. Additionally, manually extracting the maximum value from regular
forecasting results leads to suboptimal performance due to models minimizing
the mean deficit. To address these issues, this paper presents Seq2Peak, a
novel framework designed specifically for PHSF tasks, bridging the performance
gap observed in TSF models. Seq2Peak offers two key components: the CyclicNorm
pipeline to mitigate the non-stationarity issue and a simple yet effective
trainable-parameter-free peak-hour decoder with a hybrid loss function that
utilizes both the original series and peak-hour series as supervised signals.
Extensive experimentation on publicly available time series datasets
demonstrates the effectiveness of the proposed framework, yielding a remarkable
average relative improvement of 37.7% across four real-world datasets for both
transformer- and non-transformer-based TSF models.",http://arxiv.org/pdf/2307.01597v2,cs.LG
2023-07-03 19:41:22+00:00,A log-linear model for non-stationary time series of counts,"['Anne Leucht', 'Michael H. Neumann']","We propose a new model for nonstationary integer-valued time series which is
particularly suitable for data with a strong trend. In contrast to popular
Poisson-INGARCH models, but in line with classical GARCH models, we propose to
pick the conditional distributions from nearly scale invariant families where
the mean absolute value and the standard deviation are of the same order of
magnitude. As an important prerequisite for applications in statistics, we
prove absolute regularity of the count process with exponentially decaying
coefficients.",http://arxiv.org/pdf/2307.01315v1,math.ST
2023-07-03 09:08:47+00:00,MADS: Modulated Auto-Decoding SIREN for time series imputation,"['Tom Bamford', 'Elizabeth Fons', 'Yousef El-Laham', 'Svitlana Vyetrenko']","Time series imputation remains a significant challenge across many fields due
to the potentially significant variability in the type of data being modelled.
Whilst traditional imputation methods often impose strong assumptions on the
underlying data generation process, limiting their applicability, researchers
have recently begun to investigate the potential of deep learning for this
task, inspired by the strong performance shown by these models in both
classification and regression problems across a range of applications. In this
work we propose MADS, a novel auto-decoding framework for time series
imputation, built upon implicit neural representations. Our method leverages
the capabilities of SIRENs for high fidelity reconstruction of signals and
irregular data, and combines it with a hypernetwork architecture which allows
us to generalise by learning a prior over the space of time series. We evaluate
our model on two real-world datasets, and show that it outperforms
state-of-the-art methods for time series imputation. On the human activity
dataset, it improves imputation performance by at least 40%, while on the air
quality dataset it is shown to be competitive across all metrics. When
evaluated on synthetic data, our model results in the best average rank across
different dataset configurations over all baselines.",http://arxiv.org/pdf/2307.00868v1,stat.ML
2023-07-03 04:57:40+00:00,ImDiffusion: Imputed Diffusion Models for Multivariate Time Series Anomaly Detection,"['Yuhang Chen', 'Chaoyun Zhang', 'Minghua Ma', 'Yudong Liu', 'Ruomeng Ding', 'Bowen Li', 'Shilin He', 'Saravan Rajmohan', 'Qingwei Lin', 'Dongmei Zhang']","Anomaly detection in multivariate time series data is of paramount importance
for ensuring the efficient operation of large-scale systems across diverse
domains. However, accurately detecting anomalies in such data poses significant
challenges. Existing approaches, including forecasting and reconstruction-based
methods, struggle to address these challenges effectively. To overcome these
limitations, we propose a novel anomaly detection framework named ImDiffusion,
which combines time series imputation and diffusion models to achieve accurate
and robust anomaly detection. The imputation-based approach employed by
ImDiffusion leverages the information from neighboring values in the time
series, enabling precise modeling of temporal and inter-correlated
dependencies, reducing uncertainty in the data, thereby enhancing the
robustness of the anomaly detection process. ImDiffusion further leverages
diffusion models as time series imputers to accurately capturing complex
dependencies. We leverage the step-by-step denoised outputs generated during
the inference process to serve as valuable signals for anomaly prediction,
resulting in improved accuracy and robustness of the detection process.
  We evaluate the performance of ImDiffusion via extensive experiments on
benchmark datasets. The results demonstrate that our proposed framework
significantly outperforms state-of-the-art approaches in terms of detection
accuracy and timeliness. ImDiffusion is further integrated into the real
production system in Microsoft and observe a remarkable 11.4% increase in
detection F1 score compared to the legacy approach. To the best of our
knowledge, ImDiffusion represents a pioneering approach that combines
imputation-based techniques with time series anomaly detection, while
introducing the novel use of diffusion models to the field.",http://arxiv.org/pdf/2307.00754v1,cs.LG
2023-07-02 06:48:19+00:00,Fourier-Mixed Window Attention: Accelerating Informer for Long Sequence Time-Series Forecasting,"['Nhat Thanh Tran', 'Jack Xin']","We study a fast local-global window-based attention method to accelerate
Informer for long sequence time-series forecasting. While window attention is
local and a considerable computational saving, it lacks the ability to capture
global token information which is compensated by a subsequent Fourier transform
block. Our method, named FWin, does not rely on query sparsity hypothesis and
an empirical approximation underlying the ProbSparse attention of Informer.
Through experiments on univariate and multivariate datasets, we show that FWin
transformers improve the overall prediction accuracies of Informer while
accelerating its inference speeds by 40 to 50 %. We also show in a nonlinear
regression model that a learned FWin type attention approaches or even
outperforms softmax full attention based on key vectors extracted from an
Informer model's full attention layer acting on time series data.",http://arxiv.org/pdf/2307.00493v1,cs.LG
2023-06-30 18:12:22+00:00,Improving the Transferability of Time Series Forecasting with Decomposition Adaptation,"['Yan Gao', 'Yan Wang', 'Qiang Wang']","Due to effective pattern mining and feature representation, neural
forecasting models based on deep learning have achieved great progress. The
premise of effective learning is to collect sufficient data. However, in time
series forecasting, it is difficult to obtain enough data, which limits the
performance of neural forecasting models. To alleviate the data scarcity
limitation, we design Sequence Decomposition Adaptation Network (SeDAN) which
is a novel transfer architecture to improve forecasting performance on the
target domain by aligning transferable knowledge from cross-domain datasets.
Rethinking the transferability of features in time series data, we propose
Implicit Contrastive Decomposition to decompose the original features into
components including seasonal and trend features, which are easier to transfer.
Then we design the corresponding adaptation methods for decomposed features in
different domains. Specifically, for seasonal features, we perform joint
distribution adaptation and for trend features, we design an Optimal Local
Adaptation. We conduct extensive experiments on five benchmark datasets for
multivariate time series forecasting. The results demonstrate the effectiveness
of our SeDAN. It can provide more efficient and stable knowledge transfer.",http://arxiv.org/pdf/2307.00066v1,cs.LG
2023-06-30 14:18:13+00:00,Generalized Time Warping Invariant Dictionary Learning for Time Series Classification and Clustering,"['Ruiyu Xu', 'Chao Wang', 'Yongxiang Li', 'Jianguo Wu']","Dictionary learning is an effective tool for pattern recognition and
classification of time series data. Among various dictionary learning
techniques, the dynamic time warping (DTW) is commonly used for dealing with
temporal delays, scaling, transformation, and many other kinds of temporal
misalignments issues. However, the DTW suffers overfitting or information loss
due to its discrete nature in aligning time series data. To address this issue,
we propose a generalized time warping invariant dictionary learning algorithm
in this paper. Our approach features a generalized time warping operator, which
consists of linear combinations of continuous basis functions for facilitating
continuous temporal warping. The integration of the proposed operator and the
dictionary learning is formulated as an optimization problem, where the block
coordinate descent method is employed to jointly optimize warping paths,
dictionaries, and sparseness coefficients. The optimized results are then used
as hyperspace distance measures to feed classification and clustering
algorithms. The superiority of the proposed method in terms of dictionary
learning, classification, and clustering is validated through ten sets of
public datasets in comparing with various benchmark methods.",http://arxiv.org/pdf/2306.17690v1,stat.ML
2023-06-29 16:48:00+00:00,Sparsity exploitation via discovering graphical models in multi-variate time-series forecasting,"['Ngoc-Dung Do', 'Truong Son Hy', 'Duy Khuong Nguyen']","Graph neural networks (GNNs) have been widely applied in multi-variate
time-series forecasting (MTSF) tasks because of their capability in capturing
the correlations among different time-series. These graph-based learning
approaches improve the forecasting performance by discovering and understanding
the underlying graph structures, which represent the data correlation. When the
explicit prior graph structures are not available, most existing works cannot
guarantee the sparsity of the generated graphs that make the overall model
computational expensive and less interpretable. In this work, we propose a
decoupled training method, which includes a graph generating module and a GNNs
forecasting module. First, we use Graphical Lasso (or GraphLASSO) to directly
exploit the sparsity pattern from data to build graph structures in both static
and time-varying cases. Second, we fit these graph structures and the input
data into a Graph Convolutional Recurrent Network (GCRN) to train a forecasting
model. The experimental results on three real-world datasets show that our
novel approach has competitive performance against existing state-of-the-art
forecasting algorithms while providing sparse, meaningful and explainable graph
structures and reducing training time by approximately 40%. Our PyTorch
implementation is publicly available at https://github.com/HySonLab/GraphLASSO",http://arxiv.org/pdf/2306.17090v1,cs.LG
2023-06-28 23:07:43+00:00,Forecasting of the development of a partially-observed dynamical time series with the aid of time-invariance and linearity,"['Akifumi Okuno', 'Yuya Morishita', 'Yoh-ichi Mototake']","A dynamical system produces a dependent multivariate sequence called
dynamical time series, developed with an evolution function. As variables in
the dynamical time series at the current time-point usually depend on the whole
variables in the previous time-point, existing studies forecast the variables
at the future time-point by estimating the evolution function. However, some
variables in the dynamical time-series are missing in some practical
situations. In this study, we propose an autoregressive with slack time series
(ARS) model. ARS model involves the simultaneous estimation of the evolution
function and the underlying missing variables as a slack time series, with the
aid of the time-invariance and linearity of the dynamical system. This study
empirically demonstrates the effectiveness of the proposed ARS model.",http://arxiv.org/pdf/2306.16593v1,stat.ME
2023-06-28 05:14:03+00:00,Learning Dynamic Graphs from All Contextual Information for Accurate Point-of-Interest Visit Forecasting,"['Arash Hajisafi', 'Haowen Lin', 'Sina Shaham', 'Haoji Hu', 'Maria Despoina Siampou', 'Yao-Yi Chiang', 'Cyrus Shahabi']","Forecasting the number of visits to Points-of-Interest (POI) in an urban area
is critical for planning and decision-making for various application domains,
from urban planning and transportation management to public health and social
studies. Although this forecasting problem can be formulated as a multivariate
time-series forecasting task, the current approaches cannot fully exploit the
ever-changing multi-context correlations among POIs. Therefore, we propose
Busyness Graph Neural Network (BysGNN), a temporal graph neural network
designed to learn and uncover the underlying multi-context correlations between
POIs for accurate visit forecasting. Unlike other approaches where only
time-series data is used to learn a dynamic graph, BysGNN utilizes all
contextual information and time-series data to learn an accurate dynamic graph
representation. By incorporating all contextual, temporal, and spatial signals,
we observe a significant improvement in our forecasting accuracy over
state-of-the-art forecasting models in our experiments with real-world datasets
across the United States.",http://arxiv.org/pdf/2306.15927v2,cs.LG
2023-06-26 11:30:33+00:00,Multivariate Time Series Early Classification Across Channel and Time Dimensions,"['Leonardos Pantiskas', 'Kees Verstoep', 'Mark Hoogendoorn', 'Henri Bal']","Nowadays, the deployment of deep learning models on edge devices for
addressing real-world classification problems is becoming more prevalent.
Moreover, there is a growing popularity in the approach of early
classification, a technique that involves classifying the input data after
observing only an early portion of it, aiming to achieve reduced communication
and computation requirements, which are crucial parameters in edge intelligence
environments. While early classification in the field of time series analysis
has been broadly researched, existing solutions for multivariate time series
problems primarily focus on early classification along the temporal dimension,
treating the multiple input channels in a collective manner. In this study, we
propose a more flexible early classification pipeline that offers a more
granular consideration of input channels and extends the early classification
paradigm to the channel dimension. To implement this method, we utilize
reinforcement learning techniques and introduce constraints to ensure the
feasibility and practicality of our objective. To validate its effectiveness,
we conduct experiments using synthetic data and we also evaluate its
performance on real datasets. The comprehensive results from our experiments
demonstrate that, for multiple datasets, our method can enhance the early
classification paradigm by achieving improved accuracy for equal input
utilization.",http://arxiv.org/pdf/2306.14606v1,cs.LG
2023-06-23 10:44:49+00:00,On tracking varying bounds when forecasting bounded time series,"['Amandine Pierrot', 'Pierre Pinson']","We consider a new framework where a continuous, though bounded, random
variable has unobserved bounds that vary over time. In the context of
univariate time series, we look at the bounds as parameters of the distribution
of the bounded random variable. We introduce an extended log-likelihood
estimation and design algorithms to track the bound through online maximum
likelihood estimation. Since the resulting optimization problem is not convex,
we make use of recent theoretical results on Normalized Gradient Descent (NGD)
for quasiconvex optimization, to eventually derive an Online Normalized
Gradient Descent algorithm. We illustrate and discuss the workings of our
approach based on both simulation studies and a real-world wind power
forecasting problem.",http://arxiv.org/pdf/2306.13428v1,stat.ML
2023-06-23 09:28:09+00:00,Higher-order Motif-based Time Series Classification for Forced Oscillation Source Location in Power Grids,"['Long Huo', 'Xin Chen']","Time series motifs are used for discovering higher-order structures of time
series data. Based on time series motifs, the motif embedding correlation field
(MECF) is proposed to characterize higher-order temporal structures of
dynamical system time series. A MECF-based unsupervised learning approach is
applied in locating the source of the forced oscillation (FO), a periodic
disturbance that detrimentally impacts power grids. Locating the FO source is
imperative for system stability. Compared with the Fourier analysis, the
MECF-based unsupervised learning is applicable under various FO situations,
including the single FO, FO with resonance, and multiple sources FOs. The
MECF-based unsupervised learning is a data-driven approach without any prior
knowledge requirement of system models or typologies. Tests on the UK
high-voltage transmission grid illustrate the effectiveness of MECF-based
unsupervised learning. In addition, the impacts of coupling strength and
measurement noise on locating the FO source by the MECF-based unsupervised
learning are investigated.",http://arxiv.org/pdf/2306.13397v1,cs.LG
2023-06-22 14:02:49+00:00,Causal discovery for time series from multiple datasets with latent contexts,"['Wiebke Günther', 'Urmi Ninad', 'Jakob Runge']","Causal discovery from time series data is a typical problem setting across
the sciences. Often, multiple datasets of the same system variables are
available, for instance, time series of river runoff from different catchments.
The local catchment systems then share certain causal parents, such as
time-dependent large-scale weather over all catchments, but differ in other
catchment-specific drivers, such as the altitude of the catchment. These
drivers can be called temporal and spatial contexts, respectively, and are
often partially unobserved. Pooling the datasets and considering the joint
causal graph among system, context, and certain auxiliary variables enables us
to overcome such latent confounding of system variables. In this work, we
present a non-parametric time series causal discovery method, J(oint)-PCMCI+,
that efficiently learns such joint causal time series graphs when both observed
and latent contexts are present, including time lags. We present asymptotic
consistency results and numerical experiments demonstrating the utility and
limitations of the method.",http://arxiv.org/pdf/2306.12896v1,stat.ME
2023-06-21 17:57:59+00:00,"A framework for statistical modelling of the extremes of longitudinal data, applied to elite swimming","['Harry Spearing', 'Jonathan Tawn', 'David Irons', 'Tim Paulden']","We develop methods, based on extreme value theory, for analysing observations
in the tails of longitudinal data, i.e., a data set consisting of a large
number of short time series, which are typically irregularly and
non-simultaneously sampled, yet have some commonality in the structure of each
series and exhibit independence between time series. Extreme value theory has
not been considered previously for the unique features of longitudinal data.
Across time series the data are assumed to follow a common generalised Pareto
distribution, above a high threshold. To account for temporal dependence of
such data we require a model to describe (i) the variation between the
different time series properties, (ii) the changes in distribution over time,
and (iii) the temporal dependence within each series. Our methodology has the
flexibility to capture both asymptotic dependence and asymptotic independence,
with this characteristic determined by the data. Bayesian inference is used
given the need for inference of parameters that are unique to each time series.
Our novel methodology is illustrated through the analysis of data from elite
swimmers in the men's 100m breaststroke. Unlike previous analyses of
personal-best data in this event, we are able to make inference about the
careers of individual swimmers - such as the probability an individual will
break the world record or swim the fastest time next year.",http://arxiv.org/pdf/2306.12419v1,stat.ME
2023-06-21 08:05:05+00:00,What Constitutes Good Contrastive Learning in Time-Series Forecasting?,"['Chiyu Zhang', 'Qi Yan', 'Lili Meng', 'Tristan Sylvain']","In recent years, the introduction of self-supervised contrastive learning
(SSCL) has demonstrated remarkable improvements in representation learning
across various domains, including natural language processing and computer
vision. By leveraging the inherent benefits of self-supervision, SSCL enables
the pre-training of representation models using vast amounts of unlabeled data.
Despite these advances, there remains a significant gap in understanding the
impact of different SSCL strategies on time series forecasting performance, as
well as the specific benefits that SSCL can bring. This paper aims to address
these gaps by conducting a comprehensive analysis of the effectiveness of
various training variables, including different SSCL algorithms, learning
strategies, model architectures, and their interplay. Additionally, to gain
deeper insights into the improvements brought about by SSCL in the context of
time-series forecasting, a qualitative analysis of the empirical receptive
field is performed. Through our experiments, we demonstrate that the end-to-end
training of a Transformer model using the Mean Squared Error (MSE) loss and
SSCL emerges as the most effective approach in time series forecasting.
Notably, the incorporation of the contrastive objective enables the model to
prioritize more pertinent information for forecasting, such as scale and
periodic relationships. These findings contribute to a better understanding of
the benefits of SSCL in time series forecasting and provide valuable insights
for future research in this area. Our codes are available at
https://github.com/chiyuzhang94/contrastive_learning_time-series_e2e.",http://arxiv.org/pdf/2306.12086v2,cs.LG
2023-06-20 16:39:27+00:00,G-NM: A Group of Numerical Time Series Prediction Models,['Juyoung Yun'],"In this study, we focus on the development and implementation of a
comprehensive ensemble of numerical time series forecasting models,
collectively referred to as the Group of Numerical Time Series Prediction Model
(G-NM). This inclusive set comprises traditional models such as Autoregressive
Integrated Moving Average (ARIMA), Holt-Winters' method, and Support Vector
Regression (SVR), in addition to modern neural network models including
Recurrent Neural Network (RNN) and Long Short-Term Memory (LSTM). G-NM is
explicitly constructed to augment our predictive capabilities related to
patterns and trends inherent in complex natural phenomena. By utilizing time
series data relevant to these events, G-NM facilitates the prediction of such
phenomena over extended periods. The primary objective of this research is to
both advance our understanding of such occurrences and to significantly enhance
the accuracy of our forecasts. G-NM encapsulates both linear and non-linear
dependencies, seasonalities, and trends present in time series data. Each of
these models contributes distinct strengths, from ARIMA's resilience in
handling linear trends and seasonality, SVR's proficiency in capturing
non-linear patterns, to LSTM's adaptability in modeling various components of
time series data. Through the exploitation of the G-NM potential, we strive to
advance the state-of-the-art in large-scale time series forecasting models. We
anticipate that this research will represent a significant stepping stone in
our ongoing endeavor to comprehend and forecast the complex events that
constitute the natural world.",http://arxiv.org/pdf/2306.11667v4,cs.LG
2023-06-19 15:42:02+00:00,Temporal Data Meets LLM -- Explainable Financial Time Series Forecasting,"['Xinli Yu', 'Zheng Chen', 'Yuan Ling', 'Shujing Dong', 'Zongyi Liu', 'Yanbin Lu']","This paper presents a novel study on harnessing Large Language Models' (LLMs)
outstanding knowledge and reasoning abilities for explainable financial time
series forecasting. The application of machine learning models to financial
time series comes with several challenges, including the difficulty in
cross-sequence reasoning and inference, the hurdle of incorporating multi-modal
signals from historical news, financial knowledge graphs, etc., and the issue
of interpreting and explaining the model results. In this paper, we focus on
NASDAQ-100 stocks, making use of publicly accessible historical stock price
data, company metadata, and historical economic/financial news. We conduct
experiments to illustrate the potential of LLMs in offering a unified solution
to the aforementioned challenges. Our experiments include trying
zero-shot/few-shot inference with GPT-4 and instruction-based fine-tuning with
a public LLM model Open LLaMA. We demonstrate our approach outperforms a few
baselines, including the widely applied classic ARMA-GARCH model and a
gradient-boosting tree model. Through the performance comparison results and a
few examples, we find LLMs can make a well-thought decision by reasoning over
information from both textual news and price time series and extracting
insights, leveraging cross-sequence information, and utilizing the inherent
knowledge embedded within the LLM. Additionally, we show that a publicly
available LLM such as Open-LLaMA, after fine-tuning, can comprehend the
instruction to generate explainable forecasts and achieve reasonable
performance, albeit relatively inferior in comparison to GPT-4.",http://arxiv.org/pdf/2306.11025v1,cs.LG
2023-06-19 12:36:54+00:00,Transformer Training Strategies for Forecasting Multiple Load Time Series,"['Matthias Hertel', 'Maximilian Beichter', 'Benedikt Heidrich', 'Oliver Neumann', 'Benjamin Schäfer', 'Ralf Mikut', 'Veit Hagenmeyer']","In the smart grid of the future, accurate load forecasts on the level of
individual clients can help to balance supply and demand locally and to prevent
grid outages. While the number of monitored clients will increase with the
ongoing smart meter rollout, the amount of data per client will always be
limited. We evaluate whether a Transformer load forecasting model benefits from
a transfer learning strategy, where a global univariate model is trained on the
load time series from multiple clients. In experiments with two datasets
containing load time series from several hundred clients, we find that the
global training strategy is superior to the multivariate and local training
strategies used in related work. On average, the global training strategy
results in 21.8% and 12.8% lower forecasting errors than the two other
strategies, measured across forecasting horizons from one day to one month into
the future. A comparison to linear models, multi-layer perceptrons and LSTMs
shows that Transformers are effective for load forecasting when they are
trained with the global training strategy.",http://arxiv.org/pdf/2306.10891v3,cs.LG
2023-06-19 05:17:02+00:00,"FDNet: Focal Decomposed Network for Efficient, Robust and Practical Time Series Forecasting","['Li Shen', 'Yuning Wei', 'Yangzhu Wang', 'Huaxin Qiu']","This paper presents FDNet: a Focal Decomposed Network for efficient, robust
and practical time series forecasting. We break away from conventional deep
time series forecasting formulas which obtain prediction results from universal
feature maps of input sequences. In contrary, FDNet neglects universal
correlations of input elements and only extracts fine-grained local features
from input sequence. We show that: (1) Deep time series forecasting with only
fine-grained local feature maps of input sequence is feasible upon theoretical
basis. (2) By abandoning global coarse-grained feature maps, FDNet overcomes
distribution shift problem caused by changing dynamics of time series which is
common in real-world applications. (3) FDNet is not dependent on any inductive
bias of time series except basic auto-regression, making it general and
practical. Moreover, we propose focal input sequence decomposition method which
decomposes input sequence in a focal manner for efficient and robust
forecasting when facing Long Sequence Time series Input (LSTI) problem. FDNet
achieves competitive forecasting performances on six real-world benchmarks and
reduces prediction MSE by 38.4% on average compared with other thirteen SOTA
baselines. The source code is available at https://github.com/OrigamiSL/FDNet.",http://arxiv.org/pdf/2306.10703v1,cs.LG
2023-06-17 18:23:07+00:00,A semi-parametric estimation method for quantile coherence with an application to bivariate financial time series clustering,"['Cristian F. Jiménez-Varón', 'Ying Sun', 'Ta-Hsin Li']","In multivariate time series analysis, the coherence measures the linear
dependency between two-time series at different frequencies. However, real data
applications often exhibit nonlinear dependency in the frequency domain.
Conventional coherence analysis fails to capture such dependency. The quantile
coherence, on the other hand, characterizes nonlinear dependency by defining
the coherence at a set of quantile levels based on trigonometric quantile
regression. Although quantile coherence is a more powerful tool, its estimation
remains challenging due to the high level of noise. This paper introduces a new
estimation technique for quantile coherence. The proposed method is
semi-parametric, which uses the parametric form of the spectrum of the vector
autoregressive (VAR) model as an approximation to the quantile spectral matrix,
along with nonparametric smoothing across quantiles. For each fixed quantile
level, we obtain the VAR parameters from the quantile periodograms, then, using
the Durbin-Levinson algorithm, we calculate the preliminary estimate of
quantile coherence using the VAR parameters. Finally, we smooth the preliminary
estimate of quantile coherence across quantiles using a nonparametric smoother.
Numerical results show that the proposed estimation method outperforms
nonparametric methods. We show that quantile coherence-based bivariate time
series clustering has advantages over the ordinary VAR coherence. For
applications, the identified clusters of financial stocks by quantile coherence
with a market benchmark are shown to have an intriguing and more accurate
structure of diversified investment portfolios that may be used by investors to
make better decisions.",http://arxiv.org/pdf/2306.10405v2,stat.ME
2023-06-17 13:40:15+00:00,DCdetector: Dual Attention Contrastive Representation Learning for Time Series Anomaly Detection,"['Yiyuan Yang', 'Chaoli Zhang', 'Tian Zhou', 'Qingsong Wen', 'Liang Sun']","Time series anomaly detection is critical for a wide range of applications.
It aims to identify deviant samples from the normal sample distribution in time
series. The most fundamental challenge for this task is to learn a
representation map that enables effective discrimination of anomalies.
Reconstruction-based methods still dominate, but the representation learning
with anomalies might hurt the performance with its large abnormal loss. On the
other hand, contrastive learning aims to find a representation that can clearly
distinguish any instance from the others, which can bring a more natural and
promising representation for time series anomaly detection. In this paper, we
propose DCdetector, a multi-scale dual attention contrastive representation
learning model. DCdetector utilizes a novel dual attention asymmetric design to
create the permutated environment and pure contrastive loss to guide the
learning process, thus learning a permutation invariant representation with
superior discrimination abilities. Extensive experiments show that DCdetector
achieves state-of-the-art results on multiple time series anomaly detection
benchmark datasets. Code is publicly available at
https://github.com/DAMO-DI-ML/KDD2023-DCdetector.",http://arxiv.org/pdf/2306.10347v2,cs.LG
2023-06-16 19:41:07+00:00,Calculating the matrix profile from noisy data,"['Colin Hehir', 'Alan F. Smeaton']","The matrix profile (MP) is a data structure computed from a time series which
encodes the data required to locate motifs and discords, corresponding to
recurring patterns and outliers respectively. When the time series contains
noisy data then the conventional approach is to pre-filter it in order to
remove noise but this cannot apply in unsupervised settings where patterns and
outliers are not annotated. The resilience of the algorithm used to generate
the MP when faced with noisy data remains unknown. We measure the similarities
between the MP from original time series data with MPs generated from the same
data with noisy data added under a range of parameter settings including adding
duplicates and adding irrelevant data. We use three real world data sets drawn
from diverse domains for these experiments Based on dissimilarities between the
MPs, our results suggest that MP generation is resilient to a small amount of
noise being introduced into the data but as the amount of noise increases this
resilience disappears",http://arxiv.org/pdf/2306.10151v1,cs.LG
2023-06-16 18:23:10+00:00,"Self-Supervised Learning for Time Series Analysis: Taxonomy, Progress, and Prospects","['Kexin Zhang', 'Qingsong Wen', 'Chaoli Zhang', 'Rongyao Cai', 'Ming Jin', 'Yong Liu', 'James Zhang', 'Yuxuan Liang', 'Guansong Pang', 'Dongjin Song', 'Shirui Pan']","Self-supervised learning (SSL) has recently achieved impressive performance
on various time series tasks. The most prominent advantage of SSL is that it
reduces the dependence on labeled data. Based on the pre-training and
fine-tuning strategy, even a small amount of labeled data can achieve high
performance. Compared with many published self-supervised surveys on computer
vision and natural language processing, a comprehensive survey for time series
SSL is still missing. To fill this gap, we review current state-of-the-art SSL
methods for time series data in this article. To this end, we first
comprehensively review existing surveys related to SSL and time series, and
then provide a new taxonomy of existing time series SSL methods by summarizing
them from three perspectives: generative-based, contrastive-based, and
adversarial-based. These methods are further divided into ten subcategories
with detailed reviews and discussions about their key intuitions, main
frameworks, advantages and disadvantages. To facilitate the experiments and
validation of time series SSL methods, we also summarize datasets commonly used
in time series forecasting, classification, anomaly detection, and clustering
tasks. Finally, we present the future directions of SSL for time series
analysis.",http://arxiv.org/pdf/2306.10125v2,cs.LG
2023-06-16 11:57:11+00:00,Convolutional and Deep Learning based techniques for Time Series Ordinal Classification,"['Rafael Ayllón-Gavilán', 'David Guijo-Rubio', 'Pedro Antonio Gutiérrez', 'Anthony Bagnall', 'César Hervás-Martínez']","Time Series Classification (TSC) covers the supervised learning problem where
input data is provided in the form of series of values observed through
repeated measurements over time, and whose objective is to predict the category
to which they belong. When the class values are ordinal, classifiers that take
this into account can perform better than nominal classifiers. Time Series
Ordinal Classification (TSOC) is the field covering this gap, yet unexplored in
the literature. There are a wide range of time series problems showing an
ordered label structure, and TSC techniques that ignore the order relationship
discard useful information. Hence, this paper presents a first benchmarking of
TSOC methodologies, exploiting the ordering of the target labels to boost the
performance of current TSC state-of-the-art. Both convolutional- and deep
learning-based methodologies (among the best performing alternatives for
nominal TSC) are adapted for TSOC. For the experiments, a selection of 18
ordinal problems from two well-known archives has been made. In this way, this
paper contributes to the establishment of the state-of-the-art in TSOC. The
results obtained by ordinal versions are found to be significantly better than
current nominal TSC techniques in terms of ordinal performance metrics,
outlining the importance of considering the ordering of the labels when dealing
with this kind of problems.",http://arxiv.org/pdf/2306.10084v1,cs.LG
2023-06-15 23:56:39+00:00,Geometric-Based Pruning Rules For Change Point Detection in Multiple Independent Time Series,"['Liudmila Pishchagina', 'Guillem Rigaill', 'Vincent Runge']","We consider the problem of detecting multiple changes in multiple independent
time series. The search for the best segmentation can be expressed as a
minimization problem over a given cost function. We focus on dynamic
programming algorithms that solve this problem exactly. When the number of
changes is proportional to data length, an inequality-based pruning rule
encoded in the PELT algorithm leads to a linear time complexity. Another type
of pruning, called functional pruning, gives a close-to-linear time complexity
whatever the number of changes, but only for the analysis of univariate time
series.
  We propose a few extensions of functional pruning for multiple independent
time series based on the use of simple geometric shapes (balls and
hyperrectangles). We focus on the Gaussian case, but some of our rules can be
easily extended to the exponential family. In a simulation study we compare the
computational efficiency of different geometric-based pruning rules. We show
that for small dimensions (2, 3, 4) some of them ran significantly faster than
inequality-based approaches in particular when the underlying number of changes
is small compared to the data length.",http://arxiv.org/pdf/2306.09555v1,stat.ME
2023-06-15 16:36:34+00:00,Mitigating Cold-start Forecasting using Cold Causal Demand Forecasting Model,"['Zahra Fatemi', 'Minh Huynh', 'Elena Zheleva', 'Zamir Syed', 'Xiaojun Di']","Forecasting multivariate time series data, which involves predicting future
values of variables over time using historical data, has significant practical
applications. Although deep learning-based models have shown promise in this
field, they often fail to capture the causal relationship between dependent
variables, leading to less accurate forecasts. Additionally, these models
cannot handle the cold-start problem in time series data, where certain
variables lack historical data, posing challenges in identifying dependencies
among variables. To address these limitations, we introduce the Cold Causal
Demand Forecasting (CDF-cold) framework that integrates causal inference with
deep learning-based models to enhance the forecasting accuracy of multivariate
time series data affected by the cold-start problem. To validate the
effectiveness of the proposed approach, we collect 15 multivariate time-series
datasets containing the network traffic of different Google data centers. Our
experiments demonstrate that the CDF-cold framework outperforms
state-of-the-art forecasting models in predicting future values of multivariate
time series data.",http://arxiv.org/pdf/2306.09261v1,cs.LG
2023-06-15 13:41:59+00:00,Deep Learning for Energy Time-Series Analysis and Forecasting,"['Maria Tzelepi', 'Charalampos Symeonidis', 'Paraskevi Nousi', 'Efstratios Kakaletsis', 'Theodoros Manousis', 'Pavlos Tosidis', 'Nikos Nikolaidis', 'Anastasios Tefas']","Energy time-series analysis describes the process of analyzing past energy
observations and possibly external factors so as to predict the future.
Different tasks are involved in the general field of energy time-series
analysis and forecasting, with electric load demand forecasting, personalized
energy consumption forecasting, as well as renewable energy generation
forecasting being among the most common ones. Following the exceptional
performance of Deep Learning (DL) in a broad area of vision tasks, DL models
have successfully been utilized in time-series forecasting tasks. This paper
aims to provide insight into various DL methods geared towards improving the
performance in energy time-series forecasting tasks, with special emphasis in
Greek Energy Market, and equip the reader with the necessary knowledge to apply
these methods in practice.",http://arxiv.org/pdf/2306.09129v2,cs.LG
2023-06-15 08:37:16+00:00,Bootstrap aggregation and confidence measures to improve time series causal discovery,"['Kevin Debeire', 'Jakob Runge', 'Andreas Gerhardus', 'Veronika Eyring']","Causal discovery methods have demonstrated the ability to identify the time
series graphs representing the causal temporal dependency structure of
dynamical systems. However, they do not include a measure of the confidence of
the estimated links. Here, we introduce a novel bootstrap aggregation (bagging)
and confidence measure method that is combined with time series causal
discovery. This new method allows measuring confidence for the links of the
time series graphs calculated by causal discovery methods. This is done by
bootstrapping the original times series data set while preserving temporal
dependencies. Next to confidence measures, aggregating the bootstrapped graphs
by majority voting yields a final aggregated output graph. In this work, we
combine our approach with the state-of-the-art conditional-independence-based
algorithm PCMCI+. With extensive numerical experiments we empirically
demonstrate that, in addition to providing confidence measures for links,
Bagged-PCMCI+ improves the precision and recall of its base algorithm PCMCI+.
Specifically, Bagged-PCMCI+ has a higher detection power regarding adjacencies
and a higher precision in orienting contemporaneous edges while at the same
time showing a lower rate of false positives. These performance improvements
are especially pronounced in the more challenging settings (short time sample
size, large number of variables, high autocorrelation). Our bootstrap approach
can also be combined with other time series causal discovery algorithms and can
be of considerable use in many real-world applications, especially when
confidence measures for the links are desired.",http://arxiv.org/pdf/2306.08946v1,stat.ME
2023-06-14 13:23:14+00:00,Warpformer: A Multi-scale Modeling Approach for Irregular Clinical Time Series,"['Jiawen Zhang', 'Shun Zheng', 'Wei Cao', 'Jiang Bian', 'Jia Li']","Irregularly sampled multivariate time series are ubiquitous in various
fields, particularly in healthcare, and exhibit two key characteristics:
intra-series irregularity and inter-series discrepancy. Intra-series
irregularity refers to the fact that time-series signals are often recorded at
irregular intervals, while inter-series discrepancy refers to the significant
variability in sampling rates among diverse series. However, recent advances in
irregular time series have primarily focused on addressing intra-series
irregularity, overlooking the issue of inter-series discrepancy. To bridge this
gap, we present Warpformer, a novel approach that fully considers these two
characteristics. In a nutshell, Warpformer has several crucial designs,
including a specific input representation that explicitly characterizes both
intra-series irregularity and inter-series discrepancy, a warping module that
adaptively unifies irregular time series in a given scale, and a customized
attention module for representation learning. Additionally, we stack multiple
warping and attention modules to learn at different scales, producing
multi-scale representations that balance coarse-grained and fine-grained
signals for downstream tasks. We conduct extensive experiments on widely used
datasets and a new large-scale benchmark built from clinical databases. The
results demonstrate the superiority of Warpformer over existing
state-of-the-art approaches.",http://arxiv.org/pdf/2306.09368v1,cs.LG
2023-06-14 07:54:53+00:00,GCformer: An Efficient Framework for Accurate and Scalable Long-Term Multivariate Time Series Forecasting,"['YanJun Zhao', 'Ziqing Ma', 'Tian Zhou', 'Liang Sun', 'Mengni Ye', 'Yi Qian']","Transformer-based models have emerged as promising tools for time series
forecasting.
  However, these model cannot make accurate prediction for long input time
series. On the one hand, they failed to capture global dependencies within time
series data. On the other hand, the long input sequence usually leads to large
model size and high time complexity.
  To address these limitations, we present GCformer, which combines a
structured global convolutional branch for processing long input sequences with
a local Transformer-based branch for capturing short, recent signals. A
cohesive framework for a global convolution kernel has been introduced,
utilizing three distinct parameterization methods. The selected structured
convolutional kernel in the global branch has been specifically crafted with
sublinear complexity, thereby allowing for the efficient and effective
processing of lengthy and noisy input signals. Empirical studies on six
benchmark datasets demonstrate that GCformer outperforms state-of-the-art
methods, reducing MSE error in multivariate time series benchmarks by 4.38% and
model parameters by 61.92%. In particular, the global convolutional branch can
serve as a plug-in block to enhance the performance of other models, with an
average improvement of 31.93\%, including various recently published
Transformer-based models. Our code is publicly available at
https://github.com/zyj-111/GCformer.",http://arxiv.org/pdf/2306.08325v3,cs.LG
2023-06-14 06:26:23+00:00,TSMixer: Lightweight MLP-Mixer Model for Multivariate Time Series Forecasting,"['Vijay Ekambaram', 'Arindam Jati', 'Nam Nguyen', 'Phanwadee Sinthong', 'Jayant Kalagnanam']","Transformers have gained popularity in time series forecasting for their
ability to capture long-sequence interactions. However, their high memory and
computing requirements pose a critical bottleneck for long-term forecasting. To
address this, we propose TSMixer, a lightweight neural architecture exclusively
composed of multi-layer perceptron (MLP) modules. TSMixer is designed for
multivariate forecasting and representation learning on patched time series,
providing an efficient alternative to Transformers. Our model draws inspiration
from the success of MLP-Mixer models in computer vision. We demonstrate the
challenges involved in adapting Vision MLP-Mixer for time series and introduce
empirically validated components to enhance accuracy. This includes a novel
design paradigm of attaching online reconciliation heads to the MLP-Mixer
backbone, for explicitly modeling the time-series properties such as hierarchy
and channel-correlations. We also propose a Hybrid channel modeling approach to
effectively handle noisy channel interactions and generalization across diverse
datasets, a common challenge in existing patch channel-mixing methods.
Additionally, a simple gated attention mechanism is introduced in the backbone
to prioritize important features. By incorporating these lightweight
components, we significantly enhance the learning capability of simple MLP
structures, outperforming complex Transformer models with minimal computing
usage. Moreover, TSMixer's modular design enables compatibility with both
supervised and masked self-supervised learning methods, making it a promising
building block for time-series Foundation Models. TSMixer outperforms
state-of-the-art MLP and Transformer models in forecasting by a considerable
margin of 8-60%. It also outperforms the latest strong benchmarks of
Patch-Transformer models (by 1-2%) with a significant reduction in memory and
runtime (2-3X).",http://arxiv.org/pdf/2306.09364v3,cs.LG
2023-06-13 12:43:59+00:00,Robustness and Generalization Performance of Deep Learning Models on Cyber-Physical Systems: A Comparative Study,"['Alexander Windmann', 'Henrik Steude', 'Oliver Niggemann']","Deep learning (DL) models have seen increased attention for time series
forecasting, yet the application on cyber-physical systems (CPS) is hindered by
the lacking robustness of these methods. Thus, this study evaluates the
robustness and generalization performance of DL architectures on multivariate
time series data from CPS. Our investigation focuses on the models' ability to
handle a range of perturbations, such as sensor faults and noise, and assesses
their impact on overall performance. Furthermore, we test the generalization
and transfer learning capabilities of these models by exposing them to
out-of-distribution (OOD) samples. These include deviations from standard
system operations, while the core dynamics of the underlying physical system
are preserved. Additionally, we test how well the models respond to several
data augmentation techniques, including added noise and time warping. Our
experimental framework utilizes a simulated three-tank system, proposed as a
novel benchmark for evaluating the robustness and generalization performance of
DL algorithms in CPS data contexts. The findings reveal that certain DL model
architectures and training techniques exhibit superior effectiveness in
handling OOD samples and various perturbations. These insights have significant
implications for the development of DL models that deliver reliable and robust
performance in real-world CPS applications.",http://arxiv.org/pdf/2306.07737v1,cs.LG
2023-06-12 13:52:30+00:00,"Improving Forecasts for Heterogeneous Time Series by ""Averaging"", with Application to Food Demand Forecast","['Lukas Neubauer', 'Peter Filzmoser']","A common forecasting setting in real world applications considers a set of
possibly heterogeneous time series of the same domain. Due to different
properties of each time series such as length, obtaining forecasts for each
individual time series in a straight-forward way is challenging. This paper
proposes a general framework utilizing a similarity measure in Dynamic Time
Warping to find similar time series to build neighborhoods in a k-Nearest
Neighbor fashion, and improve forecasts of possibly simple models by averaging.
Several ways of performing the averaging are suggested, and theoretical
arguments underline the usefulness of averaging for forecasting. Additionally,
diagnostics tools are proposed allowing a deep understanding of the procedure.",http://arxiv.org/pdf/2306.07119v1,stat.ME
2023-06-12 13:42:56+00:00,Coupled Attention Networks for Multivariate Time Series Anomaly Detection,"['Feng Xia', 'Xin Chen', 'Shuo Yu', 'Mingliang Hou', 'Mujie Liu', 'Linlin You']","Multivariate time series anomaly detection (MTAD) plays a vital role in a
wide variety of real-world application domains. Over the past few years, MTAD
has attracted rapidly increasing attention from both academia and industry.
Many deep learning and graph learning models have been developed for effective
anomaly detection in multivariate time series data, which enable advanced
applications such as smart surveillance and risk management with unprecedented
capabilities. Nevertheless, MTAD is facing critical challenges deriving from
the dependencies among sensors and variables, which often change over time. To
address this issue, we propose a coupled attention-based neural network
framework (CAN) for anomaly detection in multivariate time series data
featuring dynamic variable relationships. We combine adaptive graph learning
methods with graph attention to generate a global-local graph that can
represent both global correlations and dynamic local correlations among
sensors. To capture inter-sensor relationships and temporal dependencies, a
convolutional neural network based on the global-local graph is integrated with
a temporal self-attention module to construct a coupled attention module. In
addition, we develop a multilevel encoder-decoder architecture that
accommodates reconstruction and prediction tasks to better characterize
multivariate time series data. Extensive experiments on real-world datasets
have been conducted to evaluate the performance of the proposed CAN approach,
and the results show that CAN significantly outperforms state-of-the-art
baselines.",http://arxiv.org/pdf/2306.07114v1,cs.LG
2023-06-12 10:20:40+00:00,On the closed-loop Volterra method for analyzing time series,"['Maryam Movahedifar', 'Thorsten Dickhaus']","The main focus of this paper is to approximate time series data based on the
closed-loop Volterra series representation. Volterra series expansions are a
valuable tool for representing, analyzing, and synthesizing nonlinear dynamical
systems. However, a major limitation of this approach is that as the order of
the expansion increases, the number of terms that need to be estimated grows
exponentially, posing a considerable challenge. This paper considers a
practical solution for estimating the closed-loop Volterra series in stationary
nonlinear time series using the concepts of Reproducing Kernel Hilbert Spaces
(RKHS) and polynomial kernels. We illustrate the applicability of the suggested
Volterra representation by means of simulations and real data analysis.
Furthermore, we apply the Kolmogorov-Smirnov Predictive Accuracy (KSPA) test,
to determine whether there exists a statistically significant difference
between the distribution of estimated errors for concurring time series models,
and secondly to determine whether the estimated time series with the lower
error based on some loss function also has exhibits a stochastically smaller
error than estimated time series from a competing method. The obtained results
indicate that the closed-loop Volterra method can outperform the ARFIMA, ETS,
and Ridge regression methods in terms of both smaller error and increased
interpretability.",http://arxiv.org/pdf/2306.07007v1,stat.ME
2023-06-12 09:42:16+00:00,Correlated Time Series Self-Supervised Representation Learning via Spatiotemporal Bootstrapping,"['Luxuan Wang', 'Lei Bai', 'Ziyue Li', 'Rui Zhao', 'Fugee Tsung']","Correlated time series analysis plays an important role in many real-world
industries. Learning an efficient representation of this large-scale data for
further downstream tasks is necessary but challenging. In this paper, we
propose a time-step-level representation learning framework for individual
instances via bootstrapped spatiotemporal representation prediction. We
evaluated the effectiveness and flexibility of our representation learning
framework on correlated time series forecasting and cold-start transferring the
forecasting model to new instances with limited data. A linear regression model
trained on top of the learned representations demonstrates our model performs
best in most cases. Especially compared to representation learning models, we
reduce the RMSE, MAE, and MAPE by 37%, 49%, and 48% on the PeMS-BAY dataset,
respectively. Furthermore, in real-world metro passenger flow data, our
framework demonstrates the ability to transfer to infer future information of
new cold-start instances, with gains of 15%, 19%, and 18%. The source code will
be released under the GitHub
https://github.com/bonaldli/Spatiotemporal-TS-Representation-Learning",http://arxiv.org/pdf/2306.06994v2,cs.LG
2023-06-12 07:00:37+00:00,MPPN: Multi-Resolution Periodic Pattern Network For Long-Term Time Series Forecasting,"['Xing Wang', 'Zhendong Wang', 'Kexin Yang', 'Junlan Feng', 'Zhiyan Song', 'Chao Deng', 'Lin zhu']","Long-term time series forecasting plays an important role in various
real-world scenarios. Recent deep learning methods for long-term series
forecasting tend to capture the intricate patterns of time series by
decomposition-based or sampling-based methods. However, most of the extracted
patterns may include unpredictable noise and lack good interpretability.
Moreover, the multivariate series forecasting methods usually ignore the
individual characteristics of each variate, which may affecting the prediction
accuracy. To capture the intrinsic patterns of time series, we propose a novel
deep learning network architecture, named Multi-resolution Periodic Pattern
Network (MPPN), for long-term series forecasting. We first construct
context-aware multi-resolution semantic units of time series and employ
multi-periodic pattern mining to capture the key patterns of time series. Then,
we propose a channel adaptive module to capture the perceptions of multivariate
towards different patterns. In addition, we present an entropy-based method for
evaluating the predictability of time series and providing an upper bound on
the prediction accuracy before forecasting. Our experimental evaluation on nine
real-world benchmarks demonstrated that MPPN significantly outperforms the
state-of-the-art Transformer-based, decomposition-based and sampling-based
methods for long-term series forecasting.",http://arxiv.org/pdf/2306.06895v1,cs.LG
2023-06-11 04:00:11+00:00,Learning Robust and Consistent Time Series Representations: A Dilated Inception-Based Approach,"['Anh Duy Nguyen', 'Trang H. Tran', 'Hieu H. Pham', 'Phi Le Nguyen', 'Lam M. Nguyen']","Representation learning for time series has been an important research area
for decades. Since the emergence of the foundation models, this topic has
attracted a lot of attention in contrastive self-supervised learning, to solve
a wide range of downstream tasks. However, there have been several challenges
for contrastive time series processing. First, there is no work considering
noise, which is one of the critical factors affecting the efficacy of time
series tasks. Second, there is a lack of efficient yet lightweight encoder
architectures that can learn informative representations robust to various
downstream tasks. To fill in these gaps, we initiate a novel sampling strategy
that promotes consistent representation learning with the presence of noise in
natural time series. In addition, we propose an encoder architecture that
utilizes dilated convolution within the Inception block to create a scalable
and robust network architecture with a wide receptive field. Experiments
demonstrate that our method consistently outperforms state-of-the-art methods
in forecasting, classification, and abnormality detection tasks, e.g. ranks
first over two-thirds of the classification UCR datasets, with only $40\%$ of
the parameters compared to the second-best approach. Our source code for
CoInception framework is accessible at
https://github.com/anhduy0911/CoInception.",http://arxiv.org/pdf/2306.06579v1,cs.LG
2023-06-10 21:17:42+00:00,TS-MoCo: Time-Series Momentum Contrast for Self-Supervised Physiological Representation Learning,"['Philipp Hallgarten', 'David Bethge', 'Ozan Özdenizci', 'Tobias Grosse-Puppendahl', 'Enkelejda Kasneci']","Limited availability of labeled physiological data often prohibits the use of
powerful supervised deep learning models in the biomedical machine intelligence
domain. We approach this problem and propose a novel encoding framework that
relies on self-supervised learning with momentum contrast to learn
representations from multivariate time-series of various physiological domains
without needing labels. Our model uses a transformer architecture that can be
easily adapted to classification problems by optimizing a linear output
classification layer. We experimentally evaluate our framework using two
publicly available physiological datasets from different domains, i.e., human
activity recognition from embedded inertial sensory and emotion recognition
from electroencephalography. We show that our self-supervised learning approach
can indeed learn discriminative features which can be exploited in downstream
classification tasks. Our work enables the development of domain-agnostic
intelligent systems that can effectively analyze multivariate time-series data
from physiological domains.",http://arxiv.org/pdf/2306.06522v1,cs.LG
2023-06-09 20:46:55+00:00,Feature Programming for Multivariate Time Series Prediction,"['Alex Reneau', 'Jerry Yao-Chieh Hu', 'Chenwei Xu', 'Weijian Li', 'Ammar Gilani', 'Han Liu']","We introduce the concept of programmable feature engineering for time series
modeling and propose a feature programming framework. This framework generates
large amounts of predictive features for noisy multivariate time series while
allowing users to incorporate their inductive bias with minimal effort. The key
motivation of our framework is to view any multivariate time series as a
cumulative sum of fine-grained trajectory increments, with each increment
governed by a novel spin-gas dynamical Ising model. This fine-grained
perspective motivates the development of a parsimonious set of operators that
summarize multivariate time series in an abstract fashion, serving as the
foundation for large-scale automated feature engineering. Numerically, we
validate the efficacy of our method on several synthetic and real-world noisy
time series datasets.",http://arxiv.org/pdf/2306.06252v1,cs.LG
2023-06-09 16:42:52+00:00,Self-Interpretable Time Series Prediction with Counterfactual Explanations,"['Jingquan Yan', 'Hao Wang']","Interpretable time series prediction is crucial for safety-critical areas
such as healthcare and autonomous driving. Most existing methods focus on
interpreting predictions by assigning important scores to segments of time
series. In this paper, we take a different and more challenging route and aim
at developing a self-interpretable model, dubbed Counterfactual Time Series
(CounTS), which generates counterfactual and actionable explanations for time
series predictions. Specifically, we formalize the problem of time series
counterfactual explanations, establish associated evaluation protocols, and
propose a variational Bayesian deep learning model equipped with counterfactual
inference capability of time series abduction, action, and prediction. Compared
with state-of-the-art baselines, our self-interpretable model can generate
better counterfactual explanations while maintaining comparable prediction
accuracy.",http://arxiv.org/pdf/2306.06024v3,cs.LG
2023-06-09 15:59:27+00:00,QBSD: Quartile-Based Seasonality Decomposition for Cost-Effective Time Series Forecasting,"['Ebenezer RHP Isaac', 'Bulbul Singh']","In the telecom domain, precise forecasting of time series patterns, such as
cell key performance indicators (KPIs), plays a pivotal role in enhancing
service quality and operational efficiency. State-of-the-art forecasting
approaches prioritize forecasting accuracy at the expense of computational
performance, rendering them less suitable for data-intensive applications
encompassing systems with a multitude of time series variables. To address this
issue, we introduce QBSD, a live forecasting approach tailored to optimize the
trade-off between accuracy and computational complexity. We have evaluated the
performance of QBSD against state-of-the-art forecasting approaches on publicly
available datasets. We have also extended this investigation to our curated
network KPI dataset, now publicly accessible, to showcase the effect of dynamic
operating ranges that varies with time. The results demonstrate that the
proposed method excels in runtime efficiency compared to the leading algorithms
available while maintaining competitive forecast accuracy.",http://arxiv.org/pdf/2306.05989v2,cs.LG
2023-06-09 13:20:04+00:00,Time Series Continuous Modeling for Imputation and Forecasting with Implicit Neural Representations,"['Etienne Le Naour', 'Louis Serrano', 'Léon Migus', 'Yuan Yin', 'Ghislain Agoua', 'Nicolas Baskiotis', 'Patrick Gallinari', 'Vincent Guigue']","We introduce a novel modeling approach for time series imputation and
forecasting, tailored to address the challenges often encountered in real-world
data, such as irregular samples, missing data, or unaligned measurements from
multiple sensors. Our method relies on a continuous-time-dependent model of the
series' evolution dynamics. It leverages adaptations of conditional, implicit
neural representations for sequential data. A modulation mechanism, driven by a
meta-learning algorithm, allows adaptation to unseen samples and extrapolation
beyond observed time-windows for long-term predictions. The model provides a
highly flexible and unified framework for imputation and forecasting tasks
across a wide range of challenging scenarios. It achieves state-of-the-art
performance on classical benchmarks and outperforms alternative time-continuous
models.",http://arxiv.org/pdf/2306.05880v4,cs.LG
2023-06-08 18:49:23+00:00,Robust Framework for Explanation Evaluation in Time Series Classification,"['Thu Trang Nguyen', 'Thach Le Nguyen', 'Georgiana Ifrim']","Time series classification is a task which deals with a prevalent data type,
temporal sequences, common in domains such as human activity recognition,
sports analytics and general healthcare. This paper provides a framework to
quantitatively evaluate and rank explanation methods for time series
classification. The recent interest in explanation methods for time series has
provided a great variety of explanation techniques. Nevertheless, when the
explanations disagree on a specific problem, it remains unclear which of them
to use. Comparing multiple explanations to find the right answer is
non-trivial. Two key challenges remain: how to quantitatively and robustly
evaluate the informativeness of a given explanation method (i.e., relevance for
the classification task), and how to compare explanation methods side-by-side.
We propose AMEE, a robust Model-Agnostic Explanation Evaluation framework for
evaluating and comparing multiple saliency-based explanations for time series
classification. In this approach, data perturbation is added to the input time
series guided by each explanation. The impact of perturbation on classification
accuracy is then measured and used for explanation evaluation. The results show
that perturbing discriminative parts of the time series leads to significant
changes in classification accuracy which can be used to evaluate each
explanation. To be robust to different types of perturbations and different
types of classifiers, we aggregate the accuracy loss across perturbations and
classifiers. This novel approach allows us to quantify and rank different
explanation methods. We provide a quantitative and qualitative analysis for
synthetic datasets, a variety of time-series datasets, as well as a real-world
dataset with known expert ground truth.",http://arxiv.org/pdf/2306.05501v3,cs.LG
2023-06-08 13:06:13+00:00,Matrix GARCH Model: Inference and Application,"['Cheng Yu', 'Dong Li', 'Feiyu Jiang', 'Ke Zhu']","Matrix-variate time series data are largely available in applications.
However, no attempt has been made to study their conditional heteroskedasticity
that is often observed in economic and financial data. To address this gap, we
propose a novel matrix generalized autoregressive conditional
heteroskedasticity (GARCH) model to capture the dynamics of conditional row and
column covariance matrices of matrix time series. The key innovation of the
matrix GARCH model is the use of a univariate GARCH specification for the trace
of conditional row or column covariance matrix, which allows for the
identification of conditional row and column covariance matrices. Moreover, we
introduce a quasi maximum likelihood estimator (QMLE) for model estimation and
develop a portmanteau test for model diagnostic checking. Simulation studies
are conducted to assess the finite-sample performance of the QMLE and
portmanteau test. To handle large dimensional matrix time series, we also
propose a matrix factor GARCH model. Finally, we demonstrate the superiority of
the matrix GARCH and matrix factor GARCH models over existing multivariate
GARCH-type models in volatility forecasting and portfolio allocations using
three applications on credit default swap prices, global stock sector indices,
and future prices.",http://arxiv.org/pdf/2306.05169v1,stat.ME
2023-06-08 08:53:59+00:00,Non-autoregressive Conditional Diffusion Models for Time Series Prediction,"['Lifeng Shen', 'James Kwok']","Recently, denoising diffusion models have led to significant breakthroughs in
the generation of images, audio and text. However, it is still an open question
on how to adapt their strong modeling ability to model time series. In this
paper, we propose TimeDiff, a non-autoregressive diffusion model that achieves
high-quality time series prediction with the introduction of two novel
conditioning mechanisms: future mixup and autoregressive initialization.
Similar to teacher forcing, future mixup allows parts of the ground-truth
future predictions for conditioning, while autoregressive initialization helps
better initialize the model with basic time series patterns such as short-term
trends. Extensive experiments are performed on nine real-world datasets.
Results show that TimeDiff consistently outperforms existing time series
diffusion models, and also achieves the best overall performance across a
variety of the existing strong baselines (including transformers and FiLM).",http://arxiv.org/pdf/2306.05043v1,cs.LG
2023-06-08 06:48:44+00:00,A nonparametrically corrected likelihood for Bayesian spectral analysis of multivariate time series,"['Yixuan Liu', 'Claudia Kirch', 'Jeong Eun Lee', 'Renate Meyer']","This paper presents a novel approach to Bayesian nonparametric spectral
analysis of stationary multivariate time series. Starting with a parametric
vector-autoregressive model, the parametric likelihood is nonparametrically
adjusted in the frequency domain to account for potential deviations from
parametric assumptions. We show mutual contiguity of the nonparametrically
corrected likelihood, the multivariate Whittle likelihood approximation and the
exact likelihood for Gaussian time series. A multivariate extension of the
nonparametric Bernstein-Dirichlet process prior for univariate spectral
densities to the space of Hermitian positive definite spectral density matrices
is specified directly on the correction matrices. An infinite series
representation of this prior is then used to develop a Markov chain Monte Carlo
algorithm to sample from the posterior distribution. The code is made publicly
available for ease of use and reproducibility. With this novel approach we
provide a generalization of the multivariate Whittle-likelihood-based method of
Meier et al. (2020) as well as an extension of the nonparametrically corrected
likelihood for univariate stationary time series of Kirch et al. (2019) to the
multivariate case. We demonstrate that the nonparametrically corrected
likelihood combines the efficiencies of a parametric with the robustness of a
nonparametric model. Its numerical accuracy is illustrated in a comprehensive
simulation study. We illustrate its practical advantages by a spectral analysis
of two environmental time series data sets: a bivariate time series of the
Southern Oscillation Index and fish recruitment and time series of windspeed
data at six locations in California.",http://arxiv.org/pdf/2306.04966v3,stat.ME
2023-06-06 16:24:27+00:00,MTS2Graph: Interpretable Multivariate Time Series Classification with Temporal Evolving Graphs,"['Raneen Younis', 'Abdul Hakmeh', 'Zahra Ahmadi']","Conventional time series classification approaches based on bags of patterns
or shapelets face significant challenges in dealing with a vast amount of
feature candidates from high-dimensional multivariate data. In contrast, deep
neural networks can learn low-dimensional features efficiently, and in
particular, Convolutional Neural Networks (CNN) have shown promising results in
classifying Multivariate Time Series (MTS) data. A key factor in the success of
deep neural networks is this astonishing expressive power. However, this power
comes at the cost of complex, black-boxed models, conflicting with the goals of
building reliable and human-understandable models. An essential criterion in
understanding such predictive deep models involves quantifying the contribution
of time-varying input variables to the classification. Hence, in this work, we
introduce a new framework for interpreting multivariate time series data by
extracting and clustering the input representative patterns that highly
activate CNN neurons. This way, we identify each signal's role and
dependencies, considering all possible combinations of signals in the MTS
input. Then, we construct a graph that captures the temporal relationship
between the extracted patterns for each layer. An effective graph merging
strategy finds the connection of each node to the previous layer's nodes.
Finally, a graph embedding algorithm generates new representations of the
created interpretable time-series features. To evaluate the performance of our
proposed framework, we run extensive experiments on eight datasets of the
UCR/UEA archive, along with HAR and PAM datasets. The experiments indicate the
benefit of our time-aware graph-based representation in MTS classification
while enriching them with more interpretability.",http://arxiv.org/pdf/2306.03834v1,cs.LG
2023-06-05 02:24:59+00:00,Non-parametric Probabilistic Time Series Forecasting via Innovations Representation,"['Xinyi Wang', 'Meijen Lee', 'Qing Zhao', 'Lang Tong']","Probabilistic time series forecasting predicts the conditional probability
distributions of the time series at a future time given past realizations. Such
techniques are critical in risk-based decision-making and planning under
uncertainties. Existing approaches are primarily based on parametric or
semi-parametric time-series models that are restrictive, difficult to validate,
and challenging to adapt to varying conditions. This paper proposes a
nonparametric method based on the classic notion of {\em innovations} pioneered
by Norbert Wiener and Gopinath Kallianpur that causally transforms a
nonparametric random process to an independent and identical uniformly
distributed {\em innovations process}. We present a machine-learning
architecture and a learning algorithm that circumvent two limitations of the
original Wiener-Kallianpur innovations representation: (i) the need for known
probability distributions of the time series and (ii) the existence of a causal
decoder that reproduces the original time series from the innovations
representation. We develop a deep-learning approach and a Monte Carlo sampling
technique to obtain a generative model for the predicted conditional
probability distribution of the time series based on a weak notion of
Wiener-Kallianpur innovations representation. The efficacy of the proposed
probabilistic forecasting technique is demonstrated on a variety of electricity
price datasets, showing marked improvement over leading benchmarks of
probabilistic forecasting techniques.",http://arxiv.org/pdf/2306.03782v1,cs.LG
2023-06-04 10:50:52+00:00,Cross-LKTCN: Modern Convolution Utilizing Cross-Variable Dependency for Multivariate Time Series Forecasting Dependency for Multivariate Time Series Forecasting,"['Donghao Luo', 'Xue Wang']","The past few years have witnessed the rapid development in multivariate time
series forecasting. The key to accurate forecasting results is capturing the
long-term dependency between each time step (cross-time dependency) and
modeling the complex dependency between each variable (cross-variable
dependency) in multivariate time series. However, recent methods mainly focus
on the cross-time dependency but seldom consider the cross-variable dependency.
To fill this gap, we find that convolution, a traditional technique but
recently losing steam in time series forecasting, meets the needs of
respectively capturing the cross-time and cross-variable dependency. Based on
this finding, we propose a modern pure convolution structure, namely
Cross-LKTCN, to better utilize both cross-time and cross-variable dependency
for time series forecasting. Specifically in each Cross-LKTCN block, a
depth-wise large kernel convolution with large receptive field is proposed to
capture cross-time dependency, and then two successive point-wise group
convolution feed forward networks are proposed to capture cross-variable
dependency. Experimental results on real-world benchmarks show that Cross-LKTCN
achieves state-of-the-art forecasting performance and improves the forecasting
accuracy significantly compared with existing convolutional-based models and
cross-variable methods.",http://arxiv.org/pdf/2306.02326v1,cs.LG
2023-06-03 14:25:15+00:00,Identifying Subgroups of ICU Patients Using End-to-End Multivariate Time-Series Clustering Algorithm Based on Real-World Vital Signs Data,"['Tongyue Shi', 'Zhilong Zhang', 'Wentie Liu', 'Junhua Fang', 'Jianguo Hao', 'Shuai Jin', 'Huiying Zhao', 'Guilan Kong']","This study employed the MIMIC-IV database as data source to investigate the
use of dynamic, high-frequency, multivariate time-series vital signs data,
including temperature, heart rate, mean blood pressure, respiratory rate, and
SpO2, monitored first 8 hours data in the ICU stay. Various clustering
algorithms were compared, and an end-to-end multivariate time series clustering
system called Time2Feat, combined with K-Means, was chosen as the most
effective method to cluster patients in the ICU. In clustering analysis, data
of 8,080 patients admitted between 2008 and 2016 was used for model development
and 2,038 patients admitted between 2017 and 2019 for model validation. By
analyzing the differences in clinical mortality prognosis among different
categories, varying risks of ICU mortality and hospital mortality were found
between different subgroups. Furthermore, the study visualized the trajectory
of vital signs changes. The findings of this study provide valuable insights
into the potential use of multivariate time-series clustering systems in
patient management and monitoring in the ICU setting.",http://arxiv.org/pdf/2306.02121v2,cs.LG
2023-06-03 13:25:26+00:00,Encoding Time-Series Explanations through Self-Supervised Model Behavior Consistency,"['Owen Queen', 'Thomas Hartvigsen', 'Teddy Koker', 'Huan He', 'Theodoros Tsiligkaridis', 'Marinka Zitnik']","Interpreting time series models is uniquely challenging because it requires
identifying both the location of time series signals that drive model
predictions and their matching to an interpretable temporal pattern. While
explainers from other modalities can be applied to time series, their inductive
biases do not transfer well to the inherently challenging interpretation of
time series. We present TimeX, a time series consistency model for training
explainers. TimeX trains an interpretable surrogate to mimic the behavior of a
pretrained time series model. It addresses the issue of model faithfulness by
introducing model behavior consistency, a novel formulation that preserves
relations in the latent space induced by the pretrained model with relations in
the latent space induced by TimeX. TimeX provides discrete attribution maps
and, unlike existing interpretability methods, it learns a latent space of
explanations that can be used in various ways, such as to provide landmarks to
visually aggregate similar explanations and easily recognize temporal patterns.
We evaluate TimeX on eight synthetic and real-world datasets and compare its
performance against state-of-the-art interpretability methods. We also conduct
case studies using physiological time series. Quantitative evaluations
demonstrate that TimeX achieves the highest or second-highest performance in
every metric compared to baselines across all datasets. Through case studies,
we show that the novel components of TimeX show potential for training
faithful, interpretable models that capture the behavior of pretrained time
series models.",http://arxiv.org/pdf/2306.02109v2,cs.LG
2023-06-03 04:23:49+00:00,GAT-GAN : A Graph-Attention-based Time-Series Generative Adversarial Network,"['Srikrishna Iyer', 'Teng Teck Hou']","Generative Adversarial Networks (GANs) have proven to be a powerful tool for
generating realistic synthetic data. However, traditional GANs often struggle
to capture complex relationships between features which results in generation
of unrealistic multivariate time-series data. In this paper, we propose a
Graph-Attention-based Generative Adversarial Network (GAT-GAN) that explicitly
includes two graph-attention layers, one that learns temporal dependencies
while the other captures spatial relationships. Unlike RNN-based GANs that
struggle with modeling long sequences of data points, GAT-GAN generates long
time-series data of high fidelity using an adversarially trained autoencoder
architecture. Our empirical evaluations, using a variety of real-time-series
datasets, show that our framework consistently outperforms state-of-the-art
benchmarks based on \emph{Frechet Transformer distance} and \emph{Predictive
score}, that characterizes (\emph{Fidelity, Diversity}) and \emph{predictive
performance} respectively. Moreover, we introduce a Frechet Inception
distance-like (FID) metric for time-series data called Frechet Transformer
distance (FTD) score (lower is better), to evaluate the quality and variety of
generated data. We also found that low FTD scores correspond to the
best-performing downstream predictive experiments. Hence, FTD scores can be
used as a standardized metric to evaluate synthetic time-series data.",http://arxiv.org/pdf/2306.01999v1,cs.LG
2023-06-02 16:46:47+00:00,Neural Differential Recurrent Neural Network with Adaptive Time Steps,"['Yixuan Tan', 'Liyan Xie', 'Xiuyuan Cheng']","The neural Ordinary Differential Equation (ODE) model has shown success in
learning complex continuous-time processes from observations on discrete time
stamps. In this work, we consider the modeling and forecasting of time series
data that are non-stationary and may have sharp changes like spikes. We propose
an RNN-based model, called RNN-ODE-Adap, that uses a neural ODE to represent
the time development of the hidden states, and we adaptively select time steps
based on the steepness of changes of the data over time so as to train the
model more efficiently for the ""spike-like"" time series. Theoretically,
RNN-ODE-Adap yields provably a consistent estimation of the intensity function
for the Hawkes-type time series data. We also provide an approximation analysis
of the RNN-ODE model showing the benefit of adaptive steps. The proposed model
is demonstrated to achieve higher prediction accuracy with reduced
computational cost on simulated dynamic system data and point process data and
on a real electrocardiography dataset.",http://arxiv.org/pdf/2306.01674v1,stat.ML
2023-06-01 22:59:45+00:00,A General Framework for Uncertainty Quantification via Neural SDE-RNN,"['Shweta Dahale', 'Sai Munikoti', 'Balasubramaniam Natarajan']","Uncertainty quantification is a critical yet unsolved challenge for deep
learning, especially for the time series imputation with irregularly sampled
measurements. To tackle this problem, we propose a novel framework based on the
principles of recurrent neural networks and neural stochastic differential
equations for reconciling irregularly sampled measurements. We impute
measurements at any arbitrary timescale and quantify the uncertainty in the
imputations in a principled manner. Specifically, we derive analytical
expressions for quantifying and propagating the epistemic and aleatoric
uncertainty across time instants. Our experiments on the IEEE 37 bus test
distribution system reveal that our framework can outperform state-of-the-art
uncertainty quantification approaches for time-series data imputations.",http://arxiv.org/pdf/2306.01189v1,cs.LG
2023-06-01 19:54:39+00:00,Improving day-ahead Solar Irradiance Time Series Forecasting by Leveraging Spatio-Temporal Context,"['Oussama Boussif', 'Ghait Boukachab', 'Dan Assouline', 'Stefano Massaroli', 'Tianle Yuan', 'Loubna Benabbou', 'Yoshua Bengio']","Solar power harbors immense potential in mitigating climate change by
substantially reducing CO$_{2}$ emissions. Nonetheless, the inherent
variability of solar irradiance poses a significant challenge for seamlessly
integrating solar power into the electrical grid. While the majority of prior
research has centered on employing purely time series-based methodologies for
solar forecasting, only a limited number of studies have taken into account
factors such as cloud cover or the surrounding physical context. In this paper,
we put forth a deep learning architecture designed to harness spatio-temporal
context using satellite data, to attain highly accurate \textit{day-ahead}
time-series forecasting for any given station, with a particular emphasis on
forecasting Global Horizontal Irradiance (GHI). We also suggest a methodology
to extract a distribution for each time step prediction, which can serve as a
very valuable measure of uncertainty attached to the forecast. When evaluating
models, we propose a testing scheme in which we separate particularly difficult
examples from easy ones, in order to capture the model performances in crucial
situations, which in the case of this study are the days suffering from varying
cloudy conditions. Furthermore, we present a new multi-modal dataset gathering
satellite imagery over a large zone and time series for solar irradiance and
other related physical variables from multiple geographically diverse solar
stations. Our approach exhibits robust performance in solar irradiance
forecasting, including zero-shot generalization tests at unobserved solar
stations, and holds great promise in promoting the effective integration of
solar power into the grid.",http://arxiv.org/pdf/2306.01112v2,cs.LG
2023-06-01 15:08:22+00:00,An End-to-End Time Series Model for Simultaneous Imputation and Forecast,"['Trang H. Tran', 'Lam M. Nguyen', 'Kyongmin Yeo', 'Nam Nguyen', 'Dzung Phan', 'Roman Vaculin', 'Jayant Kalagnanam']","Time series forecasting using historical data has been an interesting and
challenging topic, especially when the data is corrupted by missing values. In
many industrial problem, it is important to learn the inference function
between the auxiliary observations and target variables as it provides
additional knowledge when the data is not fully observed. We develop an
end-to-end time series model that aims to learn the such inference relation and
make a multiple-step ahead forecast. Our framework trains jointly two neural
networks, one to learn the feature-wise correlations and the other for the
modeling of temporal behaviors. Our model is capable of simultaneously imputing
the missing entries and making a multiple-step ahead prediction. The
experiments show good overall performance of our framework over existing
methods in both imputation and forecasting tasks.",http://arxiv.org/pdf/2306.00778v1,cs.LG
2023-06-01 12:45:00+00:00,OTW: Optimal Transport Warping for Time Series,"['Fabian Latorre', 'Chenghao Liu', 'Doyen Sahoo', 'Steven C. H. Hoi']","Dynamic Time Warping (DTW) has become the pragmatic choice for measuring
distance between time series. However, it suffers from unavoidable quadratic
time complexity when the optimal alignment matrix needs to be computed exactly.
This hinders its use in deep learning architectures, where layers involving DTW
computations cause severe bottlenecks. To alleviate these issues, we introduce
a new metric for time series data based on the Optimal Transport (OT)
framework, called Optimal Transport Warping (OTW). OTW enjoys linear time/space
complexity, is differentiable and can be parallelized. OTW enjoys a moderate
sensitivity to time and shape distortions, making it ideal for time series. We
show the efficacy and efficiency of OTW on 1-Nearest Neighbor Classification
and Hierarchical Clustering, as well as in the case of using OTW instead of DTW
in Deep Learning architectures.",http://arxiv.org/pdf/2306.00620v1,cs.LG
2023-06-01 06:50:47+00:00,Learning Gaussian Mixture Representations for Tensor Time Series Forecasting,"['Jiewen Deng', 'Jinliang Deng', 'Renhe Jiang', 'Xuan Song']","Tensor time series (TTS) data, a generalization of one-dimensional time
series on a high-dimensional space, is ubiquitous in real-world scenarios,
especially in monitoring systems involving multi-source spatio-temporal data
(e.g., transportation demands and air pollutants). Compared to modeling time
series or multivariate time series, which has received much attention and
achieved tremendous progress in recent years, tensor time series has been paid
less effort. Properly coping with the tensor time series is a much more
challenging task, due to its high-dimensional and complex inner structure. In
this paper, we develop a novel TTS forecasting framework, which seeks to
individually model each heterogeneity component implied in the time, the
location, and the source variables. We name this framework as GMRL, short for
Gaussian Mixture Representation Learning. Experiment results on two real-world
TTS datasets verify the superiority of our approach compared with the
state-of-the-art baselines. Code and data are published on
https://github.com/beginner-sketch/GMRL.",http://arxiv.org/pdf/2306.00390v3,cs.LG
2023-05-31 13:25:26+00:00,EAMDrift: An interpretable self retrain model for time series,"['Gonçalo Mateus', 'Cláudia Soares', 'João Leitão', 'António Rodrigues']","The use of machine learning for time series prediction has become
increasingly popular across various industries thanks to the availability of
time series data and advancements in machine learning algorithms. However,
traditional methods for time series forecasting rely on pre-optimized models
that are ill-equipped to handle unpredictable patterns in data. In this paper,
we present EAMDrift, a novel method that combines forecasts from multiple
individual predictors by weighting each prediction according to a performance
metric. EAMDrift is designed to automatically adapt to out-of-distribution
patterns in data and identify the most appropriate models to use at each moment
through interpretable mechanisms, which include an automatic retraining
process. Specifically, we encode different concepts with different models, each
functioning as an observer of specific behaviors. The activation of the overall
model then identifies which subset of the concept observers is identifying
concepts in the data. This activation is interpretable and based on learned
rules, allowing to study of input variables relations. Our study on real-world
datasets shows that EAMDrift outperforms individual baseline models by 20% and
achieves comparable accuracy results to non-interpretable ensemble models.
These findings demonstrate the efficacy of EAMDrift for time-series prediction
and highlight the importance of interpretability in machine learning models.",http://arxiv.org/pdf/2305.19837v1,stat.ML
2023-05-31 11:31:49+00:00,Forecasting high-dimensional functional time series: Application to sub-national age-specific mortality,"['Cristian F. Jiménez-Varón', 'Ying Sun', 'Han Lin Shang']","We consider modeling and forecasting high-dimensional functional time series
(HDFTS), which can be cross-sectionally correlated and temporally dependent. We
present a novel two-way functional median polish decomposition, which is robust
against outliers, to decompose HDFTS into deterministic and time-varying
components. A functional time series forecasting method, based on dynamic
functional principal component analysis, is implemented to produce forecasts
for the time-varying components. By combining the forecasts of the time-varying
components with the deterministic components, we obtain forecast curves for
multiple populations. Illustrated by the age- and sex-specific mortality rates
in the US, France, and Japan, which contain 51 states, 95 departments, and 47
prefectures, respectively, the proposed model delivers more accurate point and
interval forecasts in forecasting multi-population mortality than several
benchmark methods.",http://arxiv.org/pdf/2305.19749v1,stat.ME
2023-05-31 09:38:50+00:00,Causal discovery for time series with constraint-based model and PMIME measure,"['Antonin Arsac', 'Aurore Lomet', 'Jean-Philippe Poli']","Causality defines the relationship between cause and effect. In multivariate
time series field, this notion allows to characterize the links between several
time series considering temporal lags. These phenomena are particularly
important in medicine to analyze the effect of a drug for example, in
manufacturing to detect the causes of an anomaly in a complex system or in
social sciences... Most of the time, studying these complex systems is made
through correlation only. But correlation can lead to spurious relationships.
To circumvent this problem, we present in this paper a novel approach for
discovering causality in time series data that combines a causal discovery
algorithm with an information theoretic-based measure. Hence the proposed
method allows inferring both linear and non-linear relationships and building
the underlying causal graph. We evaluate the performance of our approach on
several simulated data sets, showing promising results.",http://arxiv.org/pdf/2305.19695v1,stat.ME
2023-05-31 00:04:51+00:00,Residual Spectrum Applied in Brain Functional Connectivity,"['Yuichi Goto', 'Xuze Zhang', 'Benjamin Kedem', 'Shuo Chen']","Coherence is a widely used measure to assess linear relationships between
time series. However, it fails to capture nonlinear dependencies. To overcome
this limitation, this paper introduces the notion of residual spectral density
as a higher-order extension of the squared coherence. The method is based on an
orthogonal decomposition of time series regression models. We propose a test
for testing the existence of the residual spectrum and derive its fundamental
properties. A numerical study illustrates finite sample performance of the
proposed method. An application of the method shows that the residual spectrum
can effectively detect brain connectivity.",http://arxiv.org/pdf/2305.19461v1,math.ST
2023-05-30 17:32:00+00:00,Testing for the Markov Property in Time Series via Deep Conditional Generative Learning,"['Yunzhe Zhou', 'Chengchun Shi', 'Lexin Li', 'Qiwei Yao']","The Markov property is widely imposed in analysis of time series data.
Correspondingly, testing the Markov property, and relatedly, inferring the
order of a Markov model, are of paramount importance. In this article, we
propose a nonparametric test for the Markov property in high-dimensional time
series via deep conditional generative learning. We also apply the test
sequentially to determine the order of the Markov model. We show that the test
controls the type-I error asymptotically, and has the power approaching one.
Our proposal makes novel contributions in several ways. We utilize and extend
state-of-the-art deep generative learning to estimate the conditional density
functions, and establish a sharp upper bound on the approximation error of the
estimators. We derive a doubly robust test statistic, which employs a
nonparametric estimation but achieves a parametric convergence rate. We further
adopt sample splitting and cross-fitting to minimize the conditions required to
ensure the consistency of the test. We demonstrate the efficacy of the test
through both simulations and the three data applications.",http://arxiv.org/pdf/2305.19244v1,stat.ML
2023-05-30 16:27:25+00:00,Graph-based Time Series Clustering for End-to-End Hierarchical Forecasting,"['Andrea Cini', 'Danilo Mandic', 'Cesare Alippi']","Existing relationships among time series can be exploited as inductive biases
in learning effective forecasting models. In hierarchical time series,
relationships among subsets of sequences induce hard constraints (hierarchical
inductive biases) on the predicted values. In this paper, we propose a
graph-based methodology to unify relational and hierarchical inductive biases
in the context of deep learning for time series forecasting. In particular, we
model both types of relationships as dependencies in a pyramidal graph
structure, with each pyramidal layer corresponding to a level of the hierarchy.
By exploiting modern - trainable - graph pooling operators we show that the
hierarchical structure, if not available as a prior, can be learned directly
from data, thus obtaining cluster assignments aligned with the forecasting
objective. A differentiable reconciliation stage is incorporated into the
processing architecture, allowing hierarchical constraints to act both as an
architectural bias as well as a regularization element for predictions.
Simulation results on representative datasets show that the proposed method
compares favorably against the state of the art.",http://arxiv.org/pdf/2305.19183v1,cs.LG
2023-05-30 15:50:24+00:00,Taylorformer: Probabilistic Predictions for Time Series and other Processes,"['Omer Nivron', 'Raghul Parthipan', 'Damon J. Wischik']","We propose the Taylorformer for time series and other random processes. Its
two key components are: 1) the LocalTaylor wrapper to learn how and when to use
Taylor series-based approximations for predictions, and 2) the MHA-X attention
block which makes predictions in a way inspired by how Gaussian Processes' mean
predictions are linear smoothings of contextual data. Taylorformer outperforms
the state-of-the-art on several forecasting datasets, including electricity,
oil temperatures and exchange rates with at least 14% improvement in MSE on all
tasks, and better likelihood on 5/6 classic Neural Process tasks such as
meta-learning 1D functions. Taylorformer combines desirable features from the
Neural Process (uncertainty-aware predictions and consistency) and forecasting
(predictive accuracy) literature, two previously distinct bodies.",http://arxiv.org/pdf/2305.19141v1,cs.LG
2023-05-30 09:31:57+00:00,Contrastive Shapelet Learning for Unsupervised Multivariate Time Series Representation Learning,"['Zhiyu Liang', 'Jianfeng Zhang', 'Chen Liang', 'Hongzhi Wang', 'Zheng Liang', 'Lujia Pan']","Recent studies have shown great promise in unsupervised representation
learning (URL) for multivariate time series, because URL has the capability in
learning generalizable representation for many downstream tasks without using
inaccessible labels. However, existing approaches usually adopt the models
originally designed for other domains (e.g., computer vision) to encode the
time series data and rely on strong assumptions to design learning objectives,
which limits their ability to perform well. To deal with these problems, we
propose a novel URL framework for multivariate time series by learning
time-series-specific shapelet-based representation through a popular
contrasting learning paradigm. To the best of our knowledge, this is the first
work that explores the shapelet-based embedding in the unsupervised
general-purpose representation learning. A unified shapelet-based encoder and a
novel learning objective with multi-grained contrasting and multi-scale
alignment are particularly designed to achieve our goal, and a data
augmentation library is employed to improve the generalization. We conduct
extensive experiments using tens of real-world datasets to assess the
representation quality on many downstream tasks, including classification,
clustering, and anomaly detection. The results demonstrate the superiority of
our method against not only URL competitors, but also techniques specially
designed for downstream tasks. Our code has been made publicly available at
https://github.com/real2fish/CSL.",http://arxiv.org/pdf/2305.18888v3,cs.LG
2023-05-30 08:33:50+00:00,Learning Perturbations to Explain Time Series Predictions,['Joseph Enguehard'],"Explaining predictions based on multivariate time series data carries the
additional difficulty of handling not only multiple features, but also time
dependencies. It matters not only what happened, but also when, and the same
feature could have a very different impact on a prediction depending on this
time information. Previous work has used perturbation-based saliency methods to
tackle this issue, perturbing an input using a trainable mask to discover which
features at which times are driving the predictions. However these methods
introduce fixed perturbations, inspired from similar methods on static data,
while there seems to be little motivation to do so on temporal data. In this
work, we aim to explain predictions by learning not only masks, but also
associated perturbations. We empirically show that learning these perturbations
significantly improves the quality of these explanations on time series data.",http://arxiv.org/pdf/2305.18840v1,cs.LG
2023-05-30 08:31:22+00:00,Client: Cross-variable Linear Integrated Enhanced Transformer for Multivariate Long-Term Time Series Forecasting,"['Jiaxin Gao', 'Wenbo Hu', 'Yuntian Chen']","Long-term time series forecasting (LTSF) is a crucial aspect of modern
society, playing a pivotal role in facilitating long-term planning and
developing early warning systems. While many Transformer-based models have
recently been introduced for LTSF, a doubt have been raised regarding the
effectiveness of attention modules in capturing cross-time dependencies. In
this study, we design a mask-series experiment to validate this assumption and
subsequently propose the ""Cross-variable Linear Integrated ENhanced Transformer
for Multivariate Long-Term Time Series Forecasting"" (Client), an advanced model
that outperforms both traditional Transformer-based models and linear models.
Client employs linear modules to learn trend information and attention modules
to capture cross-variable dependencies. Meanwhile, it simplifies the embedding
and position encoding layers and replaces the decoder module with a projection
layer. Essentially, Client incorporates non-linearity and cross-variable
dependencies, which sets it apart from conventional linear models and
Transformer-based models. Extensive experiments with nine real-world datasets
have confirmed the SOTA performance of Client with the least computation time
and memory consumption compared with the previous Transformer-based models. Our
code is available at https://github.com/daxin007/Client.",http://arxiv.org/pdf/2305.18838v1,cs.LG
2023-05-30 07:57:05+00:00,PyPOTS: A Python Toolbox for Data Mining on Partially-Observed Time Series,['Wenjie Du'],"PyPOTS is an open-source Python library dedicated to data mining and analysis
on multivariate partially-observed time series, i.e. incomplete time series
with missing values, A.K.A. irregularlysampled time series. Particularly, it
provides easy access to diverse algorithms categorized into four tasks:
imputation, classification, clustering, and forecasting. The included models
contain probabilistic approaches as well as neural-network methods, with a
well-designed and fully-documented programming interface for both academic
researchers and industrial professionals to use. With robustness and
scalability in its design philosophy, best practices of software construction,
for example, unit testing, continuous integration (CI) and continuous delivery
(CD), code coverage, maintainability evaluation, interactive tutorials, and
parallelization, are carried out as principles during the development of
PyPOTS. The toolkit is available on both Python Package Index (PyPI) and
Anaconda. PyPOTS is open-source and publicly available on GitHub
https://github.com/WenjieDu/PyPOTS.",http://arxiv.org/pdf/2305.18811v1,cs.LG
2023-05-30 07:40:27+00:00,Koopa: Learning Non-stationary Time Series Dynamics with Koopman Predictors,"['Yong Liu', 'Chenyu Li', 'Jianmin Wang', 'Mingsheng Long']","Real-world time series are characterized by intrinsic non-stationarity that
poses a principal challenge for deep forecasting models. While previous models
suffer from complicated series variations induced by changing temporal
distribution, we tackle non-stationary time series with modern Koopman theory
that fundamentally considers the underlying time-variant dynamics. Inspired by
Koopman theory of portraying complex dynamical systems, we disentangle
time-variant and time-invariant components from intricate non-stationary series
by Fourier Filter and design Koopman Predictor to advance respective dynamics
forward. Technically, we propose Koopa as a novel Koopman forecaster composed
of stackable blocks that learn hierarchical dynamics. Koopa seeks measurement
functions for Koopman embedding and utilizes Koopman operators as linear
portraits of implicit transition. To cope with time-variant dynamics that
exhibits strong locality, Koopa calculates context-aware operators in the
temporal neighborhood and is able to utilize incoming ground truth to scale up
forecast horizon. Besides, by integrating Koopman Predictors into deep residual
structure, we ravel out the binding reconstruction loss in previous Koopman
forecasters and achieve end-to-end forecasting objective optimization. Compared
with the state-of-the-art model, Koopa achieves competitive performance while
saving 77.3% training time and 76.0% memory.",http://arxiv.org/pdf/2305.18803v2,cs.LG
2023-05-29 21:11:34+00:00,Networked Time Series Imputation via Position-aware Graph Enhanced Variational Autoencoders,"['Dingsu Wang', 'Yuchen Yan', 'Ruizhong Qiu', 'Yada Zhu', 'Kaiyu Guan', 'Andrew J Margenot', 'Hanghang Tong']","Multivariate time series (MTS) imputation is a widely studied problem in
recent years. Existing methods can be divided into two main groups, including
(1) deep recurrent or generative models that primarily focus on time series
features, and (2) graph neural networks (GNNs) based models that utilize the
topological information from the inherent graph structure of MTS as relational
inductive bias for imputation. Nevertheless, these methods either neglect
topological information or assume the graph structure is fixed and accurately
known. Thus, they fail to fully utilize the graph dynamics for precise
imputation in more challenging MTS data such as networked time series (NTS),
where the underlying graph is constantly changing and might have missing edges.
In this paper, we propose a novel approach to overcome these limitations.
First, we define the problem of imputation over NTS which contains missing
values in both node time series features and graph structures. Then, we design
a new model named PoGeVon which leverages variational autoencoder (VAE) to
predict missing values over both node time series features and graph
structures. In particular, we propose a new node position embedding based on
random walk with restart (RWR) in the encoder with provable higher expressive
power compared with message-passing based graph neural networks (GNNs). We
further design a decoder with 3-stage predictions from the perspective of
multi-task learning to impute missing values in both time series and graph
structures reciprocally. Experiment results demonstrate the effectiveness of
our model over baselines.",http://arxiv.org/pdf/2305.18612v2,cs.LG
2023-05-26 18:49:42+00:00,Improved Sales Forecasting using Trend and Seasonality Decomposition with LightGBM,['Tong Zhou'],"Retail sales forecasting presents a significant challenge for large retailers
such as Walmart and Amazon, due to the vast assortment of products,
geographical location heterogeneity, seasonality, and external factors
including weather, local economic conditions, and geopolitical events. Various
methods have been employed to tackle this challenge, including traditional time
series models, machine learning models, and neural network mechanisms, but the
difficulty persists. Categorizing data into relevant groups has been shown to
improve sales forecast accuracy as time series from different categories may
exhibit distinct patterns. In this paper, we propose a new measure to indicate
the unique impacts of the trend and seasonality components on a time series and
suggest grouping time series based on this measure. We apply this approach to
Walmart sales data from 01/29/2011 to 05/22/2016 and generate sales forecasts
from 05/23/2016 to 06/19/2016. Our experiments show that the proposed strategy
can achieve improved accuracy. Furthermore, we present a robust pipeline for
conducting retail sales forecasting.",http://arxiv.org/pdf/2305.17201v2,cs.LG
2023-05-26 15:36:59+00:00,Better Batch for Deep Probabilistic Time Series Forecasting,"['Vincent Zhihao Zheng', 'Seongjin Choi', 'Lijun Sun']","Deep probabilistic time series forecasting has gained significant attention
due to its ability to provide valuable uncertainty quantification for
decision-making tasks. However, many existing models oversimplify the problem
by assuming the error process is time-independent, thereby overlooking the
serial correlation in the error process. This oversight can potentially
diminish the accuracy of the forecasts, rendering these models less effective
for decision-making purposes. To overcome this limitation, we propose an
innovative training method that incorporates error autocorrelation to enhance
the accuracy of probabilistic forecasting. Our method involves constructing a
mini-batch as a collection of $D$ consecutive time series segments for model
training and explicitly learning a covariance matrix over each mini-batch that
encodes the error correlation among adjacent time steps. The resulting
covariance matrix can be used to improve prediction accuracy and enhance
uncertainty quantification. We evaluate our method using DeepAR on multiple
public datasets, and the experimental results confirm that our framework can
effectively capture the error autocorrelation and enhance probabilistic
forecasting.",http://arxiv.org/pdf/2305.17028v1,stat.ML
2023-05-26 12:15:56+00:00,Knowledge Extraction with Interval Temporal Logic Decision Trees,"['Guido Sciavicco', 'Stan Ionel Eduard']","Multivariate temporal, or time, series classification is, in a way, the
temporal generalization of (numeric) classification, as every instance is
described by multiple time series instead of multiple values. Symbolic
classification is the machine learning strategy to extract explicit knowledge
from a data set, and the problem of symbolic classification of multivariate
temporal series requires the design, implementation, and test of ad-hoc machine
learning algorithms, such as, for example, algorithms for the extraction of
temporal versions of decision trees. One of the most well-known algorithms for
decision tree extraction from categorical data is Quinlan's ID3, which was
later extended to deal with numerical attributes, resulting in an algorithm
known as C4.5, and implemented in many open-sources data mining libraries,
including the so-called Weka, which features an implementation of C4.5 called
J48. ID3 was recently generalized to deal with temporal data in form of
timelines, which can be seen as discrete (categorical) versions of multivariate
time series, and such a generalization, based on the interval temporal logic
HS, is known as Temporal ID3. In this paper we introduce Temporal C4.5, that
allows the extraction of temporal decision trees from undiscretized
multivariate time series, describe its implementation, called Temporal J48, and
discuss the outcome of a set of experiments with the latter on a collection of
public data sets, comparing the results with those obtained by other,
classical, multivariate time series classification methods.",http://arxiv.org/pdf/2305.16864v1,cs.LG
2023-05-26 10:02:32+00:00,On the Generalization and Approximation Capacities of Neural Controlled Differential Equations,"['Linus Bleistein', 'Agathe Guilloux']","Neural Controlled Differential Equations (NCDEs) are a state-of-the-art tool
for supervised learning with irregularly sampled time series (Kidger, 2020).
However, no theoretical analysis of their performance has been provided yet,
and it remains unclear in particular how the irregularity of the time series
affects their predictions. By merging the rich theory of controlled
differential equations (CDE) and Lipschitz-based measures of the complexity of
deep neural nets, we take a first step towards the theoretical understanding of
NCDE. Our first result is a generalization bound for this class of predictors
that depends on the regularity of the time series data. In a second time, we
leverage the continuity of the flow of CDEs to provide a detailed analysis of
both the sampling-induced bias and the approximation bias. Regarding this last
result, we show how classical approximation results on neural nets may transfer
to NCDEs. Our theoretical results are validated through a series of
experiments.",http://arxiv.org/pdf/2305.16791v3,stat.ML
2023-05-26 08:30:51+00:00,Evaluating generation of chaotic time series by convolutional generative adversarial networks,"['Yuki Tanaka', 'Yutaka Yamaguti']","To understand the ability and limitations of convolutional neural networks to
generate time series that mimic complex temporal signals, we trained a
generative adversarial network consisting of deep convolutional networks to
generate chaotic time series and used nonlinear time series analysis to
evaluate the generated time series. A numerical measure of determinism and the
Lyapunov exponent, a measure of trajectory instability, showed that the
generated time series well reproduce the chaotic properties of the original
time series. However, error distribution analyses showed that large errors
appeared at a low but non-negligible rate. Such errors would not be expected if
the distribution were assumed to be exponential.",http://arxiv.org/pdf/2305.16729v2,cs.LG
2023-05-26 05:30:04+00:00,Improving Position Encoding of Transformers for Multivariate Time Series Classification,"['Navid Mohammadi Foumani', 'Chang Wei Tan', 'Geoffrey I. Webb', 'Mahsa Salehi']","Transformers have demonstrated outstanding performance in many applications
of deep learning. When applied to time series data, transformers require
effective position encoding to capture the ordering of the time series data.
The efficacy of position encoding in time series analysis is not well-studied
and remains controversial, e.g., whether it is better to inject absolute
position encoding or relative position encoding, or a combination of them. In
order to clarify this, we first review existing absolute and relative position
encoding methods when applied in time series classification. We then proposed a
new absolute position encoding method dedicated to time series data called time
Absolute Position Encoding (tAPE). Our new method incorporates the series
length and input embedding dimension in absolute position encoding.
Additionally, we propose computationally Efficient implementation of Relative
Position Encoding (eRPE) to improve generalisability for time series. We then
propose a novel multivariate time series classification (MTSC) model combining
tAPE/eRPE and convolution-based input encoding named ConvTran to improve the
position and data embedding of time series data. The proposed absolute and
relative position encoding methods are simple and efficient. They can be easily
integrated into transformer blocks and used for downstream tasks such as
forecasting, extrinsic regression, and anomaly detection. Extensive experiments
on 32 multivariate time-series datasets show that our model is significantly
more accurate than state-of-the-art convolution and transformer-based models.
Code and models are open-sourced at
\url{https://github.com/Navidfoumani/ConvTran}.",http://arxiv.org/pdf/2305.16642v1,cs.LG
2023-05-25 22:32:45+00:00,RoLA: A Real-Time Online Lightweight Anomaly Detection System for Multivariate Time Series,"['Ming-Chang Lee', 'Jia-Chun Lin']","A multivariate time series refers to observations of two or more variables
taken from a device or a system simultaneously over time. There is an
increasing need to monitor multivariate time series and detect anomalies in
real time to ensure proper system operation and good service quality. It is
also highly desirable to have a lightweight anomaly detection system that
considers correlations between different variables, adapts to changes in the
pattern of the multivariate time series, offers immediate responses, and
provides supportive information regarding detection results based on
unsupervised learning and online model training. In the past decade, many
multivariate time series anomaly detection approaches have been introduced.
However, they are unable to offer all the above-mentioned features. In this
paper, we propose RoLA, a real-time online lightweight anomaly detection system
for multivariate time series based on a divide-and-conquer strategy, parallel
processing, and the majority rule. RoLA employs multiple lightweight anomaly
detectors to monitor multivariate time series in parallel, determine the
correlations between variables dynamically on the fly, and then jointly detect
anomalies based on the majority rule in real time. To demonstrate the
performance of RoLA, we conducted an experiment based on a public dataset
provided by the FerryBox of the One Ocean Expedition. The results show that
RoLA provides satisfactory detection accuracy and lightweight performance.",http://arxiv.org/pdf/2305.16509v1,cs.LG
2023-05-25 14:29:27+00:00,The GNAR-edge model: A network autoregressive model for networks with time-varying edge weights,"['Anastasia Mantziou', 'Mihai Cucuringu', 'Victor Meirinhos', 'Gesine Reinert']","In economic and financial applications, there is often the need for analysing
multivariate time series, comprising of time series for a range of quantities.
In some applications such complex systems can be associated with some
underlying network describing pairwise relationships among the quantities.
Accounting for the underlying network structure for the analysis of this type
of multivariate time series is required for assessing estimation error and can
be particularly informative for forecasting. Our work is motivated by a dataset
consisting of time series of industry-to-industry transactions. In this
example, pairwise relationships between Standard Industrial Classification
(SIC) codes can be represented using a network, with SIC codes as nodes and
pairwise transactions between SIC codes as edges, while the observed time
series of the amounts of the transactions for each pair of SIC codes can be
regarded as time-varying weights on the edges. Inspired by Knight et al.
(2020), we introduce the GNAR-edge model which allows modelling of multiple
time series utilising the network structure, assuming that each edge weight
depends not only on its past values, but also on past values of its
neighbouring edges, for a range of neighbourhood stages. The method is
validated through simulations. Results from the implementation of the GNAR-edge
model on the real industry-to-industry data show good fitting and predictive
performance of the model. The predictive performance is improved when
sparsifying the network using a lead-lag analysis and thresholding edges
according to a lead-lag score.",http://arxiv.org/pdf/2305.16097v3,stat.ME
2023-05-25 13:00:46+00:00,Stecformer: Spatio-temporal Encoding Cascaded Transformer for Multivariate Long-term Time Series Forecasting,"['Zheng Sun', 'Yi Wei', 'Wenxiao Jia', 'Long Yu']","Multivariate long-term time series forecasting is of great application across
many domains, such as energy consumption and weather forecasting. With the
development of transformer-based methods, the performance of multivariate
long-term time series forecasting has been significantly improved, however, the
study of spatial features extracting in transformer-based model is rare and the
consistency of different prediction periods is unsatisfactory due to the large
span. In this work, we propose a complete solution to address these problems in
terms of feature extraction and target prediction. For extraction, we design an
efficient spatio-temporal encoding extractor including a semi-adaptive graph to
acquire sufficient spatio-temporal information. For prediction, we propose a
Cascaded Decoding Predictor (CDP) to strengthen the correlation between
different intervals, which can also be utilized as a generic component to
improve the performance of transformer-based methods. The proposed method,
termed as Spatio-temporal Encoding Cascaded Transformer (Stecformer), achieving
a notable gap over the baseline model and is comparable with the
state-of-the-art performance of transformer-based methods on five benchmark
datasets. We hope our attempt will serve as a regular configuration in
multivariate long-term time series forecasting in the future.",http://arxiv.org/pdf/2305.16370v1,cs.LG
2023-05-25 06:27:45+00:00,TLNets: Transformation Learning Networks for long-range time-series prediction,"['Wei Wang', 'Yang Liu', 'Hao Sun']","Time series prediction is a prevalent issue across various disciplines, such
as meteorology, traffic surveillance, investment, and energy production and
consumption. Many statistical and machine-learning strategies have been
developed to tackle this problem. However, these approaches either lack
explainability or exhibit less satisfactory performance when the prediction
horizon increases. To this end, we propose a novel plan for the designing of
networks' architecture based on transformations, possessing the potential to
achieve an enhanced receptive field in learning which brings benefits to fuse
features across scales. In this context, we introduce four different
transformation mechanisms as bases to construct the learning model including
Fourier Transform (FT), Singular Value Decomposition (SVD), matrix
multiplication and Conv block. Hence, we develop four learning models based on
the above building blocks, namely, FT-Matrix, FT-SVD, FT-Conv, and Conv-SVD.
Note that the FT and SVD blocks are capable of learning global information,
while the Conv blocks focus on learning local information. The matrix block is
sparsely designed to learn both global and local information simultaneously.
The above Transformation Learning Networks (TLNets) have been extensively
tested and compared with multiple baseline models based on several real-world
datasets and showed clear potential in long-range time-series forecasting.",http://arxiv.org/pdf/2305.15770v1,cs.LG
2023-05-25 02:41:24+00:00,Matrix Autoregressive Model with Vector Time Series Covariates for Spatio-Temporal Data,"['Hu Sun', 'Zuofeng Shang', 'Yang Chen']","In this paper, we propose a new model for forecasting time series data
distributed on a matrix-shaped spatial grid, using the historical
spatio-temporal data together with auxiliary vector-valued time series data. We
model the matrix time series as an auto-regressive process, where a future
matrix is jointly predicted by the historical values of the matrix time series
as well as an auxiliary vector time series. The matrix predictors are
associated with row/column-specific autoregressive matrix coefficients that map
the predictors to the future matrices via a bi-linear transformation. The
vector predictors are mapped to matrices by taking mode product with a 3D
coefficient tensor. Given the high dimensionality of the tensor coefficient and
the underlying spatial structure of the data, we propose to estimate the tensor
coefficient by estimating one functional coefficient for each covariate, with
2D input domain, from a Reproducing Kernel Hilbert Space. We jointly estimate
the autoregressive matrix coefficients and the functional coefficients under a
penalized maximum likelihood estimation framework, and couple it with an
alternating minimization algorithm. Large sample asymptotics of the estimators
are established and performances of the model are validated with extensive
simulation studies and a real data application to forecast the global total
electron content distributions.",http://arxiv.org/pdf/2305.15671v1,stat.ME
2023-05-23 23:43:26+00:00,Interpretation of Time-Series Deep Models: A Survey,"['Ziqi Zhao', 'Yucheng Shi', 'Shushan Wu', 'Fan Yang', 'Wenzhan Song', 'Ninghao Liu']","Deep learning models developed for time-series associated tasks have become
more widely researched nowadays. However, due to the unintuitive nature of
time-series data, the interpretability problem -- where we understand what is
under the hood of these models -- becomes crucial. The advancement of similar
studies in computer vision has given rise to many post-hoc methods, which can
also shed light on how to explain time-series models. In this paper, we present
a wide range of post-hoc interpretation methods for time-series models based on
backpropagation, perturbation, and approximation. We also want to bring focus
onto inherently interpretable models, a novel category of interpretation where
human-understandable information is designed within the models. Furthermore, we
introduce some common evaluation metrics used for the explanations, and propose
several directions of future researches on the time-series interpretability
problem. As a highlight, our work summarizes not only the well-established
interpretation methods, but also a handful of fairly recent and under-developed
techniques, which we hope to capture their essence and spark future endeavours
to innovate and improvise.",http://arxiv.org/pdf/2305.14582v1,cs.LG
2023-05-23 21:59:13+00:00,DF2M: An Explainable Deep Bayesian Nonparametric Model for High-Dimensional Functional Time Series,"['Yirui Liu', 'Xinghao Qiao', 'Yulong Pei', 'Liying Wang']","In this paper, we present Deep Functional Factor Model (DF2M), a Bayesian
nonparametric model for analyzing high-dimensional functional time series. The
DF2M makes use of the Indian Buffet Process and the multi-task Gaussian Process
with a deep kernel function to capture non-Markovian and nonlinear temporal
dynamics. Unlike many black-box deep learning models, the DF2M provides an
explainable way to use neural networks by constructing a factor model and
incorporating deep neural networks within the kernel function. Additionally, we
develop a computationally efficient variational inference algorithm for
inferring the DF2M. Empirical results from four real-world datasets demonstrate
that the DF2M offers better explainability and superior predictive accuracy
compared to conventional deep learning models for high-dimensional functional
time series.",http://arxiv.org/pdf/2305.14543v1,stat.ML
2023-05-23 14:55:48+00:00,Temporally Causal Discovery Tests for Discrete Time Series and Neural Spike Trains,"['A. Theocharous', 'G. G. Gregoriou', 'P. Sapountzis', 'I. Kontoyiannis']","We consider the problem of detecting causal relationships between discrete
time series, in the presence of potential confounders. A hypothesis test is
introduced for identifying the temporally causal influence of $(x_n)$ on
$(y_n)$, causally conditioned on a possibly confounding third time series
$(z_n)$. Under natural Markovian modeling assumptions, it is shown that the
null hypothesis, corresponding to the absence of temporally causal influence,
is equivalent to the underlying `causal conditional directed information rate'
being equal to zero. The plug-in estimator for this functional is identified
with the log-likelihood ratio test statistic for the desired test. This
statistic is shown that is asymptotically normal under the alternative
hypothesis and asymptotically $\chi^2$ distributed under the null, facilitating
the computation of $p$-values when used on empirical data. The effectiveness of
the resulting hypothesis test is illustrated on simulated data, validating the
underlying theory. The test is also employed in the analysis of spike train
data recorded from neurons in the V4 and FEF brain regions of behaving animals
during a visual attention task. There, the test results are seen to identify
interesting and biologically relevant information.",http://arxiv.org/pdf/2305.14131v1,stat.ME
2023-05-22 11:25:24+00:00,Forecasting Irregularly Sampled Time Series using Graphs,"['Vijaya Krishna Yalavarthi', 'Kiran Madhusudhanan', 'Randolf Sholz', 'Nourhan Ahmed', 'Johannes Burchert', 'Shayan Jawed', 'Stefan Born', 'Lars Schmidt-Thieme']","Forecasting irregularly sampled time series with missing values is a crucial
task for numerous real-world applications such as healthcare, astronomy, and
climate sciences. State-of-the-art approaches to this problem rely on Ordinary
Differential Equations (ODEs) which are known to be slow and often require
additional features to handle missing values. To address this issue, we propose
a novel model using Graphs for Forecasting Irregularly Sampled Time Series with
missing values which we call GraFITi. GraFITi first converts the time series to
a Sparsity Structure Graph which is a sparse bipartite graph, and then
reformulates the forecasting problem as the edge weight prediction task in the
graph. It uses the power of Graph Neural Networks to learn the graph and
predict the target edge weights. GraFITi has been tested on 3 real-world and 1
synthetic irregularly sampled time series dataset with missing values and
compared with various state-of-the-art models. The experimental results
demonstrate that GraFITi improves the forecasting accuracy by up to 17% and
reduces the run time up to 5 times compared to the state-of-the-art forecasting
models.",http://arxiv.org/pdf/2305.12932v2,cs.LG
2023-05-22 02:51:31+00:00,Conditional normalization in time series analysis,"['Puwasala Gamakumara', 'Edgar Santos-Fernandez', 'Priyanga Dilini Talagala', 'Rob J. Hyndman', 'Kerrie Mengersen', 'Catherine Leigh']","Time series often reflect variation associated with other related variables.
Controlling for the effect of these variables is useful when modeling or
analysing the time series. We introduce a novel approach to normalize time
series data conditional on a set of covariates. We do this by modeling the
conditional mean and the conditional variance of the time series with
generalized additive models using a set of covariates. The conditional mean and
variance are then used to normalize the time series. We illustrate the use of
conditionally normalized series using two applications involving river network
data. First, we show how these normalized time series can be used to impute
missing values in the data. Second, we show how the normalized series can be
used to estimate the conditional autocorrelation function and conditional
cross-correlation functions via additive models. Finally we use the conditional
cross-correlations to estimate the time it takes water to flow between two
locations in a river network.",http://arxiv.org/pdf/2305.12651v1,stat.ME
2023-05-21 17:05:03+00:00,PCF-GAN: generating sequential data via the characteristic function of measures on the path space,"['Hang Lou', 'Siran Li', 'Hao Ni']","Generating high-fidelity time series data using generative adversarial
networks (GANs) remains a challenging task, as it is difficult to capture the
temporal dependence of joint probability distributions induced by time-series
data. Towards this goal, a key step is the development of an effective
discriminator to distinguish between time series distributions. We propose the
so-called PCF-GAN, a novel GAN that incorporates the path characteristic
function (PCF) as the principled representation of time series distribution
into the discriminator to enhance its generative performance. On the one hand,
we establish theoretical foundations of the PCF distance by proving its
characteristicity, boundedness, differentiability with respect to generator
parameters, and weak continuity, which ensure the stability and feasibility of
training the PCF-GAN. On the other hand, we design efficient initialisation and
optimisation schemes for PCFs to strengthen the discriminative power and
accelerate training efficiency. To further boost the capabilities of complex
time series generation, we integrate the auto-encoder structure via sequential
embedding into the PCF-GAN, which provides additional reconstruction
functionality. Extensive numerical experiments on various datasets demonstrate
the consistently superior performance of PCF-GAN over state-of-the-art
baselines, in both generation and reconstruction quality. Code is available at
https://github.com/DeepIntoStreams/PCF-GAN.",http://arxiv.org/pdf/2305.12511v1,cs.LG
2023-05-20 05:16:31+00:00,Make Transformer Great Again for Time Series Forecasting: Channel Aligned Robust Dual Transformer,"['Wang Xue', 'Tian Zhou', 'Qingsong Wen', 'Jinyang Gao', 'Bolin Ding', 'Rong Jin']","Recent studies have demonstrated the great power of deep learning methods,
particularly Transformer and MLP, for time series forecasting. Despite its
success in NLP and CV, many studies found that Transformer is less effective
than MLP for time series forecasting. In this work, we design a special
Transformer, i.e., channel-aligned robust dual Transformer (CARD for short),
that addresses key shortcomings of Transformer in time series forecasting.
First, CARD introduces a dual Transformer structure that allows it to capture
both temporal correlations among signals and dynamical dependence among
multiple variables over time. Second, we introduce a robust loss function for
time series forecasting to alleviate the potential overfitting issue. This new
loss function weights the importance of forecasting over a finite horizon based
on prediction uncertainties. Our evaluation of multiple long-term and
short-term forecasting datasets demonstrates that CARD significantly
outperforms state-of-the-art time series forecasting methods, including both
Transformer and MLP-based models.",http://arxiv.org/pdf/2305.12095v3,cs.LG
2023-05-19 10:11:21+00:00,TSGM: A Flexible Framework for Generative Modeling of Synthetic Time Series,"['Alexander Nikitin', 'Letizia Iannucci', 'Samuel Kaski']","Temporally indexed data are essential in a wide range of fields and of
interest to machine learning researchers. Time series data, however, are often
scarce or highly sensitive, which precludes the sharing of data between
researchers and industrial organizations and the application of existing and
new data-intensive ML methods. A possible solution to this bottleneck is to
generate synthetic data. In this work, we introduce Time Series Generative
Modeling (TSGM), an open-source framework for the generative modeling of
synthetic time series. TSGM includes a broad repertoire of machine learning
methods: generative models, probabilistic, and simulator-based approaches. The
framework enables users to evaluate the quality of the produced data from
different angles: similarity, downstream effectiveness, predictive consistency,
diversity, and privacy. The framework is extensible, which allows researchers
to rapidly implement their own methods and compare them in a shareable
environment. TSGM was tested on open datasets and in production and proved to
be beneficial in both cases. Additionally to the library, the project allows
users to employ command line interfaces for synthetic data generation which
lowers the entry threshold for those without a programming background.",http://arxiv.org/pdf/2305.11567v1,cs.LG
2023-05-18 05:39:46+00:00,Revisiting Long-term Time Series Forecasting: An Investigation on Linear Mapping,"['Zhe Li', 'Shiyi Qi', 'Yiduo Li', 'Zenglin Xu']","Long-term time series forecasting has gained significant attention in recent
years. While there are various specialized designs for capturing temporal
dependency, previous studies have demonstrated that a single linear layer can
achieve competitive forecasting performance compared to other complex
architectures. In this paper, we thoroughly investigate the intrinsic
effectiveness of recent approaches and make three key observations: 1) linear
mapping is critical to prior long-term time series forecasting efforts; 2)
RevIN (reversible normalization) and CI (Channel Independent) play a vital role
in improving overall forecasting performance; and 3) linear mapping can
effectively capture periodic features in time series and has robustness for
different periods across channels when increasing the input horizon. We provide
theoretical and experimental explanations to support our findings and also
discuss the limitations and future works. Our framework's code is available at
\url{https://github.com/plumprc/RTSF}.",http://arxiv.org/pdf/2305.10721v1,cs.LG
2023-05-18 05:27:46+00:00,A Survey on Time-Series Pre-Trained Models,"['Qianli Ma', 'Zhen Liu', 'Zhenjing Zheng', 'Ziyang Huang', 'Siying Zhu', 'Zhongzhong Yu', 'James T. Kwok']","Time-Series Mining (TSM) is an important research area since it shows great
potential in practical applications. Deep learning models that rely on massive
labeled data have been utilized for TSM successfully. However, constructing a
large-scale well-labeled dataset is difficult due to data annotation costs.
Recently, Pre-Trained Models have gradually attracted attention in the time
series domain due to their remarkable performance in computer vision and
natural language processing. In this survey, we provide a comprehensive review
of Time-Series Pre-Trained Models (TS-PTMs), aiming to guide the understanding,
applying, and studying TS-PTMs. Specifically, we first briefly introduce the
typical deep learning models employed in TSM. Then, we give an overview of
TS-PTMs according to the pre-training techniques. The main categories we
explore include supervised, unsupervised, and self-supervised TS-PTMs. Further,
extensive experiments are conducted to analyze the advantages and disadvantages
of transfer learning strategies, Transformer-based models, and representative
TS-PTMs. Finally, we point out some potential directions of TS-PTMs for future
work.",http://arxiv.org/pdf/2305.10716v1,cs.LG
2023-05-18 02:27:48+00:00,Spectral Change Point Estimation for High Dimensional Time Series by Sparse Tensor Decomposition,"['Xinyu Zhang', 'Kung-Sik Chan']","We study the problem of change point (CP) detection with high dimensional
time series, within the framework of frequency domain. The overarching goal is
to locate all change points and for each change point, delineate which series
are activated by the change, over which set of frequencies. The working
assumption is that only a few series are activated per change and frequency. We
solve the problem by computing a CUSUM tensor based on spectra estimated from
blocks of the observed time series. A frequency-specific projection approach is
applied to the CUSUM tensor for dimension reduction. The projection direction
is estimated by a proposed sparse tensor decomposition algorithm. Finally, the
projected CUSUM vectors across frequencies are aggregated by a sparsified wild
binary segmentation for change point detection. We provide theoretical
guarantees on the number of estimated change points and the convergence rate of
their locations. We derive error bounds for the estimated projection direction
for identifying the frequency-specific series that are activated in a change.
We provide data-driven rules for the choice of parameters. We illustrate the
efficacy of the proposed method by simulation and a stock returns application.",http://arxiv.org/pdf/2305.10656v1,stat.ME
2023-05-17 17:48:52+00:00,On Consistency of Signatures Using Lasso,"['Xin Guo', 'Ruixun Zhang', 'Chaoyi Zhao']","Signature transforms are iterated path integrals of continuous and
discrete-time time series data, and their universal nonlinearity linearizes the
problem of feature selection. This paper revisits the consistency issue of
Lasso regression for the signature transform, both theoretically and
numerically. Our study shows that, for processes and time series that are
closer to Brownian motion or random walk with weaker inter-dimensional
correlations, the Lasso regression is more consistent for their signatures
defined by It\^o integrals; for mean reverting processes and time series, their
signatures defined by Stratonovich integrals have more consistency in the Lasso
regression. Our findings highlight the importance of choosing appropriate
definitions of signatures and stochastic models in statistical inference and
machine learning.",http://arxiv.org/pdf/2305.10413v2,stat.ML
2023-05-17 12:45:14+00:00,Long Memory of Max-Stable Time Series as Phase Transition: Asymptotic Behaviour of Tail Dependence Estimators,"['Marco Oesting', 'Albert Rapp']","In this paper, we consider a simple estimator for tail dependence
coefficients of a max-stable time series and show its asymptotic normality
under a mild condition. The novelty of our result is that this condition does
not involve mixing properties that are common in the literature. More
importantly, our condition is linked to the transition between long and short
range dependence (LRD/SRD) for max-stable time series. This is based on a
recently proposed notion of LRD in the sense of indicators of excursion sets
which is meaningfully defined for infinite-variance time series. In particular,
we show that asymptotic normality with standard rate of convergence and a
function of the sum of tail coefficients as asymptotic variance holds if and
only if the max-stable time series is SRD.",http://arxiv.org/pdf/2305.10168v1,math.ST
2023-05-17 06:25:22+00:00,Time Series Clustering With Random Convolutional Kernels,"['Jorge Marco-Blanco', 'Rubén Cuevas']","Time series data, spanning applications ranging from climatology to finance
to healthcare, presents significant challenges in data mining due to its size
and complexity. One open issue lies in time series clustering, which is crucial
for processing large volumes of unlabeled time series data and unlocking
valuable insights. Traditional and modern analysis methods, however, often
struggle with these complexities. To address these limitations, we introduce
R-Clustering, a novel method that utilizes convolutional architectures with
randomly selected parameters. Through extensive evaluations, R-Clustering
demonstrates superior performance over existing methods in terms of clustering
accuracy, computational efficiency and scalability. Empirical results obtained
using the UCR archive demonstrate the effectiveness of our approach across
diverse time series datasets. The findings highlight the significance of
R-Clustering in various domains and applications, contributing to the
advancement of time series data mining.",http://arxiv.org/pdf/2305.10457v2,cs.LG
2023-05-16 08:48:36+00:00,A Dictionary-based approach to Time Series Ordinal Classification,"['Rafael Ayllón-Gavilán', 'David Guijo-Rubio', 'Pedro Antonio Gutiérrez', 'César Hervás-Martinez']","Time Series Classification (TSC) is an extensively researched field from
which a broad range of real-world problems can be addressed obtaining excellent
results. One sort of the approaches performing well are the so-called
dictionary-based techniques. The Temporal Dictionary Ensemble (TDE) is the
current state-of-the-art dictionary-based TSC approach. In many TSC problems we
find a natural ordering in the labels associated with the time series. This
characteristic is referred to as ordinality, and can be exploited to improve
the methods performance. The area dealing with ordinal time series is the Time
Series Ordinal Classification (TSOC) field, which is yet unexplored. In this
work, we present an ordinal adaptation of the TDE algorithm, known as ordinal
TDE (O-TDE). For this, a comprehensive comparison using a set of 18 TSOC
problems is performed. Experiments conducted show the improvement achieved by
the ordinal dictionary-based approach in comparison to four other existing
nominal dictionary-based techniques.",http://arxiv.org/pdf/2305.09288v1,cs.LG
2023-05-16 07:00:57+00:00,pTSE: A Multi-model Ensemble Method for Probabilistic Time Series Forecasting,"['Yunyi Zhou', 'Zhixuan Chu', 'Yijia Ruan', 'Ge Jin', 'Yuchen Huang', 'Sheng Li']","Various probabilistic time series forecasting models have sprung up and shown
remarkably good performance. However, the choice of model highly relies on the
characteristics of the input time series and the fixed distribution that the
model is based on. Due to the fact that the probability distributions cannot be
averaged over different models straightforwardly, the current time series model
ensemble methods cannot be directly applied to improve the robustness and
accuracy of forecasting. To address this issue, we propose pTSE, a multi-model
distribution ensemble method for probabilistic forecasting based on Hidden
Markov Model (HMM). pTSE only takes off-the-shelf outputs from member models
without requiring further information about each model. Besides, we provide a
complete theoretical analysis of pTSE to prove that the empirical distribution
of time series subject to an HMM will converge to the stationary distribution
almost surely. Experiments on benchmarks show the superiority of pTSE overall
member models and competitive ensemble methods.",http://arxiv.org/pdf/2305.11304v2,cs.LG
2023-05-15 23:55:49+00:00,Evaluation Strategy of Time-series Anomaly Detection with Decay Function,"['Yongwan Gim', 'Kyushik Min']","Recent algorithms of time-series anomaly detection have been evaluated by
applying a Point Adjustment (PA) protocol. However, the PA protocol has a
problem of overestimating the performance of the detection algorithms because
it only depends on the number of detected abnormal segments and their size. We
propose a novel evaluation protocol called the Point-Adjusted protocol with
decay function (PAdf) to evaluate the time-series anomaly detection algorithm
by reflecting the following ideal requirements: detect anomalies quickly and
accurately without false alarms. This paper theoretically and experimentally
shows that the PAdf protocol solves the over- and under-estimation problems of
existing protocols such as PA and PA\%K. By conducting re-evaluations of SOTA
models in benchmark datasets, we show that the PA protocol only focuses on
finding many anomalous segments, whereas the score of the PAdf protocol
considers not only finding many segments but also detecting anomalies quickly
without delay.",http://arxiv.org/pdf/2305.09691v1,cs.LG
2023-05-15 10:38:24+00:00,Kernel-based Joint Independence Tests for Multivariate Stationary and Non-stationary Time Series,"['Zhaolu Liu', 'Robert L. Peach', 'Felix Laumann', 'Sara Vallejo Mengod', 'Mauricio Barahona']","Multivariate time series data that capture the temporal evolution of
interconnected systems are ubiquitous in diverse areas. Understanding the
complex relationships and potential dependencies among co-observed variables is
crucial for the accurate statistical modelling and analysis of such systems.
Here, we introduce kernel-based statistical tests of joint independence in
multivariate time series by extending the $d$-variable Hilbert-Schmidt
independence criterion (dHSIC) to encompass both stationary and non-stationary
processes, thus allowing broader real-world applications. By leveraging
resampling techniques tailored for both single- and multiple-realisation time
series, we show how the method robustly uncovers significant higher-order
dependencies in synthetic examples, including frequency mixing data and logic
gates, as well as real-world climate, neuroscience, and socioeconomic data. Our
method adds to the mathematical toolbox for the analysis of multivariate time
series and can aid in uncovering high-order interactions in data.",http://arxiv.org/pdf/2305.08529v3,stat.ME
2023-05-15 10:31:47+00:00,Differential Convolutional Fuzzy Time Series Forecasting,"['Tianxiang Zhan', 'Yuanpeng He', 'Yong Deng', 'Zhen Li']","Fuzzy time series forecasting (FTSF) is a typical forecasting method with
wide application. Traditional FTSF is regarded as an expert system which leads
to loss of the ability to recognize undefined features. The mentioned is the
main reason for poor forecasting with FTSF. To solve the problem, the proposed
model Differential Fuzzy Convolutional Neural Network (DFCNN) utilizes a
convolution neural network to re-implement FTSF with learnable ability. DFCNN
is capable of recognizing potential information and improving forecasting
accuracy. Thanks to the learnable ability of the neural network, the length of
fuzzy rules established in FTSF is expended to an arbitrary length that the
expert is not able to handle by the expert system. At the same time, FTSF
usually cannot achieve satisfactory performance of non-stationary time series
due to the trend of non-stationary time series. The trend of non-stationary
time series causes the fuzzy set established by FTSF to be invalid and causes
the forecasting to fail. DFCNN utilizes the Difference algorithm to weaken the
non-stationary of time series so that DFCNN can forecast the non-stationary
time series with a low error that FTSF cannot forecast in satisfactory
performance. After the mass of experiments, DFCNN has an excellent prediction
effect, which is ahead of the existing FTSF and common time series forecasting
algorithms. Finally, DFCNN provides further ideas for improving FTSF and holds
continued research value.",http://arxiv.org/pdf/2305.08890v2,cs.LG
2023-05-14 14:21:58+00:00,Latent Processes Identification From Multi-View Time Series,"['Zenan Huang', 'Haobo Wang', 'Junbo Zhao', 'Nenggan Zheng']","Understanding the dynamics of time series data typically requires identifying
the unique latent factors for data generation, \textit{a.k.a.}, latent
processes identification. Driven by the independent assumption, existing works
have made great progress in handling single-view data. However, it is a
non-trivial problem that extends them to multi-view time series data because of
two main challenges: (i) the complex data structure, such as temporal
dependency, can result in violation of the independent assumption; (ii) the
factors from different views are generally overlapped and are hard to be
aggregated to a complete set. In this work, we propose a novel framework MuLTI
that employs the contrastive learning technique to invert the data generative
process for enhanced identifiability. Additionally, MuLTI integrates a
permutation mechanism that merges corresponding overlapped variables by the
establishment of an optimal transport formula. Extensive experimental results
on synthetic and real-world datasets demonstrate the superiority of our method
in recovering identifiable latent variables on multi-view time series.",http://arxiv.org/pdf/2305.08164v1,cs.LG
2023-05-14 12:20:13+00:00,Predicting Unplanned Readmissions in the Intensive Care Unit: A Multimodality Evaluation,"['Eitam Sheetrit', 'Menachem Brief', 'Oren Elisha']","A hospital readmission is when a patient who was discharged from the hospital
is admitted again for the same or related care within a certain period.
Hospital readmissions are a significant problem in the healthcare domain, as
they lead to increased hospitalization costs, decreased patient satisfaction,
and increased risk of adverse outcomes such as infections, medication errors,
and even death. The problem of hospital readmissions is particularly acute in
intensive care units (ICUs), due to the severity of the patients' conditions,
and the substantial risk of complications. Predicting Unplanned Readmissions in
ICUs is a challenging task, as it involves analyzing different data modalities,
such as static data, unstructured free text, sequences of diagnoses and
procedures, and multivariate time-series. Here, we investigate the
effectiveness of each data modality separately, then alongside with others,
using state-of-the-art machine learning approaches in time-series analysis and
natural language processing. Using our evaluation process, we are able to
determine the contribution of each data modality, and for the first time in the
context of readmission, establish a hierarchy of their predictive value.
Additionally, we demonstrate the impact of Temporal Abstractions in enhancing
the performance of time-series approaches to readmission prediction. Due to
conflicting definitions in the literature, we also provide a clear definition
of the term Unplanned Readmission to enhance reproducibility and consistency of
future research and to prevent any potential misunderstandings that could
result from diverse interpretations of the term. Our experimental results on a
large benchmark clinical data set show that Discharge Notes written by
physicians, have better capabilities for readmission prediction than all other
modalities.",http://arxiv.org/pdf/2305.08139v1,cs.LG
2023-05-12 16:15:41+00:00,Nonparametric data segmentation in multivariate time series via joint characteristic functions,"['Euan T. McGonigle', 'Haeran Cho']","Modern time series data often exhibit complex dependence and structural
changes which are not easily characterised by shifts in the mean or model
parameters. We propose a nonparametric data segmentation methodology for
multivariate time series termed NP-MOJO. By considering joint characteristic
functions between the time series and its lagged values, NP-MOJO is able to
detect change points in the marginal distribution, but also those in possibly
non-linear serial dependence, all without the need to pre-specify the type of
changes. We show the theoretical consistency of NP-MOJO in estimating the total
number and the locations of the change points, and demonstrate the good
performance of NP-MOJO against a variety of change point scenarios. We further
demonstrate its usefulness in applications to seismology and economic time
series.",http://arxiv.org/pdf/2305.07581v2,stat.ME
2023-05-12 04:39:01+00:00,Provably Convergent Schrödinger Bridge with Applications to Probabilistic Time Series Imputation,"['Yu Chen', 'Wei Deng', 'Shikai Fang', 'Fengpei Li', 'Nicole Tianjiao Yang', 'Yikai Zhang', 'Kashif Rasul', 'Shandian Zhe', 'Anderson Schneider', 'Yuriy Nevmyvaka']","The Schr\""odinger bridge problem (SBP) is gaining increasing attention in
generative modeling and showing promising potential even in comparison with the
score-based generative models (SGMs). SBP can be interpreted as an
entropy-regularized optimal transport problem, which conducts projections onto
every other marginal alternatingly. However, in practice, only approximated
projections are accessible and their convergence is not well understood. To
fill this gap, we present a first convergence analysis of the Schr\""odinger
bridge algorithm based on approximated projections. As for its practical
applications, we apply SBP to probabilistic time series imputation by
generating missing values conditioned on observed data. We show that optimizing
the transport cost improves the performance and the proposed algorithm achieves
the state-of-the-art result in healthcare and environmental data while
exhibiting the advantage of exploring both temporal and feature patterns in
probabilistic time series imputation.",http://arxiv.org/pdf/2305.07247v4,cs.LG
2023-05-11 14:20:23+00:00,A Generic Approach to Integrating Time into Spatial-Temporal Forecasting via Conditional Neural Fields,"['Minh-Thanh Bui', 'Duc-Thinh Ngo', 'Demin Lu', 'Zonghua Zhang']","Self-awareness is the key capability of autonomous systems, e.g., autonomous
driving network, which relies on highly efficient time series forecasting
algorithm to enable the system to reason about the future state of the
environment, as well as its effect on the system behavior as time progresses.
Recently, a large number of forecasting algorithms using either convolutional
neural networks or graph neural networks have been developed to exploit the
complex temporal and spatial dependencies present in the time series. While
these solutions have shown significant advantages over statistical approaches,
one open question is to effectively incorporate the global information which
represents the seasonality patterns via the time component of time series into
the forecasting models to improve their accuracy. This paper presents a general
approach to integrating the time component into forecasting models. The main
idea is to employ conditional neural fields to represent the auxiliary features
extracted from the time component to obtain the global information, which will
be effectively combined with the local information extracted from
autoregressive neural networks through a layer-wise gated fusion module.
Extensive experiments on road traffic and cellular network traffic datasets
prove the effectiveness of the proposed approach.",http://arxiv.org/pdf/2305.06827v2,cs.LG
2023-05-11 11:53:31+00:00,IVP-VAE: Modeling EHR Time Series with Initial Value Problem Solvers,"['Jingge Xiao', 'Leonie Basso', 'Wolfgang Nejdl', 'Niloy Ganguly', 'Sandipan Sikdar']","Continuous-time models such as Neural ODEs and Neural Flows have shown
promising results in analyzing irregularly sampled time series frequently
encountered in electronic health records. Based on these models, time series
are typically processed with a hybrid of an initial value problem (IVP) solver
and a recurrent neural network within the variational autoencoder architecture.
Sequentially solving IVPs makes such models computationally less efficient. In
this paper, we propose to model time series purely with continuous processes
whose state evolution can be approximated directly by IVPs. This eliminates the
need for recurrent computation and enables multiple states to evolve in
parallel. We further fuse the encoder and decoder with one IVP solver utilizing
its invertibility, which leads to fewer parameters and faster convergence.
Experiments on three real-world datasets show that the proposed method can
systematically outperform its predecessors, achieve state-of-the-art results,
and have significant advantages in terms of data efficiency.",http://arxiv.org/pdf/2305.06741v2,cs.LG
2023-05-11 10:30:35+00:00,Robust Detection of Lead-Lag Relationships in Lagged Multi-Factor Models,"['Yichi Zhang', 'Mihai Cucuringu', 'Alexander Y. Shestopaloff', 'Stefan Zohren']","In multivariate time series systems, key insights can be obtained by
discovering lead-lag relationships inherent in the data, which refer to the
dependence between two time series shifted in time relative to one another, and
which can be leveraged for the purposes of control, forecasting or clustering.
We develop a clustering-driven methodology for robust detection of lead-lag
relationships in lagged multi-factor models. Within our framework, the
envisioned pipeline takes as input a set of time series, and creates an
enlarged universe of extracted subsequence time series from each input time
series, via a sliding window approach. This is then followed by an application
of various clustering techniques, (such as k-means++ and spectral clustering),
employing a variety of pairwise similarity measures, including nonlinear ones.
Once the clusters have been extracted, lead-lag estimates across clusters are
robustly aggregated to enhance the identification of the consistent
relationships in the original universe. We establish connections to the
multireference alignment problem for both the homogeneous and heterogeneous
settings. Since multivariate time series are ubiquitous in a wide range of
domains, we demonstrate that our method is not only able to robustly detect
lead-lag relationships in financial markets, but can also yield insightful
results when applied to an environmental data set.",http://arxiv.org/pdf/2305.06704v3,stat.ML
2023-05-09 10:32:36+00:00,Point and probabilistic forecast reconciliation for general linearly constrained multiple time series,"['Daniele Girolimetto', 'Tommaso Di Fonzo']","Forecast reconciliation is the post-forecasting process aimed to revise a set
of incoherent base forecasts into coherent forecasts in line with given data
structures. Most of the point and probabilistic regression-based forecast
reconciliation results ground on the so called ""structural representation"" and
on the related unconstrained generalized least squares reconciliation formula.
However, the structural representation naturally applies to genuine
hierarchical/grouped time series, where the top- and bottom-level variables are
uniquely identified. When a general linearly constrained multiple time series
is considered, the forecast reconciliation is naturally expressed according to
a projection approach. While it is well known that the classic structural
reconciliation formula is equivalent to its projection approach counterpart, so
far it is not completely understood if and how a structural-like reconciliation
formula may be derived for a general linearly constrained multiple time series.
Such an expression would permit to extend reconciliation definitions, theorems
and results in a straightforward manner. In this paper, we show that for
general linearly constrained multiple time series it is possible to express the
reconciliation formula according to a ""structural-like"" approach that keeps
distinct free and constrained, instead of bottom and upper (aggregated),
variables, establish the probabilistic forecast reconciliation framework, and
apply these findings to obtain fully reconciled point and probabilistic
forecasts for the aggregates of the Australian GDP from income and expenditure
sides, and for the European Area GDP disaggregated by income, expenditure and
output sides and by 19 countries.",http://arxiv.org/pdf/2305.05330v1,stat.ME
2023-05-09 08:58:02+00:00,Causal Discovery from Subsampled Time Series with Proxy Variables,"['Mingzhou Liu', 'Xinwei Sun', 'Lingjing Hu', 'Yizhou Wang']","Inferring causal structures from time series data is the central interest of
many scientific inquiries. A major barrier to such inference is the problem of
subsampling, i.e., the frequency of measurement is much lower than that of
causal influence. To overcome this problem, numerous methods have been
proposed, yet either was limited to the linear case or failed to achieve
identifiability. In this paper, we propose a constraint-based algorithm that
can identify the entire causal structure from subsampled time series, without
any parametric constraint. Our observation is that the challenge of subsampling
arises mainly from hidden variables at the unobserved time steps. Meanwhile,
every hidden variable has an observed proxy, which is essentially itself at
some observable time in the future, benefiting from the temporal structure.
Based on these, we can leverage the proxies to remove the bias induced by the
hidden variables and hence achieve identifiability. Following this intuition,
we propose a proxy-based causal discovery algorithm. Our algorithm is
nonparametric and can achieve full causal identification. Theoretical
advantages are reflected in synthetic and real-world experiments.",http://arxiv.org/pdf/2305.05276v4,cs.LG
2023-05-08 17:20:13+00:00,Explainable Parallel RCNN with Novel Feature Representation for Time Series Forecasting,"['Jimeng Shi', 'Rukmangadh Myana', 'Vitalii Stebliankin', 'Azam Shirali', 'Giri Narasimhan']","Accurate time series forecasting is a fundamental challenge in data science.
It is often affected by external covariates such as weather or human
intervention, which in many applications, may be predicted with reasonable
accuracy. We refer to them as predicted future covariates. However, existing
methods that attempt to predict time series in an iterative manner with
autoregressive models end up with exponential error accumulations. Other
strategies hat consider the past and future in the encoder and decoder
respectively limit themselves by dealing with the historical and future data
separately. To address these limitations, a novel feature representation
strategy -- shifting -- is proposed to fuse the past data and future covariates
such that their interactions can be considered. To extract complex dynamics in
time series, we develop a parallel deep learning framework composed of RNN and
CNN, both of which are used hierarchically. We also utilize the skip connection
technique to improve the model's performance. Extensive experiments on three
datasets reveal the effectiveness of our method. Finally, we demonstrate the
model interpretability using the Grad-CAM algorithm.",http://arxiv.org/pdf/2305.04876v3,cs.LG
2023-05-08 15:54:18+00:00,Mlinear: Rethink the Linear Model for Time-series Forecasting,"['Wei Li', 'Xiangxu Meng', 'Chuhao Chen', 'Jianing Chen']","Recently, significant advancements have been made in time-series forecasting
research, with an increasing focus on analyzing the nature of time-series data,
e.g, channel-independence (CI) and channel-dependence (CD), rather than solely
focusing on designing sophisticated forecasting models. However, current
research has primarily focused on either CI or CD in isolation, and the
challenge of effectively combining these two opposing properties to achieve a
synergistic effect remains an unresolved issue. In this paper, we carefully
examine the opposing properties of CI and CD, and raise a practical question
that has not been effectively answered, e.g.,""How to effectively mix the CI and
CD properties of time series to achieve better predictive performance?"" To
answer this question, we propose Mlinear (MIX-Linear), a simple yet effective
method based mainly on linear layers. The design philosophy of Mlinear mainly
includes two aspects:(1) dynamically tuning the CI and CD properties based on
the time semantics of different input time series, and (2) providing deep
supervision to adjust the individual performance of the ""CI predictor"" and ""CD
predictor"". In addition, empirically, we introduce a new loss function that
significantly outperforms the widely used mean squared error (MSE) on multiple
datasets. Experiments on time-series datasets covering multiple fields and
widely used have demonstrated the superiority of our method over PatchTST which
is the lateset Transformer-based method in terms of the MSE and MAE metrics on
7 datasets with identical sequence inputs (336 or 512). Specifically, our
method significantly outperforms PatchTST with a ratio of 21:3 at 336 sequence
length input and 29:10 at 512 sequence length input. Additionally, our approach
has a 10 $\times$ efficiency advantage at the unit level, taking into account
both training and inference times.",http://arxiv.org/pdf/2305.04800v2,cs.LG
2023-05-08 08:30:05+00:00,Exploring a Gradient-based Explainable AI Technique for Time-Series Data: A Case Study of Assessing Stroke Rehabilitation Exercises,"['Min Hun Lee', 'Yi Jing Choy']","Explainable artificial intelligence (AI) techniques are increasingly being
explored to provide insights into why AI and machine learning (ML) models
provide a certain outcome in various applications. However, there has been
limited exploration of explainable AI techniques on time-series data,
especially in the healthcare context. In this paper, we describe a
threshold-based method that utilizes a weakly supervised model and a
gradient-based explainable AI technique (i.e. saliency map) and explore its
feasibility to identify salient frames of time-series data. Using the dataset
from 15 post-stroke survivors performing three upper-limb exercises and labels
on whether a compensatory motion is observed or not, we implemented a
feed-forward neural network model and utilized gradients of each input on model
outcomes to identify salient frames that involve compensatory motions.
According to the evaluation using frame-level annotations, our approach
achieved a recall of 0.96 and an F2-score of 0.91. Our results demonstrated the
potential of a gradient-based explainable AI technique (e.g. saliency map) for
time-series data, such as highlighting the frames of a video that therapists
should focus on reviewing and reducing the efforts on frame-level labeling for
model training.",http://arxiv.org/pdf/2305.05525v1,cs.LG
2023-05-08 05:42:24+00:00,AnomalyBERT: Self-Supervised Transformer for Time Series Anomaly Detection using Data Degradation Scheme,"['Yungi Jeong', 'Eunseok Yang', 'Jung Hyun Ryu', 'Imseong Park', 'Myungjoo Kang']","Mechanical defects in real situations affect observation values and cause
abnormalities in multivariate time series, such as sensor values or network
data. To perceive abnormalities in such data, it is crucial to understand the
temporal context and interrelation between variables simultaneously. The
anomaly detection task for time series, especially for unlabeled data, has been
a challenging problem, and we address it by applying a suitable data
degradation scheme to self-supervised model training. We define four types of
synthetic outliers and propose the degradation scheme in which a portion of
input data is replaced with one of the synthetic outliers. Inspired by the
self-attention mechanism, we design a Transformer-based architecture to
recognize the temporal context and detect unnatural sequences with high
efficiency. Our model converts multivariate data points into temporal
representations with relative position bias and yields anomaly scores from
these representations. Our method, AnomalyBERT, shows a great capability of
detecting anomalies contained in complex time series and surpasses previous
state-of-the-art methods on five real-world benchmarks. Our code is available
at https://github.com/Jhryu30/AnomalyBERT.",http://arxiv.org/pdf/2305.04468v1,cs.LG
2023-05-02 13:58:20+00:00,Unsupervised Feature Based Algorithms for Time Series Extrinsic Regression,"['David Guijo-Rubio', 'Matthew Middlehurst', 'Guilherme Arcencio', 'Diego Furtado Silva', 'Anthony Bagnall']","Time Series Extrinsic Regression (TSER) involves using a set of training time
series to form a predictive model of a continuous response variable that is not
directly related to the regressor series. The TSER archive for comparing
algorithms was released in 2022 with 19 problems. We increase the size of this
archive to 63 problems and reproduce the previous comparison of baseline
algorithms. We then extend the comparison to include a wider range of standard
regressors and the latest versions of TSER models used in the previous study.
We show that none of the previously evaluated regressors can outperform a
regression adaptation of a standard classifier, rotation forest. We introduce
two new TSER algorithms developed from related work in time series
classification. FreshPRINCE is a pipeline estimator consisting of a transform
into a wide range of summary features followed by a rotation forest regressor.
DrCIF is a tree ensemble that creates features from summary statistics over
random intervals. Our study demonstrates that both algorithms, along with
InceptionTime, exhibit significantly better performance compared to the other
18 regressors tested. More importantly, these two proposals (DrCIF and
FreshPRINCE) models are the only ones that significantly outperform the
standard rotation forest regressor.",http://arxiv.org/pdf/2305.01429v1,cs.LG
2023-05-01 02:06:46+00:00,Diffusion Models for Time Series Applications: A Survey,"['Lequan Lin', 'Zhengkun Li', 'Ruikun Li', 'Xuliang Li', 'Junbin Gao']","Diffusion models, a family of generative models based on deep learning, have
become increasingly prominent in cutting-edge machine learning research. With a
distinguished performance in generating samples that resemble the observed
data, diffusion models are widely used in image, video, and text synthesis
nowadays. In recent years, the concept of diffusion has been extended to time
series applications, and many powerful models have been developed. Considering
the deficiency of a methodical summary and discourse on these models, we
provide this survey as an elementary resource for new researchers in this area
and also an inspiration to motivate future research. For better understanding,
we include an introduction about the basics of diffusion models. Except for
this, we primarily focus on diffusion-based methods for time series
forecasting, imputation, and generation, and present them respectively in three
individual sections. We also compare different methods for the same application
and highlight their connections if applicable. Lastly, we conclude the common
limitation of diffusion-based methods and highlight potential future research
directions.",http://arxiv.org/pdf/2305.00624v1,cs.LG
2023-04-30 22:38:06+00:00,Impact of Deep Learning Libraries on Online Adaptive Lightweight Time Series Anomaly Detection,"['Ming-Chang Lee', 'Jia-Chun Lin']","Providing online adaptive lightweight time series anomaly detection without
human intervention and domain knowledge is highly valuable. Several such
anomaly detection approaches have been introduced in the past years, but all of
them were only implemented in one deep learning library. With the development
of deep learning libraries, it is unclear how different deep learning libraries
impact these anomaly detection approaches since there is no such evaluation
available. Randomly choosing a deep learning library to implement an anomaly
detection approach might not be able to show the true performance of the
approach. It might also mislead users in believing one approach is better than
another. Therefore, in this paper, we investigate the impact of deep learning
libraries on online adaptive lightweight time series anomaly detection by
implementing two state-of-the-art anomaly detection approaches in three
well-known deep learning libraries and evaluating how these two approaches are
individually affected by the three deep learning libraries. A series of
experiments based on four real-world open-source time series datasets were
conducted. The results provide a good reference to select an appropriate deep
learning library for online adaptive lightweight anomaly detection.",http://arxiv.org/pdf/2305.00595v2,cs.LG
2023-04-30 13:12:19+00:00,Time series clustering based on prediction accuracy of global forecasting models,"['Ángel López Oriona', 'Pablo Montero Manso', 'José Antonio Vilar Fernández']","In this paper, a novel method to perform model-based clustering of time
series is proposed. The procedure relies on two iterative steps: (i) K global
forecasting models are fitted via pooling by considering the series pertaining
to each cluster and (ii) each series is assigned to the group associated with
the model producing the best forecasts according to a particular criterion.
Unlike most techniques proposed in the literature, the method considers the
predictive accuracy as the main element for constructing the clustering
partition, which contains groups jointly minimizing the overall forecasting
error. Thus, the approach leads to a new clustering paradigm where the quality
of the clustering solution is measured in terms of its predictive capability.
In addition, the procedure gives rise to an effective mechanism for selecting
the number of clusters in a time series database and can be used in combination
with any class of regression model. An extensive simulation study shows that
our method outperforms several alternative techniques concerning both
clustering effectiveness and predictive accuracy. The approach is also applied
to perform clustering in several datasets used as standard benchmarks in the
time series literature, obtaining great results.",http://arxiv.org/pdf/2305.00473v1,stat.ML
2023-04-29 12:06:57+00:00,Industry Classification Using a Novel Financial Time-Series Case Representation,"['Rian Dolphin', 'Barry Smyth', 'Ruihai Dong']","The financial domain has proven to be a fertile source of challenging machine
learning problems across a variety of tasks including prediction, clustering,
and classification. Researchers can access an abundance of time-series data and
even modest performance improvements can be translated into significant
additional value. In this work, we consider the use of case-based reasoning for
an important task in this domain, by using historical stock returns time-series
data for industry sector classification. We discuss why time-series data can
present some significant representational challenges for conventional
case-based reasoning approaches, and in response, we propose a novel
representation based on stock returns embeddings, which can be readily
calculated from raw stock returns data. We argue that this representation is
well suited to case-based reasoning and evaluate our approach using a
large-scale public dataset for the industry sector classification task,
demonstrating substantial performance improvements over several baselines using
more conventional representations.",http://arxiv.org/pdf/2305.00245v1,cs.LG
2023-04-25 20:17:42+00:00,Directed Chain Generative Adversarial Networks,"['Ming Min', 'Ruimeng Hu', 'Tomoyuki Ichiba']","Real-world data can be multimodal distributed, e.g., data describing the
opinion divergence in a community, the interspike interval distribution of
neurons, and the oscillators natural frequencies. Generating multimodal
distributed real-world data has become a challenge to existing generative
adversarial networks (GANs). For example, neural stochastic differential
equations (Neural SDEs), treated as infinite-dimensional GANs, have
demonstrated successful performance mainly in generating unimodal time series
data. In this paper, we propose a novel time series generator, named directed
chain GANs (DC-GANs), which inserts a time series dataset (called a
neighborhood process of the directed chain or input) into the drift and
diffusion coefficients of the directed chain SDEs with distributional
constraints. DC-GANs can generate new time series of the same distribution as
the neighborhood process, and the neighborhood process will provide the key
step in learning and generating multimodal distributed time series. The
proposed DC-GANs are examined on four datasets, including two stochastic models
from social sciences and computational neuroscience, and two real-world
datasets on stock prices and energy consumption. To our best knowledge, DC-GANs
are the first work that can generate multimodal time series data and
consistently outperforms state-of-the-art benchmarks with respect to measures
of distribution, data similarity, and predictive ability.",http://arxiv.org/pdf/2304.13131v2,cs.LG
2023-04-25 17:59:28+00:00,Bake off redux: a review and experimental evaluation of recent time series classification algorithms,"['Matthew Middlehurst', 'Patrick Schäfer', 'Anthony Bagnall']","In 2017, a research paper compared 18 Time Series Classification (TSC)
algorithms on 85 datasets from the University of California, Riverside (UCR)
archive. This study, commonly referred to as a `bake off', identified that only
nine algorithms performed significantly better than the Dynamic Time Warping
(DTW) and Rotation Forest benchmarks that were used. The study categorised each
algorithm by the type of feature they extract from time series data, forming a
taxonomy of five main algorithm types. This categorisation of algorithms
alongside the provision of code and accessible results for reproducibility has
helped fuel an increase in popularity of the TSC field. Over six years have
passed since this bake off, the UCR archive has expanded to 112 datasets and
there have been a large number of new algorithms proposed. We revisit the bake
off, seeing how each of the proposed categories have advanced since the
original publication, and evaluate the performance of newer algorithms against
the previous best-of-category using an expanded UCR archive. We extend the
taxonomy to include three new categories to reflect recent developments.
Alongside the originally proposed distance, interval, shapelet, dictionary and
hybrid based algorithms, we compare newer convolution and feature based
algorithms as well as deep learning approaches. We introduce 30 classification
datasets either recently donated to the archive or reformatted to the TSC
format, and use these to further evaluate the best performing algorithm from
each category. Overall, we find that two recently proposed algorithms,
Hydra+MultiROCKET and HIVE-COTEv2, perform significantly better than other
approaches on both the current and new TSC problems.",http://arxiv.org/pdf/2304.13029v1,cs.LG
2023-04-25 17:47:48+00:00,DuETT: Dual Event Time Transformer for Electronic Health Records,"['Alex Labach', 'Aslesha Pokhrel', 'Xiao Shi Huang', 'Saba Zuberi', 'Seung Eun Yi', 'Maksims Volkovs', 'Tomi Poutanen', 'Rahul G. Krishnan']","Electronic health records (EHRs) recorded in hospital settings typically
contain a wide range of numeric time series data that is characterized by high
sparsity and irregular observations. Effective modelling for such data must
exploit its time series nature, the semantic relationship between different
types of observations, and information in the sparsity structure of the data.
Self-supervised Transformers have shown outstanding performance in a variety of
structured tasks in NLP and computer vision. But multivariate time series data
contains structured relationships over two dimensions: time and recorded event
type, and straightforward applications of Transformers to time series data do
not leverage this distinct structure. The quadratic scaling of self-attention
layers can also significantly limit the input sequence length without
appropriate input engineering. We introduce the DuETT architecture, an
extension of Transformers designed to attend over both time and event type
dimensions, yielding robust representations from EHR data. DuETT uses an
aggregated input where sparse time series are transformed into a regular
sequence with fixed length; this lowers the computational complexity relative
to previous EHR Transformer models and, more importantly, enables the use of
larger and deeper neural networks. When trained with self-supervised prediction
tasks, that provide rich and informative signals for model pre-training, our
model outperforms state-of-the-art deep learning models on multiple downstream
tasks from the MIMIC-IV and PhysioNet-2012 EHR datasets.",http://arxiv.org/pdf/2304.13017v2,cs.LG
2023-04-24 16:40:27+00:00,Ordinal time series analysis with the R package otsfeatures,"['Ángel López Oriona', 'José Antonio Vilar Fernández']","The 21st century has witnessed a growing interest in the analysis of time
series data. Whereas most of the literature on the topic deals with real-valued
time series, ordinal time series have typically received much less attention.
However, the development of specific analytical tools for the latter objects
has substantially increased in recent years. The R package otsfeatures attempts
to provide a set of simple functions for analyzing ordinal time series. In
particular, several commands allowing the extraction of well-known statistical
features and the execution of inferential tasks are available for the user. The
output of several functions can be employed to perform traditional machine
learning tasks including clustering, classification or outlier detection.
otsfeatures also incorporates two datasets of financial time series which were
used in the literature for clustering purposes, as well as three interesting
synthetic databases. The main properties of the package are described and its
use is illustrated through several examples. Researchers from a broad variety
of disciplines could benefit from the powerful tools provided by otsfeatures.",http://arxiv.org/pdf/2304.12251v1,stat.ML
2023-04-24 16:39:22+00:00,Fuzzy clustering of ordinal time series based on two novel distances with economic applications,"['Ángel López Oriona', 'Christian Weiss', 'José Antonio Vilar']","Time series clustering is a central machine learning task with applications
in many fields. While the majority of the methods focus on real-valued time
series, very few works consider series with discrete response. In this paper,
the problem of clustering ordinal time series is addressed. To this aim, two
novel distances between ordinal time series are introduced and used to
construct fuzzy clustering procedures. Both metrics are functions of the
estimated cumulative probabilities, thus automatically taking advantage of the
ordering inherent to the series' range. The resulting clustering algorithms are
computationally efficient and able to group series generated from similar
stochastic processes, reaching accurate results even though the series come
from a wide variety of models. Since the dynamic of the series may vary over
the time, we adopt a fuzzy approach, thus enabling the procedures to locate
each series into several clusters with different membership degrees. An
extensive simulation study shows that the proposed methods outperform several
alternative procedures. Weighted versions of the clustering algorithms are also
presented and their advantages with respect to the original methods are
discussed. Two specific applications involving economic time series illustrate
the usefulness of the proposed approaches.",http://arxiv.org/pdf/2304.12249v1,stat.ML
2023-04-24 16:16:56+00:00,Analyzing categorical time series with the R package ctsfeatures,"['Ángel López Oriona', 'José Antonio Vilar Fernández']","Time series data are ubiquitous nowadays. Whereas most of the literature on
the topic deals with real-valued time series, categorical time series have
received much less attention. However, the development of data mining
techniques for this kind of data has substantially increased in recent years.
The R package ctsfeatures offers users a set of useful tools for analyzing
categorical time series. In particular, several functions allowing the
extraction of well-known statistical features and the construction of
illustrative graphs describing underlying temporal patterns are provided in the
package. The output of some functions can be employed to perform traditional
machine learning tasks including clustering, classification and outlier
detection. The package also includes two datasets of biological sequences
introduced in the literature for clustering purposes, as well as three
interesting synthetic databases. In this work, the main characteristics of the
package are described and its use is illustrated through various examples.
Practitioners from a wide variety of fields could benefit from the valuable
tools provided by ctsfeatures.",http://arxiv.org/pdf/2304.12332v1,stat.ML
2023-04-23 07:17:45+00:00,Identifying Stochasticity in Time-Series with Autoencoder-Based Content-aware 2D Representation: Application to Black Hole Data,"['Chakka Sai Pradeep', 'Neelam Sinha']","In this work, we report an autoencoder-based 2D representation to classify a
time-series as stochastic or non-stochastic, to understand the underlying
physical process. Content-aware conversion of 1D time-series to 2D
representation, that simultaneously utilizes time- and frequency-domain
characteristics, is proposed. An autoencoder is trained with a loss function to
learn latent space (using both time- and frequency domains) representation,
that is designed to be, time-invariant. Every element of the time-series is
represented as a tuple with two components, one each, from latent space
representation in time- and frequency-domains, forming a binary image. In this
binary image, those tuples that represent the points in the time-series,
together form the ``Latent Space Signature"" (LSS) of the input time-series. The
obtained binary LSS images are fed to a classification network. The
EfficientNetv2-S classifier is trained using 421 synthetic time-series, with
fair representation from both categories. The proposed methodology is evaluated
on publicly available astronomical data which are 12 distinct temporal classes
of time-series pertaining to the black hole GRS 1915 + 105, obtained from RXTE
satellite. Results obtained using the proposed methodology are compared with
existing techniques. Concurrence in labels obtained across the classes,
illustrates the efficacy of the proposed 2D representation using the latent
space co-ordinates. The proposed methodology also outputs the confidence in the
classification label.",http://arxiv.org/pdf/2304.11560v1,cs.LG
2023-04-20 19:20:18+00:00,An Attention Free Conditional Autoencoder For Anomaly Detection in Cryptocurrencies,"['Hugo Inzirillo', 'Ludovic De Villelongue']","It is difficult to identify anomalies in time series, especially when there
is a lot of noise. Denoising techniques can remove the noise but this technique
can cause a significant loss of information. To detect anomalies in the time
series we have proposed an attention free conditional autoencoder (AF-CA). We
started from the autoencoder conditional model on which we added an
Attention-Free LSTM layer \cite{inzirillo2022attention} in order to make the
anomaly detection capacity more reliable and to increase the power of anomaly
detection. We compared the results of our Attention Free Conditional
Autoencoder with those of an LSTM Autoencoder and clearly improved the
explanatory power of the model and therefore the detection of anomaly in noisy
time series.",http://arxiv.org/pdf/2304.10614v1,cs.LG
2023-04-17 16:46:48+00:00,Long-term Forecasting with TiDE: Time-series Dense Encoder,"['Abhimanyu Das', 'Weihao Kong', 'Andrew Leach', 'Shaan Mathur', 'Rajat Sen', 'Rose Yu']","Recent work has shown that simple linear models can outperform several
Transformer based approaches in long term time-series forecasting. Motivated by
this, we propose a Multi-layer Perceptron (MLP) based encoder-decoder model,
Time-series Dense Encoder (TiDE), for long-term time-series forecasting that
enjoys the simplicity and speed of linear models while also being able to
handle covariates and non-linear dependencies. Theoretically, we prove that the
simplest linear analogue of our model can achieve near optimal error rate for
linear dynamical systems (LDS) under some assumptions. Empirically, we show
that our method can match or outperform prior approaches on popular long-term
time-series forecasting benchmarks while being 5-10x faster than the best
Transformer based model.",http://arxiv.org/pdf/2304.08424v3,stat.ML
2023-04-15 02:28:58+00:00,Context-aware Domain Adaptation for Time Series Anomaly Detection,"['Kwei-Herng Lai', 'Lan Wang', 'Huiyuan Chen', 'Kaixiong Zhou', 'Fei Wang', 'Hao Yang', 'Xia Hu']","Time series anomaly detection is a challenging task with a wide range of
real-world applications. Due to label sparsity, training a deep anomaly
detector often relies on unsupervised approaches. Recent efforts have been
devoted to time series domain adaptation to leverage knowledge from similar
domains. However, existing solutions may suffer from negative knowledge
transfer on anomalies due to their diversity and sparsity. Motivated by the
empirical study of context alignment between two domains, we aim to transfer
knowledge between two domains via adaptively sampling context information for
two domains. This is challenging because it requires simultaneously modeling
the complex in-domain temporal dependencies and cross-domain correlations while
exploiting label information from the source domain. To this end, we propose a
framework that combines context sampling and anomaly detection into a joint
learning procedure. We formulate context sampling into the Markov decision
process and exploit deep reinforcement learning to optimize the time series
domain adaptation process via context sampling and design a tailored reward
function to generate domain-invariant features that better align two domains
for anomaly detection. Experiments on three public datasets show promise for
knowledge transfer between two similar domains and two entirely different
domains.",http://arxiv.org/pdf/2304.07453v1,cs.LG
2023-04-14 08:56:31+00:00,Detection and Estimation of Structural Breaks in High-Dimensional Functional Time Series,"['Degui Li', 'Runze Li', 'Han Lin Shang']","In this paper, we consider detecting and estimating breaks in heterogeneous
mean functions of high-dimensional functional time series which are allowed to
be cross-sectionally correlated and temporally dependent. A new test statistic
combining the functional CUSUM statistic and power enhancement component is
proposed with asymptotic null distribution theory comparable to the
conventional CUSUM theory derived for a single functional time series. In
particular, the extra power enhancement component enlarges the region where the
proposed test has power, and results in stable power performance when breaks
are sparse in the alternative hypothesis. Furthermore, we impose a latent group
structure on the subjects with heterogeneous break points and introduce an
easy-to-implement clustering algorithm with an information criterion to
consistently estimate the unknown group number and membership. The estimated
group structure can subsequently improve the convergence property of the
post-clustering break point estimate. Monte-Carlo simulation studies and
empirical applications show that the proposed estimation and testing techniques
have satisfactory performance in finite samples.",http://arxiv.org/pdf/2304.07003v1,stat.ME
2023-04-12 21:48:53+00:00,NP-Free: A Real-Time Normalization-free and Parameter-tuning-free Representation Approach for Open-ended Time Series,"['Ming-Chang Lee', 'Jia-Chun Lin', 'Volker Stolz']","As more connected devices are implemented in a cyber-physical world and data
is expected to be collected and processed in real time, the ability to handle
time series data has become increasingly significant. To help analyze time
series in data mining applications, many time series representation approaches
have been proposed to convert a raw time series into another series for
representing the original time series. However, existing approaches are not
designed for open-ended time series (which is a sequence of data points being
continuously collected at a fixed interval without any length limit) because
these approaches need to know the total length of the target time series in
advance and pre-process the entire time series using normalization methods.
Furthermore, many representation approaches require users to configure and tune
some parameters beforehand in order to achieve satisfactory representation
results. In this paper, we propose NP-Free, a real-time Normalization-free and
Parameter-tuning-free representation approach for open-ended time series.
Without needing to use any normalization method or tune any parameter, NP-Free
can generate a representation for a raw time series on the fly by converting
each data point of the time series into a root-mean-square error (RMSE) value
based on Long Short-Term Memory (LSTM) and a Look-Back and Predict-Forward
strategy. To demonstrate the capability of NP-Free in representing time series,
we conducted several experiments based on real-world open-source time series
datasets. We also evaluated the time consumption of NP-Free in generating
representations.",http://arxiv.org/pdf/2304.06168v1,cs.LG
2023-04-12 18:56:17+00:00,Time-varying STARMA models by wavelets,"['Yangyang Chen', 'Pedro Alberto Morettin', 'Chang Chiann']","The spatio-temporal autoregressive moving average (STARMA) model is
frequently used in several studies of multivariate time series data, where the
assumption of stationarity is important, but it is not always guaranteed in
practice. One way to proceed is to consider locally stationary processes. In
this paper we propose a time-varying spatio-temporal autoregressive and moving
average (tvSTARMA) modelling based on the locally stationarity assumption. The
time-varying parameters are expanded as linear combinations of wavelet bases
and procedures are proposed to estimate the coefficients. Some simulations and
an application to historical daily precipitation records of Midwestern states
of the USA are illustrated.",http://arxiv.org/pdf/2304.06110v1,stat.ME
2023-04-12 12:22:31+00:00,Proximity Forest 2.0: A new effective and scalable similarity-based classifier for time series,"['Matthieu Herrmann', 'Chang Wei Tan', 'Mahsa Salehi', 'Geoffrey I. Webb']","Time series classification (TSC) is a challenging task due to the diversity
of types of feature that may be relevant for different classification tasks,
including trends, variance, frequency, magnitude, and various patterns. To
address this challenge, several alternative classes of approach have been
developed, including similarity-based, features and intervals, shapelets,
dictionary, kernel, neural network, and hybrid approaches. While kernel, neural
network, and hybrid approaches perform well overall, some specialized
approaches are better suited for specific tasks. In this paper, we propose a
new similarity-based classifier, Proximity Forest version 2.0 (PF 2.0), which
outperforms previous state-of-the-art similarity-based classifiers across the
UCR benchmark and outperforms state-of-the-art kernel, neural network, and
hybrid methods on specific datasets in the benchmark that are best addressed by
similarity-base methods. PF 2.0 incorporates three recent advances in time
series similarity measures -- (1) computationally efficient early abandoning
and pruning to speedup elastic similarity computations; (2) a new elastic
similarity measure, Amerced Dynamic Time Warping (ADTW); and (3) cost function
tuning. It rationalizes the set of similarity measures employed, reducing the
eight base measures of the original PF to three and using the first derivative
transform with all similarity measures, rather than a limited subset. We have
implemented both PF 1.0 and PF 2.0 in a single C++ framework, making the PF
framework more efficient.",http://arxiv.org/pdf/2304.05800v2,cs.LG
2023-04-11 13:15:33+00:00,The Capacity and Robustness Trade-off: Revisiting the Channel Independent Strategy for Multivariate Time Series Forecasting,"['Lu Han', 'Han-Jia Ye', 'De-Chuan Zhan']","Multivariate time series data comprises various channels of variables. The
multivariate forecasting models need to capture the relationship between the
channels to accurately predict future values. However, recently, there has been
an emergence of methods that employ the Channel Independent (CI) strategy.
These methods view multivariate time series data as separate univariate time
series and disregard the correlation between channels. Surprisingly, our
empirical results have shown that models trained with the CI strategy
outperform those trained with the Channel Dependent (CD) strategy, usually by a
significant margin. Nevertheless, the reasons behind this phenomenon have not
yet been thoroughly explored in the literature. This paper provides
comprehensive empirical and theoretical analyses of the characteristics of
multivariate time series datasets and the CI/CD strategy. Our results conclude
that the CD approach has higher capacity but often lacks robustness to
accurately predict distributionally drifted time series. In contrast, the CI
approach trades capacity for robust prediction. Practical measures inspired by
these analyses are proposed to address the capacity and robustness dilemma,
including a modified CD method called Predict Residuals with Regularization
(PRReg) that can surpass the CI strategy. We hope our findings can raise
awareness among researchers about the characteristics of multivariate time
series and inspire the construction of better forecasting models.",http://arxiv.org/pdf/2304.05206v1,cs.LG
2023-04-11 09:21:28+00:00,TodyNet: Temporal Dynamic Graph Neural Network for Multivariate Time Series Classification,"['Huaiyuan Liu', 'Xianzhang Liu', 'Donghua Yang', 'Zhiyu Liang', 'Hongzhi Wang', 'Yong Cui', 'Jun Gu']","Multivariate time series classification (MTSC) is an important data mining
task, which can be effectively solved by popular deep learning technology.
Unfortunately, the existing deep learning-based methods neglect the hidden
dependencies in different dimensions and also rarely consider the unique
dynamic features of time series, which lack sufficient feature extraction
capability to obtain satisfactory classification accuracy. To address this
problem, we propose a novel temporal dynamic graph neural network (TodyNet)
that can extract hidden spatio-temporal dependencies without undefined graph
structure. It enables information flow among isolated but implicit
interdependent variables and captures the associations between different time
slots by dynamic graph mechanism, which further improves the classification
performance of the model. Meanwhile, the hierarchical representations of graphs
cannot be learned due to the limitation of GNNs. Thus, we also design a
temporal graph pooling layer to obtain a global graph-level representation for
graph learning with learnable temporal parameters. The dynamic graph, graph
information propagation, and temporal convolution are jointly learned in an
end-to-end framework. The experiments on 26 UEA benchmark datasets illustrate
that the proposed TodyNet outperforms existing deep learning-based methods in
the MTSC tasks.",http://arxiv.org/pdf/2304.05078v1,cs.LG
2023-04-11 00:56:57+00:00,Financial Time Series Forecasting using CNN and Transformer,"['Zhen Zeng', 'Rachneet Kaur', 'Suchetha Siddagangappa', 'Saba Rahimi', 'Tucker Balch', 'Manuela Veloso']","Time series forecasting is important across various domains for
decision-making. In particular, financial time series such as stock prices can
be hard to predict as it is difficult to model short-term and long-term
temporal dependencies between data points. Convolutional Neural Networks (CNN)
are good at capturing local patterns for modeling short-term dependencies.
However, CNNs cannot learn long-term dependencies due to the limited receptive
field. Transformers on the other hand are capable of learning global context
and long-term dependencies. In this paper, we propose to harness the power of
CNNs and Transformers to model both short-term and long-term dependencies
within a time series, and forecast if the price would go up, down or remain the
same (flat) in the future. In our experiments, we demonstrated the success of
the proposed method in comparison to commonly adopted statistical and deep
learning methods on forecasting intraday stock price change of S&P 500
constituents.",http://arxiv.org/pdf/2304.04912v1,cs.LG
2023-04-10 12:47:42+00:00,Two Steps Forward and One Behind: Rethinking Time Series Forecasting with Deep Learning,"['Riccardo Ughi', 'Eugenio Lomurno', 'Matteo Matteucci']","The Transformer is a highly successful deep learning model that has
revolutionised the world of artificial neural networks, first in natural
language processing and later in computer vision. This model is based on the
attention mechanism and is able to capture complex semantic relationships
between a variety of patterns present in the input data. Precisely because of
these characteristics, the Transformer has recently been exploited for time
series forecasting problems, assuming a natural adaptability to the domain of
continuous numerical series. Despite the acclaimed results in the literature,
some works have raised doubts about the robustness and effectiveness of this
approach. In this paper, we further investigate the effectiveness of
Transformer-based models applied to the domain of time series forecasting,
demonstrate their limitations, and propose a set of alternative models that are
better performing and significantly less complex. In particular, we empirically
show how simplifying Transformer-based forecasting models almost always leads
to an improvement, reaching state of the art performance. We also propose
shallow models without the attention mechanism, which compete with the overall
state of the art in long time series forecasting, and demonstrate their ability
to accurately predict time series over extremely long windows. From a
methodological perspective, we show how it is always necessary to use a simple
baseline to verify the effectiveness of proposed models, and finally, we
conclude the paper with a reflection on recent research paths and the
opportunity to follow trends and hypes even where it may not be necessary.",http://arxiv.org/pdf/2304.04553v3,cs.LG
2023-04-09 20:30:10+00:00,Ensemble Modeling for Time Series Forecasting: an Adaptive Robust Optimization Approach,"['Dimitris Bertsimas', 'Leonard Boussioux']","Accurate time series forecasting is critical for a wide range of problems
with temporal data. Ensemble modeling is a well-established technique for
leveraging multiple predictive models to increase accuracy and robustness, as
the performance of a single predictor can be highly variable due to shifts in
the underlying data distribution. This paper proposes a new methodology for
building robust ensembles of time series forecasting models. Our approach
utilizes Adaptive Robust Optimization (ARO) to construct a linear regression
ensemble in which the models' weights can adapt over time. We demonstrate the
effectiveness of our method through a series of synthetic experiments and
real-world applications, including air pollution management, energy consumption
forecasting, and tropical cyclone intensity forecasting. Our results show that
our adaptive ensembles outperform the best ensemble member in hindsight by
16-26% in root mean square error and 14-28% in conditional value at risk and
improve over competitive ensemble techniques.",http://arxiv.org/pdf/2304.04308v1,cs.LG
2023-04-09 16:38:47+00:00,Filling out the missing gaps: Time Series Imputation with Semi-Supervised Learning,"['Karan Aggarwal', 'Jaideep Srivastava']","Missing data in time series is a challenging issue affecting time series
analysis. Missing data occurs due to problems like data drops or sensor
malfunctioning. Imputation methods are used to fill in these values, with
quality of imputation having a significant impact on downstream tasks like
classification. In this work, we propose a semi-supervised imputation method,
ST-Impute, that uses both unlabeled data along with downstream task's labeled
data. ST-Impute is based on sparse self-attention and trains on tasks that
mimic the imputation process. Our results indicate that the proposed method
outperforms the existing supervised and unsupervised time series imputation
methods measured on the imputation quality as well as on the downstream tasks
ingesting imputed time series.",http://arxiv.org/pdf/2304.04275v1,cs.LG
2023-04-09 16:34:06+00:00,Embarrassingly Simple MixUp for Time-series,"['Karan Aggarwal', 'Jaideep Srivastava']","Labeling time series data is an expensive task because of domain expertise
and dynamic nature of the data. Hence, we often have to deal with limited
labeled data settings. Data augmentation techniques have been successfully
deployed in domains like computer vision to exploit the use of existing labeled
data. We adapt one of the most commonly used technique called MixUp, in the
time series domain. Our proposed, MixUp++ and LatentMixUp++, use simple
modifications to perform interpolation in raw time series and classification
model's latent space, respectively. We also extend these methods with
semi-supervised learning to exploit unlabeled data. We observe significant
improvements of 1\% - 15\% on time series classification on two public
datasets, for both low labeled data as well as high labeled data regimes, with
LatentMixUp++.",http://arxiv.org/pdf/2304.04271v1,cs.LG
2023-04-08 00:18:03+00:00,OFTER: An Online Pipeline for Time Series Forecasting,"['Nikolas Michael', 'Mihai Cucuringu', 'Sam Howison']","We introduce OFTER, a time series forecasting pipeline tailored for mid-sized
multivariate time series. OFTER utilizes the non-parametric models of k-nearest
neighbors and Generalized Regression Neural Networks, integrated with a
dimensionality reduction component. To circumvent the curse of dimensionality,
we employ a weighted norm based on a modified version of the maximal
correlation coefficient. The pipeline we introduce is specifically designed for
online tasks, has an interpretable output, and is able to outperform several
state-of-the art baselines. The computational efficacy of the algorithm, its
online nature, and its ability to operate in low signal-to-noise regimes,
render OFTER an ideal approach for financial multivariate time series problems,
such as daily equity forecasting. Our work demonstrates that while deep
learning models hold significant promise for time series forecasting,
traditional methods carefully integrating mainstream tools remain very
competitive alternatives with the added benefits of scalability and
interpretability.",http://arxiv.org/pdf/2304.03877v1,stat.ML
2023-04-06 04:01:00+00:00,SS-shapelets: Semi-supervised Clustering of Time Series Using Representative Shapelets,"['Borui Cai', 'Guangyan Huang', 'Shuiqiao Yang', 'Yong Xiang', 'Chi-Hung Chi']","Shapelets that discriminate time series using local features (subsequences)
are promising for time series clustering. Existing time series clustering
methods may fail to capture representative shapelets because they discover
shapelets from a large pool of uninformative subsequences, and thus result in
low clustering accuracy. This paper proposes a Semi-supervised Clustering of
Time Series Using Representative Shapelets (SS-Shapelets) method, which
utilizes a small number of labeled and propagated pseudo-labeled time series to
help discover representative shapelets, thereby improving the clustering
accuracy. In SS-Shapelets, we propose two techniques to discover representative
shapelets for the effective clustering of time series. 1) A \textit{salient
subsequence chain} ($SSC$) that can extract salient subsequences (as candidate
shapelets) of a labeled/pseudo-labeled time series, which helps remove massive
uninformative subsequences from the pool. 2) A \textit{linear discriminant
selection} ($LDS$) algorithm to identify shapelets that can capture
representative local features of time series in different classes, for
convenient clustering. Experiments on UCR time series datasets demonstrate that
SS-shapelets discovers representative shapelets and achieves higher clustering
accuracy than counterpart semi-supervised time series clustering methods.",http://arxiv.org/pdf/2304.03292v1,cs.LG
2023-04-04 06:29:39+00:00,A nonlinearity and model specification test for functional time series,"['Xin Huang', 'Han Lin Shang', 'Tak Kuen Siu']","An important issue in functional time series analysis is whether an observed
series comes from a purely random process. We extend the BDS test, a
widely-used nonlinear independence test, to the functional time series. Like
the BDS test in the univariate case, the functional BDS test can act as the
model specification test to evaluate the adequacy of various prediction models
and as a nonlinearity test to detect the existence of nonlinear structures in a
functional time series after removing the linear structure exhibited. We show
that the test statistic from the functional BDS test has the same asymptotic
properties as those in the univariate case and provides the recommended range
of its hyperparameters. Additionally, empirical data analysis features its
applications in evaluating the adequacy of the fAR(1) and fGARCH(1,1) models in
fitting the daily curves of cumulative intraday returns (CIDR) of the VIX
index. We showed that the functional BDS test remedies the weakness of the
existing independence test in the literature, as the latter is restricted in
detecting linear structures, thus, can neglect nonlinear temporal structures.",http://arxiv.org/pdf/2304.01558v1,stat.ME
2023-04-04 03:46:25+00:00,Handling Concept Drift in Global Time Series Forecasting,"['Ziyi Liu', 'Rakshitha Godahewa', 'Kasun Bandara', 'Christoph Bergmeir']","Machine learning (ML) based time series forecasting models often require and
assume certain degrees of stationarity in the data when producing forecasts.
However, in many real-world situations, the data distributions are not
stationary and they can change over time while reducing the accuracy of the
forecasting models, which in the ML literature is known as concept drift.
Handling concept drift in forecasting is essential for many ML methods in use
nowadays, however, the prior work only proposes methods to handle concept drift
in the classification domain. To fill this gap, we explore concept drift
handling methods in particular for Global Forecasting Models (GFM) which
recently have gained popularity in the forecasting domain. We propose two new
concept drift handling methods, namely: Error Contribution Weighting (ECW) and
Gradient Descent Weighting (GDW), based on a continuous adaptive weighting
concept. These methods use two forecasting models which are separately trained
with the most recent series and all series, and finally, the weighted average
of the forecasts provided by the two models are considered as the final
forecasts. Using LightGBM as the underlying base learner, in our evaluation on
three simulated datasets, the proposed models achieve significantly higher
accuracy than a set of statistical benchmarks and LightGBM baselines across
four evaluation metrics.",http://arxiv.org/pdf/2304.01512v1,cs.LG
2023-04-04 03:35:14+00:00,OneShotSTL: One-Shot Seasonal-Trend Decomposition For Online Time Series Anomaly Detection And Forecasting,"['Xiao He', 'Ye Li', 'Jian Tan', 'Bin Wu', 'Feifei Li']","Seasonal-trend decomposition is one of the most fundamental concepts in time
series analysis that supports various downstream tasks, including time series
anomaly detection and forecasting. However, existing decomposition methods rely
on batch processing with a time complexity of O(W), where W is the number of
data points within a time window. Therefore, they cannot always efficiently
support real-time analysis that demands low processing delay. To address this
challenge, we propose OneShotSTL, an efficient and accurate algorithm that can
decompose time series online with an update time complexity of O(1). OneShotSTL
is more than $1,000$ times faster than the batch methods, with accuracy
comparable to the best counterparts. Extensive experiments on real-world
benchmark datasets for downstream time series anomaly detection and forecasting
tasks demonstrate that OneShotSTL is from 10 to over 1,000 times faster than
the state-of-the-art methods, while still providing comparable or even better
accuracy.",http://arxiv.org/pdf/2304.01506v1,cs.LG
2023-04-04 02:01:48+00:00,Time-space-frequency feature Fusion for 3-channel motor imagery classification,"['Zhengqing Miao', 'Meirong Zhao']","Low-channel EEG devices are crucial for portable and entertainment
applications. However, the low spatial resolution of EEG presents challenges in
decoding low-channel motor imagery. This study introduces TSFF-Net, a novel
network architecture that integrates time-space-frequency features, effectively
compensating for the limitations of single-mode feature extraction networks
based on time-series or time-frequency modalities. TSFF-Net comprises four main
components: time-frequency representation, time-frequency feature extraction,
time-space feature extraction, and feature fusion and classification.
Time-frequency representation and feature extraction transform raw EEG signals
into time-frequency spectrograms and extract relevant features. The time-space
network processes time-series EEG trials as input and extracts temporal-spatial
features. Feature fusion employs MMD loss to constrain the distribution of
time-frequency and time-space features in the Reproducing Kernel Hilbert Space,
subsequently combining these features using a weighted fusion approach to
obtain effective time-space-frequency features. Moreover, few studies have
explored the decoding of three-channel motor imagery based on time-frequency
spectrograms. This study proposes a shallow, lightweight decoding architecture
(TSFF-img) based on time-frequency spectrograms and compares its classification
performance in low-channel motor imagery with other methods using two publicly
available datasets. Experimental results demonstrate that TSFF-Net not only
compensates for the shortcomings of single-mode feature extraction networks in
EEG decoding, but also outperforms other state-of-the-art methods. Overall,
TSFF-Net offers considerable advantages in decoding low-channel motor imagery
and provides valuable insights for algorithmically enhancing low-channel EEG
decoding.",http://arxiv.org/pdf/2304.01461v1,cs.LG
2023-04-03 14:26:16+00:00,Artificial neural networks and time series of counts: A class of nonlinear INGARCH models,['Malte Jahn'],"Time series of counts are frequently analyzed using generalized
integer-valued autoregressive models with conditional heteroskedasticity
(INGARCH). These models employ response functions to map a vector of past
observations and past conditional expectations to the conditional expectation
of the present observation. In this paper, it is shown how INGARCH models can
be combined with artificial neural network (ANN) response functions to obtain a
class of nonlinear INGARCH models. The ANN framework allows for the
interpretation of many existing INGARCH models as a degenerate version of a
corresponding neural model. Details on maximum likelihood estimation, marginal
effects and confidence intervals are given. The empirical analysis of time
series of bounded and unbounded counts reveals that the neural INGARCH models
are able to outperform reasonable degenerate competitor models in terms of the
information loss.",http://arxiv.org/pdf/2304.01025v1,stat.ME
2023-03-31 16:59:40+00:00,SimTS: Rethinking Contrastive Representation Learning for Time Series Forecasting,"['Xiaochen Zheng', 'Xingyu Chen', 'Manuel Schürch', 'Amina Mollaysa', 'Ahmed Allam', 'Michael Krauthammer']","Contrastive learning methods have shown an impressive ability to learn
meaningful representations for image or time series classification. However,
these methods are less effective for time series forecasting, as optimization
of instance discrimination is not directly applicable to predicting the future
state from the history context. Moreover, the construction of positive and
negative pairs in current technologies strongly relies on specific time series
characteristics, restricting their generalization across diverse types of time
series data. To address these limitations, we propose SimTS, a simple
representation learning approach for improving time series forecasting by
learning to predict the future from the past in the latent space. SimTS does
not rely on negative pairs or specific assumptions about the characteristics of
the particular time series. Our extensive experiments on several benchmark time
series forecasting datasets show that SimTS achieves competitive performance
compared to existing contrastive learning methods. Furthermore, we show the
shortcomings of the current contrastive learning framework used for time series
forecasting through a detailed ablation study. Overall, our work suggests that
SimTS is a promising alternative to other contrastive learning approaches for
time series forecasting.",http://arxiv.org/pdf/2303.18205v1,cs.LG
2023-03-31 12:11:21+00:00,"Neural Network Entropy (NNetEn): Entropy-Based EEG Signal and Chaotic Time Series Classification, Python Package for NNetEn Calculation","['Andrei Velichko', 'Maksim Belyaev', 'Yuriy Izotov', 'Murugappan Murugappan', 'Hanif Heidari']","Entropy measures are effective features for time series classification
problems. Traditional entropy measures, such as Shannon entropy, use
probability distribution function. However, for the effective separation of
time series, new entropy estimation methods are required to characterize the
chaotic dynamic of the system. Our concept of Neural Network Entropy (NNetEn)
is based on the classification of special datasets in relation to the entropy
of the time series recorded in the reservoir of the neural network. NNetEn
estimates the chaotic dynamics of time series in an original way and does not
take into account probability distribution functions. We propose two new
classification metrics: R2 Efficiency and Pearson Efficiency. The efficiency of
NNetEn is verified on separation of two chaotic time series of sine mapping
using dispersion analysis. For two close dynamic time series (r = 1.1918 and r
= 1.2243), the F-ratio has reached the value of 124 and reflects high
efficiency of the introduced method in classification problems. The
electroenceph-alography signal classification for healthy persons and patients
with Alzheimer disease illustrates the practical application of the NNetEn
features. Our computations demonstrate the synergistic effect of increasing
classification accuracy when applying traditional entropy measures and the
NNetEn concept conjointly. An implementation of the algorithms in Python is
presented.",http://arxiv.org/pdf/2303.17995v2,cs.LG
2023-03-31 09:24:08+00:00,Granger Causality Detection via Sequential Hypothesis Testing,"['Rahul Devendra', 'Ribhu Chopra', 'Kumar Appaiah']","Most of the metrics used for detecting a causal relationship among multiple
time series ignore the effects of practical measurement impairments, such as
finite sample effects, undersampling and measurement noise. It has been shown
that these effects significantly impair the performance of the underlying
causality test. In this paper, we consider the problem of sequentially
detecting the causal relationship between two time series while accounting for
these measurement impairments. In this context, we first formulate the problem
of Granger causality detection as a binary hypothesis test using the norm of
the estimates of the vector auto-regressive~(VAR) coefficients of the two time
series as the test statistic. Following this, we investigate sequential
estimation of these coefficients and formulate a sequential test for detecting
the causal relationship between two time series. Finally via detailed
simulations, we validate our derived results, and evaluate the performance of
the proposed causality detectors.",http://arxiv.org/pdf/2303.17916v1,stat.ME
2023-03-31 05:55:54+00:00,Never a Dull Moment: Distributional Properties as a Baseline for Time-Series Classification,"['Trent Henderson', 'Annie G. Bryant', 'Ben D. Fulcher']","The variety of complex algorithmic approaches for tackling time-series
classification problems has grown considerably over the past decades, including
the development of sophisticated but challenging-to-interpret
deep-learning-based methods. But without comparison to simpler methods it can
be difficult to determine when such complexity is required to obtain strong
performance on a given problem. Here we evaluate the performance of an
extremely simple classification approach -- a linear classifier in the space of
two simple features that ignore the sequential ordering of the data: the mean
and standard deviation of time-series values. Across a large repository of 128
univariate time-series classification problems, this simple distributional
moment-based approach outperformed chance on 69 problems, and reached 100%
accuracy on two problems. With a neuroimaging time-series case study, we find
that a simple linear model based on the mean and standard deviation performs
better at classifying individuals with schizophrenia than a model that
additionally includes features of the time-series dynamics. Comparing the
performance of simple distributional features of a time series provides
important context for interpreting the performance of complex time-series
classification models, which may not always be required to obtain high
accuracy.",http://arxiv.org/pdf/2303.17809v1,stat.ME
2023-03-31 05:22:56+00:00,Time-series Anomaly Detection based on Difference Subspace between Signal Subspaces,"['Takumi Kanai', 'Naoya Sogi', 'Atsuto Maki', 'Kazuhiro Fukui']","This paper proposes a new method for anomaly detection in time-series data by
incorporating the concept of difference subspace into the singular spectrum
analysis (SSA). The key idea is to monitor slight temporal variations of the
difference subspace between two signal subspaces corresponding to the past and
present time-series data, as anomaly score. It is a natural generalization of
the conventional SSA-based method which measures the minimum angle between the
two signal subspaces as the degree of changes. By replacing the minimum angle
with the difference subspace, our method boosts the performance while using the
SSA-based framework as it can capture the whole structural difference between
the two subspaces in its magnitude and direction. We demonstrate our method's
effectiveness through performance evaluations on public time-series datasets.",http://arxiv.org/pdf/2303.17802v2,cs.LG
2023-03-30 15:50:22+00:00,A Bayesian Dirichlet Auto-Regressive Moving Average Model for Forecasting Lead Times,"['Harrison Katz', 'Kai Brusch', 'Robert E. Weiss']","Lead time data is compositional data found frequently in the hospitality
industry. Hospitality businesses earn fees each day, however these fees cannot
be recognized until later. For business purposes, it is important to understand
and forecast the distribution of future fees for the allocation of resources,
for business planning, and for staffing. Motivated by 5 years of daily fees
data, we propose a new class of Bayesian time series models, a Bayesian
Dirichlet Auto-Regressive Moving Average (B-DARMA) model for compositional time
series, modeling the proportion of future fees that will be recognized in 11
consecutive 30 day windows and 1 last consecutive 35 day window. Each day's
compositional datum is modeled as Dirichlet distributed given the mean and a
scale parameter. The mean is modeled with a Vector Autoregressive Moving
Average process after transforming with an additive log ratio link function and
depends on previous compositional data, previous compositional parameters and
daily covariates. The B-DARMA model offers solutions to data analyses of large
compositional vectors and short or long time series, offers efficiency gains
through choice of priors, provides interpretable parameters for inference, and
makes reasonable forecasts.",http://arxiv.org/pdf/2303.17478v1,stat.ME
2023-03-29 13:22:20+00:00,A Byzantine-Resilient Aggregation Scheme for Federated Learning via Matrix Autoregression on Client Updates,"['Gabriele Tolomei', 'Edoardo Gabrielli', 'Dimitri Belli', 'Vittorio Miori']","In this work, we propose FLANDERS, a novel federated learning (FL)
aggregation scheme robust to Byzantine attacks. FLANDERS considers the local
model updates sent by clients at each FL round as a matrix-valued time series.
Then, it identifies malicious clients as outliers of this time series by
comparing actual observations with those estimated by a matrix autoregressive
forecasting model. Experiments conducted on several datasets under different FL
settings demonstrate that FLANDERS matches the robustness of the most powerful
baselines against Byzantine clients. Furthermore, FLANDERS remains highly
effective even under extremely severe attack scenarios, as opposed to existing
defense strategies.",http://arxiv.org/pdf/2303.16668v1,cs.LG
2023-03-29 11:25:11+00:00,Difference-based covariance matrix estimate in time series nonparametric regression with applications to specification tests,"['Lujia Bai', 'Weichi Wu']","Long-run covariance matrix estimation is the building block of time series
inference problems. The corresponding difference-based estimator, which avoids
detrending, has attracted considerable interest due to its robustness to both
smooth and abrupt structural breaks and its competitive finite sample
performance. However, existing methods mainly focus on estimators for the
univariate process while their direct and multivariate extensions for most
linear models are asymptotically biased. We propose a novel difference-based
and debiased long-run covariance matrix estimator for functional linear models
with time-varying regression coefficients, allowing time series
non-stationarity, long-range dependence, state-heteroscedasticity and their
mixtures. We apply the new estimator to i) the structural stability test,
overcoming the notorious non-monotonic power phenomena caused by piecewise
smooth alternatives for regression coefficients, and (ii) the nonparametric
residual-based tests for long memory, improving the performance via the
residual-free formula of the proposed estimator. The effectiveness of the
proposed method is justified theoretically and demonstrated by superior
performance in simulation studies, while its usefulness is elaborated by means
of real data analysis.",http://arxiv.org/pdf/2303.16599v1,stat.ME
2023-03-28 12:10:45+00:00,From Private to Public: Benchmarking GANs in the Context of Private Time Series Classification,"['Dominique Mercier', 'Andreas Dengel', 'Sheraz Ahmed']","Deep learning has proven to be successful in various domains and for
different tasks. However, when it comes to private data several restrictions
are making it difficult to use deep learning approaches in these application
fields. Recent approaches try to generate data privately instead of applying a
privacy-preserving mechanism directly, on top of the classifier. The solution
is to create public data from private data in a manner that preserves the
privacy of the data. In this work, two very prominent GAN-based architectures
were evaluated in the context of private time series classification. In
contrast to previous work, mostly limited to the image domain, the scope of
this benchmark was the time series domain. The experiments show that especially
GSWGAN performs well across a variety of public datasets outperforming the
competitor DPWGAN. An analysis of the generated datasets further validates the
superiority of GSWGAN in the context of time series generation.",http://arxiv.org/pdf/2303.15916v2,cs.LG
2023-03-24 22:36:26+00:00,Clustering Multivariate Time Series using Energy Distance,"['Richard A. Davis', 'Leon Fernandes', 'Konstantinos Fokianos']","A novel methodology is proposed for clustering multivariate time series data
using energy distance defined in Sz\'ekely and Rizzo (2013). Specifically, a
dissimilarity matrix is formed using the energy distance statistic to measure
separation between the finite dimensional distributions for the component time
series. Once the pairwise dissimilarity matrix is calculated, a hierarchical
clustering method is then applied to obtain the dendrogram. This procedure is
completely nonparametric as the dissimilarities between stationary
distributions are directly calculated without making any model assumptions. In
order to justify this procedure, asymptotic properties of the energy distance
estimates are derived for general stationary and ergodic time series. The
method is illustrated in a simulation study for various component time series
that are either linear or nonlinear. Finally the methodology is applied to two
examples; one involves GDP of selected countries and the other is population
size of various states in the U.S.A. in the years 1900 -1999.",http://arxiv.org/pdf/2303.14295v1,stat.ME
2023-03-24 19:40:34+00:00,Towards Diverse and Coherent Augmentation for Time-Series Forecasting,"['Xiyuan Zhang', 'Ranak Roy Chowdhury', 'Jingbo Shang', 'Rajesh Gupta', 'Dezhi Hong']","Time-series data augmentation mitigates the issue of insufficient training
data for deep learning models. Yet, existing augmentation methods are mainly
designed for classification, where class labels can be preserved even if
augmentation alters the temporal dynamics. We note that augmentation designed
for forecasting requires diversity as well as coherence with the original
temporal dynamics. As time-series data generated by real-life physical
processes exhibit characteristics in both the time and frequency domains, we
propose to combine Spectral and Time Augmentation (STAug) for generating more
diverse and coherent samples. Specifically, in the frequency domain, we use the
Empirical Mode Decomposition to decompose a time series and reassemble the
subcomponents with random weights. This way, we generate diverse samples while
being coherent with the original temporal relationships as they contain the
same set of base components. In the time domain, we adapt a mix-up strategy
that generates diverse as well as linearly in-between coherent samples.
Experiments on five real-world time-series datasets demonstrate that STAug
outperforms the base models without data augmentation as well as
state-of-the-art augmentation methods.",http://arxiv.org/pdf/2303.14254v1,cs.LG
2023-03-24 04:57:17+00:00,UniTS: A Universal Time Series Analysis Framework with Self-supervised Representation Learning,"['Zhiyu Liang', 'Chen Liang', 'Zheng Liang', 'Hongzhi Wang']","Machine learning has emerged as a powerful tool for time series analysis.
Existing methods are usually customized for different analysis tasks and face
challenges in tackling practical problems such as partial labeling and domain
shift. To achieve universal analysis and address the aforementioned problems,
we develop UniTS, a novel framework that incorporates self-supervised
representation learning (or pre-training). The components of UniTS are designed
using sklearn-like APIs to allow flexible extensions. We demonstrate how users
can easily perform an analysis task using the user-friendly GUIs, and show the
superior performance of UniTS over the traditional task-specific methods
without self-supervised pre-training on five mainstream tasks and two practical
settings.",http://arxiv.org/pdf/2303.13804v1,cs.LG
2023-03-22 17:52:54+00:00,Conformal Prediction for Time Series with Modern Hopfield Networks,"['Andreas Auer', 'Martin Gauch', 'Daniel Klotz', 'Sepp Hochreiter']","To quantify uncertainty, conformal prediction methods are gaining
continuously more interest and have already been successfully applied to
various domains. However, they are difficult to apply to time series as the
autocorrelative structure of time series violates basic assumptions required by
conformal prediction. We propose HopCPT, a novel conformal prediction approach
for time series that not only copes with temporal structures but leverages
them. We show that our approach is theoretically well justified for time series
where temporal dependencies are present. In experiments, we demonstrate that
our new approach outperforms state-of-the-art conformal prediction methods on
multiple real-world time series datasets from four different domains.",http://arxiv.org/pdf/2303.12783v2,cs.LG
2023-03-22 07:50:15+00:00,Wasserstein Adversarial Examples on Univariant Time Series Data,"['Wenjie Wang', 'Li Xiong', 'Jian Lou']","Adversarial examples are crafted by adding indistinguishable perturbations to
normal examples in order to fool a well-trained deep learning model to
misclassify. In the context of computer vision, this notion of
indistinguishability is typically bounded by $L_{\infty}$ or other norms.
However, these norms are not appropriate for measuring indistinguishiability
for time series data. In this work, we propose adversarial examples in the
Wasserstein space for time series data for the first time and utilize
Wasserstein distance to bound the perturbation between normal examples and
adversarial examples. We introduce Wasserstein projected gradient descent
(WPGD), an adversarial attack method for perturbing univariant time series
data. We leverage the closed-form solution of Wasserstein distance in the 1D
space to calculate the projection step of WPGD efficiently with the gradient
descent method. We further propose a two-step projection so that the search of
adversarial examples in the Wasserstein space is guided and constrained by
Euclidean norms to yield more effective and imperceptible perturbations. We
empirically evaluate the proposed attack on several time series datasets in the
healthcare domain. Extensive results demonstrate that the Wasserstein attack is
powerful and can successfully attack most of the target classifiers with a high
attack success rate. To better study the nature of Wasserstein adversarial
example, we evaluate a strong defense mechanism named Wasserstein smoothing for
potential certified robustness defense. Although the defense can achieve some
accuracy gain, it still has limitations in many cases and leaves space for
developing a stronger certified robustness method to Wasserstein adversarial
examples on univariant time series data.",http://arxiv.org/pdf/2303.12357v1,cs.LG
2023-03-22 05:14:36+00:00,TsSHAP: Robust model agnostic feature-based explainability for time series forecasting,"['Vikas C. Raykar', 'Arindam Jati', 'Sumanta Mukherjee', 'Nupur Aggarwal', 'Kanthi Sarpatwar', 'Giridhar Ganapavarapu', 'Roman Vaculin']","A trustworthy machine learning model should be accurate as well as
explainable. Understanding why a model makes a certain decision defines the
notion of explainability. While various flavors of explainability have been
well-studied in supervised learning paradigms like classification and
regression, literature on explainability for time series forecasting is
relatively scarce.
  In this paper, we propose a feature-based explainability algorithm, TsSHAP,
that can explain the forecast of any black-box forecasting model. The method is
agnostic of the forecasting model and can provide explanations for a forecast
in terms of interpretable features defined by the user a prior.
  The explanations are in terms of the SHAP values obtained by applying the
TreeSHAP algorithm on a surrogate model that learns a mapping between the
interpretable feature space and the forecast of the black-box model.
  Moreover, we formalize the notion of local, semi-local, and global
explanations in the context of time series forecasting, which can be useful in
several scenarios. We validate the efficacy and robustness of TsSHAP through
extensive experiments on multiple datasets.",http://arxiv.org/pdf/2303.12316v1,cs.LG
2023-03-21 15:02:50+00:00,Time Series Contrastive Learning with Information-Aware Augmentations,"['Dongsheng Luo', 'Wei Cheng', 'Yingheng Wang', 'Dongkuan Xu', 'Jingchao Ni', 'Wenchao Yu', 'Xuchao Zhang', 'Yanchi Liu', 'Yuncong Chen', 'Haifeng Chen', 'Xiang Zhang']","Various contrastive learning approaches have been proposed in recent years
and achieve significant empirical success. While effective and prevalent,
contrastive learning has been less explored for time series data. A key
component of contrastive learning is to select appropriate augmentations
imposing some priors to construct feasible positive samples, such that an
encoder can be trained to learn robust and discriminative representations.
Unlike image and language domains where ``desired'' augmented samples can be
generated with the rule of thumb guided by prefabricated human priors, the
ad-hoc manual selection of time series augmentations is hindered by their
diverse and human-unrecognizable temporal structures. How to find the desired
augmentations of time series data that are meaningful for given contrastive
learning tasks and datasets remains an open question. In this work, we address
the problem by encouraging both high \textit{fidelity} and \textit{variety}
based upon information theory. A theoretical analysis leads to the criteria for
selecting feasible data augmentations. On top of that, we propose a new
contrastive learning approach with information-aware augmentations, InfoTS,
that adaptively selects optimal augmentations for time series representation
learning. Experiments on various datasets show highly competitive performance
with up to 12.0\% reduction in MSE on forecasting tasks and up to 3.7\%
relative improvement in accuracy on classification tasks over the leading
baselines.",http://arxiv.org/pdf/2303.11911v1,cs.LG
2023-03-21 07:46:28+00:00,Are uGLAD? Time will tell!,"['Shima Imani', 'Harsh Shrivastava']","We frequently encounter multiple series that are temporally correlated in our
surroundings, such as EEG data to examine alterations in brain activity or
sensors to monitor body movements. Segmentation of multivariate time series
data is a technique for identifying meaningful patterns or changes in the time
series that can signal a shift in the system's behavior. However, most
segmentation algorithms have been designed primarily for univariate time
series, and their performance on multivariate data remains largely
unsatisfactory, making this a challenging problem. In this work, we introduce a
novel approach for multivariate time series segmentation using conditional
independence (CI) graphs. CI graphs are probabilistic graphical models that
represents the partial correlations between the nodes. We propose a domain
agnostic multivariate segmentation framework `$\texttt{tGLAD}$' which draws a
parallel between the CI graph nodes and the variables of the time series.
Consider applying a graph recovery model $\texttt{uGLAD}$ to a short interval
of the time series, it will result in a CI graph that shows partial
correlations among the variables. We extend this idea to the entire time series
by utilizing a sliding window to create a batch of time intervals and then run
a single $\texttt{uGLAD}$ model in multitask learning mode to recover all the
CI graphs simultaneously. As a result, we obtain a corresponding temporal CI
graphs representation. We then designed a first-order and second-order based
trajectory tracking algorithms to study the evolution of these graphs across
distinct intervals. Finally, an `Allocation' algorithm is used to determine a
suitable segmentation of the temporal graph sequence. $\texttt{tGLAD}$ provides
a competitive time complexity of $O(N)$ for settings where number of variables
$D<<N$. We demonstrate successful empirical results on a Physical Activity
Monitoring data.",http://arxiv.org/pdf/2303.11647v1,cs.LG
2023-03-20 06:57:10+00:00,Graph Neural Rough Differential Equations for Traffic Forecasting,"['Jeongwhan Choi', 'Noseong Park']","Traffic forecasting is one of the most popular spatio-temporal tasks in the
field of machine learning. A prevalent approach in the field is to combine
graph convolutional networks and recurrent neural networks for the
spatio-temporal processing. There has been fierce competition and many novel
methods have been proposed. In this paper, we present the method of
spatio-temporal graph neural rough differential equation (STG-NRDE). Neural
rough differential equations (NRDEs) are a breakthrough concept for processing
time-series data. Their main concept is to use the log-signature transform to
convert a time-series sample into a relatively shorter series of feature
vectors. We extend the concept and design two NRDEs: one for the temporal
processing and the other for the spatial processing. After that, we combine
them into a single framework. We conduct experiments with 6 benchmark datasets
and 27 baselines. STG-NRDE shows the best accuracy in all cases, outperforming
all those 27 baselines by non-trivial margins.",http://arxiv.org/pdf/2303.10909v2,cs.LG
2023-03-19 21:58:37+00:00,Deep Declarative Dynamic Time Warping for End-to-End Learning of Alignment Paths,"['Ming Xu', 'Sourav Garg', 'Michael Milford', 'Stephen Gould']","This paper addresses learning end-to-end models for time series data that
include a temporal alignment step via dynamic time warping (DTW). Existing
approaches to differentiable DTW either differentiate through a fixed warping
path or apply a differentiable relaxation to the min operator found in the
recursive steps used to solve the DTW problem. We instead propose a DTW layer
based around bi-level optimisation and deep declarative networks, which we name
DecDTW. By formulating DTW as a continuous, inequality constrained optimisation
problem, we can compute gradients for the solution of the optimal alignment
(with respect to the underlying time series) using implicit differentiation. An
interesting byproduct of this formulation is that DecDTW outputs the optimal
warping path between two time series as opposed to a soft approximation,
recoverable from Soft-DTW. We show that this property is particularly useful
for applications where downstream loss functions are defined on the optimal
alignment path itself. This naturally occurs, for instance, when learning to
improve the accuracy of predicted alignments against ground truth alignments.
We evaluate DecDTW on two such applications, namely the audio-to-score
alignment task in music information retrieval and the visual place recognition
task in robotics, demonstrating state-of-the-art results in both.",http://arxiv.org/pdf/2303.10778v1,cs.LG
2023-03-18 14:37:37+00:00,Discovering Predictable Latent Factors for Time Series Forecasting,"['Jingyi Hou', 'Zhen Dong', 'Jiayu Zhou', 'Zhijie Liu']","Modern time series forecasting methods, such as Transformer and its variants,
have shown strong ability in sequential data modeling. To achieve high
performance, they usually rely on redundant or unexplainable structures to
model complex relations between variables and tune the parameters with
large-scale data. Many real-world data mining tasks, however, lack sufficient
variables for relation reasoning, and therefore these methods may not properly
handle such forecasting problems. With insufficient data, time series appear to
be affected by many exogenous variables, and thus, the modeling becomes
unstable and unpredictable. To tackle this critical issue, in this paper, we
develop a novel algorithmic framework for inferring the intrinsic latent
factors implied by the observable time series. The inferred factors are used to
form multiple independent and predictable signal components that enable not
only sparse relation reasoning for long-term efficiency but also reconstructing
the future temporal data for accurate prediction. To achieve this, we introduce
three characteristics, i.e., predictability, sufficiency, and identifiability,
and model these characteristics via the powerful deep latent dynamics models to
infer the predictable signal components. Empirical results on multiple real
datasets show the efficiency of our method for different kinds of time series
forecasting. The statistical analysis validates the predictability of the
learned latent factors.",http://arxiv.org/pdf/2303.10426v1,cs.LG
2023-03-17 00:24:28+00:00,A Bi-LSTM Autoencoder Framework for Anomaly Detection -- A Case Study of a Wind Power Dataset,"['Ahmed Shoyeb Raihan', 'Imtiaz Ahmed']","Anomalies refer to data points or events that deviate from normal and
homogeneous events, which can include fraudulent activities, network
infiltrations, equipment malfunctions, process changes, or other significant
but infrequent events. Prompt detection of such events can prevent potential
losses in terms of finances, information, and human resources. With the
advancement of computational capabilities and the availability of large
datasets, anomaly detection has become a major area of research. Among these,
anomaly detection in time series has gained more attention recently due to the
added complexity imposed by the time dimension. This study presents a novel
framework for time series anomaly detection using a combination of
Bidirectional Long Short Term Memory (Bi-LSTM) architecture and Autoencoder.
The Bi-LSTM network, which comprises two unidirectional LSTM networks, can
analyze the time series data from both directions and thus effectively discover
the long-term dependencies hidden in the sequential data. Meanwhile, the
Autoencoder mechanism helps to establish the optimal threshold beyond which an
event can be classified as an anomaly. To demonstrate the effectiveness of the
proposed framework, it is applied to a real-world multivariate time series
dataset collected from a wind farm. The Bi-LSTM Autoencoder model achieved a
classification accuracy of 96.79% and outperformed more commonly used LSTM
Autoencoder models.",http://arxiv.org/pdf/2303.09703v1,cs.LG
2023-03-16 17:08:21+00:00,Effectively Modeling Time Series with Simple Discrete State Spaces,"['Michael Zhang', 'Khaled K. Saab', 'Michael Poli', 'Tri Dao', 'Karan Goel', 'Christopher Ré']","Time series modeling is a well-established problem, which often requires that
methods (1) expressively represent complicated dependencies, (2) forecast long
horizons, and (3) efficiently train over long sequences. State-space models
(SSMs) are classical models for time series, and prior works combine SSMs with
deep learning layers for efficient sequence modeling. However, we find
fundamental limitations with these prior approaches, proving their SSM
representations cannot express autoregressive time series processes. We thus
introduce SpaceTime, a new state-space time series architecture that improves
all three criteria. For expressivity, we propose a new SSM parameterization
based on the companion matrix -- a canonical representation for discrete-time
processes -- which enables SpaceTime's SSM layers to learn desirable
autoregressive processes. For long horizon forecasting, we introduce a
""closed-loop"" variation of the companion SSM, which enables SpaceTime to
predict many future time-steps by generating its own layer-wise inputs. For
efficient training and inference, we introduce an algorithm that reduces the
memory and compute of a forward pass with the companion matrix. With sequence
length $\ell$ and state-space size $d$, we go from $\tilde{O}(d \ell)$
na\""ively to $\tilde{O}(d + \ell)$. In experiments, our contributions lead to
state-of-the-art results on extensive and diverse benchmarks, with best or
second-best AUROC on 6 / 7 ECG and speech time series classification, and best
MSE on 14 / 16 Informer forecasting tasks. Furthermore, we find SpaceTime (1)
fits AR($p$) processes that prior deep SSMs fail on, (2) forecasts notably more
accurately on longer horizons than prior state-of-the-art, and (3) speeds up
training on real-world ETTh1 data by 73% and 80% relative wall-clock time over
Transformers and LSTMs.",http://arxiv.org/pdf/2303.09489v1,cs.LG
2023-03-15 16:19:49+00:00,A Bayesian Non-Stationary Heteroskedastic Time Series Model for Multivariate Critical Care Data,"['Zayd Omar', 'David A. Stephens', 'Alexandra M. Schmidt', 'David L. Buckeridge']","We propose a multivariate GARCH model for non-stationary health time series
by modifying the variance of the observations of the standard state space
model. The proposed model provides an intuitive way of dealing with
heteroskedastic data using the conditional nature of state space models. We
follow the Bayesian paradigm to perform the inference procedure. In particular,
we use Markov chain Monte Carlo methods to obtain samples from the resultant
posterior distribution. Due to the natural temporal correlation structure
induced on model parameters, we use the forward filtering backward sampling
algorithm to efficiently obtain samples from the posterior distribution. The
proposed model also handles missing data in a fully Bayesian fashion. We
validate our model on synthetic data, and then use it to analyze a data set
obtained from an intensive care unit in a Montreal hospital. We further show
that our proposed models offer better performance, in terms of WAIC, than
standard state space models. The proposed model provides a new way to model
multivariate heteroskedastic non-stationary time series data and the simplicity
in applying the WAIC allows us to compare competing models.",http://arxiv.org/pdf/2303.08735v1,stat.ME
2023-03-14 21:26:30+00:00,Optimal Sampling Designs for Multi-dimensional Streaming Time Series with Application to Power Grid Sensor Data,"['Rui Xie', 'Shuyang Bai', 'Ping Ma']","The Internet of Things (IoT) system generates massive high-speed temporally
correlated streaming data and is often connected with online inference tasks
under computational or energy constraints. Online analysis of these streaming
time series data often faces a trade-off between statistical efficiency and
computational cost. One important approach to balance this trade-off is
sampling, where only a small portion of the sample is selected for the model
fitting and update. Motivated by the demands of dynamic relationship analysis
of IoT system, we study the data-dependent sample selection and online
inference problem for a multi-dimensional streaming time series, aiming to
provide low-cost real-time analysis of high-speed power grid electricity
consumption data. Inspired by D-optimality criterion in design of experiments,
we propose a class of online data reduction methods that achieve an optimal
sampling criterion and improve the computational efficiency of the online
analysis. We show that the optimal solution amounts to a strategy that is a
mixture of Bernoulli sampling and leverage score sampling. The leverage score
sampling involves auxiliary estimations that have a computational advantage
over recursive least squares updates. Theoretical properties of the auxiliary
estimations involved are also discussed. When applied to European power grid
consumption data, the proposed leverage score based sampling methods outperform
the benchmark sampling method in online estimation and prediction. The general
applicability of the sampling-assisted online estimation method is assessed via
simulation studies.",http://arxiv.org/pdf/2303.08242v1,stat.ML
2023-03-14 14:31:38+00:00,Delay-SDE-net: A deep learning approach for time series modelling with memory and uncertainty estimates,"['Mari Dahl Eggen', 'Alise Danielle Midtfjord']","To model time series accurately is important within a wide range of fields.
As the world is generally too complex to be modelled exactly, it is often
meaningful to assess the probability of a dynamical system to be in a specific
state. This paper presents the Delay-SDE-net, a neural network model based on
stochastic delay differential equations (SDDEs). The use of SDDEs with multiple
delays as modelling framework makes it a suitable model for time series with
memory effects, as it includes memory through previous states of the system.
The stochastic part of the Delay-SDE-net provides a basis for estimating
uncertainty in modelling, and is split into two neural networks to account for
aleatoric and epistemic uncertainty. The uncertainty is provided instantly,
making the model suitable for applications where time is sparse. We derive the
theoretical error of the Delay-SDE-net and analyze the convergence rate
numerically. At comparisons with similar models, the Delay-SDE-net has
consistently the best performance, both in predicting time series values and
uncertainties.",http://arxiv.org/pdf/2303.08587v1,cs.LG
2023-03-14 10:22:21+00:00,Automatic Locally Stationary Time Series Forecasting with application to predicting U.K. Gross Value Added Time Series under sudden shocks caused by the COVID pandemic,"['Rebecca Killick', 'Marina I. Knight', 'Guy P. Nason', 'Matthew A. Nunes', 'Idris A. Eckley']","Accurate forecasting of the U.K. gross value added (GVA) is fundamental for
measuring the growth of the U.K. economy. A common nonstationarity in GVA data,
such as the ABML series, is its increase in variance over time due to
inflation. Transformed or inflation-adjusted series can still be challenging
for classical stationarity-assuming forecasters. We adopt a different approach
that works directly with the GVA series by advancing recent forecasting methods
for locally stationary time series. Our approach results in more accurate and
reliable forecasts, and continues to work well even when the ABML series
becomes highly variable during the COVID pandemic.",http://arxiv.org/pdf/2303.07772v1,stat.ME
2023-03-14 02:46:42+00:00,Forecasting COVID-19 Infections in Gulf Cooperation Council (GCC) Countries using Machine Learning,"['Leila Ismail', 'Huned Materwala', 'Alain Hennebelle']","COVID-19 has infected more than 68 million people worldwide since it was
first detected about a year ago. Machine learning time series models have been
implemented to forecast COVID-19 infections. In this paper, we develop time
series models for the Gulf Cooperation Council (GCC) countries using the public
COVID-19 dataset from Johns Hopkins. The dataset set includes the one-year
cumulative COVID-19 cases between 22/01/2020 to 22/01/2021. We developed
different models for the countries under study based on the spatial
distribution of the infection data. Our experimental results show that the
developed models can forecast COVID-19 infections with high precision.",http://arxiv.org/pdf/2303.07600v1,cs.LG
2023-03-13 14:05:19+00:00,Comparing statistical and machine learning methods for time series forecasting in data-driven logistics -- A simulation study,"['Lena Schmid', 'Moritz Roidl', 'Markus Pauly']","Many planning and decision activities in logistics and supply chain
management are based on forecasts of multiple time dependent factors.
Therefore, the quality of planning depends on the quality of the forecasts. We
compare various forecasting methods in terms of out of the box forecasting
performance on a broad set of simulated time series. We simulate various linear
and non-linear time series and look at the one step forecast performance of
statistical learning methods.",http://arxiv.org/pdf/2303.07139v1,stat.ML
2023-03-13 12:13:28+00:00,Hybrid Variational Autoencoder for Time Series Forecasting,"['Borui Cai', 'Shuiqiao Yang', 'Longxiang Gao', 'Yong Xiang']","Variational autoencoders (VAE) are powerful generative models that learn the
latent representations of input data as random variables. Recent studies show
that VAE can flexibly learn the complex temporal dynamics of time series and
achieve more promising forecasting results than deterministic models. However,
a major limitation of existing works is that they fail to jointly learn the
local patterns (e.g., seasonality and trend) and temporal dynamics of time
series for forecasting. Accordingly, we propose a novel hybrid variational
autoencoder (HyVAE) to integrate the learning of local patterns and temporal
dynamics by variational inference for time series forecasting. Experimental
results on four real-world datasets show that the proposed HyVAE achieves
better forecasting results than various counterpart methods, as well as two
HyVAE variants that only learn the local patterns or temporal dynamics of time
series, respectively.",http://arxiv.org/pdf/2303.07048v1,cs.LG
2023-03-13 05:54:01+00:00,Spacecraft Anomaly Detection with Attention Temporal Convolution Network,"['Liang Liu', 'Ling Tian', 'Zhao Kang', 'Tianqi Wan']","Spacecraft faces various situations when carrying out exploration missions in
complex space, thus monitoring the anomaly status of spacecraft is crucial to
the development of \textcolor{blue}{the} aerospace industry. The time series
telemetry data generated by on-orbit spacecraft \textcolor{blue}{contains}
important information about the status of spacecraft. However, traditional
domain knowledge-based spacecraft anomaly detection methods are not effective
due to high dimensionality and complex correlation among variables. In this
work, we propose an anomaly detection framework for spacecraft multivariate
time-series data based on temporal convolution networks (TCNs). First, we
employ dynamic graph attention to model the complex correlation among variables
and time series. Second, temporal convolution networks with parallel processing
ability are used to extract multidimensional \textcolor{blue}{features} for
\textcolor{blue}{the} downstream prediction task. Finally, many potential
anomalies are detected by the best threshold. Experiments on real NASA SMAP/MSL
spacecraft datasets show the superiority of our proposed model with respect to
state-of-the-art methods.",http://arxiv.org/pdf/2303.06879v1,cs.LG
2023-03-11 12:07:26+00:00,"A Novel Method Combines Moving Fronts, Data Decomposition and Deep Learning to Forecast Intricate Time Series",['Debdarsan Niyogi'],"A univariate time series with high variability can pose a challenge even to
Deep Neural Network (DNN). To overcome this, a univariate time series is
decomposed into simpler constituent series, whose sum equals the original
series. As demonstrated in this article, the conventional one-time
decomposition technique suffers from a leak of information from the future,
referred to as a data leak. In this work, a novel Moving Front (MF) method is
proposed to prevent data leakage, so that the decomposed series can be treated
like other time series. Indian Summer Monsoon Rainfall (ISMR) is a very complex
time series, which poses a challenge to DNN and is therefore selected as an
example. From the many signal processing tools available, Empirical Wavelet
Transform (EWT) was chosen for decomposing the ISMR into simpler constituent
series, as it was found to be more effective than the other popular algorithm,
Complete Ensemble Empirical Mode Decomposition with Adaptive Noise (CEEMDAN).
The proposed MF method was used to generate the constituent leakage-free time
series. Predictions and forecasts were made by state-of-the-art Long and
Short-Term Memory (LSTM) network architecture, especially suitable for making
predictions of sequential patterns. The constituent MF series has been divided
into training, testing, and forecasting. It has been found that the model
(EWT-MF-LSTM) developed here made exceptionally good train and test
predictions, as well as Walk-Forward Validation (WFV), forecasts with
Performance Parameter ($PP$) values of 0.99, 0.86, and 0.95, respectively,
where $PP$ = 1.0 signifies perfect reproduction of the data.",http://arxiv.org/pdf/2303.06394v1,cs.LG
2023-03-11 10:20:47+00:00,Explainable AI for Time Series via Virtual Inspection Layers,"['Johanna Vielhaben', 'Sebastian Lapuschkin', 'Grégoire Montavon', 'Wojciech Samek']","The field of eXplainable Artificial Intelligence (XAI) has greatly advanced
in recent years, but progress has mainly been made in computer vision and
natural language processing. For time series, where the input is often not
interpretable, only limited research on XAI is available. In this work, we put
forward a virtual inspection layer, that transforms the time series to an
interpretable representation and allows to propagate relevance attributions to
this representation via local XAI methods like layer-wise relevance propagation
(LRP). In this way, we extend the applicability of a family of XAI methods to
domains (e.g. speech) where the input is only interpretable after a
transformation. Here, we focus on the Fourier transformation which is
prominently applied in the interpretation of time series and LRP and refer to
our method as DFT-LRP. We demonstrate the usefulness of DFT-LRP in various time
series classification settings like audio and electronic health records. We
showcase how DFT-LRP reveals differences in the classification strategies of
models trained in different domains (e.g., time vs. frequency domain) or helps
to discover how models act on spurious correlations in the data.",http://arxiv.org/pdf/2303.06365v1,cs.LG
2023-03-11 02:56:29+00:00,Machine Learning Enhanced Hankel Dynamic-Mode Decomposition,"['Christopher W. Curtis', 'D. Jay Alford-Lago', 'Erik Bollt', 'Andrew Tuma']","While the acquisition of time series has become more straightforward,
developing dynamical models from time series is still a challenging and
evolving problem domain. Within the last several years, to address this
problem, there has been a merging of machine learning tools with what is called
the dynamic mode decomposition (DMD). This general approach has been shown to
be an especially promising avenue for accurate model development. Building on
this prior body of work, we develop a deep learning DMD based method which
makes use of the fundamental insight of Takens' Embedding Theorem to build an
adaptive learning scheme that better approximates higher dimensional and
chaotic dynamics. We call this method the Deep Learning Hankel DMD (DLHDMD). We
likewise explore how our method learns mappings which tend, after successful
training, to significantly change the mutual information between dimensions in
the dynamics. This appears to be a key feature in enhancing the DMD overall,
and it should help provide further insight for developing other deep learning
methods for time series analysis and model generation.",http://arxiv.org/pdf/2303.06289v3,cs.LG
2023-03-10 16:41:24+00:00,TSMixer: An All-MLP Architecture for Time Series Forecasting,"['Si-An Chen', 'Chun-Liang Li', 'Nate Yoder', 'Sercan O. Arik', 'Tomas Pfister']","Real-world time-series datasets are often multivariate with complex dynamics.
To capture this complexity, high capacity architectures like recurrent- or
attention-based sequential deep learning models have become popular. However,
recent work demonstrates that simple univariate linear models can outperform
such deep learning models on several commonly used academic benchmarks.
Extending them, in this paper, we investigate the capabilities of linear models
for time-series forecasting and present Time-Series Mixer (TSMixer), a novel
architecture designed by stacking multi-layer perceptrons (MLPs). TSMixer is
based on mixing operations along both the time and feature dimensions to
extract information efficiently. On popular academic benchmarks, the
simple-to-implement TSMixer is comparable to specialized state-of-the-art
models that leverage the inductive biases of specific benchmarks. On the
challenging and large scale M5 benchmark, a real-world retail dataset, TSMixer
demonstrates superior performance compared to the state-of-the-art
alternatives. Our results underline the importance of efficiently utilizing
cross-variate and auxiliary information for improving the performance of time
series forecasting. We present various analyses to shed light into the
capabilities of TSMixer. The design paradigms utilized in TSMixer are expected
to open new horizons for deep learning-based time series forecasting. The
implementation is available at
https://github.com/google-research/google-research/tree/master/tsmixer",http://arxiv.org/pdf/2303.06053v5,cs.LG
2023-03-09 13:27:54+00:00,On the Soundness of XAI in Prognostics and Health Management (PHM),"['David Solís-Martín', 'Juan Galán-Páez', 'Joaquín Borrego-Díaz']","The aim of Predictive Maintenance, within the field of Prognostics and Health
Management (PHM), is to identify and anticipate potential issues in the
equipment before these become critical. The main challenge to be addressed is
to assess the amount of time a piece of equipment will function effectively
before it fails, which is known as Remaining Useful Life (RUL). Deep Learning
(DL) models, such as Deep Convolutional Neural Networks (DCNN) and Long
Short-Term Memory (LSTM) networks, have been widely adopted to address the
task, with great success. However, it is well known that this kind of black box
models are opaque decision systems, and it may be hard to explain its outputs
to stakeholders (experts in the industrial equipment). Due to the large number
of parameters that determine the behavior of these complex models,
understanding the reasoning behind the predictions is challenging. This work
presents a critical and comparative revision on a number of XAI methods applied
on time series regression model for PM. The aim is to explore XAI methods
within time series regression, which have been less studied than those for time
series classification. The model used during the experimentation is a DCNN
trained to predict the RUL of an aircraft engine. The methods are reviewed and
compared using a set of metrics that quantifies a number of desirable
properties that any XAI method should fulfill. The results show that GRAD-CAM
is the most robust method, and that the best layer is not the bottom one, as is
commonly seen within the context of Image Processing.",http://arxiv.org/pdf/2303.05517v1,cs.LG
2023-03-09 08:20:17+00:00,Multi-task Meta Label Correction for Time Series Prediction,"['Luxuan Yang', 'Ting Gao', 'Wei Wei', 'Min Dai', 'Cheng Fang', 'Jinqiao Duan']","Time series classification faces two unavoidable problems. One is partial
feature information and the other is poor label quality, which may affect model
performance. To address the above issues, we create a label correction method
to time series data with meta-learning under a multi-task framework. There are
three main contributions. First, we train the label correction model with a
two-branch neural network for the outer loop. While in the model-agnostic inner
loop, we use pre-existing classification models in a multi-task way and jointly
update the meta-knowledge, which makes us achieve adaptive labeling on complex
time series. Second, we devise new data visualization methods for both image
patterns of the historical data and data in the prediction horizon. Finally, we
test our method with various financial datasets, including XOM, S\&P500, and
SZ50. Results show that our method is more effective and accurate than some
existing label correction techniques.",http://arxiv.org/pdf/2303.08103v2,cs.LG
2023-03-08 17:27:39+00:00,Vector Quantized Time Series Generation with a Bidirectional Prior Model,"['Daesoo Lee', 'Sara Malacarne', 'Erlend Aune']","Time series generation (TSG) studies have mainly focused on the use of
Generative Adversarial Networks (GANs) combined with recurrent neural network
(RNN) variants. However, the fundamental limitations and challenges of training
GANs still remain. In addition, the RNN-family typically has difficulties with
temporal consistency between distant timesteps. Motivated by the successes in
the image generation (IMG) domain, we propose TimeVQVAE, the first work, to our
knowledge, that uses vector quantization (VQ) techniques to address the TSG
problem. Moreover, the priors of the discrete latent spaces are learned with
bidirectional transformer models that can better capture global temporal
consistency. We also propose VQ modeling in a time-frequency domain, separated
into low-frequency (LF) and high-frequency (HF). This allows us to retain
important characteristics of the time series and, in turn, generate new
synthetic signals that are of better quality, with sharper changes in
modularity, than its competing TSG methods. Our experimental evaluation is
conducted on all datasets from the UCR archive, using well-established metrics
in the IMG literature, such as Fr\'echet inception distance and inception
scores. Our implementation on GitHub:
\url{https://github.com/ML4ITS/TimeVQVAE}.",http://arxiv.org/pdf/2303.04743v3,cs.LG
2023-03-08 08:52:04+00:00,Time series conditional extremes,"['Graeme Auld', 'Ioannis Papastathopoulos']","Accurate modelling of the joint extremal dependence structure within a
stationary time series is a challenging problem that is important in many
applications.\ Several previous approaches to this problem are only applicable
to certain types of extremal dependence in the time series such as asymptotic
dependence, or Markov time series of finite order.\ In this paper, we develop
statistical methodology for time series extremes based on recent probabilistic
results that allow us to flexibly model the decay of a stationary time series
after witnessing an extreme event.\ While Markov sequences of finite order are
naturally accommodated by our approach, we consider a broader setup, based on
the conditional extreme value model, which allows for a wide range of possible
dependence structures in the time series.\ We consider inference based on Monte
Carlo simulation and derive an upper bound for the variance of a commonly used
importance sampler.\ Our methodology is illustrated via estimation of cluster
functionals in simulated data and in a time series of daily maximum
temperatures from Orleans, France.",http://arxiv.org/pdf/2303.04447v1,stat.ME
2023-03-06 23:37:58+00:00,Robust Dominant Periodicity Detection for Time Series with Missing Data,"['Qingsong Wen', 'Linxiao Yang', 'Liang Sun']","Periodicity detection is an important task in time series analysis, but still
a challenging problem due to the diverse characteristics of time series data
like abrupt trend change, outlier, noise, and especially block missing data. In
this paper, we propose a robust and effective periodicity detection algorithm
for time series with block missing data. We first design a robust trend filter
to remove the interference of complicated trend patterns under missing data.
Then, we propose a robust autocorrelation function (ACF) that can handle
missing values and outliers effectively. We rigorously prove that the proposed
robust ACF can still work well when the length of the missing block is less
than $1/3$ of the period length. Last, by combining the time-frequency
information, our algorithm can generate the period length accurately. The
experimental results demonstrate that our algorithm outperforms existing
periodicity detection algorithms on real-world time series datasets.",http://arxiv.org/pdf/2303.03553v1,cs.LG
2023-03-06 17:52:35+00:00,Time series anomaly detection with reconstruction-based state-space models,"['Fan Wang', 'Keli Wang', 'Boyu Yao']","Recent advances in digitization have led to the availability of multivariate
time series data in various domains, enabling real-time monitoring of
operations. Identifying abnormal data patterns and detecting potential failures
in these scenarios are important yet rather challenging. In this work, we
propose a novel unsupervised anomaly detection method for time series data. The
proposed framework jointly learns the observation model and the dynamic model,
and model uncertainty is estimated from normal samples. Specifically, a long
short-term memory (LSTM)-based encoder-decoder is adopted to represent the
mapping between the observation space and the latent space. Bidirectional
transitions of states are simultaneously modeled by leveraging backward and
forward temporal information. Regularization of the latent space places
constraints on the states of normal samples, and Mahalanobis distance is used
to evaluate the abnormality level. Empirical studies on synthetic and
real-world datasets demonstrate the superior performance of the proposed method
in anomaly detection tasks.",http://arxiv.org/pdf/2303.03324v3,cs.LG
2023-03-04 04:55:34+00:00,Estimating Treatment Effects from Irregular Time Series Observations with Hidden Confounders,"['Defu Cao', 'James Enouen', 'Yujing Wang', 'Xiangchen Song', 'Chuizheng Meng', 'Hao Niu', 'Yan Liu']","Causal analysis for time series data, in particular estimating individualized
treatment effect (ITE), is a key task in many real-world applications, such as
finance, retail, healthcare, etc. Real-world time series can include
large-scale, irregular, and intermittent time series observations, raising
significant challenges to existing work attempting to estimate treatment
effects. Specifically, the existence of hidden confounders can lead to biased
treatment estimates and complicate the causal inference process. In particular,
anomaly hidden confounders which exceed the typical range can lead to high
variance estimates. Moreover, in continuous time settings with irregular
samples, it is challenging to directly handle the dynamics of causality. In
this paper, we leverage recent advances in Lipschitz regularization and neural
controlled differential equations (CDE) to develop an effective and scalable
solution, namely LipCDE, to address the above challenges. LipCDE can directly
model the dynamic causal relationships between historical data and outcomes
with irregular samples by considering the boundary of hidden confounders given
by Lipschitz-constrained neural networks. Furthermore, we conduct extensive
experiments on both synthetic and real-world datasets to demonstrate the
effectiveness and scalability of LipCDE.",http://arxiv.org/pdf/2303.02320v1,cs.LG
2023-03-03 10:49:09+00:00,Anamnesic Neural Differential Equations with Orthogonal Polynomial Projections,"['Edward De Brouwer', 'Rahul G. Krishnan']","Neural ordinary differential equations (Neural ODEs) are an effective
framework for learning dynamical systems from irregularly sampled time series
data. These models provide a continuous-time latent representation of the
underlying dynamical system where new observations at arbitrary time points can
be used to update the latent representation of the dynamical system. Existing
parameterizations for the dynamics functions of Neural ODEs limit the ability
of the model to retain global information about the time series; specifically,
a piece-wise integration of the latent process between observations can result
in a loss of memory on the dynamic patterns of previously observed data points.
We propose PolyODE, a Neural ODE that models the latent continuous-time process
as a projection onto a basis of orthogonal polynomials. This formulation
enforces long-range memory and preserves a global representation of the
underlying dynamical system. Our construction is backed by favourable
theoretical guarantees and in a series of experiments, we demonstrate that it
outperforms previous works in the reconstruction of past and future data, and
in downstream prediction tasks.",http://arxiv.org/pdf/2303.01841v1,cs.LG
2023-03-02 13:58:06+00:00,Navigating the Metric Maze: A Taxonomy of Evaluation Metrics for Anomaly Detection in Time Series,"['Sondre Sørbø', 'Massimiliano Ruocco']","The field of time series anomaly detection is constantly advancing, with
several methods available, making it a challenge to determine the most
appropriate method for a specific domain. The evaluation of these methods is
facilitated by the use of metrics, which vary widely in their properties.
Despite the existence of new evaluation metrics, there is limited agreement on
which metrics are best suited for specific scenarios and domain, and the most
commonly used metrics have faced criticism in the literature. This paper
provides a comprehensive overview of the metrics used for the evaluation of
time series anomaly detection methods, and also defines a taxonomy of these
based on how they are calculated. By defining a set of properties for
evaluation metrics and a set of specific case studies and experiments, twenty
metrics are analyzed and discussed in detail, highlighting the unique
suitability of each for specific tasks. Through extensive experimentation and
analysis, this paper argues that the choice of evaluation metric must be made
with care, taking into account the specific requirements of the task at hand.",http://arxiv.org/pdf/2303.01272v1,cs.LG
2023-03-02 07:44:06+00:00,Multi-Task Self-Supervised Time-Series Representation Learning,"['Heejeong Choi', 'Pilsung Kang']","Time-series representation learning can extract representations from data
with temporal dynamics and sparse labels. When labeled data are sparse but
unlabeled data are abundant, contrastive learning, i.e., a framework to learn a
latent space where similar samples are close to each other while dissimilar
ones are far from each other, has shown outstanding performance. This strategy
can encourage varied consistency of time-series representations depending on
the positive pair selection and contrastive loss. We propose a new time-series
representation learning method by combining the advantages of self-supervised
tasks related to contextual, temporal, and transformation consistency. It
allows the network to learn general representations for various downstream
tasks and domains. Specifically, we first adopt data preprocessing to generate
positive and negative pairs for each self-supervised task. The model then
performs contextual, temporal, and transformation contrastive learning and is
optimized jointly using their contrastive losses. We further investigate an
uncertainty weighting approach to enable effective multi-task learning by
considering the contribution of each consistency. We evaluate the proposed
framework on three downstream tasks: time-series classification, forecasting,
and anomaly detection. Experimental results show that our method not only
outperforms the benchmark models on these downstream tasks, but also shows
efficiency in cross-domain transfer learning.",http://arxiv.org/pdf/2303.01034v1,cs.LG
2023-03-01 22:42:44+00:00,Time Series as Images: Vision Transformer for Irregularly Sampled Time Series,"['Zekun Li', 'Shiyang Li', 'Xifeng Yan']","Irregularly sampled time series are increasingly prevalent, particularly in
medical domains. While various specialized methods have been developed to
handle these irregularities, effectively modeling their complex dynamics and
pronounced sparsity remains a challenge. This paper introduces a novel
perspective by converting irregularly sampled time series into line graph
images, then utilizing powerful pre-trained vision transformers for time series
classification in the same way as image classification. This method not only
largely simplifies specialized algorithm designs but also presents the
potential to serve as a universal framework for time series modeling.
Remarkably, despite its simplicity, our approach outperforms state-of-the-art
specialized algorithms on several popular healthcare and human activity
datasets. Especially in the rigorous leave-sensors-out setting where a portion
of variables is omitted during testing, our method exhibits strong robustness
against varying degrees of missing observations, achieving an impressive
improvement of 42.8% in absolute F1 score points over leading specialized
baselines even with half the variables masked. Code and data are available at
https://github.com/Leezekun/ViTST",http://arxiv.org/pdf/2303.12799v2,cs.LG
2023-03-01 11:00:20+00:00,"RePAD2: Real-Time, Lightweight, and Adaptive Anomaly Detection for Open-Ended Time Series","['Ming-Chang Lee', 'Jia-Chun Lin']","An open-ended time series refers to a series of data points indexed in time
order without an end. Such a time series can be found everywhere due to the
prevalence of Internet of Things. Providing lightweight and real-time anomaly
detection for open-ended time series is highly desirable to industry and
organizations since it allows immediate response and avoids potential financial
loss. In the last few years, several real-time time series anomaly detection
approaches have been introduced. However, they might exhaust system resources
when they are applied to open-ended time series for a long time. To address
this issue, in this paper we propose RePAD2, a lightweight real-time anomaly
detection approach for open-ended time series by improving its predecessor
RePAD, which is one of the state-of-the-art anomaly detection approaches. We
conducted a series of experiments to compare RePAD2 with RePAD and another
similar detection approach based on real-world time series datasets, and
demonstrated that RePAD2 can address the mentioned resource exhaustion issue
while offering comparable detection accuracy and slightly less time
consumption.",http://arxiv.org/pdf/2303.00409v2,cs.LG
2023-03-01 08:33:16+00:00,TimeMAE: Self-Supervised Representations of Time Series with Decoupled Masked Autoencoders,"['Mingyue Cheng', 'Qi Liu', 'Zhiding Liu', 'Hao Zhang', 'Rujiao Zhang', 'Enhong Chen']","Enhancing the expressive capacity of deep learning-based time series models
with self-supervised pre-training has become ever-increasingly prevalent in
time series classification. Even though numerous efforts have been devoted to
developing self-supervised models for time series data, we argue that the
current methods are not sufficient to learn optimal time series representations
due to solely unidirectional encoding over sparse point-wise input units. In
this work, we propose TimeMAE, a novel self-supervised paradigm for learning
transferrable time series representations based on transformer networks. The
distinct characteristics of the TimeMAE lie in processing each time series into
a sequence of non-overlapping sub-series via window-slicing partitioning,
followed by random masking strategies over the semantic units of localized
sub-series. Such a simple yet effective setting can help us achieve the goal of
killing three birds with one stone, i.e., (1) learning enriched contextual
representations of time series with a bidirectional encoding scheme; (2)
increasing the information density of basic semantic units; (3) efficiently
encoding representations of time series using transformer networks.
Nevertheless, it is a non-trivial to perform reconstructing task over such a
novel formulated modeling paradigm. To solve the discrepancy issue incurred by
newly injected masked embeddings, we design a decoupled autoencoder
architecture, which learns the representations of visible (unmasked) positions
and masked ones with two different encoder modules, respectively. Furthermore,
we construct two types of informative targets to accomplish the corresponding
pretext tasks. One is to create a tokenizer module that assigns a codeword to
each masked region, allowing the masked codeword classification (MCC) task to
be completed effectively...",http://arxiv.org/pdf/2303.00320v3,cs.LG
2023-02-28 08:17:50+00:00,Your time series is worth a binary image: machine vision assisted deep framework for time series forecasting,"['Luoxiao Yang', 'Xinqi Fan', 'Zijun Zhang']","Time series forecasting (TSF) has been a challenging research area, and
various models have been developed to address this task. However, almost all
these models are trained with numerical time series data, which is not as
effectively processed by the neural system as visual information. To address
this challenge, this paper proposes a novel machine vision assisted deep time
series analysis (MV-DTSA) framework. The MV-DTSA framework operates by
analyzing time series data in a novel binary machine vision time series metric
space, which includes a mapping and an inverse mapping function from the
numerical time series space to the binary machine vision space, and a deep
machine vision model designed to address the TSF task in the binary space. A
comprehensive computational analysis demonstrates that the proposed MV-DTSA
framework outperforms state-of-the-art deep TSF models, without requiring
sophisticated data decomposition or model customization. The code for our
framework is accessible at https://github.com/IkeYang/
machine-vision-assisted-deep-time-series-analysis-MV-DTSA-.",http://arxiv.org/pdf/2302.14390v1,cs.LG
2023-02-27 07:48:06+00:00,Deep Imbalanced Time-series Forecasting via Local Discrepancy Density,"['Junwoo Park', 'Jungsoo Lee', 'Youngin Cho', 'Woncheol Shin', 'Dongmin Kim', 'Jaegul Choo', 'Edward Choi']","Time-series forecasting models often encounter abrupt changes in a given
period of time which generally occur due to unexpected or unknown events.
Despite their scarce occurrences in the training set, abrupt changes incur loss
that significantly contributes to the total loss. Therefore, they act as noisy
training samples and prevent the model from learning generalizable patterns,
namely the normal states. Based on our findings, we propose a reweighting
framework that down-weights the losses incurred by abrupt changes and
up-weights those by normal states. For the reweighting framework, we first
define a measurement termed Local Discrepancy (LD) which measures the degree of
abruptness of a change in a given period of time. Since a training set is
mostly composed of normal states, we then consider how frequently the temporal
changes appear in the training set based on LD. Our reweighting framework is
applicable to existing time-series forecasting models regardless of the
architectures. Through extensive experiments on 12 time-series forecasting
models over eight datasets with various in-output sequence lengths, we
demonstrate that applying our reweighting framework reduces MSE by 10.1% on
average and by up to 18.6% in the state-of-the-art model.",http://arxiv.org/pdf/2302.13563v2,cs.LG
2023-02-27 01:05:17+00:00,A Self-Supervised Learning-based Approach to Clustering Multivariate Time-Series Data with Missing Values (SLAC-Time): An Application to TBI Phenotyping,"['Hamid Ghaderi', 'Brandon Foreman', 'Amin Nayebi', 'Sindhu Tipirneni', 'Chandan K. Reddy', 'Vignesh Subbian']","Self-supervised learning approaches provide a promising direction for
clustering multivariate time-series data. However, real-world time-series data
often include missing values, and the existing approaches require imputing
missing values before clustering, which may cause extensive computations and
noise and result in invalid interpretations. To address these challenges, we
present a Self-supervised Learning-based Approach to Clustering multivariate
Time-series data with missing values (SLAC-Time). SLAC-Time is a
Transformer-based clustering method that uses time-series forecasting as a
proxy task for leveraging unlabeled data and learning more robust time-series
representations. This method jointly learns the neural network parameters and
the cluster assignments of the learned representations. It iteratively clusters
the learned representations with the K-means method and then utilizes the
subsequent cluster assignments as pseudo-labels to update the model parameters.
To evaluate our proposed approach, we applied it to clustering and phenotyping
Traumatic Brain Injury (TBI) patients in the Transforming Research and Clinical
Knowledge in Traumatic Brain Injury (TRACK-TBI) study. Our experiments
demonstrate that SLAC-Time outperforms the baseline K-means clustering
algorithm in terms of silhouette coefficient, Calinski Harabasz index, Dunn
index, and Davies Bouldin index. We identified three TBI phenotypes that are
distinct from one another in terms of clinically significant variables as well
as clinical outcomes, including the Extended Glasgow Outcome Scale (GOSE)
score, Intensive Care Unit (ICU) length of stay, and mortality rate. The
experiments show that the TBI phenotypes identified by SLAC-Time can be
potentially used for developing targeted clinical trials and therapeutic
strategies.",http://arxiv.org/pdf/2302.13457v2,cs.LG
2023-02-26 19:13:42+00:00,Factorization of a spectral density with smooth eigenvalues of a multidimensional stationary time series,['Tamás Szabados'],"The aim of this paper to give a multidimensional version of the classical
one-dimensional case of smooth spectral density. A smooth spectral density
gives an explicit method to factorize the spectral density and compute the
constituents of the Wold representation of a regular weakly stationary time
series. These constituents are important to give the best linear predictions of
the time series.",http://arxiv.org/pdf/2302.13388v1,math.ST
2023-02-24 16:20:40+00:00,LightTS: Lightweight Time Series Classification with Adaptive Ensemble Distillation -- Extended Version,"['David Campos', 'Miao Zhang', 'Bin Yang', 'Tung Kieu', 'Chenjuan Guo', 'Christian S. Jensen']","Due to the sweeping digitalization of processes, increasingly vast amounts of
time series data are being produced. Accurate classification of such time
series facilitates decision making in multiple domains. State-of-the-art
classification accuracy is often achieved by ensemble learning where results
are synthesized from multiple base models. This characteristic implies that
ensemble learning needs substantial computing resources, preventing their use
in resource-limited environments, such as in edge devices. To extend the
applicability of ensemble learning, we propose the LightTS framework that
compresses large ensembles into lightweight models while ensuring competitive
accuracy. First, we propose adaptive ensemble distillation that assigns
adaptive weights to different base models such that their varying
classification capabilities contribute purposefully to the training of the
lightweight model. Second, we propose means of identifying Pareto optimal
settings w.r.t. model accuracy and model size, thus enabling users with a space
budget to select the most accurate lightweight model. We report on experiments
using 128 real-world time series sets and different types of base models that
justify key decisions in the design of LightTS and provide evidence that
LightTS is able to outperform competitors.",http://arxiv.org/pdf/2302.12721v1,cs.LG
2023-02-24 13:30:35+00:00,T-Phenotype: Discovering Phenotypes of Predictive Temporal Patterns in Disease Progression,"['Yuchao Qin', 'Mihaela van der Schaar', 'Changhee Lee']","Clustering time-series data in healthcare is crucial for clinical phenotyping
to understand patients' disease progression patterns and to design treatment
guidelines tailored to homogeneous patient subgroups. While rich temporal
dynamics enable the discovery of potential clusters beyond static correlations,
two major challenges remain outstanding: i) discovery of predictive patterns
from many potential temporal correlations in the multi-variate time-series data
and ii) association of individual temporal patterns to the target label
distribution that best characterizes the underlying clinical progression. To
address such challenges, we develop a novel temporal clustering method,
T-Phenotype, to discover phenotypes of predictive temporal patterns from
labeled time-series data. We introduce an efficient representation learning
approach in frequency domain that can encode variable-length,
irregularly-sampled time-series into a unified representation space, which is
then applied to identify various temporal patterns that potentially contribute
to the target label using a new notion of path-based similarity. Throughout the
experiments on synthetic and real-world datasets, we show that T-Phenotype
achieves the best phenotype discovery performance over all the evaluated
baselines. We further demonstrate the utility of T-Phenotype by uncovering
clinically meaningful patient subgroups characterized by unique temporal
patterns.",http://arxiv.org/pdf/2302.12619v1,cs.LG
2023-02-23 20:37:04+00:00,Testing Serial Independence of Object-Valued Time Series,"['Feiyu Jiang', 'Hanjia Gao', 'Xiaofeng Shao']","We propose a novel method for testing serial independence of object-valued
time series in metric spaces, which is more general than Euclidean or Hilbert
spaces. The proposed method is fully nonparametric, free of tuning parameters,
and can capture all nonlinear pairwise dependence. The key concept used in this
paper is the distance covariance in metric spaces, which is extended to auto
distance covariance for object-valued time series. Furthermore, we propose a
generalized spectral density function to account for pairwise dependence at all
lags and construct a Cramer-von Mises type test statistic. New theoretical
arguments are developed to establish the asymptotic behavior of the test
statistic. A wild bootstrap is also introduced to obtain the critical values of
the non-pivotal limiting null distribution. Extensive numerical simulations and
two real data applications are conducted to illustrate the effectiveness and
versatility of our proposed method.",http://arxiv.org/pdf/2302.12322v2,stat.ME
2023-02-23 11:37:39+00:00,One Fits All:Power General Time Series Analysis by Pretrained LM,"['Tian Zhou', 'PeiSong Niu', 'Xue Wang', 'Liang Sun', 'Rong Jin']","Although we have witnessed great success of pre-trained models in natural
language processing (NLP) and computer vision (CV), limited progress has been
made for general time series analysis. Unlike NLP and CV where a unified model
can be used to perform different tasks, specially designed approach still
dominates in each time series analysis task such as classification, anomaly
detection, forecasting, and few-shot learning. The main challenge that blocks
the development of pre-trained model for time series analysis is the lack of a
large amount of data for training. In this work, we address this challenge by
leveraging language or CV models, pre-trained from billions of tokens, for time
series analysis. Specifically, we refrain from altering the self-attention and
feedforward layers of the residual blocks in the pre-trained language or image
model. This model, known as the Frozen Pretrained Transformer (FPT), is
evaluated through fine-tuning on all major types of tasks involving time
series. Our results demonstrate that pre-trained models on natural language or
images can lead to a comparable or state-of-the-art performance in all main
time series analysis tasks, as illustrated in Figure 1. We also found both
theoretically and empirically that the self-attention module behaviors
similarly to principle component analysis (PCA), an observation that helps
explains how transformer bridges the domain gap and a crucial step towards
understanding the universality of a pre-trained transformer.The code is
publicly available at https://github.com/DAMO-DI-ML/One_Fits_All.",http://arxiv.org/pdf/2302.11939v6,cs.LG
2023-02-22 09:43:00+00:00,The DeepCAR Method: Forecasting Time-Series Data That Have Change Points,"['Ayla Jungbluth', 'Johannes Lederer']","Many methods for time-series forecasting are known in classical statistics,
such as autoregression, moving averages, and exponential smoothing. The DeepAR
framework is a novel, recent approach for time-series forecasting based on deep
learning. DeepAR has shown very promising results already. However, time series
often have change points, which can degrade the DeepAR's prediction performance
substantially. This paper extends the DeepAR framework by detecting and
including those change points. We show that our method performs as well as
standard DeepAR when there are no change points and considerably better when
there are change points. More generally, we show that the batch size provides
an effective and surprisingly simple way to deal with change points in DeepAR,
Transformers, and other modern forecasting models.",http://arxiv.org/pdf/2302.11241v1,cs.LG
2023-02-22 07:56:45+00:00,Dish-TS: A General Paradigm for Alleviating Distribution Shift in Time Series Forecasting,"['Wei Fan', 'Pengyang Wang', 'Dongkun Wang', 'Dongjie Wang', 'Yuanchun Zhou', 'Yanjie Fu']","The distribution shift in Time Series Forecasting (TSF), indicating series
distribution changes over time, largely hinders the performance of TSF models.
Existing works towards distribution shift in time series are mostly limited in
the quantification of distribution and, more importantly, overlook the
potential shift between lookback and horizon windows. To address above
challenges, we systematically summarize the distribution shift in TSF into two
categories. Regarding lookback windows as input-space and horizon windows as
output-space, there exist (i) intra-space shift, that the distribution within
the input-space keeps shifted over time, and (ii) inter-space shift, that the
distribution is shifted between input-space and output-space. Then we
introduce, Dish-TS, a general neural paradigm for alleviating distribution
shift in TSF. Specifically, for better distribution estimation, we propose the
coefficient net (CONET), which can be any neural architectures, to map input
sequences into learnable distribution coefficients. To relieve intra-space and
inter-space shift, we organize Dish-TS as a Dual-CONET framework to separately
learn the distribution of input- and output-space, which naturally captures the
distribution difference of two spaces. In addition, we introduce a more
effective training strategy for intractable CONET learning. Finally, we conduct
extensive experiments on several datasets coupled with different
state-of-the-art forecasting models. Experimental results show Dish-TS
consistently boosts them with a more than 20% average improvement. Code is
available.",http://arxiv.org/pdf/2302.14829v3,cs.LG
2023-02-22 00:51:44+00:00,Learning Mixture Structure on Multi-Source Time Series for Probabilistic Forecasting,['Tian Guo'],"In many data-driven applications, collecting data from different sources is
increasingly desirable for enhancing performance. In this paper, we are
interested in the problem of probabilistic forecasting with multi-source time
series. We propose a neural mixture structure-based probability model for
learning different predictive relations and their adaptive combinations from
multi-source time series. We present the prediction and uncertainty
quantification methods that apply to different distributions of target
variables. Additionally, given the imbalanced and unstable behaviors observed
during the direct training of the proposed mixture model, we develop a phased
learning method and provide a theoretical analysis. In experimental
evaluations, the mixture model trained by the phased learning exhibits
competitive performance on both point and probabilistic prediction metrics.
Meanwhile, the proposed uncertainty conditioned error suggests the potential of
the mixture model's uncertainty score as a reliability indicator of
predictions.",http://arxiv.org/pdf/2302.11078v1,cs.LG
2023-02-21 07:38:46+00:00,Creating Disasters: Recession Forecasting with GAN-Generated Synthetic Time Series Data,['Sam Dannels'],"A common problem when forecasting rare events, such as recessions, is limited
data availability. Recent advancements in deep learning and generative
adversarial networks (GANs) make it possible to produce high-fidelity synthetic
data in large quantities. This paper uses a model called DoppelGANger, a GAN
tailored to producing synthetic time series data, to generate synthetic
Treasury yield time series and associated recession indicators. It is then
shown that short-range forecasting performance for Treasury yields is improved
for models trained on synthetic data relative to models trained only on real
data. Finally, synthetic recession conditions are produced and used to train
classification models to predict the probability of a future recession. It is
shown that training models on synthetic recessions can improve a model's
ability to predict future recessions over a model trained only on real data.",http://arxiv.org/pdf/2302.10490v1,cs.LG
2023-02-20 22:25:47+00:00,Online Evolutionary Neural Architecture Search for Multivariate Non-Stationary Time Series Forecasting,"['Zimeng Lyu', 'Alexander Ororbia', 'Travis Desell']","Time series forecasting (TSF) is one of the most important tasks in data
science given the fact that accurate time series (TS) predictive models play a
major role across a wide variety of domains including finance, transportation,
health care, and power systems. Real-world utilization of machine learning (ML)
typically involves (pre-)training models on collected, historical data and then
applying them to unseen data points. However, in real-world applications, time
series data streams are usually non-stationary and trained ML models usually,
over time, face the problem of data or concept drift.
  To address this issue, models must be periodically retrained or redesigned,
which takes significant human and computational resources. Additionally,
historical data may not even exist to re-train or re-design model with. As a
result, it is highly desirable that models are designed and trained in an
online fashion. This work presents the Online NeuroEvolution-based Neural
Architecture Search (ONE-NAS) algorithm, which is a novel neural architecture
search method capable of automatically designing and dynamically training
recurrent neural networks (RNNs) for online forecasting tasks. Without any
pre-training, ONE-NAS utilizes populations of RNNs that are continuously
updated with new network structures and weights in response to new multivariate
input data. ONE-NAS is tested on real-world, large-scale multivariate wind
turbine data as well as the univariate Dow Jones Industrial Average (DJIA)
dataset. Results demonstrate that ONE-NAS outperforms traditional statistical
time series forecasting methods, including online linear regression, fixed long
short-term memory (LSTM) and gated recurrent unit (GRU) models trained online,
as well as state-of-the-art, online ARIMA strategies.",http://arxiv.org/pdf/2302.10347v1,cs.LG
2023-02-20 07:46:14+00:00,FormerTime: Hierarchical Multi-Scale Representations for Multivariate Time Series Classification,"['Mingyue Cheng', 'Qi Liu', 'Zhiding Liu', 'Zhi Li', 'Yucong Luo', 'Enhong Chen']","Deep learning-based algorithms, e.g., convolutional networks, have
significantly facilitated multivariate time series classification (MTSC) task.
Nevertheless, they suffer from the limitation in modeling long-range dependence
due to the nature of convolution operations. Recent advancements have shown the
potential of transformers to capture long-range dependence. However, it would
incur severe issues, such as fixed scale representations, temporal-invariant
and quadratic time complexity, with transformers directly applicable to the
MTSC task because of the distinct properties of time series data. To tackle
these issues, we propose FormerTime, an hierarchical representation model for
improving the classification capacity for the MTSC task. In the proposed
FormerTime, we employ a hierarchical network architecture to perform
multi-scale feature maps. Besides, a novel transformer encoder is further
designed, in which an efficient temporal reduction attention layer and a
well-informed contextual positional encoding generating strategy are developed.
To sum up, FormerTime exhibits three aspects of merits: (1) learning
hierarchical multi-scale representations from time series data, (2) inheriting
the strength of both transformers and convolutional networks, and (3) tacking
the efficiency challenges incurred by the self-attention mechanism. Extensive
experiments performed on $10$ publicly available datasets from UEA archive
verify the superiorities of the FormerTime compared to previous competitive
baselines.",http://arxiv.org/pdf/2302.09818v1,cs.LG
2023-02-18 11:25:42+00:00,FrAug: Frequency Domain Augmentation for Time Series Forecasting,"['Muxi Chen', 'Zhijian Xu', 'Ailing Zeng', 'Qiang Xu']","Data augmentation (DA) has become a de facto solution to expand training data
size for deep learning. With the proliferation of deep models for time series
analysis, various time series DA techniques are proposed in the literature,
e.g., cropping-, warping-, flipping-, and mixup-based methods. However, these
augmentation methods mainly apply to time series classification and anomaly
detection tasks. In time series forecasting (TSF), we need to model the
fine-grained temporal relationship within time series segments to generate
accurate forecasting results given data in a look-back window. Existing DA
solutions in the time domain would break such a relationship, leading to poor
forecasting accuracy. To tackle this problem, this paper proposes simple yet
effective frequency domain augmentation techniques that ensure the semantic
consistency of augmented data-label pairs in forecasting, named FrAug. We
conduct extensive experiments on eight widely-used benchmarks with several
state-of-the-art TSF deep models. Our results show that FrAug can boost the
forecasting accuracy of TSF models in most cases. Moreover, we show that FrAug
enables models trained with 1\% of the original training data to achieve
similar performance to the ones trained on full training data, which is
particularly attractive for cold-start forecasting. Finally, we show that
applying test-time training with FrAug greatly improves forecasting accuracy
for time series with significant distribution shifts, which often occurs in
real-life TSF applications. Our code is available at
https://anonymous.4open.science/r/Fraug-more-results-1785.",http://arxiv.org/pdf/2302.09292v1,cs.LG
2023-02-17 16:51:07+00:00,On automated identification in singular spectrum analysis for different types of objects,"['Nina Golyandina', 'Polina Zhornikova']","Approaches to automated grouping in singular spectrum analysis are
considered. A new method for the identification of periodic components is
proposed. The possibilities of extensions to multivariate time series and
images are discussed.",http://arxiv.org/pdf/2302.08993v1,stat.ME
2023-02-17 10:54:13+00:00,Graphical estimation of multivariate count time series,"['Sathish Vurukonda', 'Debraj Chakraborty', 'Siuli Mukhopadhyay']","The problems of selecting partial correlation and causality graphs for count
data are considered. A parameter driven generalized linear model is used to
describe the observed multivariate time series of counts. Partial correlation
and causality graphs corresponding to this model explain the dependencies
between each time series of the multivariate count data. In order to estimate
these graphs with tunable sparsity, an appropriate likelihood function
maximization is regularized with an l1-type constraint. A novel MCEM algorithm
is proposed to iteratively solve this regularized MLE. Asymptotic convergence
results are proved for the sequence generated by the proposed MCEM algorithm
with l1-type regularization. The algorithm is first successfully tested on
simulated data. Thereafter, it is applied to observed weekly dengue disease
counts from each ward of Greater Mumbai city. The interdependence of various
wards in the proliferation of the disease is characterized by the edges of the
inferred partial correlation graph. On the other hand, the relative roles of
various wards as sources and sinks of dengue spread is quantified by the number
and weights of the directed edges originating from and incident upon each ward.
From these estimated graphs, it is observed that some special wards act as
epicentres of dengue spread even though their disease counts are relatively
low.",http://arxiv.org/pdf/2302.08801v1,stat.ML
2023-02-17 10:09:22+00:00,Forecasting with Deep Learning,['Gissel Velarde'],"This paper presents a method for time series forecasting with deep learning
and its assessment on two datasets. The method starts with data preparation,
followed by model training and evaluation. The final step is a visual
inspection. Experimental work demonstrates that a single time series can be
used to train deep learning networks if time series in a dataset contain
patterns that repeat even with a certain variation. However, for less
structured time series such as stock market closing prices, the networks
perform just like a baseline that repeats the last observed value. The
implementation of the method as well as the experiments are open-source.",http://arxiv.org/pdf/2302.12027v1,cs.LG
2023-02-15 07:23:48+00:00,Excess risk bound for deep learning under weak dependence,['William Kengne'],"This paper considers deep neural networks for learning weakly dependent
processes in a general framework that includes, for instance, regression
estimation, time series prediction, time series classification. The $\psi$-weak
dependence structure considered is quite large and covers other conditions such
as mixing, association,$\ldots$ Firstly, the approximation of smooth functions
by deep neural networks with a broad class of activation functions is
considered. We derive the required depth, width and sparsity of a deep neural
network to approximate any H\""{o}lder smooth function, defined on any compact
set $\mx$. Secondly, we establish a bound of the excess risk for the learning
of weakly dependent observations by deep neural networks. When the target
function is sufficiently smooth, this bound is close to the usual
$\mathcal{O}(n^{-1/2})$.",http://arxiv.org/pdf/2302.07503v1,stat.ML
2023-02-15 04:16:34+00:00,CUTS: Neural Causal Discovery from Irregular Time-Series Data,"['Yuxiao Cheng', 'Runzhao Yang', 'Tingxiong Xiao', 'Zongren Li', 'Jinli Suo', 'Kunlun He', 'Qionghai Dai']","Causal discovery from time-series data has been a central task in machine
learning. Recently, Granger causality inference is gaining momentum due to its
good explainability and high compatibility with emerging deep neural networks.
However, most existing methods assume structured input data and degenerate
greatly when encountering data with randomly missing entries or non-uniform
sampling frequencies, which hampers their applications in real scenarios. To
address this issue, here we present CUTS, a neural Granger causal discovery
algorithm to jointly impute unobserved data points and build causal graphs, via
plugging in two mutually boosting modules in an iterative framework: (i) Latent
data prediction stage: designs a Delayed Supervision Graph Neural Network
(DSGNN) to hallucinate and register unstructured data which might be of high
dimension and with complex distribution; (ii) Causal graph fitting stage:
builds a causal adjacency matrix with imputed data under sparse penalty.
Experiments show that CUTS effectively infers causal graphs from unstructured
time-series data, with significantly superior performance to existing methods.
Our approach constitutes a promising step towards applying causal discovery to
real applications with non-ideal observations.",http://arxiv.org/pdf/2302.07458v1,cs.LG
2023-02-13 15:12:15+00:00,Label-efficient Time Series Representation Learning: A Review,"['Emadeldeen Eldele', 'Mohamed Ragab', 'Zhenghua Chen', 'Min Wu', 'Chee-Keong Kwoh', 'Xiaoli Li']","The scarcity of labeled data is one of the main challenges of applying deep
learning models on time series data in the real world. Therefore, several
approaches, e.g., transfer learning, self-supervised learning, and
semi-supervised learning, have been recently developed to promote the learning
capability of deep learning models from the limited time series labels. In this
survey, for the first time, we provide a novel taxonomy to categorize existing
approaches that address the scarcity of labeled data problem in time series
data based on their dependency on external data sources. Moreover, we present a
review of the recent advances in each approach and conclude the limitations of
the current works and provide future directions that could yield better
progress in the field.",http://arxiv.org/pdf/2302.06433v2,cs.LG
2023-02-10 16:03:36+00:00,Deep Imputation of Missing Values in Time Series Health Data: A Review with Benchmarking,"['Maksims Kazijevs', 'Manar D. Samad']","The imputation of missing values in multivariate time series (MTS) data is
critical in ensuring data quality and producing reliable data-driven predictive
models. Apart from many statistical approaches, a few recent studies have
proposed state-of-the-art deep learning methods to impute missing values in MTS
data. However, the evaluation of these deep methods is limited to one or two
data sets, low missing rates, and completely random missing value types. This
survey performs six data-centric experiments to benchmark state-of-the-art deep
imputation methods on five time series health data sets. Our extensive analysis
reveals that no single imputation method outperforms the others on all five
data sets. The imputation performance depends on data types, individual
variable statistics, missing value rates, and types. Deep learning methods that
jointly perform cross-sectional (across variables) and longitudinal (across
time) imputations of missing values in time series data yield statistically
better data quality than traditional imputation methods. Although
computationally expensive, deep learning methods are practical given the
current availability of high-performance computing resources, especially when
data quality and sample size are highly important in healthcare informatics.
Our findings highlight the importance of data-centric selection of imputation
methods to optimize data-driven predictive models.",http://arxiv.org/pdf/2302.10902v2,cs.LG
2023-02-10 10:34:59+00:00,Time-varying correlation network analysis of non-stationary multivariate time series with complex trends,"['Lujia Bai', 'Weichi Wu']","This paper proposes a flexible framework for inferring large-scale
time-varying and time-lagged correlation networks from multivariate or
high-dimensional non-stationary time series with piecewise smooth trends. Built
on a novel and unified multiple-testing procedure of time-lagged
cross-correlation functions with a fixed or diverging number of lags, our
method can accurately disclose flexible time-varying network structures
associated with complex functional structures at all time points. We broaden
the applicability of our method to the structure breaks by developing
difference-based nonparametric estimators of cross-correlations, achieve
accurate family-wise error control via a bootstrap-assisted procedure adaptive
to the complex temporal dynamics, and enhance the probability of recovering the
time-varying network structures using a new uniform variance reduction
technique. We prove the asymptotic validity of the proposed method and
demonstrate its effectiveness in finite samples through simulation studies and
empirical applications.",http://arxiv.org/pdf/2302.05158v1,stat.ME
2023-02-10 02:30:31+00:00,ShapeWordNet: An Interpretable Shapelet Neural Network for Physiological Signal Classification,"['Wenqiang He', 'Mingyue Cheng', 'Qi Liu', 'Zhi Li']","Physiological signals are high-dimensional time series of great practical
values in medical and healthcare applications. However, previous works on its
classification fail to obtain promising results due to the intractable data
characteristics and the severe label sparsity issues. In this paper, we try to
address these challenges by proposing a more effective and interpretable scheme
tailored for the physiological signal classification task. Specifically, we
exploit the time series shapelets to extract prominent local patterns and
perform interpretable sequence discretization to distill the whole-series
information. By doing so, the long and continuous raw signals are compressed
into short and discrete token sequences, where both local patterns and global
contexts are well preserved. Moreover, to alleviate the label sparsity issue, a
multi-scale transformation strategy is adaptively designed to augment data and
a cross-scale contrastive learning mechanism is accordingly devised to guide
the model training. We name our method as ShapeWordNet and conduct extensive
experiments on three real-world datasets to investigate its effectiveness.
Comparative results show that our proposed scheme remarkably outperforms four
categories of cutting-edge approaches. Visualization analysis further witnesses
the good interpretability of the sequence discretization idea based on
shapelets.",http://arxiv.org/pdf/2302.05021v1,cs.LG
2023-02-09 08:52:49+00:00,MTS-Mixers: Multivariate Time Series Forecasting via Factorized Temporal and Channel Mixing,"['Zhe Li', 'Zhongwen Rao', 'Lujia Pan', 'Zenglin Xu']","Multivariate time series forecasting has been widely used in various
practical scenarios. Recently, Transformer-based models have shown significant
potential in forecasting tasks due to the capture of long-range dependencies.
However, recent studies in the vision and NLP fields show that the role of
attention modules is not clear, which can be replaced by other token
aggregation operations. This paper investigates the contributions and
deficiencies of attention mechanisms on the performance of time series
forecasting. Specifically, we find that (1) attention is not necessary for
capturing temporal dependencies, (2) the entanglement and redundancy in the
capture of temporal and channel interaction affect the forecasting performance,
and (3) it is important to model the mapping between the input and the
prediction sequence. To this end, we propose MTS-Mixers, which use two
factorized modules to capture temporal and channel dependencies. Experimental
results on several real-world datasets show that MTS-Mixers outperform existing
Transformer-based models with higher efficiency.",http://arxiv.org/pdf/2302.04501v1,cs.LG
2023-02-08 14:46:24+00:00,ASTRIDE: Adaptive Symbolization for Time Series Databases,"['Sylvain W. Combettes', 'Charles Truong', 'Laurent Oudre']","We introduce ASTRIDE (Adaptive Symbolization for Time seRIes DatabasEs), a
novel symbolic representation of time series, along with its accelerated
variant FASTRIDE (Fast ASTRIDE). Unlike most symbolization procedures, ASTRIDE
is adaptive during both the segmentation step by performing change-point
detection and the quantization step by using quantiles. Instead of proceeding
signal by signal, ASTRIDE builds a dictionary of symbols that is common to all
signals in a data set. We also introduce D-GED (Dynamic General Edit Distance),
a novel similarity measure on symbolic representations based on the general
edit distance. We demonstrate the performance of the ASTRIDE and FASTRIDE
representations compared to SAX (Symbolic Aggregate approXimation), 1d-SAX, SFA
(Symbolic Fourier Approximation), and ABBA (Adaptive Brownian Bridge-based
Aggregation) on reconstruction and, when applicable, on classification tasks.
These algorithms are evaluated on 86 univariate equal-size data sets from the
UCR Time Series Classification Archive. An open source GitHub repository called
astride is made available to reproduce all the experiments in Python.",http://arxiv.org/pdf/2302.04097v1,cs.LG
2023-02-08 14:18:56+00:00,Taming Local Effects in Graph-based Spatiotemporal Forecasting,"['Andrea Cini', 'Ivan Marisca', 'Daniele Zambon', 'Cesare Alippi']","Spatiotemporal graph neural networks have shown to be effective in time
series forecasting applications, achieving better performance than standard
univariate predictors in several settings. These architectures take advantage
of a graph structure and relational inductive biases to learn a single (global)
inductive model to predict any number of the input time series, each associated
with a graph node. Despite the gain achieved in computational and data
efficiency w.r.t. fitting a set of local models, relying on a single global
model can be a limitation whenever some of the time series are generated by a
different spatiotemporal stochastic process. The main objective of this paper
is to understand the interplay between globality and locality in graph-based
spatiotemporal forecasting, while contextually proposing a methodological
framework to rationalize the practice of including trainable node embeddings in
such architectures. We ascribe to trainable node embeddings the role of
amortizing the learning of specialized components. Moreover, embeddings allow
for 1) effectively combining the advantages of shared message-passing layers
with node-specific parameters and 2) efficiently transferring the learned model
to new node sets. Supported by strong empirical evidence, we provide insights
and guidelines for specializing graph-based models to the dynamics of each time
series and show how this aspect plays a crucial role in obtaining accurate
predictions.",http://arxiv.org/pdf/2302.04071v1,cs.LG
2023-02-08 13:44:36+00:00,Finding Short Signals in Long Irregular Time Series with Continuous-Time Attention Policy Networks,"['Thomas Hartvigsen', 'Jidapa Thadajarassiri', 'Xiangnan Kong', 'Elke Rundensteiner']","Irregularly-sampled time series (ITS) are native to high-impact domains like
healthcare, where measurements are collected over time at uneven intervals.
However, for many classification problems, only small portions of long time
series are often relevant to the class label. In this case, existing ITS models
often fail to classify long series since they rely on careful imputation, which
easily over- or under-samples the relevant regions. Using this insight, we then
propose CAT, a model that classifies multivariate ITS by explicitly seeking
highly-relevant portions of an input series' timeline. CAT achieves this by
integrating three components: (1) A Moment Network learns to seek relevant
moments in an ITS's continuous timeline using reinforcement learning. (2) A
Receptor Network models the temporal dynamics of both observations and their
timing localized around predicted moments. (3) A recurrent Transition Model
models the sequence of transitions between these moments, cultivating a
representation with which the series is classified. Using synthetic and real
data, we find that CAT outperforms ten state-of-the-art methods by finding
short signals in long irregular time series.",http://arxiv.org/pdf/2302.04052v1,cs.LG
2023-02-08 03:26:50+00:00,DeepVATS: Deep Visual Analytics for Time Series,"['Victor Rodriguez-Fernandez', 'David Montalvo', 'Francesco Piccialli', 'Grzegorz J. Nalepa', 'David Camacho']","The field of Deep Visual Analytics (DVA) has recently arisen from the idea of
developing Visual Interactive Systems supported by deep learning, in order to
provide them with large-scale data processing capabilities and to unify their
implementation across different data and domains. In this paper we present
DeepVATS, an open-source tool that brings the field of DVA into time series
data. DeepVATS trains, in a self-supervised way, a masked time series
autoencoder that reconstructs patches of a time series, and projects the
knowledge contained in the embeddings of that model in an interactive plot,
from which time series patterns and anomalies emerge and can be easily spotted.
The tool includes a back-end for data processing pipeline and model training,
as well as a front-end with a interactive user interface. We report on results
that validate the utility of DeepVATS, running experiments on both synthetic
and real datasets. The code is publicly available on
https://github.com/vrodriguezf/deepvats",http://arxiv.org/pdf/2302.03858v2,cs.LG
2023-02-07 10:02:05+00:00,Towards Better Time Series Contrastive Learning: A Dynamic Bad Pair Mining Approach,"['Xiang Lan', 'Hanshu Yan', 'Shenda Hong', 'Mengling Feng']","Not all positive pairs are beneficial to time series contrastive learning. In
this paper, we study two types of bad positive pairs that impair the quality of
time series representation learned through contrastive learning ($i.e.$, noisy
positive pair and faulty positive pair). We show that, with the presence of
noisy positive pairs, the model tends to simply learn the pattern of noise
(Noisy Alignment). Meanwhile, when faulty positive pairs arise, the model
spends considerable efforts aligning non-representative patterns (Faulty
Alignment). To address this problem, we propose a Dynamic Bad Pair Mining
(DBPM) algorithm, which reliably identifies and suppresses bad positive pairs
in time series contrastive learning. DBPM utilizes a memory module to track the
training behavior of each positive pair along training process. This allows us
to identify potential bad positive pairs at each epoch based on their
historical training behaviors. The identified bad pairs are then down-weighted
using a transformation module. Our experimental results show that DBPM
effectively mitigates the negative impacts of bad pairs, and can be easily used
as a plug-in to boost performance of state-of-the-art methods. Codes will be
made publicly available.",http://arxiv.org/pdf/2302.03357v1,cs.LG
2023-02-07 06:33:07+00:00,Unsupervised Deep Learning for IoT Time Series,"['Ya Liu', 'Yingjie Zhou', 'Kai Yang', 'Xin Wang']","IoT time series analysis has found numerous applications in a wide variety of
areas, ranging from health informatics to network security. Nevertheless, the
complex spatial temporal dynamics and high dimensionality of IoT time series
make the analysis increasingly challenging. In recent years, the powerful
feature extraction and representation learning capabilities of deep learning
(DL) have provided an effective means for IoT time series analysis. However,
few existing surveys on time series have systematically discussed unsupervised
DL-based methods. To fill this void, we investigate unsupervised deep learning
for IoT time series, i.e., unsupervised anomaly detection and clustering, under
a unified framework. We also discuss the application scenarios, public
datasets, existing challenges, and future research directions in this area.",http://arxiv.org/pdf/2302.03284v3,cs.LG
2023-02-07 04:13:48+00:00,CDANs: Temporal Causal Discovery from Autocorrelated and Non-Stationary Time Series Data,"['Muhammad Hasan Ferdous', 'Uzma Hasan', 'Md Osman Gani']","Time series data are found in many areas of healthcare such as medical time
series, electronic health records (EHR), measurements of vitals, and wearable
devices. Causal discovery, which involves estimating causal relationships from
observational data, holds the potential to play a significant role in
extracting actionable insights about human health. In this study, we present a
novel constraint-based causal discovery approach for autocorrelated and
non-stationary time series data (CDANs). Our proposed method addresses several
limitations of existing causal discovery methods for autocorrelated and
non-stationary time series data, such as high dimensionality, the inability to
identify lagged causal relationships, and overlooking changing modules. Our
approach identifies lagged and instantaneous/contemporaneous causal
relationships along with changing modules that vary over time. The method
optimizes the conditioning sets in a constraint-based search by considering
lagged parents instead of conditioning on the entire past that addresses high
dimensionality. The changing modules are detected by considering both
contemporaneous and lagged parents. The approach first detects the lagged
adjacencies, then identifies the changing modules and contemporaneous
adjacencies, and finally determines the causal direction. We extensively
evaluated our proposed method on synthetic and real-world clinical datasets,
and compared its performance with several baseline approaches. The experimental
results demonstrate the effectiveness of the proposed method in detecting
causal relationships and changing modules for autocorrelated and non-stationary
time series data.",http://arxiv.org/pdf/2302.03246v2,cs.LG
2023-02-07 02:21:35+00:00,Multivariate Bayesian dynamic modeling for causal prediction,"['Graham Tierney', 'Christoph Hellmayr', 'Greg Barkimer', 'Mike West']","Bayesian dynamic modeling and forecasting is developed in the setting of
sequential time series analysis for causal inference. Causal evaluation of
sequentially observed time series data from control and treated units focuses
on the impacts of interventions using synthetic control constructs.
Methodological contributions include the development of multivariate dynamic
models for time-varying effects across multiple treated units and explicit foci
on sequential learning of effects of interventions. Analysis explores the
utility of dimension reduction of multiple potential synthetic control
variables. These methodological advances are evaluated in a detailed case study
in commercial forecasting. This involves in-study evaluation of interventions
in a supermarket promotions experiment, with coupled predictive analyses in
selected regions of a large-scale commercial system. Generalization of causal
predictive inferences from experimental settings to broader populations is a
central concern, and one that can be impacted by cross-series dependencies.",http://arxiv.org/pdf/2302.03200v1,stat.ME
2023-02-06 21:46:19+00:00,Domain Adaptation for Time Series Under Feature and Label Shifts,"['Huan He', 'Owen Queen', 'Teddy Koker', 'Consuelo Cuevas', 'Theodoros Tsiligkaridis', 'Marinka Zitnik']","Unsupervised domain adaptation (UDA) enables the transfer of models trained
on source domains to unlabeled target domains. However, transferring complex
time series models presents challenges due to the dynamic temporal structure
variations across domains. This leads to feature shifts in the time and
frequency representations. Additionally, the label distributions of tasks in
the source and target domains can differ significantly, posing difficulties in
addressing label shifts and recognizing labels unique to the target domain.
Effectively transferring complex time series models remains a formidable
problem. We present Raincoat, the first model for both closed-set and universal
domain adaptation on complex time series. Raincoat addresses feature and label
shifts by considering both temporal and frequency features, aligning them
across domains, and correcting for misalignments to facilitate the detection of
private labels. Additionally, Raincoat improves transferability by identifying
label shifts in target domains. Our experiments with 5 datasets and 13
state-of-the-art UDA methods demonstrate that Raincoat can improve transfer
learning performance by up to 16.33% and can handle both closed-set and
universal domain adaptation.",http://arxiv.org/pdf/2302.03133v2,cs.LG
2023-02-06 21:43:39+00:00,Importance attribution in neural networks by means of persistence landscapes of time series,"['Aina Ferrà', 'Carles Casacuberta', 'Oriol Pujol']","We propose and implement a method to analyze time series with a neural
network using a matrix of area-normalized persistence landscapes obtained
through topological data analysis. We include a gating layer in the network's
architecture that is able to identify the most relevant landscape levels for
the classification task, thus working as an importance attribution system.
Next, we perform a matching between the selected landscape functions and the
corresponding critical points of the original time series. From this matching
we are able to reconstruct an approximate shape of the time series that gives
insight into the classification decision. We test this technique with input
data from a dataset of electrocardiographic signals.",http://arxiv.org/pdf/2302.03132v1,cs.LG
2023-02-06 08:21:21+00:00,On the asymptotic behavior of a finite-section of the optimal causal filter,['Junho Yang'],"We establish an $L_1$-bound between the coefficients of the optimal causal
filter applied to the data-generating process and its finite sample
approximation. Here, we assume that the data-generating process is a
second-order stationary time series with either short or long memory
autocovariances. To derive the $L_1$-bound, we first provide an exact
expression for the coefficients of the causal filter and their approximations
in terms of the absolute convergent series of the multistep ahead infinite and
finite predictor coefficients, respectively. Then, we prove a so-called uniform
Baxter's inequality to obtain a bound for the difference between the infinite
and finite multistep ahead predictor coefficients in both short and memory time
series. The $L_1$-approximation error bound for the causal filter coefficients
can be used to evaluate the performance of the linear predictions of time
series through the mean squared error criterion.",http://arxiv.org/pdf/2302.02613v3,math.ST
2023-02-06 01:01:00+00:00,Deep Learning for Time Series Classification and Extrinsic Regression: A Current Survey,"['Navid Mohammadi Foumani', 'Lynn Miller', 'Chang Wei Tan', 'Geoffrey I. Webb', 'Germain Forestier', 'Mahsa Salehi']","Time Series Classification and Extrinsic Regression are important and
challenging machine learning tasks. Deep learning has revolutionized natural
language processing and computer vision and holds great promise in other fields
such as time series analysis where the relevant features must often be
abstracted from the raw data but are not known a priori. This paper surveys the
current state of the art in the fast-moving field of deep learning for time
series classification and extrinsic regression. We review different network
architectures and training methods used for these tasks and discuss the
challenges and opportunities when applying deep learning to time series data.
We also summarize two critical applications of time series classification and
extrinsic regression, human activity recognition and satellite earth
observation.",http://arxiv.org/pdf/2302.02515v1,cs.LG
2023-02-05 20:27:09+00:00,Estimating Time-Varying Networks for High-Dimensional Time Series,"['Jia Chen', 'Degui Li', 'Yuning Li', 'Oliver Linton']","We explore time-varying networks for high-dimensional locally stationary time
series, using the large VAR model framework with both the transition and
(error) precision matrices evolving smoothly over time. Two types of
time-varying graphs are investigated: one containing directed edges of Granger
causality linkages, and the other containing undirected edges of partial
correlation linkages. Under the sparse structural assumption, we propose a
penalised local linear method with time-varying weighted group LASSO to jointly
estimate the transition matrices and identify their significant entries, and a
time-varying CLIME method to estimate the precision matrices. The estimated
transition and precision matrices are then used to determine the time-varying
network structures. Under some mild conditions, we derive the theoretical
properties of the proposed estimates including the consistency and oracle
properties. In addition, we extend the methodology and theory to cover
highly-correlated large-scale time series, for which the sparsity assumption
becomes invalid and we allow for common factors before estimating the
factor-adjusted time-varying networks. We provide extensive simulation studies
and an empirical application to a large U.S. macroeconomic dataset to
illustrate the finite-sample performance of our methods.",http://arxiv.org/pdf/2302.02476v1,stat.ME
2023-02-04 14:33:07+00:00,A Survey on Deep Learning based Time Series Analysis with Frequency Transformation,"['Kun Yi', 'Qi Zhang', 'Longbing Cao', 'Shoujin Wang', 'Guodong Long', 'Liang Hu', 'Hui He', 'Zhendong Niu', 'Wei Fan', 'Hui Xiong']","Recently, frequency transformation (FT) has been increasingly incorporated
into deep learning models to significantly enhance state-of-the-art accuracy
and efficiency in time series analysis. The advantages of FT, such as high
efficiency and a global view, have been rapidly explored and exploited in
various time series tasks and applications, demonstrating the promising
potential of FT as a new deep learning paradigm for time series analysis.
Despite the growing attention and the proliferation of research in this
emerging field, there is currently a lack of a systematic review and in-depth
analysis of deep learning-based time series models with FT. It is also unclear
why FT can enhance time series analysis and what its limitations in the field
are. To address these gaps, we present a comprehensive review that
systematically investigates and summarizes the recent research advancements in
deep learning-based time series analysis with FT. Specifically, we explore the
primary approaches used in current models that incorporate FT, the types of
neural networks that leverage FT, and the representative FT-equipped models in
deep time series analysis. We propose a novel taxonomy to categorize the
existing methods in this field, providing a structured overview of the diverse
approaches employed in incorporating FT into deep learning models for time
series analysis. Finally, we highlight the advantages and limitations of FT for
time series modeling and identify potential future research directions that can
further contribute to the community of time series analysis.",http://arxiv.org/pdf/2302.02173v4,cs.LG
2023-02-04 03:22:16+00:00,Cross-Frequency Time Series Meta-Forecasting,"['Mike Van Ness', 'Huibin Shen', 'Hao Wang', 'Xiaoyong Jin', 'Danielle C. Maddix', 'Karthick Gopalswamy']","Meta-forecasting is a newly emerging field which combines meta-learning and
time series forecasting. The goal of meta-forecasting is to train over a
collection of source time series and generalize to new time series
one-at-a-time. Previous approaches in meta-forecasting achieve competitive
performance, but with the restriction of training a separate model for each
sampling frequency. In this work, we investigate meta-forecasting over
different sampling frequencies, and introduce a new model, the Continuous
Frequency Adapter (CFA), specifically designed to learn frequency-invariant
representations. We find that CFA greatly improves performance when
generalizing to unseen frequencies, providing a first step towards forecasting
over larger multi-frequency datasets.",http://arxiv.org/pdf/2302.02077v1,cs.LG
2023-02-04 01:27:01+00:00,Multivariate Time Series Anomaly Detection via Dynamic Graph Forecasting,"['Katrina Chen', 'Mingbin Feng', 'Tony S. Wirjanto']","Anomalies in univariate time series often refer to abnormal values and
deviations from the temporal patterns from majority of historical observations.
In multivariate time series, anomalies also refer to abnormal changes in the
inter-series relationship, such as correlation, over time. Existing studies
have been able to model such inter-series relationships through graph neural
networks. However, most works settle on learning a static graph globally or
within a context window to assist a time series forecasting task or a
reconstruction task, whose objective is not tailored to explicitly detect the
abnormal relationship. Some other works detect anomalies based on
reconstructing or forecasting a list of inter-series graphs, which
inadvertently weakens their power to capture temporal patterns within the data
due to the discrete nature of graphs. In this study, we propose DyGraphAD, a
multivariate time series anomaly detection framework based upon a list of
dynamic inter-series graphs. The core idea is to detect anomalies based on the
deviation of inter-series relationships and intra-series temporal patterns from
normal to anomalous states, by leveraging the evolving nature of the graphs in
order to assist a graph forecasting task and a time series forecasting task
simultaneously. Our numerical experiments on real-world datasets demonstrate
that DyGraphAD has superior performance than baseline anomaly detection
approaches.",http://arxiv.org/pdf/2302.02051v1,cs.LG
2023-02-03 09:10:31+00:00,dynamite: An R Package for Dynamic Multivariate Panel Models,"['Santtu Tikka', 'Jouni Helske']","dynamite is an R package for Bayesian inference of intensive panel (time
series) data comprising of multiple measurements per multiple individuals
measured in time. The package supports joint modeling of multiple response
variables, time-varying and time-invariant effects, a wide range of discrete
and continuous distributions, group-specific random effects, latent factors,
and customization of prior distributions of the model parameters. Models in the
package are defined via a user-friendly formula interface, and estimation of
the posterior distribution of the model parameters takes advantage of
state-of-the-art Markov chain Monte Carlo methods. The package enables
efficient computation of both individual-level and summarized predictions and
offers a comprehensive suite of tools for visualization and model diagnostics.",http://arxiv.org/pdf/2302.01607v1,stat.ME
2023-02-02 04:12:29+00:00,SimMTM: A Simple Pre-Training Framework for Masked Time-Series Modeling,"['Jiaxiang Dong', 'Haixu Wu', 'Haoran Zhang', 'Li Zhang', 'Jianmin Wang', 'Mingsheng Long']","Time series analysis is widely used in extensive areas. Recently, to reduce
labeling expenses and benefit various tasks, self-supervised pre-training has
attracted immense interest. One mainstream paradigm is masked modeling, which
successfully pre-trains deep models by learning to reconstruct the masked
content based on the unmasked part. However, since the semantic information of
time series is mainly contained in temporal variations, the standard way of
randomly masking a portion of time points will seriously ruin vital temporal
variations of time series, making the reconstruction task too difficult to
guide representation learning. We thus present SimMTM, a Simple pre-training
framework for Masked Time-series Modeling. By relating masked modeling to
manifold learning, SimMTM proposes to recover masked time points by the
weighted aggregation of multiple neighbors outside the manifold, which eases
the reconstruction task by assembling ruined but complementary temporal
variations from multiple masked series. SimMTM further learns to uncover the
local structure of the manifold, which is helpful for masked modeling.
Experimentally, SimMTM achieves state-of-the-art fine-tuning performance
compared to the most advanced time series pre-training methods in two canonical
time series analysis tasks: forecasting and classification, covering both in-
and cross-domain settings.",http://arxiv.org/pdf/2302.00861v4,cs.LG
2023-02-01 22:24:49+00:00,Monitoring the risk of a tailings dam collapse through spectral analysis of satellite InSAR time-series data,"['Sourav Das', 'Anuradha Priyadarshana', 'Stephen Grebby']","Slope failures possess destructive power that can cause significant damage to
both life and infrastructure. Monitoring slopes prone to instabilities is
therefore critical in mitigating the risk posed by their failure. The purpose
of slope monitoring is to detect precursory signs of stability issues, such as
changes in the rate of displacement with which a slope is deforming. This
information can then be used to predict the timing or probability of an
imminent failure in order to provide an early warning. In this study, a more
objective, statistical-learning algorithm is proposed to detect and
characterise the risk of a slope failure, based on spectral analysis of
serially correlated displacement time series data. The algorithm is applied to
satellite-based interferometric synthetic radar (InSAR) displacement time
series data to retrospectively analyse the risk of the 2019 Brumadinho tailings
dam collapse in Brazil. Two potential risk milestones are identified and signs
of a definitive but emergent risk (27 February 2018 to 26 August 2018) and
imminent risk of collapse of the tailings dam (27 June 2018 to 24 December
2018) are detected by the algorithm. Importantly, this precursory indication of
risk of failure is detected as early as at least five months prior to the dam
collapse on 25 January 2019. The results of this study demonstrate that the
combination of spectral methods and second order statistical properties of
InSAR displacement time series data can reveal signs of a transition into an
unstable deformation regime, and that this algorithm can provide sufficient
early warning that could help mitigate catastrophic slope failures.",http://arxiv.org/pdf/2302.00781v2,stat.ME
2023-02-01 09:31:15+00:00,Deep learning for $ψ$-weakly dependent processes,"['William Kengne', 'Wade Modou']","In this paper, we perform deep neural networks for learning $\psi$-weakly
dependent processes. Such weak-dependence property includes a class of weak
dependence conditions such as mixing, association,$\cdots$ and the setting
considered here covers many commonly used situations such as: regression
estimation, time series prediction, time series classification,$\cdots$ The
consistency of the empirical risk minimization algorithm in the class of deep
neural networks predictors is established. We achieve the generalization bound
and obtain a learning rate, which is less than $\mathcal{O}(n^{-1/\alpha})$,
for all $\alpha > 2 $. Applications to binary time series classification and
prediction in affine causal models with exogenous covariates are carried out.
Some simulation results are provided, as well as an application to the US
recession data.",http://arxiv.org/pdf/2302.00333v1,stat.ML
2023-01-31 19:52:04+00:00,Online estimation methods for irregular autoregressive models,"['Felipe Elorrieta', 'Lucas Osses', 'Matias Cáceres', 'Susana Eyheramendy', 'Wilfredo Palma']","In the last decades, due to the huge technological growth observed, it has
become increasingly common that a collection of temporal data rapidly
accumulates in vast amounts. This provides an opportunity for extracting
valuable information through the estimation of increasingly precise models. But
at the same time it imposes the challenge of continuously updating the models
as new data become available.
  Currently available methods for addressing this problem, the so-called online
learning methods, use current parameter estimations and novel data to update
the estimators. These approaches avoid using the full raw data and speeding up
the computations.
  In this work we consider three online learning algorithms for parameters
estimation in the context of time series models. In particular, the methods
implemented are: gradient descent, Newton-step and Kalman filter recursions.
These algorithms are applied to the recently developed irregularly observed
autoregressive (iAR) model. The estimation accuracy of the proposed methods is
assessed by means of Monte Carlo experiments.
  The results obtained show that the proposed online estimation methods allow
for a precise estimation of the parameters that generate the data both for the
regularly and irregularly observed time series. These online approaches are
numerically efficient, allowing substantial computational time savings.
Moreover, we show that the proposed methods are able to adapt the parameter
estimates quickly when the time series behavior changes, unlike batch
estimation methods.",http://arxiv.org/pdf/2302.10785v1,cs.LG
2023-01-31 19:48:01+00:00,Graph-based Time-Series Anomaly Detection: A Survey,"['Thi Kieu Khanh Ho', 'Ali Karami', 'Narges Armanfard']","With the recent advances in technology, a wide range of systems continue to
collect a large amount of data over time and thus generate time series.
Time-Series Anomaly Detection (TSAD) is an important task in various
time-series applications such as e-commerce, cybersecurity, vehicle
maintenance, and healthcare monitoring. However, this task is very challenging
as it requires considering both the intra-variable dependency and the
inter-variable dependency, where a variable can be defined as an observation in
time series data. Recent graph-based approaches have made impressive progress
in tackling the challenges of this field. In this survey, we conduct a
comprehensive and up-to-date review of Graph-based TSAD (G-TSAD). First, we
explore the significant potential of graph representation learning for
time-series data. Then, we review state-of-the-art graph anomaly detection
techniques in the context of time series and discuss their strengths and
drawbacks. Finally, we discuss the technical challenges and potential future
directions for possible improvements in this research field.",http://arxiv.org/pdf/2302.00058v2,cs.LG
2023-01-31 16:12:26+00:00,"A Bayesian Generative Adversarial Network (GAN) to Generate Synthetic Time-Series Data, Application in Combined Sewer Flow Prediction","['Amin E. Bakhshipour', 'Alireza Koochali', 'Ulrich Dittmer', 'Ali Haghighi', 'Sheraz Ahmad', 'Andreas Dengel']","Despite various breakthroughs in machine learning and data analysis
techniques for improving smart operation and management of urban water
infrastructures, some key limitations obstruct this progress. Among these
shortcomings, the absence of freely available data due to data privacy or high
costs of data gathering and the nonexistence of adequate rare or extreme events
in the available data plays a crucial role. Here, Generative Adversarial
Networks (GANs) can help overcome these challenges. In machine learning,
generative models are a class of methods capable of learning data distribution
to generate artificial data. In this study, we developed a GAN model to
generate synthetic time series to balance our limited recorded time series data
and improve the accuracy of a data-driven model for combined sewer flow
prediction. We considered the sewer system of a small town in Germany as the
test case. Precipitation and inflow to the storage tanks are used for the
Data-Driven model development. The aim is to predict the flow using
precipitation data and examine the impact of data augmentation using synthetic
data in model performance. Results show that GAN can successfully generate
synthetic time series from real data distribution, which helps more accurate
peak flow prediction. However, the model without data augmentation works better
for dry weather prediction. Therefore, an ensemble model is suggested to
combine the advantages of both models.",http://arxiv.org/pdf/2301.13733v1,cs.LG
2023-01-31 10:07:23+00:00,Recurrences reveal shared causal drivers of complex time series,['William Gilpin'],"Many experimental time series measurements share unobserved causal drivers.
Examples include genes targeted by transcription factors, ocean flows
influenced by large-scale atmospheric currents, and motor circuits steered by
descending neurons. Reliably inferring this unseen driving force is necessary
to understand the intermittent nature of top-down control schemes in diverse
biological and engineered systems. Here, we introduce a new unsupervised
learning algorithm that uses recurrences in time series measurements to
gradually reconstruct an unobserved driving signal. Drawing on the mathematical
theory of skew-product dynamical systems, we identify recurrence events shared
across response time series, which implicitly define a recurrence graph with
glass-like structure. As the amount or quality of observed data improves, this
recurrence graph undergoes a percolation transition manifesting as weak
ergodicity breaking for random walks on the induced landscape -- revealing the
shared driver's dynamics, even in the presence of strongly corrupted or noisy
measurements. Across several thousand random dynamical systems, we empirically
quantify the dependence of reconstruction accuracy on the rate of information
transfer from a chaotic driver to the response systems, and we find that
effective reconstruction proceeds through gradual approximation of the driver's
dominant orbit topology. Through extensive benchmarks against classical and
neural-network-based signal processing techniques, we demonstrate our method's
strong ability to extract causal driving signals from diverse real-world
datasets spanning ecology, genomics, fluid dynamics, and physiology.",http://arxiv.org/pdf/2301.13516v2,cs.LG
2023-01-30 17:49:12+00:00,Benchmarking optimality of time series classification methods in distinguishing diffusions,"['Zehong Zhang', 'Fei Lu', 'Esther Xu Fei', 'Terry Lyons', 'Yannis Kevrekidis', 'Tom Woolf']","Statistical optimality benchmarking is crucial for analyzing and designing
time series classification (TSC) algorithms. This study proposes to benchmark
the optimality of TSC algorithms in distinguishing diffusion processes by the
likelihood ratio test (LRT). The LRT is an optimal classifier by the
Neyman-Pearson lemma. The LRT benchmarks are computationally efficient because
the LRT does not need training, and the diffusion processes can be efficiently
simulated and are flexible to reflect the specific features of real-world
applications. We demonstrate the benchmarking with three widely-used TSC
algorithms: random forest, ResNet, and ROCKET. These algorithms can achieve the
LRT optimality for univariate time series and multivariate Gaussian processes.
However, these model-agnostic algorithms are suboptimal in classifying
high-dimensional nonlinear multivariate time series. Additionally, the LRT
benchmark provides tools to analyze the dependence of classification accuracy
on the time length, dimension, temporal sampling frequency, and randomness of
the time series.",http://arxiv.org/pdf/2301.13112v3,stat.ML
2023-01-30 13:27:47+00:00,Approximating DTW with a convolutional neural network on EEG data,"['Hugo Lerogeron', 'Romain Picot-Clemente', 'Alain Rakotomamonjy', 'Laurent Heutte']","Dynamic Time Wrapping (DTW) is a widely used algorithm for measuring
similarities between two time series. It is especially valuable in a wide
variety of applications, such as clustering, anomaly detection, classification,
or video segmentation, where the time-series have different timescales, are
irregularly sampled, or are shifted. However, it is not prone to be considered
as a loss function in an end-to-end learning framework because of its
non-differentiability and its quadratic temporal complexity. While
differentiable variants of DTW have been introduced by the community, they
still present some drawbacks: computing the distance is still expensive and
this similarity tends to blur some differences in the time-series. In this
paper, we propose a fast and differentiable approximation of DTW by comparing
two architectures: the first one for learning an embedding in which the
Euclidean distance mimics the DTW, and the second one for directly predicting
the DTW output using regression. We build the former by training a siamese
neural network to regress the DTW value between two time-series. Depending on
the nature of the activation function, this approximation naturally supports
differentiation, and it is efficient to compute. We show, in a time-series
retrieval context on EEG datasets, that our methods achieve at least the same
level of accuracy as other DTW main approximations with higher computational
efficiency. We also show that it can be used to learn in an end-to-end setting
on long time series by proposing generative models of EEGs.",http://arxiv.org/pdf/2301.12873v1,cs.LG
2023-01-29 17:18:59+00:00,Time-Series Pattern Recognition in Smart Manufacturing Systems: A Literature Review and Ontology,"['Mojtaba A. Farahani', 'M. R. McCormick', 'Robert Gianinny', 'Frank Hudacheck', 'Ramy Harik', 'Zhichao Liu', 'Thorsten Wuest']","Since the inception of Industry 4.0 in 2012, emerging technologies have
enabled the acquisition of vast amounts of data from diverse sources such as
machine tools, robust and affordable sensor systems with advanced information
models, and other sources within Smart Manufacturing Systems (SMS). As a
result, the amount of data that is available in manufacturing settings has
exploded, allowing data-hungry tools such as Artificial Intelligence (AI) and
Machine Learning (ML) to be leveraged. Time-series analytics has been
successfully applied in a variety of industries, and that success is now being
migrated to pattern recognition applications in manufacturing to support higher
quality products, zero defect manufacturing, and improved customer
satisfaction. However, the diverse landscape of manufacturing presents a
challenge for successfully solving problems in industry using time-series
pattern recognition. The resulting research gap of understanding and applying
the subject matter of time-series pattern recognition in manufacturing is a
major limiting factor for adoption in industry. The purpose of this paper is to
provide a structured perspective of the current state of time-series pattern
recognition in manufacturing with a problem-solving focus. By using an ontology
to classify and define concepts, how they are structured, their properties, the
relationships between them, and considerations when applying them, this paper
aims to provide practical and actionable guidelines for application and
recommendations for advancing time-series analytics.",http://arxiv.org/pdf/2301.12495v2,cs.LG
2023-01-27 13:31:15+00:00,Effect of temporal resolution on the reproduction of chaotic dynamics via reservoir computing,"['Kohei Tsuchiyama', 'André Röhm', 'Takatomo Mihana', 'Ryoichi Horisaki', 'Makoto Naruse']","Reservoir computing is a machine learning paradigm that uses a structure
called a reservoir, which has nonlinearities and short-term memory. In recent
years, reservoir computing has expanded to new functions such as the autonomous
generation of chaotic time series, as well as time series prediction and
classification. Furthermore, novel possibilities have been demonstrated, such
as inferring the existence of previously unseen attractors. Sampling, in
contrast, has a strong influence on such functions. Sampling is indispensable
in a physical reservoir computer that uses an existing physical system as a
reservoir because the use of an external digital system for the data input is
usually inevitable. This study analyzes the effect of sampling on the ability
of reservoir computing to autonomously regenerate chaotic time series. We
found, as expected, that excessively coarse sampling degrades the system
performance, but also that excessively dense sampling is unsuitable. Based on
quantitative indicators that capture the local and global characteristics of
attractors, we identify a suitable window of the sampling frequency and discuss
its underlying mechanisms.",http://arxiv.org/pdf/2302.10761v2,cs.LG
2023-01-27 12:47:27+00:00,PrecTime: A Deep Learning Architecture for Precise Time Series Segmentation in Industrial Manufacturing Operations,"['Stefan Gaugel', 'Manfred Reichert']","The fourth industrial revolution creates ubiquitous sensor data in production
plants. To generate maximum value out of these data, reliable and precise time
series-based machine learning methods like temporal neural networks are needed.
This paper proposes a novel sequence-to-sequence deep learning architecture for
time series segmentation called PrecTime which tries to combine the concepts
and advantages of sliding window and dense labeling approaches. The
general-purpose architecture is evaluated on a real-world industry dataset
containing the End-of-Line testing sensor data of hydraulic pumps. We are able
to show that PrecTime outperforms five implemented state-of-the-art baseline
networks based on multiple metrics. The achieved segmentation accuracy of
around 96% shows that PrecTime can achieve results close to human intelligence
in operational state segmentation within a testing cycle.",http://arxiv.org/pdf/2302.10182v1,cs.LG
2023-01-27 10:48:28+00:00,Learning the Dynamics of Sparsely Observed Interacting Systems,"['Linus Bleistein', 'Adeline Fermanian', 'Anne-Sophie Jannot', 'Agathe Guilloux']","We address the problem of learning the dynamics of an unknown non-parametric
system linking a target and a feature time series. The feature time series is
measured on a sparse and irregular grid, while we have access to only a few
points of the target time series. Once learned, we can use these dynamics to
predict values of the target from the previous values of the feature time
series. We frame this task as learning the solution map of a controlled
differential equation (CDE). By leveraging the rich theory of signatures, we
are able to cast this non-linear problem as a high-dimensional linear
regression. We provide an oracle bound on the prediction error which exhibits
explicit dependencies on the individual-specific sampling schemes. Our
theoretical results are illustrated by simulations which show that our method
outperforms existing algorithms for recovering the full time series while being
computationally cheap. We conclude by demonstrating its potential on real-world
epidemiological data.",http://arxiv.org/pdf/2301.11647v2,stat.ML
2023-01-27 06:09:42+00:00,Targeted Attacks on Timeseries Forecasting,"['Yuvaraj Govindarajulu', 'Avinash Amballa', 'Pavan Kulkarni', 'Manojkumar Parmar']","Real-world deep learning models developed for Time Series Forecasting are
used in several critical applications ranging from medical devices to the
security domain. Many previous works have shown how deep learning models are
prone to adversarial attacks and studied their vulnerabilities. However, the
vulnerabilities of time series models for forecasting due to adversarial inputs
are not extensively explored. While the attack on a forecasting model might aim
to deteriorate the performance of the model, it is more effective, if the
attack is focused on a specific impact on the model's output. In this paper, we
propose a novel formulation of Directional, Amplitudinal, and Temporal targeted
adversarial attacks on time series forecasting models. These targeted attacks
create a specific impact on the amplitude and direction of the output
prediction. We use the existing adversarial attack techniques from the computer
vision domain and adapt them for time series. Additionally, we propose a
modified version of the Auto Projected Gradient Descent attack for targeted
attacks. We examine the impact of the proposed targeted attacks versus
untargeted attacks. We use KS-Tests to statistically demonstrate the impact of
the attack. Our experimental results show how targeted attacks on time series
models are viable and are more powerful in terms of statistical similarity. It
is, hence difficult to detect through statistical methods. We believe that this
work opens a new paradigm in the time series forecasting domain and represents
an important consideration for developing better defenses.",http://arxiv.org/pdf/2301.11544v1,cs.LG
2023-01-26 18:45:04+00:00,Neural Continuous-Discrete State Space Models for Irregularly-Sampled Time Series,"['Abdul Fatir Ansari', 'Alvin Heng', 'Andre Lim', 'Harold Soh']","Learning accurate predictive models of real-world dynamic phenomena (e.g.,
climate, biological) remains a challenging task. One key issue is that the data
generated by both natural and artificial processes often comprise time series
that are irregularly sampled and/or contain missing observations. In this work,
we propose the Neural Continuous-Discrete State Space Model (NCDSSM) for
continuous-time modeling of time series through discrete-time observations.
NCDSSM employs auxiliary variables to disentangle recognition from dynamics,
thus requiring amortized inference only for the auxiliary variables. Leveraging
techniques from continuous-discrete filtering theory, we demonstrate how to
perform accurate Bayesian inference for the dynamic states. We propose three
flexible parameterizations of the latent dynamics and an efficient training
objective that marginalizes the dynamic states during inference. Empirical
results on multiple benchmark datasets across various domains show improved
imputation and forecasting performance of NCDSSM over existing models.",http://arxiv.org/pdf/2301.11308v3,cs.LG
2023-01-24 23:34:13+00:00,Parameterizing the cost function of Dynamic Time Warping with application to time series classification,"['Matthieu Herrmann', 'Chang Wei Tan', 'Geoffrey I. Webb']","Dynamic Time Warping (DTW) is a popular time series distance measure that
aligns the points in two series with one another. These alignments support
warping of the time dimension to allow for processes that unfold at differing
rates. The distance is the minimum sum of costs of the resulting alignments
over any allowable warping of the time dimension. The cost of an alignment of
two points is a function of the difference in the values of those points. The
original cost function was the absolute value of this difference. Other cost
functions have been proposed. A popular alternative is the square of the
difference. However, to our knowledge, this is the first investigation of both
the relative impacts of using different cost functions and the potential to
tune cost functions to different tasks. We do so in this paper by using a
tunable cost function {\lambda}{\gamma} with parameter {\gamma}. We show that
higher values of {\gamma} place greater weight on larger pairwise differences,
while lower values place greater weight on smaller pairwise differences. We
demonstrate that training {\gamma} significantly improves the accuracy of both
the DTW nearest neighbor and Proximity Forest classifiers.",http://arxiv.org/pdf/2301.10350v2,cs.LG
2023-01-24 18:10:11+00:00,"WEASEL 2.0 -- A Random Dilated Dictionary Transform for Fast, Accurate and Memory Constrained Time Series Classification","['Patrick Schäfer', 'Ulf Leser']","A time series is a sequence of sequentially ordered real values in time. Time
series classification (TSC) is the task of assigning a time series to one of a
set of predefined classes, usually based on a model learned from examples.
Dictionary-based methods for TSC rely on counting the frequency of certain
patterns in time series and are important components of the currently most
accurate TSC ensembles. One of the early dictionary-based methods was WEASEL,
which at its time achieved SotA results while also being very fast. However, it
is outperformed both in terms of speed and accuracy by other methods.
Furthermore, its design leads to an unpredictably large memory footprint,
making it inapplicable for many applications.
  In this paper, we present WEASEL 2.0, a complete overhaul of WEASEL based on
two recent advancements in TSC: Dilation and ensembling of randomized
hyper-parameter settings. These two techniques allow WEASEL 2.0 to work with a
fixed-size memory footprint while at the same time improving accuracy. Compared
to 15 other SotA methods on the UCR benchmark set, WEASEL 2.0 is significantly
more accurate than other dictionary methods and not significantly worse than
the currently best methods. Actually, it achieves the highest median accuracy
over all data sets, and it performs best in 5 out of 12 problem classes. We
thus believe that WEASEL 2.0 is a viable alternative for current TSC and also a
potentially interesting input for future ensembles.",http://arxiv.org/pdf/2301.10194v2,cs.LG
2023-01-24 04:29:30+00:00,Multi-view Kernel PCA for Time series Forecasting,"['Arun Pandey', 'Hannes De Meulemeester', 'Bart De Moor', 'Johan A. K. Suykens']","In this paper, we propose a kernel principal component analysis model for
multi-variate time series forecasting, where the training and prediction
schemes are derived from the multi-view formulation of Restricted Kernel
Machines. The training problem is simply an eigenvalue decomposition of the
summation of two kernel matrices corresponding to the views of the input and
output data. When a linear kernel is used for the output view, it is shown that
the forecasting equation takes the form of kernel ridge regression. When that
kernel is non-linear, a pre-image problem has to be solved to forecast a point
in the input space. We evaluate the model on several standard time series
datasets, perform ablation studies, benchmark with closely related models and
discuss its results.",http://arxiv.org/pdf/2301.09811v1,cs.LG
2023-01-21 16:32:22+00:00,The Conditional Cauchy-Schwarz Divergence with Applications to Time-Series Data and Sequential Decision Making,"['Shujian Yu', 'Hongming Li', 'Sigurd Løkse', 'Robert Jenssen', 'José C. Príncipe']","The Cauchy-Schwarz (CS) divergence was developed by Pr\'{i}ncipe et al. in
2000. In this paper, we extend the classic CS divergence to quantify the
closeness between two conditional distributions and show that the developed
conditional CS divergence can be simply estimated by a kernel density estimator
from given samples. We illustrate the advantages (e.g., the rigorous
faithfulness guarantee, the lower computational complexity, the higher
statistical power, and the much more flexibility in a wide range of
applications) of our conditional CS divergence over previous proposals, such as
the conditional KL divergence and the conditional maximum mean discrepancy. We
also demonstrate the compelling performance of conditional CS divergence in two
machine learning tasks related to time series data and sequential inference,
namely the time series clustering and the uncertainty-guided exploration for
sequential decision making.",http://arxiv.org/pdf/2301.08970v1,cs.LG
2023-01-21 03:20:23+00:00,Ti-MAE: Self-Supervised Masked Time Series Autoencoders,"['Zhe Li', 'Zhongwen Rao', 'Lujia Pan', 'Pengyun Wang', 'Zenglin Xu']","Multivariate Time Series forecasting has been an increasingly popular topic
in various applications and scenarios. Recently, contrastive learning and
Transformer-based models have achieved good performance in many long-term
series forecasting tasks. However, there are still several issues in existing
methods. First, the training paradigm of contrastive learning and downstream
prediction tasks are inconsistent, leading to inaccurate prediction results.
Second, existing Transformer-based models which resort to similar patterns in
historical time series data for predicting future values generally induce
severe distribution shift problems, and do not fully leverage the sequence
information compared to self-supervised methods. To address these issues, we
propose a novel framework named Ti-MAE, in which the input time series are
assumed to follow an integrate distribution. In detail, Ti-MAE randomly masks
out embedded time series data and learns an autoencoder to reconstruct them at
the point-level. Ti-MAE adopts mask modeling (rather than contrastive learning)
as the auxiliary task and bridges the connection between existing
representation learning and generative Transformer-based methods, reducing the
difference between upstream and downstream forecasting tasks while maintaining
the utilization of original time series data. Experiments on several public
real-world datasets demonstrate that our framework of masked autoencoding could
learn strong representations directly from the raw data, yielding better
performance in time series forecasting and classification tasks.",http://arxiv.org/pdf/2301.08871v1,cs.LG
2023-01-20 11:34:12+00:00,Regular Time-series Generation using SGM,"['Haksoo Lim', 'Minjung Kim', 'Sewon Park', 'Noseong Park']","Score-based generative models (SGMs) are generative models that are in the
spotlight these days. Time-series frequently occurs in our daily life, e.g.,
stock data, climate data, and so on. Especially, time-series forecasting and
classification are popular research topics in the field of machine learning.
SGMs are also known for outperforming other generative models. As a result, we
apply SGMs to synthesize time-series data by learning conditional score
functions. We propose a conditional score network for the time-series
generation domain. Furthermore, we also derive the loss function between the
score matching and the denoising score matching in the time-series generation
domain. Finally, we achieve state-of-the-art results on real-world datasets in
terms of sampling diversity and quality.",http://arxiv.org/pdf/2301.08518v1,cs.LG
2023-01-12 06:49:55+00:00,LB-SimTSC: An Efficient Similarity-Aware Graph Neural Network for Semi-Supervised Time Series Classification,"['Wenjie Xi', 'Arnav Jain', 'Li Zhang', 'Jessica Lin']","Time series classification is an important data mining task that has received
a lot of interest in the past two decades. Due to the label scarcity in
practice, semi-supervised time series classification with only a few labeled
samples has become popular. Recently, Similarity-aware Time Series
Classification (SimTSC) is proposed to address this problem by using a graph
neural network classification model on the graph generated from pairwise
Dynamic Time Warping (DTW) distance of batch data. It shows excellent accuracy
and outperforms state-of-the-art deep learning models in several few-label
settings. However, since SimTSC relies on pairwise DTW distances, the quadratic
complexity of DTW limits its usability to only reasonably sized datasets. To
address this challenge, we propose a new efficient semi-supervised time series
classification technique, LB-SimTSC, with a new graph construction module.
Instead of using DTW, we propose to utilize a lower bound of DTW, LB_Keogh, to
approximate the dissimilarity between instances in linear time, while retaining
the relative proximity relationships one would have obtained via computing DTW.
We construct the pairwise distance matrix using LB_Keogh and build a graph for
the graph neural network. We apply this approach to the ten largest datasets
from the well-known UCR time series classification archive. The results
demonstrate that this approach can be up to 104x faster than SimTSC when
constructing the graph on large datasets without significantly decreasing
classification accuracy.",http://arxiv.org/pdf/2301.04838v3,cs.LG
2023-01-11 07:05:27+00:00,Learnable Path in Neural Controlled Differential Equations,"['Sheo Yon Jhin', 'Minju Jo', 'Seungji Kook', 'Noseong Park', 'Sungpil Woo', 'Sunhwan Lim']","Neural controlled differential equations (NCDEs), which are continuous
analogues to recurrent neural networks (RNNs), are a specialized model in
(irregular) time-series processing. In comparison with similar models, e.g.,
neural ordinary differential equations (NODEs), the key distinctive
characteristics of NCDEs are i) the adoption of the continuous path created by
an interpolation algorithm from each raw discrete time-series sample and ii)
the adoption of the Riemann--Stieltjes integral. It is the continuous path
which makes NCDEs be analogues to continuous RNNs. However, NCDEs use existing
interpolation algorithms to create the path, which is unclear whether they can
create an optimal path. To this end, we present a method to generate another
latent path (rather than relying on existing interpolation algorithms), which
is identical to learning an appropriate interpolation method. We design an
encoder-decoder module based on NCDEs and NODEs, and a special training method
for it. Our method shows the best performance in both time-series
classification and forecasting.",http://arxiv.org/pdf/2301.04333v1,cs.LG
2023-01-09 22:24:31+00:00,On the Susceptibility and Robustness of Time Series Models through Adversarial Attack and Defense,"['Asadullah Hill Galib', 'Bidhan Bashyal']","Under adversarial attacks, time series regression and classification are
vulnerable. Adversarial defense, on the other hand, can make the models more
resilient. It is important to evaluate how vulnerable different time series
models are to attacks and how well they recover using defense. The sensitivity
to various attacks and the robustness using the defense of several time series
models are investigated in this study. Experiments are run on seven-time series
models with three adversarial attacks and one adversarial defense. According to
the findings, all models, particularly GRU and RNN, appear to be vulnerable.
LSTM and GRU also have better defense recovery. FGSM exceeds the competitors in
terms of attacks. PGD attacks are more difficult to recover from than other
sorts of attacks.",http://arxiv.org/pdf/2301.03703v1,cs.LG
2023-01-09 20:19:00+00:00,Frequency Band Analysis of Nonstationary Multivariate Time Series,"['Raanju R. Sundararajan', 'Scott A. Bruce']","Information from frequency bands in biomedical time series provides useful
summaries of the observed signal. Many existing methods consider summaries of
the time series obtained over a few well-known, pre-defined frequency bands of
interest. However, these methods do not provide data-driven methods for
identifying frequency bands that optimally summarize frequency-domain
information in the time series. A new method to identify partition points in
the frequency space of a multivariate locally stationary time series is
proposed. These partition points signify changes across frequencies in the
time-varying behavior of the signal and provide frequency band summary measures
that best preserve the nonstationary dynamics of the observed series. An $L_2$
norm-based discrepancy measure that finds differences in the time-varying
spectral density matrix is constructed, and its asymptotic properties are
derived. New nonparametric bootstrap tests are also provided to identify
significant frequency partition points and to identify components and
cross-components of the spectral matrix exhibiting changes over frequencies.
Finite-sample performance of the proposed method is illustrated via
simulations. The proposed method is used to develop optimal frequency band
summary measures for characterizing time-varying behavior in resting-state
electroencephalography (EEG) time series, as well as identifying components and
cross-components associated with each frequency partition point.",http://arxiv.org/pdf/2301.03664v1,stat.ME
2023-01-08 18:47:31+00:00,Granger causality test for heteroskedastic and structural-break time series using generalized least squares,['Hugo J. Bello'],"This paper proposes a novel method (GLS Granger test) to determine causal
relationships between time series based on the estimation of the autocovariance
matrix and generalized least squares. We show the effectiveness of proposed
autocovariance matrix estimator (the sliding autocovariance matrix) and we
compare the proposed method with the classical Granger F-test with via a
synthetic dataset and a real dataset composed by cryptocurrencies. The
simulations show that the proposed GLS Granger test captures causality more
accurately than Granger F-tests in the cases of heteroskedastic or
structural-break residuals. Finally, we use the proposed method to unravel
unknown causal relationships between cryptocurrencies.",http://arxiv.org/pdf/2301.03085v1,stat.ME
2023-01-08 12:20:46+00:00,"Generative Time Series Forecasting with Diffusion, Denoise, and Disentanglement","['Yan Li', 'Xinjiang Lu', 'Yaqing Wang', 'Dejing Dou']","Time series forecasting has been a widely explored task of great importance
in many applications. However, it is common that real-world time series data
are recorded in a short time period, which results in a big gap between the
deep model and the limited and noisy time series. In this work, we propose to
address the time series forecasting problem with generative modeling and
propose a bidirectional variational auto-encoder (BVAE) equipped with
diffusion, denoise, and disentanglement, namely D3VAE. Specifically, a coupled
diffusion probabilistic model is proposed to augment the time series data
without increasing the aleatoric uncertainty and implement a more tractable
inference process with BVAE. To ensure the generated series move toward the
true target, we further propose to adapt and integrate the multiscale denoising
score matching into the diffusion process for time series forecasting. In
addition, to enhance the interpretability and stability of the prediction, we
treat the latent variable in a multivariate manner and disentangle them on top
of minimizing total correlation. Extensive experiments on synthetic and
real-world data show that D3VAE outperforms competitive algorithms with
remarkable margins. Our implementation is available at
https://github.com/PaddlePaddle/PaddleSpatial/tree/main/research/D3VAE.",http://arxiv.org/pdf/2301.03028v1,cs.LG
2023-01-05 23:40:23+00:00,DANLIP: Deep Autoregressive Networks for Locally Interpretable Probabilistic Forecasting,"['Ozan Ozyegen', 'Juyoung Wang', 'Mucahit Cevik']","Despite the high performance of neural network-based time series forecasting
methods, the inherent challenge in explaining their predictions has limited
their applicability in certain application areas. Due to the difficulty in
identifying causal relationships between the input and output of such black-box
methods, they rarely have been adopted in domains such as legal and medical
fields in which the reliability and interpretability of the results can be
essential. In this paper, we propose \model, a novel deep learning-based
probabilistic time series forecasting architecture that is intrinsically
interpretable. We conduct experiments with multiple datasets and performance
metrics and empirically show that our model is not only interpretable but also
provides comparable performance to state-of-the-art probabilistic time series
forecasting methods. Furthermore, we demonstrate that interpreting the
parameters of the stochastic processes of interest can provide useful insights
into several application areas.",http://arxiv.org/pdf/2301.02332v1,cs.LG
2023-01-05 13:59:29+00:00,"Towards Long-Term Time-Series Forecasting: Feature, Pattern, and Distribution","['Yan Li', 'Xinjiang Lu', 'Haoyi Xiong', 'Jian Tang', 'Jiantao Su', 'Bo Jin', 'Dejing Dou']","Long-term time-series forecasting (LTTF) has become a pressing demand in many
applications, such as wind power supply planning. Transformer models have been
adopted to deliver high prediction capacity because of the high computational
self-attention mechanism. Though one could lower the complexity of Transformers
by inducing the sparsity in point-wise self-attentions for LTTF, the limited
information utilization prohibits the model from exploring the complex
dependencies comprehensively. To this end, we propose an efficient
Transformerbased model, named Conformer, which differentiates itself from
existing methods for LTTF in three aspects: (i) an encoder-decoder architecture
incorporating a linear complexity without sacrificing information utilization
is proposed on top of sliding-window attention and Stationary and Instant
Recurrent Network (SIRN); (ii) a module derived from the normalizing flow is
devised to further improve the information utilization by inferring the outputs
with the latent variables in SIRN directly; (iii) the inter-series correlation
and temporal dynamics in time-series data are modeled explicitly to fuel the
downstream self-attention mechanism. Extensive experiments on seven real-world
datasets demonstrate that Conformer outperforms the state-of-the-art methods on
LTTF and generates reliable prediction results with uncertainty quantification.",http://arxiv.org/pdf/2301.02068v1,cs.LG
2023-01-04 14:08:21+00:00,Infomaxformer: Maximum Entropy Transformer for Long Time-Series Forecasting Problem,"['Peiwang Tang', 'Xianchao Zhang']","The Transformer architecture yields state-of-the-art results in many tasks
such as natural language processing (NLP) and computer vision (CV), since the
ability to efficiently capture the precise long-range dependency coupling
between input sequences. With this advanced capability, however, the quadratic
time complexity and high memory usage prevents the Transformer from dealing
with long time-series forecasting problem (LTFP). To address these
difficulties: (i) we revisit the learned attention patterns of the vanilla
self-attention, redesigned the calculation method of self-attention based the
Maximum Entropy Principle. (ii) we propose a new method to sparse the
self-attention, which can prevent the loss of more important self-attention
scores due to random sampling.(iii) We propose Keys/Values Distilling method
motivated that a large amount of feature in the original self-attention map is
redundant, which can further reduce the time and spatial complexity and make it
possible to input longer time-series. Finally, we propose a method that
combines the encoder-decoder architecture with seasonal-trend decomposition,
i.e., using the encoder-decoder architecture to capture more specific seasonal
parts. A large number of experiments on several large-scale datasets show that
our Infomaxformer is obviously superior to the existing methods. We expect this
to open up a new solution for Transformer to solve LTFP, and exploring the
ability of the Transformer architecture to capture much longer temporal
dependencies.",http://arxiv.org/pdf/2301.01772v1,cs.LG
2023-01-03 22:04:39+00:00,Covariate-guided Bayesian mixture model for multivariate time series,"['Haoyi Fu', 'Lu Tang', 'Ori Rosen', 'Alison E. Hipwell', 'Theodore J. Huppert', 'Robert T. Krafty']","With rapid development of techniques to measure brain activity and structure,
statistical methods for analyzing modern brain-imaging play an important role
in the advancement of science. Imaging data that measure brain function are
usually multivariate time series and are heterogeneous across both imaging
sources and subjects, which lead to various statistical and computational
challenges. In this paper, we propose a group-based method to cluster a
collection of multivariate time series via a Bayesian mixture of smoothing
splines. Our method assumes each multivariate time series is a mixture of
multiple components with different mixing weights. Time-independent covariates
are assumed to be associated with the mixture components and are incorporated
via logistic weights of a mixture-of-experts model. We formulate this approach
under a fully Bayesian framework using Gibbs sampling where the number of
components is selected based on a deviance information criterion. The proposed
method is compared to existing methods via simulation studies and is applied to
a study on functional near-infrared spectroscopy (fNIRS), which aims to
understand infant emotional reactivity and recovery from stress. The results
reveal distinct patterns of brain activity, as well as associations between
these patterns and selected covariates.",http://arxiv.org/pdf/2301.01373v1,stat.ME
2023-01-02 00:19:01+00:00,High-dimensional latent Gaussian count time series: Concentration results for autocovariances and applications,"['Marie-Christine Düker', 'Robert Lund', 'Vladas Pipiras']","This work considers stationary vector count time series models defined via
deterministic functions of a latent stationary vector Gaussian series. The
construction is very general and ensures a pre-specified marginal distribution
for the counts in each dimension, depending on unknown parameters that can be
marginally estimated. The vector Gaussian series injects flexibility into the
model's temporal and cross-dimensional dependencies, perhaps through a
parametric model akin to a vector autoregression. We show that the latent
Gaussian model can be estimated by relating the covariances of the counts and
the latent Gaussian series. In a possibly high-dimensional setting,
concentration bounds are established for the differences between the estimated
and true latent Gaussian autocovariances, in terms of those for the observed
count series and the estimated marginal parameters. The results are applied to
the case where the latent Gaussian series is a vector autoregression, and its
parameters are estimated sparsely through a LASSO-type procedure.",http://arxiv.org/pdf/2301.00491v2,math.ST
2023-01-01 06:09:15+00:00,A Functional approach for Two Way Dimension Reduction in Time Series,"['Aniruddha Rajendra Rao', 'Haiyan Wang', 'Chetan Gupta']","The rise in data has led to the need for dimension reduction techniques,
especially in the area of non-scalar variables, including time series, natural
language processing, and computer vision. In this paper, we specifically
investigate dimension reduction for time series through functional data
analysis. Current methods for dimension reduction in functional data are
functional principal component analysis and functional autoencoders, which are
limited to linear mappings or scalar representations for the time series, which
is inefficient. In real data applications, the nature of the data is much more
complex. We propose a non-linear function-on-function approach, which consists
of a functional encoder and a functional decoder, that uses continuous hidden
layers consisting of continuous neurons to learn the structure inherent in
functional data, which addresses the aforementioned concerns in the existing
approaches. Our approach gives a low dimension latent representation by
reducing the number of functional features as well as the timepoints at which
the functions are observed. The effectiveness of the proposed model is
demonstrated through multiple simulations and real data examples.",http://arxiv.org/pdf/2301.00357v1,cs.LG
2022-12-31 01:44:17+00:00,Inference on Time Series Nonparametric Conditional Moment Restrictions Using General Sieves,"['Xiaohong Chen', 'Yuan Liao', 'Weichen Wang']","General nonlinear sieve learnings are classes of nonlinear sieves that can
approximate nonlinear functions of high dimensional variables much more
flexibly than various linear sieves (or series). This paper considers general
nonlinear sieve quasi-likelihood ratio (GN-QLR) based inference on expectation
functionals of time series data, where the functionals of interest are based on
some nonparametric function that satisfy conditional moment restrictions and
are learned using multilayer neural networks. While the asymptotic normality of
the estimated functionals depends on some unknown Riesz representer of the
functional space, we show that the optimally weighted GN-QLR statistic is
asymptotically Chi-square distributed, regardless whether the expectation
functional is regular (root-$n$ estimable) or not. This holds when the data are
weakly dependent beta-mixing condition. We apply our method to the off-policy
evaluation in reinforcement learning, by formulating the Bellman equation into
the conditional moment restriction framework, so that we can make inference
about the state-specific value functional using the proposed GN-QLR method with
time series data. In addition, estimating the averaged partial means and
averaged partial derivatives of nonparametric instrumental variables and
quantile IV models are also presented as leading examples. Finally, a Monte
Carlo study shows the finite sample performance of the procedure",http://arxiv.org/pdf/2301.00092v2,stat.ML
2022-12-30 14:41:53+00:00,Time series Forecasting to detect anomalous behaviours in Multiphase Flow Meters,"['Tommaso Barbariol', 'Davide Masiero', 'Enrico Feltresi', 'Gian Antonio Susto']","An Anomaly Detection (AD) System for Self-diagnosis has been developed for
Multiphase Flow Meter (MPFM). The system relies on machine learning algorithms
for time series forecasting, historical data have been used to train a model
and to predict the behavior of a sensor and, thus, to detect anomalies.",http://arxiv.org/pdf/2301.00014v1,cs.LG
2022-12-30 10:16:15+00:00,Label-Efficient Interactive Time-Series Anomaly Detection,"['Hong Guo', 'Yujing Wang', 'Jieyu Zhang', 'Zhengjie Lin', 'Yunhai Tong', 'Lei Yang', 'Luoxing Xiong', 'Congrui Huang']","Time-series anomaly detection is an important task and has been widely
applied in the industry. Since manual data annotation is expensive and
inefficient, most applications adopt unsupervised anomaly detection methods,
but the results are usually sub-optimal and unsatisfactory to end customers.
Weak supervision is a promising paradigm for obtaining considerable labels in a
low-cost way, which enables the customers to label data by writing heuristic
rules rather than annotating each instance individually. However, in the
time-series domain, it is hard for people to write reasonable labeling
functions as the time-series data is numerically continuous and difficult to be
understood. In this paper, we propose a Label-Efficient Interactive Time-Series
Anomaly Detection (LEIAD) system, which enables a user to improve the results
of unsupervised anomaly detection by performing only a small amount of
interactions with the system. To achieve this goal, the system integrates weak
supervision and active learning collaboratively while generating labeling
functions automatically using only a few labeled data. All of these techniques
are complementary and can promote each other in a reinforced manner. We conduct
experiments on three time-series anomaly detection datasets, demonstrating that
the proposed system is superior to existing solutions in both weak supervision
and active learning areas. Also, the system has been tested in a real scenario
in industry to show its practicality.",http://arxiv.org/pdf/2212.14621v1,cs.LG
2022-12-29 16:43:34+00:00,Deep Temporal Contrastive Clustering,"['Ying Zhong', 'Dong Huang', 'Chang-Dong Wang']","Recently the deep learning has shown its advantage in representation learning
and clustering for time series data. Despite the considerable progress, the
existing deep time series clustering approaches mostly seek to train the deep
neural network by some instance reconstruction based or cluster distribution
based objective, which, however, lack the ability to exploit the sample-wise
(or augmentation-wise) contrastive information or even the higher-level (e.g.,
cluster-level) contrastiveness for learning discriminative and
clustering-friendly representations. In light of this, this paper presents a
deep temporal contrastive clustering (DTCC) approach, which for the first time,
to our knowledge, incorporates the contrastive learning paradigm into the deep
time series clustering research. Specifically, with two parallel views
generated from the original time series and their augmentations, we utilize two
identical auto-encoders to learn the corresponding representations, and in the
meantime perform the cluster distribution learning by incorporating a k-means
objective. Further, two levels of contrastive learning are simultaneously
enforced to capture the instance-level and cluster-level contrastive
information, respectively. With the reconstruction loss of the auto-encoder,
the cluster distribution loss, and the two levels of contrastive losses jointly
optimized, the network architecture is trained in a self-supervised manner and
the clustering result can thereby be obtained. Experiments on a variety of time
series datasets demonstrate the superiority of our DTCC approach over the
state-of-the-art.",http://arxiv.org/pdf/2212.14366v1,cs.LG
2022-12-29 00:32:24+00:00,Investigating Sindy As a Tool For Causal Discovery In Time Series Signals,"[""Andrew O'Brien"", 'Rosina Weber', 'Edward Kim']","The SINDy algorithm has been successfully used to identify the governing
equations of dynamical systems from time series data. In this paper, we argue
that this makes SINDy a potentially useful tool for causal discovery and that
existing tools for causal discovery can be used to dramatically improve the
performance of SINDy as tool for robust sparse modeling and system
identification. We then demonstrate empirically that augmenting the SINDy
algorithm with tools from causal discovery can provides engineers with a tool
for learning causally robust governing equations.",http://arxiv.org/pdf/2212.14133v1,cs.LG
2022-12-27 17:22:21+00:00,AER: Auto-Encoder with Regression for Time Series Anomaly Detection,"['Lawrence Wong', 'Dongyu Liu', 'Laure Berti-Equille', 'Sarah Alnegheimish', 'Kalyan Veeramachaneni']","Anomaly detection on time series data is increasingly common across various
industrial domains that monitor metrics in order to prevent potential accidents
and economic losses. However, a scarcity of labeled data and ambiguous
definitions of anomalies can complicate these efforts. Recent unsupervised
machine learning methods have made remarkable progress in tackling this problem
using either single-timestamp predictions or time series reconstructions. While
traditionally considered separately, these methods are not mutually exclusive
and can offer complementary perspectives on anomaly detection. This paper first
highlights the successes and limitations of prediction-based and
reconstruction-based methods with visualized time series signals and anomaly
scores. We then propose AER (Auto-encoder with Regression), a joint model that
combines a vanilla auto-encoder and an LSTM regressor to incorporate the
successes and address the limitations of each method. Our model can produce
bi-directional predictions while simultaneously reconstructing the original
time series by optimizing a joint objective function. Furthermore, we propose
several ways of combining the prediction and reconstruction errors through a
series of ablation studies. Finally, we compare the performance of the AER
architecture against two prediction-based methods and three
reconstruction-based methods on 12 well-known univariate time series datasets
from NASA, Yahoo, Numenta, and UCR. The results show that AER has the highest
averaged F1 score across all datasets (a 23.5% improvement compared to ARIMA)
while retaining a runtime similar to its vanilla auto-encoder and regressor
components. Our model is available in Orion, an open-source benchmarking tool
for time series anomaly detection.",http://arxiv.org/pdf/2212.13558v1,cs.LG
2022-12-21 18:29:55+00:00,Inference for Non-Stationary Heavy Tailed Time Series,"['Fumiya Akashi', 'Konstantinos Fokianos', 'Junichi Hirukawa']","We consider the problem of inference for non-stationary time series with
heavy-tailed error distribution. Under a time-varying linear process framework
we show that there exists a suitable local approximation by a stationary
process with heavy-tails. This enable us to introduce a local
approximation-based estimator which estimates consistently time-varying
parameters of the model at hand. To develop a robust method, we also suggest a
self-weighing scheme which is shown to recover the asymptotic normality of the
estimator regardless of whether the finite variance of the underlying process
exists. Empirical evidence favoring this approach is provided.",http://arxiv.org/pdf/2212.11253v1,math.ST
2022-12-21 09:15:34+00:00,Temporal Disaggregation of the Cumulative Grass Growth,"['Thomas Guyet', 'Laurent Spillemaecker', 'Simon Malinowski', 'Anne-Isabelle Graux']","Information on the grass growth over a year is essential for some models
simulating the use of this resource to feed animals on pasture or at barn with
hay or grass silage. Unfortunately, this information is rarely available. The
challenge is to reconstruct grass growth from two sources of information: usual
daily climate data (rainfall, radiation, etc.) and cumulative growth over the
year. We have to be able to capture the effect of seasonal climatic events
which are known to distort the growth curve within the year. In this paper, we
formulate this challenge as a problem of disaggregating the cumulative growth
into a time series. To address this problem, our method applies time series
forecasting using climate information and grass growth from previous time
steps. Several alternatives of the method are proposed and compared
experimentally using a database generated from a grassland process-based model.
The results show that our method can accurately reconstruct the time series,
independently of the use of the cumulative growth information.",http://arxiv.org/pdf/2212.10865v1,cs.LG
2022-12-20 14:54:04+00:00,A Pattern Discovery Approach to Multivariate Time Series Forecasting,"['Yunyao Cheng', 'Chenjuan Guo', 'Kaixuan Chen', 'Kai Zhao', 'Bin Yang', 'Jiandong Xie', 'Christian S. Jensen', 'Feiteng Huang', 'Kai Zheng']","Multivariate time series forecasting constitutes important functionality in
cyber-physical systems, whose prediction accuracy can be improved significantly
by capturing temporal and multivariate correlations among multiple time series.
State-of-the-art deep learning methods fail to construct models for full time
series because model complexity grows exponentially with time series length.
Rather, these methods construct local temporal and multivariate correlations
within subsequences, but fail to capture correlations among subsequences, which
significantly affect their forecasting accuracy. To capture the temporal and
multivariate correlations among subsequences, we design a pattern discovery
model, that constructs correlations via diverse pattern functions. While the
traditional pattern discovery method uses shared and fixed pattern functions
that ignore the diversity across time series. We propose a novel pattern
discovery method that can automatically capture diverse and complex time series
patterns. We also propose a learnable correlation matrix, that enables the
model to capture distinct correlations among multiple time series. Extensive
experiments show that our model achieves state-of-the-art prediction accuracy.",http://arxiv.org/pdf/2212.10306v1,cs.LG
2022-12-20 04:45:39+00:00,A marginalized three-part interrupted time series regression model for proportional data,"['Shangyuan Ye', 'Maricela Cruz', 'Yuchen Hu', 'Yun Yu']","Interrupted time series (ITS) is often used to evaluate the effectiveness of
a health policy intervention that accounts for the temporal dependence of
outcomes. When the outcome of interest is a percentage or percentile, the data
can be highly skewed, bounded in $[0, 1]$, and have many zeros or ones. A
three-part Beta regression model is commonly used to separate zeros, ones, and
positive values explicitly by three submodels. However, incorporating temporal
dependence into the three-part Beta regression model is challenging. In this
article, we propose a marginalized zero-one-inflated Beta time series model
that captures the temporal dependence of outcomes through copula and allows
investigators to examine covariate effects on the marginal mean. We investigate
its practical performance using simulation studies and apply the model to a
real ITS study.",http://arxiv.org/pdf/2212.09996v1,stat.ME
2022-12-19 20:32:27+00:00,"Dynamic Sparse Network for Time Series Classification: Learning What to ""see''","['Qiao Xiao', 'Boqian Wu', 'Yu Zhang', 'Shiwei Liu', 'Mykola Pechenizkiy', 'Elena Mocanu', 'Decebal Constantin Mocanu']","The receptive field (RF), which determines the region of time series to be
``seen'' and used, is critical to improve the performance for time series
classification (TSC). However, the variation of signal scales across and within
time series data, makes it challenging to decide on proper RF sizes for TSC. In
this paper, we propose a dynamic sparse network (DSN) with sparse connections
for TSC, which can learn to cover various RF without cumbersome
hyper-parameters tuning. The kernels in each sparse layer are sparse and can be
explored under the constraint regions by dynamic sparse training, which makes
it possible to reduce the resource cost. The experimental results show that the
proposed DSN model can achieve state-of-art performance on both univariate and
multivariate TSC datasets with less than 50\% computational cost compared with
recent baseline methods, opening the path towards more accurate resource-aware
methods for time series analyses. Our code is publicly available at:
https://github.com/QiaoXiao7282/DSN.",http://arxiv.org/pdf/2212.09840v1,cs.LG
2022-12-19 17:16:47+00:00,Simultaneous Inference of a Partially Linear Model in Time Series,"['Jiaqi Li', 'Likai Chen', 'Kun Ho Kim', 'Tianwei Zhou']","We introduce a new methodology to conduct simultaneous inference of the
nonparametric component in partially linear time series regression models where
the nonparametric part is a multivariate unknown function. In particular, we
construct a simultaneous confidence region (SCR) for the multivariate function
by extending the high-dimensional Gaussian approximation to dependent processes
with continuous index sets. Our results allow for a more general dependence
structure compared to previous works and are widely applicable to a variety of
linear and nonlinear autoregressive processes. We demonstrate the validity of
our proposed methodology by examining the finite-sample performance in the
simulation study. Finally, an application in time series, the forward premium
regression, is presented, where we construct the SCR for the foreign exchange
risk premium from the exchange rate and macroeconomic data.",http://arxiv.org/pdf/2212.10359v2,stat.ME
2022-12-19 14:57:52+00:00,FedTADBench: Federated Time-Series Anomaly Detection Benchmark,"['Fanxing Liu', 'Cheng Zeng', 'Le Zhang', 'Yingjie Zhou', 'Qing Mu', 'Yanru Zhang', 'Ling Zhang', 'Ce Zhu']","Time series anomaly detection strives to uncover potential abnormal behaviors
and patterns from temporal data, and has fundamental significance in diverse
application scenarios. Constructing an effective detection model usually
requires adequate training data stored in a centralized manner, however, this
requirement sometimes could not be satisfied in realistic scenarios. As a
prevailing approach to address the above problem, federated learning has
demonstrated its power to cooperate with the distributed data available while
protecting the privacy of data providers. However, it is still unclear that how
existing time series anomaly detection algorithms perform with decentralized
data storage and privacy protection through federated learning. To study this,
we conduct a federated time series anomaly detection benchmark, named
FedTADBench, which involves five representative time series anomaly detection
algorithms and four popular federated learning methods. We would like to answer
the following questions: (1)How is the performance of time series anomaly
detection algorithms when meeting federated learning? (2) Which federated
learning method is the most appropriate one for time series anomaly detection?
(3) How do federated time series anomaly detection approaches perform on
different partitions of data in clients? Numbers of results as well as
corresponding analysis are provided from extensive experiments with various
settings. The source code of our benchmark is publicly available at
https://github.com/fanxingliu2020/FedTADBench.",http://arxiv.org/pdf/2212.09518v1,cs.LG
2022-12-16 17:46:46+00:00,A smooth transition autoregressive model for matrix-variate time series,['Andrea Bucci'],"In many applications, data are observed as matrices with temporal dependence.
Matrix-variate time series modeling is a new branch of econometrics. Although
stylized facts in several fields, the existing models do not account for regime
switches in the dynamics of matrices that are not abrupt. In this paper, we
extend linear matrix-variate autoregressive models by introducing a
regime-switching model capable of accounting for smooth changes, the matrix
smooth transition autoregressive model. We present the estimation processes
with the asymptotic properties demonstrated with simulated and real data.",http://arxiv.org/pdf/2212.08615v1,stat.ME
2022-12-16 09:07:45+00:00,Some recent trends in embeddings of time series and dynamic networks,"['Dag Tjøstheim', 'Martin Jullum', 'Anders Løland']","We give a review of some recent developments in embeddings of time series and
dynamic networks. We start out with traditional principal components and then
look at extensions to dynamic factor models for time series. Unlike principal
components for time series, the literature on time-varying nonlinear embedding
is rather sparse. The most promising approaches in the literature is neural
network based, and has recently performed well in forecasting competitions. We
also touch upon different forms of dynamics in topological data analysis. The
last part of the paper deals with embedding of dynamic networks where we
believe there is a gap between available theory and the behavior of most real
world networks. We illustrate our review with two simulated examples.
Throughout the review, we highlight differences between the static and dynamic
case, and point to several open problems in the dynamic case.",http://arxiv.org/pdf/2212.08358v1,stat.ME
2022-12-15 21:46:52+00:00,Skip-sampling: subsampling in the frequency domain,"['Tucker McElroy', 'Dimitris Politis']","Over the last 35 years, several bootstrap methods for time series have been
proposed. Popular `time-domain' methods include the block-bootstrap, the
stationary bootstrap, the linear process bootstrap, etc.; subsampling for time
series is also available, and is closely related to the block-bootstrap.
`Frequency-domain' bootstrap has been performed either by resampling the
periodogram ordinates or by resampling the ordinates of the Discrete Fourier
Transform (DFT). The paper at hand proposes a novel construction of subsampling
the DFT ordinates, and investigates its theoretical properties and realm of
applicability.",http://arxiv.org/pdf/2212.08160v1,stat.ME
2022-12-15 21:34:19+00:00,First De-Trend then Attend: Rethinking Attention for Time-Series Forecasting,"['Xiyuan Zhang', 'Xiaoyong Jin', 'Karthick Gopalswamy', 'Gaurav Gupta', 'Youngsuk Park', 'Xingjian Shi', 'Hao Wang', 'Danielle C. Maddix', 'Yuyang Wang']","Transformer-based models have gained large popularity and demonstrated
promising results in long-term time-series forecasting in recent years. In
addition to learning attention in time domain, recent works also explore
learning attention in frequency domains (e.g., Fourier domain, wavelet domain),
given that seasonal patterns can be better captured in these domains. In this
work, we seek to understand the relationships between attention models in
different time and frequency domains. Theoretically, we show that attention
models in different domains are equivalent under linear conditions (i.e.,
linear kernel to attention scores). Empirically, we analyze how attention
models of different domains show different behaviors through various synthetic
experiments with seasonality, trend and noise, with emphasis on the role of
softmax operation therein. Both these theoretical and empirical analyses
motivate us to propose a new method: TDformer (Trend Decomposition
Transformer), that first applies seasonal-trend decomposition, and then
additively combines an MLP which predicts the trend component with Fourier
attention which predicts the seasonal component to obtain the final prediction.
Extensive experiments on benchmark time-series forecasting datasets demonstrate
that TDformer achieves state-of-the-art performance against existing
attention-based models.",http://arxiv.org/pdf/2212.08151v1,cs.LG
2022-12-15 15:21:28+00:00,Multimodal Teacher Forcing for Reconstructing Nonlinear Dynamical Systems,"['Manuel Brenner', 'Georgia Koppe', 'Daniel Durstewitz']","Many, if not most, systems of interest in science are naturally described as
nonlinear dynamical systems (DS). Empirically, we commonly access these systems
through time series measurements, where often we have time series from
different types of data modalities simultaneously. For instance, we may have
event counts in addition to some continuous signal. While by now there are many
powerful machine learning (ML) tools for integrating different data modalities
into predictive models, this has rarely been approached so far from the
perspective of uncovering the underlying, data-generating DS (aka DS
reconstruction). Recently, sparse teacher forcing (TF) has been suggested as an
efficient control-theoretic method for dealing with exploding loss gradients
when training ML models on chaotic DS. Here we incorporate this idea into a
novel recurrent neural network (RNN) training framework for DS reconstruction
based on multimodal variational autoencoders (MVAE). The forcing signal for the
RNN is generated by the MVAE which integrates different types of simultaneously
given time series data into a joint latent code optimal for DS reconstruction.
We show that this training method achieves significantly better reconstructions
on multimodal datasets generated from chaotic DS benchmarks than various
alternative methods.",http://arxiv.org/pdf/2212.07892v1,cs.LG
2022-12-15 12:47:59+00:00,Temporal Saliency Detection Towards Explainable Transformer-based Timeseries Forecasting,"['Nghia Duong-Trung', 'Duc-Manh Nguyen', 'Danh Le-Phuoc']","Despite the notable advancements in numerous Transformer-based models, the
task of long multi-horizon time series forecasting remains a persistent
challenge, especially towards explainability. Focusing on commonly used
saliency maps in explaining DNN in general, our quest is to build
attention-based architecture that can automatically encode saliency-related
temporal patterns by establishing connections with appropriate attention heads.
Hence, this paper introduces Temporal Saliency Detection (TSD), an effective
approach that builds upon the attention mechanism and applies it to
multi-horizon time series prediction. While our proposed architecture adheres
to the general encoder-decoder structure, it undergoes a significant renovation
in the encoder component, wherein we incorporate a series of information
contracting and expanding blocks inspired by the U-Net style architecture. The
TSD approach facilitates the multiresolution analysis of saliency patterns by
condensing multi-heads, thereby progressively enhancing the forecasting of
complex time series data. Empirical evaluations illustrate the superiority of
our proposed approach compared to other models across multiple standard
benchmark datasets in diverse far-horizon forecasting settings. The initial TSD
achieves substantial relative improvements of 31% and 46% over several models
in the context of multivariate and univariate prediction. We believe the
comprehensive investigations presented in this study will offer valuable
insights and benefits to future research endeavors.",http://arxiv.org/pdf/2212.07771v3,cs.LG
2022-12-13 12:40:28+00:00,On Mini-Batch Training with Varying Length Time Series,['Brian Kenji Iwana'],"In real-world time series recognition applications, it is possible to have
data with varying length patterns. However, when using artificial neural
networks (ANN), it is standard practice to use fixed-sized mini-batches. To do
this, time series data with varying lengths are typically normalized so that
all the patterns are the same length. Normally, this is done using zero padding
or truncation without much consideration. We propose a novel method of
normalizing the lengths of the time series in a dataset by exploiting the
dynamic matching ability of Dynamic Time Warping (DTW). In this way, the time
series lengths in a dataset can be set to a fixed size while maintaining
features typical to the dataset. In the experiments, all 11 datasets with
varying length time series from the 2018 UCR Time Series Archive are used. We
evaluate the proposed method by comparing it with 18 other length normalization
methods on a Convolutional Neural Network (CNN), a Long-Short Term Memory
network (LSTM), and a Bidirectional LSTM (BLSTM).",http://arxiv.org/pdf/2212.06536v1,cs.LG
2022-12-12 11:21:26+00:00,Multiplicative Error Models for Count Time Series,"['Christian H. Weiß', 'Fukang Zhu']","Multiplicative error models (MEMs) are commonly used for real-valued time
series, but they cannot be applied to discrete-valued count time series as the
involved multiplication would not preserve the integer nature of the data. We
propose the concept of a multiplicative operator for counts as well as several
specific instances thereof, which are then used to develop MEMs for count time
series (CMEMs). If equipped with a linear conditional mean, the resulting CMEMs
are closely related to the class of so-called integer-valued generalized
autoregressive conditional heteroskedasticity (INGARCH) models and might be
used as a semi-parametric extension thereof. We derive important stochastic
properties of different types of INGARCH-CMEM as well as relevant estimation
approaches, namely types of quasi-maximum likelihood and weighted least squares
estimation. The performance and application are demonstrated with simulations
as well as with two real-world data examples.",http://arxiv.org/pdf/2212.05831v1,stat.ME
2022-12-09 23:02:23+00:00,Matrix Profile XXVII: A Novel Distance Measure for Comparing Long Time Series,"['Audrey Der', 'Chin-Chia Michael Yeh', 'Renjie Wu', 'Junpeng Wang', 'Yan Zheng', 'Zhongfang Zhuang', 'Liang Wang', 'Wei Zhang', 'Eamonn Keogh']","The most useful data mining primitives are distance measures. With an
effective distance measure, it is possible to perform classification,
clustering, anomaly detection, segmentation, etc. For single-event time series
Euclidean Distance and Dynamic Time Warping distance are known to be extremely
effective. However, for time series containing cyclical behaviors, the semantic
meaningfulness of such comparisons is less clear. For example, on two separate
days the telemetry from an athlete workout routine might be very similar. The
second day may change the order in of performing push-ups and squats, adding
repetitions of pull-ups, or completely omitting dumbbell curls. Any of these
minor changes would defeat existing time series distance measures. Some
bag-of-features methods have been proposed to address this problem, but we
argue that in many cases, similarity is intimately tied to the shapes of
subsequences within these longer time series. In such cases, summative features
will lack discrimination ability. In this work we introduce PRCIS, which stands
for Pattern Representation Comparison in Series. PRCIS is a distance measure
for long time series, which exploits recent progress in our ability to
summarize time series with dictionaries. We will demonstrate the utility of our
ideas on diverse tasks and datasets.",http://arxiv.org/pdf/2212.06146v1,cs.LG
2022-12-09 13:35:39+00:00,Towards Better Long-range Time Series Forecasting using Generative Forecasting,"['Shiyu Liu', 'Rohan Ghosh', 'Mehul Motani']","Long-range time series forecasting is usually based on one of two existing
forecasting strategies: Direct Forecasting and Iterative Forecasting, where the
former provides low bias, high variance forecasts and the latter leads to low
variance, high bias forecasts. In this paper, we propose a new forecasting
strategy called Generative Forecasting (GenF), which generates synthetic data
for the next few time steps and then makes long-range forecasts based on
generated and observed data. We theoretically prove that GenF is able to better
balance the forecasting variance and bias, leading to a much smaller
forecasting error. We implement GenF via three components: (i) a novel
conditional Wasserstein Generative Adversarial Network (GAN) based generator
for synthetic time series data generation, called CWGAN-TS. (ii) a transformer
based predictor, which makes long-range predictions using both generated and
observed data. (iii) an information theoretic clustering algorithm to improve
the training of both the CWGAN-TS and the transformer based predictor. The
experimental results on five public datasets demonstrate that GenF
significantly outperforms a diverse range of state-of-the-art benchmarks and
classical approaches. Specifically, we find a 5% - 11% improvement in
predictive performance (mean absolute error) while having a 15% - 50% reduction
in parameters compared to the benchmarks. Lastly, we conduct an ablation study
to further explore and demonstrate the effectiveness of the components
comprising GenF.",http://arxiv.org/pdf/2212.06142v1,cs.LG
2022-12-08 04:44:21+00:00,Fractionally integrated curve time series with cointegration,"['Won-Ki Seo', 'Han Lin Shang']","We introduce methods and theory for fractionally cointegrated curve time
series. We develop a variance ratio test to determine the dimensions associated
with the nonstationary and stationary subspaces. For each subspace, we apply a
local Whittle estimator to estimate the long-memory parameter and establish its
consistency. A Monte Carlo study of finite-sample performance is included,
along with an empirical application.",http://arxiv.org/pdf/2212.04071v1,math.ST
2022-12-07 10:25:59+00:00,CrossPyramid: Neural Ordinary Differential Equations Architecture for Partially-observed Time-series,"['Futoon M. Abushaqra', 'Hao Xue', 'Yongli Ren', 'Flora D. Salim']","Ordinary Differential Equations (ODE)-based models have become popular
foundation models to solve many time-series problems. Combining neural ODEs
with traditional RNN models has provided the best representation for irregular
time series. However, ODE-based models require the trajectory of hidden states
to be defined based on the initial observed value or the last available
observation. This fact raises questions about how long the generated hidden
state is sufficient and whether it is effective when long sequences are used
instead of the typically used shorter sequences. In this article, we introduce
CrossPyramid, a novel ODE-based model that aims to enhance the generalizability
of sequences representation. CrossPyramid does not rely only on the hidden
state from the last observed value; it also considers ODE latent
representations learned from other samples. The main idea of our proposed model
is to define the hidden state for the unobserved values based on the non-linear
correlation between samples. Accordingly, CrossPyramid is built with three
distinctive parts: (1) ODE Auto-Encoder to learn the best data representation.
(2) Pyramidal attention method to categorize the learned representations
(hidden state) based on the relationship characteristics between samples. (3)
Cross-level ODE-RNN to integrate the previously learned information and provide
the final latent state for each sample. Through extensive experiments on
partially-observed synthetic and real-world datasets, we show that the proposed
architecture can effectively model the long gaps in intermittent series and
outperforms state-of-the-art approaches. The results show an average
improvement of 10\% on univariate and multivariate datasets for both
forecasting and classification tasks.",http://arxiv.org/pdf/2212.03560v1,cs.LG
2022-12-07 05:07:27+00:00,Sequential Predictive Conformal Inference for Time Series,"['Chen Xu', 'Yao Xie']","We present a new distribution-free conformal prediction algorithm for
sequential data (e.g., time series), called the \textit{sequential predictive
conformal inference} (\texttt{SPCI}). We specifically account for the nature
that time series data are non-exchangeable, and thus many existing conformal
prediction algorithms are not applicable. The main idea is to adaptively
re-estimate the conditional quantile of non-conformity scores (e.g., prediction
residuals), upon exploiting the temporal dependence among them. More precisely,
we cast the problem of conformal prediction interval as predicting the quantile
of a future residual, given a user-specified point prediction algorithm.
Theoretically, we establish asymptotic valid conditional coverage upon
extending consistency analyses in quantile regression. Using simulation and
real-data experiments, we demonstrate a significant reduction in interval width
of \texttt{SPCI} compared to other existing methods under the desired empirical
coverage.",http://arxiv.org/pdf/2212.03463v3,stat.ML
2022-12-06 19:32:06+00:00,Copula Conformal Prediction for Multi-step Time Series Forecasting,"['Sophia Sun', 'Rose Yu']","Accurate uncertainty measurement is a key step to building robust and
reliable machine learning systems. Conformal prediction is a distribution-free
uncertainty quantification algorithm popular for its ease of implementation,
statistical coverage guarantees, and versatility for underlying forecasters.
However, existing conformal prediction algorithms for time series are limited
to single-step prediction without considering the temporal dependency. In this
paper we propose a Copula Conformal Prediction algorithm for multivariate,
multi-step Time Series forecasting, CopulaCPTS. We prove that CopulaCPTS has
finite sample validity guarantee. On several synthetic and real-world
multivariate time series datasets, we show that CopulaCPTS produces more
calibrated and sharp confidence intervals for multi-step prediction tasks than
existing techniques.",http://arxiv.org/pdf/2212.03281v2,cs.LG
2022-12-06 15:05:54+00:00,Unsupervised Anomaly Detection in Time-series: An Extensive Evaluation and Analysis of State-of-the-art Methods,"['Nesryne Mejri', 'Laura Lopez-Fuentes', 'Kankana Roy', 'Pavel Chernakov', 'Enjie Ghorbel', 'Djamila Aouada']","Unsupervised anomaly detection in time-series has been extensively
investigated in the literature. Notwithstanding the relevance of this topic in
numerous application fields, a complete and extensive evaluation of recent
state-of-the-art techniques is still missing. Few efforts have been made to
compare existing unsupervised time-series anomaly detection methods rigorously.
However, only standard performance metrics, namely precision, recall, and
F1-score are usually considered. Essential aspects for assessing their
practical relevance are therefore neglected. This paper proposes an original
and in-depth evaluation study of recent unsupervised anomaly detection
techniques in time-series. Instead of relying solely on standard performance
metrics, additional yet informative metrics and protocols are taken into
account. In particular, (1) more elaborate performance metrics specifically
tailored for time-series are used; (2) the model size and the model stability
are studied; (3) an analysis of the tested approaches with respect to the
anomaly type is provided; and (4) a clear and unique protocol is followed for
all experiments. Overall, this extensive analysis aims to assess the maturity
of state-of-the-art time-series anomaly detection, give insights regarding
their applicability under real-world setups and provide to the community a more
complete evaluation protocol.",http://arxiv.org/pdf/2212.03637v2,cs.LG
2022-12-06 07:00:31+00:00,A K-variate Time Series Is Worth K Words: Evolution of the Vanilla Transformer Architecture for Long-term Multivariate Time Series Forecasting,"['Zanwei Zhou', 'Ruizhe Zhong', 'Chen Yang', 'Yan Wang', 'Xiaokang Yang', 'Wei Shen']","Multivariate time series forecasting (MTSF) is a fundamental problem in
numerous real-world applications. Recently, Transformer has become the de facto
solution for MTSF, especially for the long-term cases. However, except for the
one forward operation, the basic configurations in existing MTSF Transformer
architectures were barely carefully verified. In this study, we point out that
the current tokenization strategy in MTSF Transformer architectures ignores the
token uniformity inductive bias of Transformers. Therefore, the vanilla MTSF
transformer struggles to capture details in time series and presents inferior
performance. Based on this observation, we make a series of evolution on the
basic architecture of the vanilla MTSF transformer. We vary the flawed
tokenization strategy, along with the decoder structure and embeddings.
Surprisingly, the evolved simple transformer architecture is highly effective,
which successfully avoids the over-smoothing phenomena in the vanilla MTSF
transformer, achieves a more detailed and accurate prediction, and even
substantially outperforms the state-of-the-art Transformers that are
well-designed for MTSF.",http://arxiv.org/pdf/2212.02789v1,cs.LG
2022-12-05 19:46:47+00:00,cs-net: structural approach to time-series forecasting for high-dimensional feature space data with limited observations,"['Weiyu Zong', 'Mingqian Feng', 'Griffin Heyrich', 'Peter Chin']","In recent years, deep-learning-based approaches have been introduced to
solving time-series forecasting-related problems. These novel methods have
demonstrated impressive performance in univariate and low-dimensional
multivariate time-series forecasting tasks. However, when these novel methods
are used to handle high-dimensional multivariate forecasting problems, their
performance is highly restricted by a practical training time and a reasonable
GPU memory configuration. In this paper, inspired by a change of basis in the
Hilbert space, we propose a flexible data feature extraction technique that
excels in high-dimensional multivariate forecasting tasks. Our approach was
originally developed for the National Science Foundation (NSF) Algorithms for
Threat Detection (ATD) 2022 Challenge. Implemented using the attention
mechanism and Convolutional Neural Networks (CNN) architecture, our method
demonstrates great performance and compatibility. Our models trained on the
GDELT Dataset finished 1st and 2nd places in the ATD sprint series and hold
promise for other datasets for time series forecasting.",http://arxiv.org/pdf/2212.02567v1,cs.LG
2022-12-03 06:53:38+00:00,Contrastive Domain Adaptation for Time-Series via Temporal Mixup,"['Emadeldeen Eldele', 'Mohamed Ragab', 'Zhenghua Chen', 'Min Wu', 'Chee-Keong Kwoh', 'Xiaoli Li']","Unsupervised Domain Adaptation (UDA) has emerged as a powerful solution for
the domain shift problem via transferring the knowledge from a labeled source
domain to a shifted unlabeled target domain. Despite the prevalence of UDA for
visual applications, it remains relatively less explored for time-series
applications. In this work, we propose a novel lightweight contrastive domain
adaptation framework called CoTMix for time-series data. Unlike existing
approaches that either use statistical distances or adversarial techniques, we
leverage contrastive learning solely to mitigate the distribution shift across
the different domains. Specifically, we propose a novel temporal mixup strategy
to generate two intermediate augmented views for the source and target domains.
Subsequently, we leverage contrastive learning to maximize the similarity
between each domain and its corresponding augmented view. The generated views
consider the temporal dynamics of time-series data during the adaptation
process while inheriting the semantics among the two domains. Hence, we
gradually push both domains towards a common intermediate space, mitigating the
distribution shift across them. Extensive experiments conducted on five
real-world time-series datasets show that our approach can significantly
outperform all state-of-the-art UDA methods. The implementation code of CoTMix
is available at
\href{https://github.com/emadeldeen24/CoTMix}{github.com/emadeldeen24/CoTMix}.",http://arxiv.org/pdf/2212.01555v2,cs.LG
2022-12-03 04:08:56+00:00,Laplacian Convolutional Representation for Traffic Time Series Imputation,"['Xinyu Chen', 'Zhanhong Cheng', 'Nicolas Saunier', 'Lijun Sun']","Spatiotemporal traffic data imputation is of great significance in
intelligent transportation systems and data-driven decision-making processes.
To make an accurate reconstruction from partially observed traffic data, we
assert the importance of characterizing both global and local trends in traffic
time series. In the literature, substantial prior works have demonstrated the
effectiveness of utilizing low-rankness property of traffic data by
matrix/tensor completion models. In this study, we first introduce a Laplacian
kernel to temporal regularization for characterizing local trends in traffic
time series, which can be formulated in the form of circular convolution. Then,
we develop a low-rank Laplacian convolutional representation (LCR) model by
putting the nuclear norm of a circulant matrix and the Laplacian temporal
regularization together, which is proved to meet a unified framework that takes
a fast Fourier transform (FFT) solution in a relatively low time complexity.
Through extensive experiments on some traffic datasets, we demonstrate the
superiority of LCR for imputing traffic time series of various time series
behaviors (e.g., data noises and strong/weak periodicity). The proposed LCR
model is an efficient and effective solution to large-scale traffic data
imputation over the existing baseline models. Despite the LCR's application to
time series data, the key modeling idea lies in bridging the low-rank models
and the Laplacian regularization through FFT, which is also applicable to image
inpainting. The adapted datasets and Python implementation are publicly
available at https://github.com/xinychen/transdim.",http://arxiv.org/pdf/2212.01529v2,cs.LG
2022-12-02 12:42:53+00:00,MHCCL: Masked Hierarchical Cluster-Wise Contrastive Learning for Multivariate Time Series,"['Qianwen Meng', 'Hangwei Qian', 'Yong Liu', 'Lizhen Cui', 'Yonghui Xu', 'Zhiqi Shen']","Learning semantic-rich representations from raw unlabeled time series data is
critical for downstream tasks such as classification and forecasting.
Contrastive learning has recently shown its promising representation learning
capability in the absence of expert annotations. However, existing contrastive
approaches generally treat each instance independently, which leads to false
negative pairs that share the same semantics. To tackle this problem, we
propose MHCCL, a Masked Hierarchical Cluster-wise Contrastive Learning model,
which exploits semantic information obtained from the hierarchical structure
consisting of multiple latent partitions for multivariate time series.
Motivated by the observation that fine-grained clustering preserves higher
purity while coarse-grained one reflects higher-level semantics, we propose a
novel downward masking strategy to filter out fake negatives and supplement
positives by incorporating the multi-granularity information from the
clustering hierarchy. In addition, a novel upward masking strategy is designed
in MHCCL to remove outliers of clusters at each partition to refine prototypes,
which helps speed up the hierarchical clustering process and improves the
clustering quality. We conduct experimental evaluations on seven widely-used
multivariate time series datasets. The results demonstrate the superiority of
MHCCL over the state-of-the-art approaches for unsupervised time series
representation learning.",http://arxiv.org/pdf/2212.01141v4,cs.LG
2022-12-02 12:26:00+00:00,RIPPLE: Concept-Based Interpretation for Raw Time Series Models in Education,"['Mohammad Asadi', 'Vinitra Swamy', 'Jibril Frej', 'Julien Vignoud', 'Mirko Marras', 'Tanja Käser']","Time series is the most prevalent form of input data for educational
prediction tasks. The vast majority of research using time series data focuses
on hand-crafted features, designed by experts for predictive performance and
interpretability. However, extracting these features is labor-intensive for
humans and computers. In this paper, we propose an approach that utilizes
irregular multivariate time series modeling with graph neural networks to
achieve comparable or better accuracy with raw time series clickstreams in
comparison to hand-crafted features. Furthermore, we extend concept activation
vectors for interpretability in raw time series models. We analyze these
advances in the education domain, addressing the task of early student
performance prediction for downstream targeted interventions and instructional
support. Our experimental analysis on 23 MOOCs with millions of combined
interactions over six behavioral dimensions show that models designed with our
approach can (i) beat state-of-the-art educational time series baselines with
no feature extraction and (ii) provide interpretable insights for personalized
interventions. Source code: https://github.com/epfl-ml4ed/ripple/.",http://arxiv.org/pdf/2212.01133v4,cs.LG
2022-12-01 11:37:49+00:00,Functional estimation and change detection for nonstationary time series,['Fabian Mies'],"Tests for structural breaks in time series should ideally be sensitive to
breaks in the parameter of interest, while being robust to nuisance changes.
Statistical analysis thus needs to allow for some form of nonstationarity under
the null hypothesis of no change. In this paper, estimators for integrated
parameters of locally stationary time series are constructed and a
corresponding functional central limit theorem is established, enabling
change-point inference for a broad class of parameters under mild assumptions.
The proposed framework covers all parameters which may be expressed as
nonlinear functions of moments, for example kurtosis, autocorrelation, and
coefficients in a linear regression model. To perform feasible inference based
on the derived limit distribution, a bootstrap variant is proposed and its
consistency is established. The methodology is illustrated by means of a
simulation study and by an application to high-frequency asset prices.",http://arxiv.org/pdf/2212.00447v1,stat.ME
2022-11-30 00:47:03+00:00,CRU: A Novel Neural Architecture for Improving the Predictive Performance of Time-Series Data,"['Sunghyun Sim', 'Dohee Kim', 'Hyerim Bae']","The time-series forecasting (TSF) problem is a traditional problem in the
field of artificial intelligence. Models such as Recurrent Neural Network
(RNN), Long Short Term Memory (LSTM), and GRU (Gate Recurrent Units) have
contributed to improving the predictive accuracy of TSF. Furthermore, model
structures have been proposed to combine time-series decomposition methods,
such as seasonal-trend decomposition using Loess (STL) to ensure improved
predictive accuracy. However, because this approach is learned in an
independent model for each component, it cannot learn the relationships between
time-series components. In this study, we propose a new neural architecture
called a correlation recurrent unit (CRU) that can perform time series
decomposition within a neural cell and learn correlations (autocorrelation and
correlation) between each decomposition component. The proposed neural
architecture was evaluated through comparative experiments with previous
studies using five univariate time-series datasets and four multivariate
time-series data. The results showed that long- and short-term predictive
performance was improved by more than 10%. The experimental results show that
the proposed CRU is an excellent method for TSF problems compared to other
neural architectures.",http://arxiv.org/pdf/2211.16653v2,cs.LG
2022-11-29 12:03:54+00:00,Joint Neural Architecture and Hyperparameter Search for Correlated Time Series Forecasting,"['Xinle Wu', 'Dalin Zhang', 'Miao Zhang', 'Chenjuan Guo', 'Bin Yang', 'Christian S. Jensen']","Sensors in cyber-physical systems often capture interconnected processes and
thus emit correlated time series (CTS), the forecasting of which enables
important applications. The key to successful CTS forecasting is to uncover the
temporal dynamics of time series and the spatial correlations among time
series. Deep learning-based solutions exhibit impressive performance at
discerning these aspects. In particular, automated CTS forecasting, where the
design of an optimal deep learning architecture is automated, enables
forecasting accuracy that surpasses what has been achieved by manual
approaches. However, automated CTS solutions remain in their infancy and are
only able to find optimal architectures for predefined hyperparameters and
scale poorly to large-scale CTS. To overcome these limitations, we propose
SEARCH, a joint, scalable framework, to automatically devise effective CTS
forecasting models. Specifically, we encode each candidate architecture and
accompanying hyperparameters into a joint graph representation. We introduce an
efficient Architecture-Hyperparameter Comparator (AHC) to rank all
architecture-hyperparameter pairs, and we then further evaluate the top-ranked
pairs to select a final result. Extensive experiments on six benchmark datasets
demonstrate that SEARCH not only eliminates manual efforts but also is capable
of better performance than manually designed and existing automatically
designed CTS models. In addition, it shows excellent scalability to large CTS.",http://arxiv.org/pdf/2211.16126v2,cs.LG
2022-11-29 03:01:59+00:00,An Extreme-Adaptive Time Series Prediction Model Based on Probability-Enhanced LSTM Neural Networks,"['Yanhong Li', 'Jack Xu', 'David C. Anastasiu']","Forecasting time series with extreme events has been a challenging and
prevalent research topic, especially when the time series data are affected by
complicated uncertain factors, such as is the case in hydrologic prediction.
Diverse traditional and deep learning models have been applied to discover the
nonlinear relationships and recognize the complex patterns in these types of
data. However, existing methods usually ignore the negative influence of
imbalanced data, or severe events, on model training. Moreover, methods are
usually evaluated on a small number of generally well-behaved time series,
which does not show their ability to generalize. To tackle these issues, we
propose a novel probability-enhanced neural network model, called NEC+, which
concurrently learns extreme and normal prediction functions and a way to choose
among them via selective back propagation. We evaluate the proposed model on
the difficult 3-day ahead hourly water level prediction task applied to 9
reservoirs in California. Experimental results demonstrate that the proposed
model significantly outperforms state-of-the-art baselines and exhibits
superior generalization ability on data with diverse distributions.",http://arxiv.org/pdf/2211.15891v1,cs.LG
2022-11-28 06:37:15+00:00,Hierarchical Proxy Modeling for Improved HPO in Time Series Forecasting,"['Arindam Jati', 'Vijay Ekambaram', 'Shaonli Pal', 'Brian Quanz', 'Wesley M. Gifford', 'Pavithra Harsha', 'Stuart Siegel', 'Sumanta Mukherjee', 'Chandra Narayanaswami']","Selecting the right set of hyperparameters is crucial in time series
forecasting. The classical temporal cross-validation framework for
hyperparameter optimization (HPO) often leads to poor test performance because
of a possible mismatch between validation and test periods. To address this
test-validation mismatch, we propose a novel technique, H-Pro to drive HPO via
test proxies by exploiting data hierarchies often associated with time series
datasets. Since higher-level aggregated time series often show less
irregularity and better predictability as compared to the lowest-level time
series which can be sparse and intermittent, we optimize the hyperparameters of
the lowest-level base-forecaster by leveraging the proxy forecasts for the test
period generated from the forecasters at higher levels. H-Pro can be applied on
any off-the-shelf machine learning model to perform HPO. We validate the
efficacy of our technique with extensive empirical evaluation on five publicly
available hierarchical forecasting datasets. Our approach outperforms existing
state-of-the-art methods in Tourism, Wiki, and Traffic datasets, and achieves
competitive result in Tourism-L dataset, without any model-specific
enhancements. Moreover, our method outperforms the winning method of the M5
forecast accuracy competition.",http://arxiv.org/pdf/2211.15092v2,cs.LG
2022-11-27 21:12:26+00:00,An Anomaly Detection Method for Satellites Using Monte Carlo Dropout,"['Mohammad Amin Maleki Sadr', 'Yeying Zhu', 'Peng Hu']","Recently, there has been a significant amount of interest in satellite
telemetry anomaly detection (AD) using neural networks (NN). For AD purposes,
the current approaches focus on either forecasting or reconstruction of the
time series, and they cannot measure the level of reliability or the
probability of correct detection. Although the Bayesian neural network
(BNN)-based approaches are well known for time series uncertainty estimation,
they are computationally intractable. In this paper, we present a tractable
approximation for BNN based on the Monte Carlo (MC) dropout method for
capturing the uncertainty in the satellite telemetry time series, without
sacrificing accuracy. For time series forecasting, we employ an NN, which
consists of several Long Short-Term Memory (LSTM) layers followed by various
dense layers. We employ the MC dropout inside each LSTM layer and before the
dense layers for uncertainty estimation. With the proposed uncertainty region
and by utilizing a post-processing filter, we can effectively capture the
anomaly points. Numerical results show that our proposed time series AD
approach outperforms the existing methods from both prediction accuracy and AD
perspectives.",http://arxiv.org/pdf/2211.14938v1,cs.LG
2022-11-27 05:15:42+00:00,A Time Series is Worth 64 Words: Long-term Forecasting with Transformers,"['Yuqi Nie', 'Nam H. Nguyen', 'Phanwadee Sinthong', 'Jayant Kalagnanam']","We propose an efficient design of Transformer-based models for multivariate
time series forecasting and self-supervised representation learning. It is
based on two key components: (i) segmentation of time series into
subseries-level patches which are served as input tokens to Transformer; (ii)
channel-independence where each channel contains a single univariate time
series that shares the same embedding and Transformer weights across all the
series. Patching design naturally has three-fold benefit: local semantic
information is retained in the embedding; computation and memory usage of the
attention maps are quadratically reduced given the same look-back window; and
the model can attend longer history. Our channel-independent patch time series
Transformer (PatchTST) can improve the long-term forecasting accuracy
significantly when compared with that of SOTA Transformer-based models. We also
apply our model to self-supervised pre-training tasks and attain excellent
fine-tuning performance, which outperforms supervised training on large
datasets. Transferring of masked pre-trained representation on one dataset to
others also produces SOTA forecasting accuracy. Code is available at:
https://github.com/yuqinie98/PatchTST.",http://arxiv.org/pdf/2211.14730v2,cs.LG
2022-11-26 14:33:34+00:00,Distribution estimation and change-point estimation for time series via DNN-based GANs,"['Jianya Lu', 'Yingjun Mo', 'Zhijie Xiao', 'Lihu Xu', 'Qiuran Yao']","The generative adversarial networks (GANs) have recently been applied to
estimating the distribution of independent and identically distributed data,
and have attracted a lot of research attention. In this paper, we use the
blocking technique to demonstrate the effectiveness of GANs for estimating the
distribution of stationary time series. Theoretically, we derive a
non-asymptotic error bound for the Deep Neural Network (DNN)-based GANs
estimator for the stationary distribution of the time series. Based on our
theoretical analysis, we propose an algorithm for estimating the change point
in time series distribution. The two main results are verified by two Monte
Carlo experiments respectively, one is to estimate the joint stationary
distribution of $5$-tuple samples of a 20 dimensional AR(3) model, the other is
about estimating the change point at the combination of two different
stationary time series. A real world empirical application to the human
activity recognition dataset highlights the potential of the proposed methods.",http://arxiv.org/pdf/2211.14577v2,cs.LG
2022-11-25 22:12:03+00:00,Machine Learning Algorithms for Time Series Analysis and Forecasting,"['Rameshwar Garg', 'Shriya Barpanda', 'Girish Rao Salanke N S', 'Ramya S']","Time series data is being used everywhere, from sales records to patients'
health evolution metrics. The ability to deal with this data has become a
necessity, and time series analysis and forecasting are used for the same.
Every Machine Learning enthusiast would consider these as very important tools,
as they deepen the understanding of the characteristics of data. Forecasting is
used to predict the value of a variable in the future, based on its past
occurrences. A detailed survey of the various methods that are used for
forecasting has been presented in this paper. The complete process of
forecasting, from preprocessing to validation has also been explained
thoroughly. Various statistical and deep learning models have been considered,
notably, ARIMA, Prophet and LSTMs. Hybrid versions of Machine Learning models
have also been explored and elucidated. Our work can be used by anyone to
develop a good understanding of the forecasting process, and to identify
various state of the art models which are being used today.",http://arxiv.org/pdf/2211.14387v1,cs.LG
2022-11-25 06:08:08+00:00,Confidence Interval Construction for Multivariate time series using Long Short Term Memory Network,"['Aryan Bhambu', 'Arabin Kumar Dey']","In this paper we propose a novel procedure to construct a confidence interval
for multivariate time series predictions using long short term memory network.
The construction uses a few novel block bootstrap techniques. We also propose
an innovative block length selection procedure for each of these schemes. Two
novel benchmarks help us to compare the construction of this confidence
intervals by different bootstrap techniques. We illustrate the whole
construction through S\&P $500$ and Dow Jones Index datasets.",http://arxiv.org/pdf/2211.13915v1,stat.ME
2022-11-22 10:17:42+00:00,MGADN: A Multi-task Graph Anomaly Detection Network for Multivariate Time Series,"['Weixuan Xiong', 'Xiaochen Sun']","Anomaly detection of time series, especially multivariate time series(time
series with multiple sensors), has been focused on for several years. Though
existing method has achieved great progress, there are several challenging
problems to be solved. Firstly, existing method including neural network only
concentrate on the relationship in terms of timestamp. To be exact, they only
want to know how does the data in the past influence which in the future.
However, one sensor sometimes intervenes in other sensor such as the speed of
wind may cause decrease of temperature. Secondly, there exist two categories of
model for time series anomaly detection: prediction model and reconstruction
model. Prediction model is adept at learning timely representation while short
of capability when faced with sparse anomaly. Conversely, reconstruction model
is opposite. Therefore, how can we efficiently get the relationship both in
terms of both timestamp and sensors becomes our main topic. Our approach uses
GAT, which is originated from graph neural network, to obtain connection
between sensors. And LSTM is used to obtain relationships timely. Our approach
is also designed to be double headed to calculate both prediction loss and
reconstruction loss via VAE(Variational Auto-Encoder). In order to take
advantage of two sorts of model, multi-task optimization algorithm is used in
this model.",http://arxiv.org/pdf/2211.12141v2,cs.LG
2022-11-22 06:09:29+00:00,Time Series Forecasting with Hypernetworks Generating Parameters in Advance,"['Jaehoon Lee', 'Chan Kim', 'Gyumin Lee', 'Haksoo Lim', 'Jeongwhan Choi', 'Kookjin Lee', 'Dongeun Lee', 'Sanghyun Hong', 'Noseong Park']","Forecasting future outcomes from recent time series data is not easy,
especially when the future data are different from the past (i.e. time series
are under temporal drifts). Existing approaches show limited performances under
data drifts, and we identify the main reason: It takes time for a model to
collect sufficient training data and adjust its parameters for complicated
temporal patterns whenever the underlying dynamics change. To address this
issue, we study a new approach; instead of adjusting model parameters (by
continuously re-training a model on new data), we build a hypernetwork that
generates other target models' parameters expected to perform well on the
future data. Therefore, we can adjust the model parameters beforehand (if the
hypernetwork is correct). We conduct extensive experiments with 6 target
models, 6 baselines, and 4 datasets, and show that our HyperGPA outperforms
other baselines.",http://arxiv.org/pdf/2211.12034v1,cs.LG
2022-11-21 22:52:51+00:00,Margin-closed vector autoregressive time series models,"['Lin Zhang', 'Harry Joe', 'Natalia Nolde']","Conditions are obtained for a Gaussian vector autoregressive time series of
order $k$, VAR($k$), to have univariate margins that are autoregressive of
order $k$ or lower-dimensional margins that are also VAR($k$). This can lead to
$d$-dimensional VAR($k$) models that are closed with respect to a given
partition $\{S_1,\ldots,S_n\}$ of $\{1,\ldots,d\}$ by specifying marginal
serial dependence and some cross-sectional dependence parameters. The special
closure property allows one to fit the sub-processes of multivariate time
series before assembling them by fitting the dependence structure between the
sub-processes. We revisit the use of the Gaussian copula of the stationary
joint distribution of observations in the VAR($k$) process with non-Gaussian
univariate margins but under the constraint of closure under margins. This
construction allows more flexibility in handling higher-dimensional time series
and a multi-stage estimation procedure can be used. The proposed class of
models is applied to a macro-economic data set and compared with the relevant
benchmark models.",http://arxiv.org/pdf/2211.11898v2,stat.ME
2022-11-20 19:25:02+00:00,Deep learning delay coordinate dynamics for chaotic attractors from partial observable data,"['Charles D. Young', 'Michael D. Graham']","A common problem in time series analysis is to predict dynamics with only
scalar or partial observations of the underlying dynamical system. For data on
a smooth compact manifold, Takens theorem proves a time delayed embedding of
the partial state is diffeomorphic to the attractor, although for chaotic and
highly nonlinear systems learning these delay coordinate mappings is
challenging. We utilize deep artificial neural networks (ANNs) to learn
discrete discrete time maps and continuous time flows of the partial state.
Given training data for the full state, we also learn a reconstruction map.
Thus, predictions of a time series can be made from the current state and
several previous observations with embedding parameters determined from time
series analysis. The state space for time evolution is of comparable dimension
to reduced order manifold models. These are advantages over recurrent neural
network models, which require a high dimensional internal state or additional
memory terms and hyperparameters. We demonstrate the capacity of deep ANNs to
predict chaotic behavior from a scalar observation on a manifold of dimension
three via the Lorenz system. We also consider multivariate observations on the
Kuramoto-Sivashinsky equation, where the observation dimension required for
accurately reproducing dynamics increases with the manifold dimension via the
spatial extent of the system.",http://arxiv.org/pdf/2211.11061v1,cs.LG
2022-11-19 07:51:51+00:00,Class-Specific Attention (CSA) for Time-Series Classification,"['Yifan Hao', 'Huiping Cao', 'K. Selcuk Candan', 'Jiefei Liu', 'Huiying Chen', 'Ziwei Ma']","Most neural network-based classifiers extract features using several hidden
layers and make predictions at the output layer by utilizing these extracted
features. We observe that not all features are equally pronounced in all
classes; we call such features class-specific features. Existing models do not
fully utilize the class-specific differences in features as they feed all
extracted features from the hidden layers equally to the output layers. Recent
attention mechanisms allow giving different emphasis (or attention) to
different features, but these attention models are themselves class-agnostic.
In this paper, we propose a novel class-specific attention (CSA) module to
capture significant class-specific features and improve the overall
classification performance of time series. The CSA module is designed in a way
such that it can be adopted in existing neural network (NN) based models to
conduct time series classification. In the experiments, this module is plugged
into five start-of-the-art neural network models for time series classification
to test its effectiveness by using 40 different real datasets. Extensive
experiments show that an NN model embedded with the CSA module can improve the
base model in most cases and the accuracy improvement can be up to 42%. Our
statistical analysis show that the performance of an NN model embedding the CSA
module is better than the base NN model on 67% of MTS and 80% of UTS test cases
and is significantly better on 11% of MTS and 13% of UTS test cases.",http://arxiv.org/pdf/2211.10609v1,cs.LG
2022-11-17 11:51:35+00:00,Parameterization of state duration in Hidden semi-Markov Models: an application in electrocardiography,"['Adrián Pérez Herrero', 'Paulo Félix Lamas', 'Jesús María Rodríguez Presedo']","This work aims at providing a new model for time series classification based
on learning from just one example. We assume that time series can be well
characterized as a parametric random process, a sort of Hidden semi-Markov
Model representing a sequence of regression models with variable duration. We
introduce a parametric stochastic model for time series pattern recognition and
provide a maximum-likelihood estimation of its parameters. Particularly, we are
interested in examining two different representations for state duration: i) a
discrete density distribution requiring an estimate for each possible duration;
and ii) a parametric family of continuous density functions, here the Gamma
distribution, with just two parameters to estimate. An application on heartbeat
classification reveals the main strengths and weaknesses of each alternative.",http://arxiv.org/pdf/2211.09478v1,stat.ML
2022-11-16 09:37:08+00:00,"Data-driven Real-time Short-term Prediction of Air Quality: Comparison of ES, ARIMA, and LSTM","['Iryna Talamanova', 'Sabri Pllana']","Air pollution is a worldwide issue that affects the lives of many people in
urban areas. It is considered that the air pollution may lead to heart and lung
diseases. A careful and timely forecast of the air quality could help to reduce
the exposure risk for affected people. In this paper, we use a data-driven
approach to predict air quality based on historical data. We compare three
popular methods for time series prediction: Exponential Smoothing (ES),
Auto-Regressive Integrated Moving Average (ARIMA) and Long short-term memory
(LSTM). Considering prediction accuracy and time complexity, our experiments
reveal that for short-term air pollution prediction ES performs better than
ARIMA and LSTM.",http://arxiv.org/pdf/2211.09814v1,cs.LG
2022-11-16 04:30:42+00:00,SETAR-Tree: A Novel and Accurate Tree Algorithm for Global Time Series Forecasting,"['Rakshitha Godahewa', 'Geoffrey I. Webb', 'Daniel Schmidt', 'Christoph Bergmeir']","Threshold Autoregressive (TAR) models have been widely used by statisticians
for non-linear time series forecasting during the past few decades, due to
their simplicity and mathematical properties. On the other hand, in the
forecasting community, general-purpose tree-based regression algorithms
(forests, gradient-boosting) have become popular recently due to their ease of
use and accuracy. In this paper, we explore the close connections between TAR
models and regression trees. These enable us to use the rich methodology from
the literature on TAR models to define a hierarchical TAR model as a regression
tree that trains globally across series, which we call SETAR-Tree. In contrast
to the general-purpose tree-based models that do not primarily focus on
forecasting, and calculate averages at the leaf nodes, we introduce a new
forecasting-specific tree algorithm that trains global Pooled Regression (PR)
models in the leaves allowing the models to learn cross-series information and
also uses some time-series-specific splitting and stopping procedures. The
depth of the tree is controlled by conducting a statistical linearity test
commonly employed in TAR models, as well as measuring the error reduction
percentage at each node split. Thus, the proposed tree model requires minimal
external hyperparameter tuning and provides competitive results under its
default configuration. We also use this tree algorithm to develop a forest
where the forecasts provided by a collection of diverse SETAR-Trees are
combined during the forecasting process. In our evaluation on eight publicly
available datasets, the proposed tree and forest models are able to achieve
significantly higher accuracy than a set of state-of-the-art tree-based
algorithms and forecasting benchmarks across four evaluation metrics.",http://arxiv.org/pdf/2211.08661v1,cs.LG
2022-11-15 06:00:28+00:00,Backdoor Attacks on Time Series: A Generative Approach,"['Yujing Jiang', 'Xingjun Ma', 'Sarah Monazam Erfani', 'James Bailey']","Backdoor attacks have emerged as one of the major security threats to deep
learning models as they can easily control the model's test-time predictions by
pre-injecting a backdoor trigger into the model at training time. While
backdoor attacks have been extensively studied on images, few works have
investigated the threat of backdoor attacks on time series data. To fill this
gap, in this paper we present a novel generative approach for time series
backdoor attacks against deep learning based time series classifiers. Backdoor
attacks have two main goals: high stealthiness and high attack success rate. We
find that, compared to images, it can be more challenging to achieve the two
goals on time series. This is because time series have fewer input dimensions
and lower degrees of freedom, making it hard to achieve a high attack success
rate without compromising stealthiness. Our generative approach addresses this
challenge by generating trigger patterns that are as realistic as real-time
series patterns while achieving a high attack success rate without causing a
significant drop in clean accuracy. We also show that our proposed attack is
resistant to potential backdoor defenses. Furthermore, we propose a novel
universal generator that can poison any type of time series with a single
generator that allows universal attacks without the need to fine-tune the
generative model for new time series datasets.",http://arxiv.org/pdf/2211.07915v5,cs.LG
2022-11-13 13:48:43+00:00,HigeNet: A Highly Efficient Modeling for Long Sequence Time Series Prediction in AIOps,"['Jiajia Li', 'Feng Tan', 'Cheng He', 'Zikai Wang', 'Haitao Song', 'Lingfei Wu', 'Pengwei Hu']","Modern IT system operation demands the integration of system software and
hardware metrics. As a result, it generates a massive amount of data, which can
be potentially used to make data-driven operational decisions. In the basic
form, the decision model needs to monitor a large set of machine data, such as
CPU utilization, allocated memory, disk and network latency, and predicts the
system metrics to prevent performance degradation. Nevertheless, building an
effective prediction model in this scenario is rather challenging as the model
has to accurately capture the long-range coupling dependency in the
Multivariate Time-Series (MTS). Moreover, this model needs to have low
computational complexity and can scale efficiently to the dimension of data
available. In this paper, we propose a highly efficient model named HigeNet to
predict the long-time sequence time series. We have deployed the HigeNet on
production in the D-matrix platform. We also provide offline evaluations on
several publicly available datasets as well as one online dataset to
demonstrate the model's efficacy. The extensive experiments show that training
time, resource usage and accuracy of the model are found to be significantly
better than five state-of-the-art competing models.",http://arxiv.org/pdf/2211.07642v1,cs.LG
2022-11-11 23:02:54+00:00,WindowSHAP: An Efficient Framework for Explaining Time-series Classifiers based on Shapley Values,"['Amin Nayebi', 'Sindhu Tipirneni', 'Chandan K Reddy', 'Brandon Foreman', 'Vignesh Subbian']","Unpacking and comprehending how black-box machine learning algorithms make
decisions has been a persistent challenge for researchers and end-users.
Explaining time-series predictive models is useful for clinical applications
with high stakes to understand the behavior of prediction models. However,
existing approaches to explain such models are frequently unique to data where
the features do not have a time-varying component. In this paper, we introduce
WindowSHAP, a model-agnostic framework for explaining time-series classifiers
using Shapley values. We intend for WindowSHAP to mitigate the computational
complexity of calculating Shapley values for long time-series data as well as
improve the quality of explanations. WindowSHAP is based on partitioning a
sequence into time windows. Under this framework, we present three distinct
algorithms of Stationary, Sliding and Dynamic WindowSHAP, each evaluated
against baseline approaches, KernelSHAP and TimeSHAP, using perturbation and
sequence analyses metrics. We applied our framework to clinical time-series
data from both a specialized clinical domain (Traumatic Brain Injury - TBI) as
well as a broad clinical domain (critical care medicine). The experimental
results demonstrate that, based on the two quantitative metrics, our framework
is superior at explaining clinical time-series classifiers, while also reducing
the complexity of computations. We show that for time-series data with 120 time
steps (hours), merging 10 adjacent time points can reduce the CPU time of
WindowSHAP by 80% compared to KernelSHAP. We also show that our Dynamic
WindowSHAP algorithm focuses more on the most important time steps and provides
more understandable explanations. As a result, WindowSHAP not only accelerates
the calculation of Shapley values for time-series data, but also delivers more
understandable explanations with higher quality.",http://arxiv.org/pdf/2211.06507v2,cs.LG
2022-11-11 14:29:13+00:00,Comparison of Uncertainty Quantification with Deep Learning in Time Series Regression,"['Levente Foldesi', 'Matias Valdenegro-Toro']","Increasingly high-stakes decisions are made using neural networks in order to
make predictions. Specifically, meteorologists and hedge funds apply these
techniques to time series data. When it comes to prediction, there are certain
limitations for machine learning models (such as lack of expressiveness,
vulnerability of domain shifts and overconfidence) which can be solved using
uncertainty estimation. There is a set of expectations regarding how
uncertainty should ``behave"". For instance, a wider prediction horizon should
lead to more uncertainty or the model's confidence should be proportional to
its accuracy. In this paper, different uncertainty estimation methods are
compared to forecast meteorological time series data and evaluate these
expectations. The results show how each uncertainty estimation method performs
on the forecasting task, which partially evaluates the robustness of predicted
uncertainty.",http://arxiv.org/pdf/2211.06233v1,cs.LG
2022-11-11 07:09:49+00:00,Does Deep Learning REALLY Outperform Non-deep Machine Learning for Clinical Prediction on Physiological Time Series?,"['Ke Liao', 'Wei Wang', 'Armagan Elibol', 'Lingzhong Meng', 'Xu Zhao', 'Nak Young Chong']","Machine learning has been widely used in healthcare applications to
approximate complex models, for clinical diagnosis, prognosis, and treatment.
As deep learning has the outstanding ability to extract information from time
series, its true capabilities on sparse, irregularly sampled, multivariate, and
imbalanced physiological data are not yet fully explored. In this paper, we
systematically examine the performance of machine learning models for the
clinical prediction task based on the EHR, especially physiological time
series. We choose Physionet 2019 challenge public dataset to predict Sepsis
outcomes in ICU units. Ten baseline machine learning models are compared,
including 3 deep learning methods and 7 non-deep learning methods, commonly
used in the clinical prediction domain. Nine evaluation metrics with specific
clinical implications are used to assess the performance of models. Besides, we
sub-sample training dataset sizes and use learning curve fit to investigate the
impact of the training dataset size on the performance of the machine learning
models. We also propose the general pre-processing method for the physiology
time-series data and use Dice Loss to deal with the dataset imbalanced problem.
The results show that deep learning indeed outperforms non-deep learning, but
with certain conditions: firstly, evaluating with some particular evaluation
metrics (AUROC, AUPRC, Sensitivity, and FNR), but not others; secondly, the
training dataset size is large enough (with an estimation of a magnitude of
thousands).",http://arxiv.org/pdf/2211.06034v1,cs.LG
2022-11-09 22:40:22+00:00,Deep Learning for Time Series Anomaly Detection: A Survey,"['Zahra Zamanzadeh Darban', 'Geoffrey I. Webb', 'Shirui Pan', 'Charu C. Aggarwal', 'Mahsa Salehi']","Time series anomaly detection has applications in a wide range of research
fields and applications, including manufacturing and healthcare. The presence
of anomalies can indicate novel or unexpected events, such as production
faults, system defects, or heart fluttering, and is therefore of particular
interest. The large size and complex patterns of time series have led
researchers to develop specialised deep learning models for detecting anomalous
patterns. This survey focuses on providing structured and comprehensive
state-of-the-art time series anomaly detection models through the use of deep
learning. It providing a taxonomy based on the factors that divide anomaly
detection models into different categories. Aside from describing the basic
anomaly detection technique for each category, the advantages and limitations
are also discussed. Furthermore, this study includes examples of deep anomaly
detection in time series across various application domains in recent years. It
finally summarises open issues in research and challenges faced while adopting
deep anomaly detection models.",http://arxiv.org/pdf/2211.05244v2,cs.LG
2022-11-08 04:04:56+00:00,Dynamic Interpretable Change Point Detection,"['Kopal Garg', 'Jennifer Yu', 'Tina Behrouzi', 'Sana Tonekaboni', 'Anna Goldenberg']","Identifying change points (CPs) in a time series is crucial to guide better
decision making across various fields like finance and healthcare and
facilitating timely responses to potential risks or opportunities. Existing
Change Point Detection (CPD) methods have a limitation in tracking changes in
the joint distribution of multidimensional features. In addition, they fail to
generalize effectively within the same time series as different types of CPs
may require different detection methods. As the volume of multidimensional time
series continues to grow, capturing various types of complex CPs such as
changes in the correlation structure of the time-series features has become
essential. To overcome the limitations of existing methods, we propose TiVaCPD,
an approach that uses a Time-Varying Graphical Lasso (TVGL) to identify changes
in correlation patterns between multidimensional features over time, and
combines that with an aggregate Kernel Maximum Mean Discrepancy (MMD) test to
identify changes in the underlying statistical distributions of dynamic time
windows with varying length. The MMD and TVGL scores are combined using a novel
ensemble method based on similarity measures leveraging the power of both
statistical tests. We evaluate the performance of TiVaCPD in identifying and
characterizing various types of CPs and show that our method outperforms
current state-of-the-art methods in real-world CPD datasets. We further
demonstrate that TiVaCPD scores characterize the type of CPs and facilitate
interpretation of change dynamics, offering insights into real-life
applications.",http://arxiv.org/pdf/2211.03991v2,cs.LG
2022-11-05 23:06:25+00:00,A Comprehensive Survey of Regression Based Loss Functions for Time Series Forecasting,"['Aryan Jadon', 'Avinash Patil', 'Shruti Jadon']","Time Series Forecasting has been an active area of research due to its many
applications ranging from network usage prediction, resource allocation,
anomaly detection, and predictive maintenance. Numerous publications published
in the last five years have proposed diverse sets of objective loss functions
to address cases such as biased data, long-term forecasting, multicollinear
features, etc. In this paper, we have summarized 14 well-known regression loss
functions commonly used for time series forecasting and listed out the
circumstances where their application can aid in faster and better model
convergence. We have also demonstrated how certain categories of loss functions
perform well across all data sets and can be considered as a baseline objective
function in circumstances where the distribution of the data is unknown. Our
code is available at GitHub:
https://github.com/aryan-jadon/Regression-Loss-Functions-in-Time-Series-Forecasting-Tensorflow.",http://arxiv.org/pdf/2211.02989v1,cs.LG
2022-11-04 16:52:45+00:00,Inference for Network Count Time Series with the R Package PNAR,"['Mirko Armillotta', 'Michail Tsagris', 'Konstantinos Fokianos']","We introduce a new R package useful for inference about network count time
series. Such data are frequently encountered in statistics and they are usually
treated as multivariate time series. Their statistical analysis is based on
linear or log linear models. Nonlinear models, which have been applied
successfully in several research areas, have been neglected from such
applications mainly because of their computational complexity. We provide R
users the flexibility to fit and study nonlinear network count time series
models which include either a drift in the intercept or a regime switching
mechanism. We develop several computational tools including estimation of
various count Network Autoregressive models and fast computational algorithms
for testing linearity in standard cases and when non-identifiable parameters
hamper the analysis. Finally, we introduce a copula Poisson algorithm for
simulating multivariate network count time series. We illustrate the
methodology by modeling weekly number of influenza cases in Germany.",http://arxiv.org/pdf/2211.02582v2,stat.ME
2022-11-04 05:58:04+00:00,Time series quantile regression using random forests,"['Hiroshi Shiraishi', 'Tomoshige Nakamura', 'Ryotato Shibuki']","We discuss an application of Generalized Random Forests (GRF) proposed by
Athey et al.(2019) to quantile regression for time series data. We extracted
the theoretical results of the GRF consistency for i.i.d. data to time series
data. In particular, in the main theorem, based only on the general assumptions
for time series data in Davis and Nielsen (2020), and trees in Athey et
al.(2019), we show that the tsQRF (time series Quantile Regression Forests)
estimator is consistent. Davis and Nielsen (2020) also discussed the estimation
problem using Random Forests (RF) for time series data, but the construction
procedure of the RF treated by the GRF is essentially different, and different
ideas are used throughout the theoretical proof. In addition, a simulation and
real data analysis were conducted.In the simulation, the accuracy of the
conditional quantile estimation was evaluated under time series models. In the
real data using the Nikkei Stock Average, our estimator is demonstrated to be
more sensitive than the others in terms of volatility, thus preventing
underestimation of risk.",http://arxiv.org/pdf/2211.02273v1,math.ST
2022-11-03 21:05:57+00:00,Robust Time Series Chain Discovery with Incremental Nearest Neighbors,"['Li Zhang', 'Yan Zhu', 'Yifeng Gao', 'Jessica Lin']","Time series motif discovery has been a fundamental task to identify
meaningful repeated patterns in time series. Recently, time series chains were
introduced as an expansion of time series motifs to identify the continuous
evolving patterns in time series data. Informally, a time series chain (TSC) is
a temporally ordered set of time series subsequences, in which every
subsequence is similar to the one that precedes it, but the last and the first
can be arbitrarily dissimilar. TSCs are shown to be able to reveal latent
continuous evolving trends in the time series, and identify precursors of
unusual events in complex systems. Despite its promising interpretability,
unfortunately, we have observed that existing TSC definitions lack the ability
to accurately cover the evolving part of a time series: the discovered chains
can be easily cut by noise and can include non-evolving patterns, making them
impractical in real-world applications. Inspired by a recent work that tracks
how the nearest neighbor of a time series subsequence changes over time, we
introduce a new TSC definition which is much more robust to noise in the data,
in the sense that they can better locate the evolving patterns while excluding
the non-evolving ones. We further propose two new quality metrics to rank the
discovered chains. With extensive empirical evaluations, we demonstrate that
the proposed TSC definition is significantly more robust to noise than the
state of the art, and the top ranked chains discovered can reveal meaningful
regularities in a variety of real world datasets.",http://arxiv.org/pdf/2211.02146v1,cs.LG
2022-11-02 21:44:16+00:00,"Fast, effective, and coherent time series modeling using the sparsity-ranked lasso","['Ryan Peterson', 'Joseph Cavanaugh']","The sparsity-ranked lasso (SRL) has been developed for model selection and
estimation in the presence of interactions and polynomials. The main tenet of
the SRL is that an algorithm should be more skeptical of higher-order
polynomials and interactions *a priori* compared to main effects, and hence the
inclusion of these more complex terms should require a higher level of
evidence. In time series, the same idea of ranked prior skepticism can be
applied to the possibly seasonal autoregressive (AR) structure of the series
during the model fitting process, becoming especially useful in settings with
uncertain or multiple modes of seasonality. The SRL can naturally incorporate
exogenous variables, with streamlined options for inference and/or feature
selection. The fitting process is quick even for large series with a
high-dimensional feature set. In this work, we discuss both the formulation of
this procedure and the software we have developed for its implementation via
the **srlTS** R package. We explore the performance of our SRL-based approach
in a novel application involving the autoregressive modeling of hourly
emergency room arrivals at the University of Iowa Hospitals and Clinics. We
find that the SRL is considerably faster than its competitors, while producing
more accurate predictions.",http://arxiv.org/pdf/2211.01492v1,stat.ME
2022-11-02 13:51:08+00:00,Solving an Inverse Problem for Time Series Valued Computer Simulators via Multiple Contour Estimation,"['Pritam Ranjan', 'Joseph Resch', 'Abhyuday Mandal']","Computer simulators are often used as a substitute of complex real-life
phenomena which are either expensive or infeasible to experiment with. This
paper focuses on how to efficiently solve the inverse problem for an expensive
to evaluate time series valued computer simulator. The research is motivated by
a hydrological simulator which has to be tuned for generating realistic
rainfall-runoff measurements in Athens, Georgia, USA. Assuming that the
simulator returns g(x,t) over L time points for a given input x, the proposed
methodology begins with a careful construction of a discretization (time-)
point set (DPS) of size $k << L$, achieved by adopting a regression spline
approximation of the target response series at k optimal knots locations
$\{t^*_1, t^*_2, ..., t^*_k\}$. Subsequently, we solve k scalar valued inverse
problems for simulator $g(x,t^*_j)$ via the contour estimation method. The
proposed approach, named MSCE, also facilitates the uncertainty quantification
of the inverse solution. Extensive simulation study is used to demonstrate the
performance comparison of the proposed method with the popular competitors for
several test-function based computer simulators and a real-life rainfall-runoff
measurement model.",http://arxiv.org/pdf/2211.01119v1,stat.ME
2022-11-01 05:01:34+00:00,HFN: Heterogeneous Feature Network for Multivariate Time Series Anomaly Detection,"['Jun Zhan', 'Chengkun Wu', 'Canqun Yang', 'Qiucheng Miao', 'Xiandong Ma']","Network or physical attacks on industrial equipment or computer systems may
cause massive losses. Therefore, a quick and accurate anomaly detection (AD)
based on monitoring data, especially the multivariate time-series (MTS) data,
is of great significance. As the key step of anomaly detection for MTS data,
learning the relations among different variables has been explored by many
approaches. However, most of the existing approaches do not consider the
heterogeneity between variables, that is, different types of variables
(continuous numerical variables, discrete categorical variables or hybrid
variables) may have different and distinctive edge distributions. In this
paper, we propose a novel semi-supervised anomaly detection framework based on
a heterogeneous feature network (HFN) for MTS, learning heterogeneous structure
information from a mass of unlabeled time-series data to improve the accuracy
of anomaly detection, and using attention coefficient to provide an explanation
for the detected anomalies. Specifically, we first combine the embedding
similarity subgraph generated by sensor embedding and feature value similarity
subgraph generated by sensor values to construct a time-series heterogeneous
graph, which fully utilizes the rich heterogeneous mutual information among
variables. Then, a prediction model containing nodes and channel attentions is
jointly optimized to obtain better time-series representations. This approach
fuses the state-of-the-art technologies of heterogeneous graph structure
learning (HGSL) and representation learning. The experiments on four sensor
datasets from real-world applications demonstrate that our approach detects the
anomalies more accurately than those baseline approaches, thus providing a
basis for the rapid positioning of anomalies.",http://arxiv.org/pdf/2211.00277v2,cs.LG
2022-10-31 18:29:40+00:00,Spatial-Temporal Synchronous Graph Transformer network (STSGT) for COVID-19 forecasting,"['Soumyanil Banerjee', 'Ming Dong', 'Weisong Shi']","COVID-19 has become a matter of serious concern over the last few years. It
has adversely affected numerous people around the globe and has led to the loss
of billions of dollars of business capital. In this paper, we propose a novel
Spatial-Temporal Synchronous Graph Transformer network (STSGT) to capture the
complex spatial and temporal dependency of the COVID-19 time series data and
forecast the future status of an evolving pandemic. The layers of STSGT combine
the graph convolution network (GCN) with the self-attention mechanism of
transformers on a synchronous spatial-temporal graph to capture the dynamically
changing pattern of the COVID time series. The spatial-temporal synchronous
graph simultaneously captures the spatial and temporal dependencies between the
vertices of the graph at a given and subsequent time-steps, which helps capture
the heterogeneity in the time series and improve the forecasting accuracy. Our
extensive experiments on two publicly available real-world COVID-19 time series
datasets demonstrate that STSGT significantly outperforms state-of-the-art
algorithms that were designed for spatial-temporal forecasting tasks.
Specifically, on average over a 12-day horizon, we observe a potential
improvement of 12.19% and 3.42% in Mean Absolute Error(MAE) over the next best
algorithm while forecasting the daily infected and death cases respectively for
the 50 states of US and Washington, D.C. Additionally, STSGT also outperformed
others when forecasting the daily infected cases at the state level, e.g., for
all the counties in the State of Michigan. The code and models are publicly
available at https://github.com/soumbane/STSGT.",http://arxiv.org/pdf/2211.00082v1,cs.LG
2022-10-31 15:22:50+00:00,Probabilistic Decomposition Transformer for Time Series Forecasting,"['Junlong Tong', 'Liping Xie', 'Wankou Yang', 'Kanjian Zhang']","Time series forecasting is crucial for many fields, such as disaster warning,
weather prediction, and energy consumption. The Transformer-based models are
considered to have revolutionized the field of sequence modeling. However, the
complex temporal patterns of the time series hinder the model from mining
reliable temporal dependencies. Furthermore, the autoregressive form of the
Transformer introduces cumulative errors in the inference step. In this paper,
we propose the probabilistic decomposition Transformer model that combines the
Transformer with a conditional generative model, which provides hierarchical
and interpretable probabilistic forecasts for intricate time series. The
Transformer is employed to learn temporal patterns and implement primary
probabilistic forecasts, while the conditional generative model is used to
achieve non-autoregressive hierarchical probabilistic forecasts by introducing
latent space feature representations. In addition, the conditional generative
model reconstructs typical features of the series, such as seasonality and
trend terms, from probability distributions in the latent space to enable
complex pattern separation and provide interpretable forecasts. Extensive
experiments on several datasets demonstrate the effectiveness and robustness of
the proposed model, indicating that it compares favorably with the state of the
art.",http://arxiv.org/pdf/2210.17393v1,cs.LG
2022-10-26 21:32:20+00:00,TILDE-Q: A Transformation Invariant Loss Function for Time-Series Forecasting,"['Hyunwook Lee', 'Chunggi Lee', 'Hongkyu Lim', 'Sungahn Ko']","Time-series forecasting has caught increasing attention in the AI research
field due to its importance in solving real-world problems across different
domains, such as energy, weather, traffic, and economy. As shown in various
types of data, it has been a must-see issue to deal with drastic changes,
temporal patterns, and shapes in sequential data that previous models are weak
in prediction. This is because most cases in time-series forecasting aim to
minimize $L_p$ norm distances as loss functions, such as mean absolute error
(MAE) or mean square error (MSE). These loss functions are vulnerable to not
only considering temporal dynamics modeling but also capturing the shape of
signals. In addition, these functions often make models misbehave and return
uncorrelated results to the original time-series. To become an effective loss
function, it has to be invariant to the set of distortions between two
time-series data instead of just comparing exact values. In this paper, we
propose a novel loss function, called TILDE-Q (Transformation Invariant Loss
function with Distance EQuilibrium), that not only considers the distortions in
amplitude and phase but also allows models to capture the shape of time-series
sequences. In addition, TILDE-Q supports modeling periodic and non-periodic
temporal dynamics at the same time. We evaluate the effectiveness of TILDE-Q by
conducting extensive experiments with respect to periodic and non-periodic
conditions of data, from naive models to state-of-the-art models. The
experiment results indicate that the models trained with TILDE-Q outperform
those trained with other training metrics (e.g., MSE, dynamic time warping
(DTW), temporal distortion index (TDI), and longest common subsequence (LCSS)).",http://arxiv.org/pdf/2210.15050v1,cs.LG
2022-10-25 19:58:02+00:00,WaveBound: Dynamic Error Bounds for Stable Time Series Forecasting,"['Youngin Cho', 'Daejin Kim', 'Dongmin Kim', 'Mohammad Azam Khan', 'Jaegul Choo']","Time series forecasting has become a critical task due to its high
practicality in real-world applications such as traffic, energy consumption,
economics and finance, and disease analysis. Recent deep-learning-based
approaches have shown remarkable success in time series forecasting.
Nonetheless, due to the dynamics of time series data, deep networks still
suffer from unstable training and overfitting. Inconsistent patterns appearing
in real-world data lead the model to be biased to a particular pattern, thus
limiting the generalization. In this work, we introduce the dynamic error
bounds on training loss to address the overfitting issue in time series
forecasting. Consequently, we propose a regularization method called WaveBound
which estimates the adequate error bounds of training loss for each time step
and feature at each iteration. By allowing the model to focus less on
unpredictable data, WaveBound stabilizes the training process, thus
significantly improving generalization. With the extensive experiments, we show
that WaveBound consistently improves upon the existing models in large margins,
including the state-of-the-art model.",http://arxiv.org/pdf/2210.14303v2,cs.LG
2022-10-25 12:30:48+00:00,Mitigating Health Data Poverty: Generative Approaches versus Resampling for Time-series Clinical Data,"['Raffaele Marchesi', 'Nicolo Micheletti', 'Giuseppe Jurman', 'Venet Osmani']","Several approaches have been developed to mitigate algorithmic bias stemming
from health data poverty, where minority groups are underrepresented in
training datasets. Augmenting the minority class using resampling (such as
SMOTE) is a widely used approach due to the simplicity of the algorithms.
However, these algorithms decrease data variability and may introduce
correlations between samples, giving rise to the use of generative approaches
based on GAN. Generation of high-dimensional, time-series, authentic data that
provides a wide distribution coverage of the real data, remains a challenging
task for both resampling and GAN-based approaches. In this work we propose
CA-GAN architecture that addresses some of the shortcomings of the current
approaches, where we provide a detailed comparison with both SMOTE and
WGAN-GP*, using a high-dimensional, time-series, real dataset of 3343
hypotensive Caucasian and Black patients. We show that our approach is better
at both generating authentic data of the minority class and remaining within
the original distribution of the real data.",http://arxiv.org/pdf/2210.13958v2,cs.LG
2022-10-24 16:01:46+00:00,Novelty Detection in Time Series via Weak Innovations Representation: A Deep Learning Approach,"['Xinyi Wang', 'Mei-jen Lee', 'Qing Zhao', 'Lang Tong']","We consider novelty detection in time series with unknown and nonparametric
probability structures. A deep learning approach is proposed to causally
extract an innovations sequence consisting of novelty samples statistically
independent of all past samples of the time series. A novelty detection
algorithm is developed for the online detection of novel changes in the
probability structure in the innovations sequence. A minimax optimality under a
Bayes risk measure is established for the proposed novelty detection method,
and its robustness and efficacy are demonstrated in experiments using real and
synthetic datasets.",http://arxiv.org/pdf/2210.13358v1,cs.LG
2022-10-20 18:45:33+00:00,A Semiparametric Approach to the Detection of Change-points in Volatility Dynamics of Financial Data,"['Huaiyu Hu', 'Ashis Gangopadhyay']","One of the most important features of financial time series data is
volatility. There are often structural changes in volatility over time, and an
accurate estimation of the volatility of financial time series requires careful
identification of change-points. A common approach to modeling the volatility
of time series data is the well-known GARCH model. Although the problem of
change-point estimation of volatility dynamics derived from the GARCH model has
been considered in the literature, these approaches rely on parametric
assumptions of the conditional error distribution, which are often violated in
financial time series. This may lead to inaccuracies in change-point detection
resulting in unreliable GARCH volatility estimates. This paper introduces a
novel change-point detection algorithm based on a semiparametric GARCH model.
The proposed method retains the structural advantages of the GARCH process
while incorporating the flexibility of nonparametric conditional error
distribution. The approach utilizes a penalized likelihood derived from a
semiparametric GARCH model and an efficient binary segmentation algorithm. The
results show that in terms of change-point estimation and detection accuracy,
the semiparametric method outperforms the commonly used Quasi-MLE (QMLE) and
other variations of GARCH models in wide-ranging scenarios.",http://arxiv.org/pdf/2210.11520v1,stat.ME
2022-10-18 20:29:26+00:00,Improving Medical Predictions by Irregular Multimodal Electronic Health Records Modeling,"['Xinlu Zhang', 'Shiyang Li', 'Zhiyu Chen', 'Xifeng Yan', 'Linda Petzold']","Health conditions among patients in intensive care units (ICUs) are monitored
via electronic health records (EHRs), composed of numerical time series and
lengthy clinical note sequences, both taken at irregular time intervals.
Dealing with such irregularity in every modality, and integrating irregularity
into multimodal representations to improve medical predictions, is a
challenging problem. Our method first addresses irregularity in each single
modality by (1) modeling irregular time series by dynamically incorporating
hand-crafted imputation embeddings into learned interpolation embeddings via a
gating mechanism, and (2) casting a series of clinical note representations as
multivariate irregular time series and tackling irregularity via a time
attention mechanism. We further integrate irregularity in multimodal fusion
with an interleaved attention mechanism across temporal steps. To the best of
our knowledge, this is the first work to thoroughly model irregularity in
multimodalities for improving medical predictions. Our proposed methods for two
medical prediction tasks consistently outperforms state-of-the-art (SOTA)
baselines in each single modality and multimodal fusion scenarios.
Specifically, we observe relative improvements of 6.5\%, 3.6\%, and 4.3\% in F1
for time series, clinical notes, and multimodal fusion, respectively. These
results demonstrate the effectiveness of our methods and the importance of
considering irregularity in multimodal EHRs.",http://arxiv.org/pdf/2210.12156v2,cs.LG
2022-10-18 12:54:08+00:00,Universal hidden monotonic trend estimation with contrastive learning,"['Edouard Pineau', 'Sébastien Razakarivony', 'Mauricio Gonzalez', 'Anthony Schrapffer']","In this paper, we describe a universal method for extracting the underlying
monotonic trend factor from time series data. We propose an approach related to
the Mann-Kendall test, a standard monotonic trend detection method and call it
contrastive trend estimation (CTE). We show that the CTE method identifies any
hidden trend underlying temporal data while avoiding the standard assumptions
used for monotonic trend identification. In particular, CTE can take any type
of temporal data (vector, images, graphs, time series, etc.) as input. We
finally illustrate the interest of our CTE method through several experiments
on different types of data and problems.",http://arxiv.org/pdf/2210.09817v2,cs.LG
2022-10-18 09:08:57+00:00,TFAD: A Decomposition Time Series Anomaly Detection Architecture with Time-Frequency Analysis,"['Chaoli Zhang', 'Tian Zhou', 'Qingsong Wen', 'Liang Sun']","Time series anomaly detection is a challenging problem due to the complex
temporal dependencies and the limited label data. Although some algorithms
including both traditional and deep models have been proposed, most of them
mainly focus on time-domain modeling, and do not fully utilize the information
in the frequency domain of the time series data. In this paper, we propose a
Time-Frequency analysis based time series Anomaly Detection model, or TFAD for
short, to exploit both time and frequency domains for performance improvement.
Besides, we incorporate time series decomposition and data augmentation
mechanisms in the designed time-frequency architecture to further boost the
abilities of performance and interpretability. Empirical studies on widely used
benchmark datasets show that our approach obtains state-of-the-art performance
in univariate and multivariate time series anomaly detection tasks. Code is
provided at https://github.com/DAMO-DI-ML/CIKM22-TFAD.",http://arxiv.org/pdf/2210.09693v2,cs.LG
2022-10-18 04:21:18+00:00,Fast same-step forecast in SUTSE model and its theoretical properties,"['Wataru Yoshida', 'Kei Hirose']","We consider the problem of forecasting multivariate time series by a
Seemingly Unrelated Time Series Equations (SUTSE) model. The SUTSE model
usually assumes that error variables are correlated. A crucial issue is that
the model estimation requires heavy computational loads because of a large
matrix computation, especially for high-dimensional data. To alleviate the
computational issue, we propose a two-stage procedure for forecasting. First,
we perform the Kalman filter as if error variables are uncorrelated; that is,
univariate time-series analyses are conducted separately to avoid a large
matrix computation. Next, the forecast value is computed by using a
distribution of forecast error. The proposed algorithm is much faster than the
ordinary SUTSE model because we do not require a large matrix computation. Some
theoretical properties of our proposed estimator are presented. Monte Carlo
simulation is performed to investigate the effectiveness of our proposed
method. The usefulness of our proposed procedure is illustrated through a bus
congestion data application.",http://arxiv.org/pdf/2210.09578v2,math.ST
2022-10-17 00:10:25+00:00,Temporal-Spatial dependencies ENhanced deep learning model (TSEN) for household leverage series forecasting,"['Hu Yang', 'Yi Huang', 'Haijun Wang', 'Yu Chen']","Analyzing both temporal and spatial patterns for an accurate forecasting
model for financial time series forecasting is a challenge due to the complex
nature of temporal-spatial dynamics: time series from different locations often
have distinct patterns; and for the same time series, patterns may vary as time
goes by. Inspired by the successful applications of deep learning, we propose a
new model to resolve the issues of forecasting household leverage in China. Our
solution consists of multiple RNN-based layers and an attention layer: each
RNN-based layer automatically learns the temporal pattern of a specific series
with multivariate exogenous series, and then the attention layer learns the
spatial correlative weight and obtains the global representations
simultaneously. The results show that the new approach can capture the
temporal-spatial dynamics of household leverage well and get more accurate and
solid predictive results. More, the simulation also studies show that
clustering and choosing correlative series are necessary to obtain accurate
forecasting results.",http://arxiv.org/pdf/2210.08668v1,cs.LG
2022-10-14 08:13:20+00:00,Quantifying Quality of Class-Conditional Generative Models in Time-Series Domain,"['Alireza Koochali', 'Maria Walch', 'Sankrutyayan Thota', 'Peter Schichtel', 'Andreas Dengel', 'Sheraz Ahmed']","Generative models are designed to address the data scarcity problem. Even
with the exploding amount of data, due to computational advancements, some
applications (e.g., health care, weather forecast, fault detection) still
suffer from data insufficiency, especially in the time-series domain. Thus
generative models are essential and powerful tools, but they still lack a
consensual approach for quality assessment. Such deficiency hinders the
confident application of modern implicit generative models on time-series data.
Inspired by assessment methods on the image domain, we introduce the
InceptionTime Score (ITS) and the Frechet InceptionTime Distance (FITD) to
gauge the qualitative performance of class conditional generative models on the
time-series domain. We conduct extensive experiments on 80 different datasets
to study the discriminative capabilities of proposed metrics alongside two
existing evaluation metrics: Train on Synthetic Test on Real (TSTR) and Train
on Real Test on Synthetic (TRTS). Extensive evaluation reveals that the
proposed assessment method, i.e., ITS and FITD in combination with TSTR, can
accurately assess class-conditional generative model performance.",http://arxiv.org/pdf/2210.07617v1,cs.LG
2022-10-14 07:16:16+00:00,Consistent Causal Inference from Time Series with PC Algorithm and its Time-Aware Extension,"['Rahul Biswas', 'Somabha Mukherjee']","The estimator of a causal directed acyclic graph (DAG) with the PC algorithm
is known to be consistent based on independent and identically distributed
samples. In this paper, we consider the scenario when the multivariate samples
are identically distributed but not independent. A common example is a
stationary multivariate time series. We show that under a standard set of
assumptions on the underlying time series involving $\rho$-mixing, the PC
algorithm is consistent in this dependent sample scenario. Further, we show
that for the popular time series models such as vector auto-regressive moving
average and linear processes, consistency of the PC algorithm holds. We also
prove the consistency for the Time-Aware PC algorithm, a recent adaptation of
the PC algorithm for the time series scenario. Our findings are supported by
simulations and benchmark real data analyses provided towards the end of the
paper.",http://arxiv.org/pdf/2210.09038v1,stat.ME
2022-10-13 20:18:22+00:00,LEAVES: Learning Views for Time-Series Data in Contrastive Learning,"['Han Yu', 'Huiyuan Yang', 'Akane Sano']","Contrastive learning, a self-supervised learning method that can learn
representations from unlabeled data, has been developed promisingly. Many
methods of contrastive learning depend on data augmentation techniques, which
generate different views from the original signal. However, tuning policies and
hyper-parameters for more effective data augmentation methods in contrastive
learning is often time and resource-consuming. Researchers have designed
approaches to automatically generate new views for some input signals,
especially on the image data. But the view-learning method is not well
developed for time-series data. In this work, we propose a simple but effective
module for automating view generation for time-series data in contrastive
learning, named learning views for time-series data (LEAVES). The proposed
module learns the hyper-parameters for augmentations using adversarial training
in contrastive learning. We validate the effectiveness of the proposed method
using multiple time-series datasets. The experiments demonstrate that the
proposed method is more effective in finding reasonable views and performs
downstream tasks better than the baselines, including manually tuned
augmentation-based contrastive learning methods and SOTA methods.",http://arxiv.org/pdf/2210.07340v1,cs.LG
2022-10-13 10:55:47+00:00,Entropy Approximation by Machine Learning Regression: Application for Irregularity Evaluation of Images in Remote Sensing,"['Andrei Velichko', 'Maksim Belyaev', 'Matthias P. Wagner', 'Alireza Taravat']","Approximation of entropies of various types using machine learning (ML)
regression methods are shown for the first time. The ML models presented in
this study define the complexity of the short time series by approximating
dissimilar entropy techniques such as Singular value decomposition entropy
(SvdEn), Permutation entropy (PermEn), Sample entropy (SampEn) and Neural
Network entropy (NNetEn) and their 2D analogies. A new method for calculating
SvdEn2D, PermEn2D and SampEn2D for 2D images was tested using the technique of
circular kernels. Training and testing datasets on the basis of Sentinel-2
images are presented (two training images and one hundred and ninety-eight
testing images). The results of entropy approximation are demonstrated using
the example of calculating the 2D entropy of Sentinel-2 images and R^2 metric
evaluation. The applicability of the method for the short time series with a
length from N = 5 to N = 113 elements is shown. A tendency for the R^2 metric
to decrease with an increase in the length of the time series was found. For
SvdEn entropy, the regression accuracy is R^2 > 0.99 for N = 5 and R^2 > 0.82
for N = 113. The best metrics were observed for the ML_SvdEn2D and ML_NNetEn2D
models. The results of the study can be used for fundamental research of
entropy approximations of various types using ML regression, as well as for
accelerating entropy calculations in remote sensing. The versatility of the
model is shown on a synthetic chaotic time series using Planck map and logistic
map.",http://arxiv.org/pdf/2210.06901v2,cs.LG
2022-10-13 03:40:12+00:00,Empirical Evaluation of Data Augmentations for Biobehavioral Time Series Data with Deep Learning,"['Huiyuan Yang', 'Han Yu', 'Akane Sano']","Deep learning has performed remarkably well on many tasks recently. However,
the superior performance of deep models relies heavily on the availability of a
large number of training data, which limits the wide adaptation of deep models
on various clinical and affective computing tasks, as the labeled data are
usually very limited. As an effective technique to increase the data
variability and thus train deep models with better generalization, data
augmentation (DA) is a critical step for the success of deep learning models on
biobehavioral time series data. However, the effectiveness of various DAs for
different datasets with different tasks and deep models is understudied for
biobehavioral time series data. In this paper, we first systematically review
eight basic DA methods for biobehavioral time series data, and evaluate the
effects on seven datasets with three backbones. Next, we explore adapting more
recent DA techniques (i.e., automatic augmentation, random augmentation) to
biobehavioral time series data by designing a new policy architecture
applicable to time series data. Last, we try to answer the question of why a DA
is effective (or not) by first summarizing two desired attributes for
augmentations (challenging and faithful), and then utilizing two metrics to
quantitatively measure the corresponding attributes, which can guide us in the
search for more effective DA for biobehavioral time series data by designing
more challenging but still faithful transformations. Our code and results are
available at Link.",http://arxiv.org/pdf/2210.06701v1,cs.LG
2022-10-11 12:37:15+00:00,Class-Specific Explainability for Deep Time Series Classifiers,"['Ramesh Doddaiah', 'Prathyush Parvatharaju', 'Elke Rundensteiner', 'Thomas Hartvigsen']","Explainability helps users trust deep learning solutions for time series
classification. However, existing explainability methods for multi-class time
series classifiers focus on one class at a time, ignoring relationships between
the classes. Instead, when a classifier is choosing between many classes, an
effective explanation must show what sets the chosen class apart from the rest.
We now formalize this notion, studying the open problem of class-specific
explainability for deep time series classifiers, a challenging and impactful
problem setting. We design a novel explainability method, DEMUX, which learns
saliency maps for explaining deep multi-class time series classifiers by
adaptively ensuring that its explanation spotlights the regions in an input
time series that a model uses specifically to its predicted class. DEMUX adopts
a gradient-based approach composed of three interdependent modules that combine
to generate consistent, class-specific saliency maps that remain faithful to
the classifier's behavior yet are easily understood by end users. Our
experimental study demonstrates that DEMUX outperforms nine state-of-the-art
alternatives on five popular datasets when explaining two types of deep time
series classifiers. Further, through a case study, we demonstrate that DEMUX's
explanations indeed highlight what separates the predicted class from the
others in the eyes of the classifier. Our code is publicly available at
https://github.com/rameshdoddaiah/DEMUX.",http://arxiv.org/pdf/2210.05411v1,cs.LG
2022-10-10 20:03:57+00:00,Testing unit root non-stationarity in the presence of missing data in univariate time series of mobile health studies,"['Charlotte Fowler', 'Xiaoxuan Cai', 'Justin T. Baker', 'Jukka-Pekka Onnela', 'Linda Valeri']","The use of digital devices to collect data in mobile health (mHealth) studies
introduces a novel application of time series methods, with the constraint of
potential data missing at random (MAR) or missing not at random (MNAR). In time
series analysis, testing for stationarity is an important preliminary step to
inform appropriate later analyses. The augmented Dickey-Fuller (ADF) test was
developed to test the null hypothesis of unit root non-stationarity, under no
missing data. Beyond recommendations under data missing completely at random
(MCAR) for complete case analysis or last observation carry forward imputation,
researchers have not extended unit root non-stationarity testing to a context
with more complex missing data mechanisms. Multiple imputation with chained
equations, Kalman smoothing imputation, and linear interpolation have also been
proposed for time series data, however such methods impose constraints on the
autocorrelation structure, and thus impact unit root testing. We propose
maximum likelihood estimation and multiple imputation using state space model
approaches to adapt the ADF test to a context with missing data. We further
develop sensitivity analysis techniques to examine the impact of MNAR data. We
evaluate the performance of existing and proposed methods across different
missing mechanisms in extensive simulations and in their application to a
multi-year smartphone study of bipolar patients.",http://arxiv.org/pdf/2210.04998v1,stat.ME
2022-10-10 18:53:13+00:00,Mining Causality from Continuous-time Dynamics Models: An Application to Tsunami Forecasting,"['Fan Wu', 'Sanghyun Hong', 'Donsub Rim', 'Noseong Park', 'Kookjin Lee']","Continuous-time dynamics models, such as neural ordinary differential
equations, have enabled the modeling of underlying dynamics in time-series data
and accurate forecasting. However, parameterization of dynamics using a neural
network makes it difficult for humans to identify causal structures in the
data. In consequence, this opaqueness hinders the use of these models in the
domains where capturing causal relationships carries the same importance as
accurate predictions, e.g., tsunami forecasting. In this paper, we address this
challenge by proposing a mechanism for mining causal structures from
continuous-time models. We train models to capture the causal structure by
enforcing sparsity in the weights of the input layers of the dynamics models.
We first verify the effectiveness of our method in the scenario where the exact
causal-structures of time-series are known as a priori. We next apply our
method to a real-world problem, namely tsunami forecasting, where the exact
causal-structures are difficult to characterize. Experimental results show that
the proposed method is effective in learning physically-consistent causal
relationships while achieving high forecasting accuracy.",http://arxiv.org/pdf/2210.04958v2,cs.LG
2022-10-10 03:24:18+00:00,Self-explaining Hierarchical Model for Intraoperative Time Series,"['Dingwen Li', 'Bing Xue', 'Christopher King', 'Bradley Fritz', 'Michael Avidan', 'Joanna Abraham', 'Chenyang Lu']","Major postoperative complications are devastating to surgical patients. Some
of these complications are potentially preventable via early predictions based
on intraoperative data. However, intraoperative data comprise long and
fine-grained multivariate time series, prohibiting the effective learning of
accurate models. The large gaps associated with clinical events and protocols
are usually ignored. Moreover, deep models generally lack transparency.
Nevertheless, the interpretability is crucial to assist clinicians in planning
for and delivering postoperative care and timely interventions. Towards this
end, we propose a hierarchical model combining the strength of both attention
and recurrent models for intraoperative time series. We further develop an
explanation module for the hierarchical model to interpret the predictions by
providing contributions of intraoperative data in a fine-grained manner.
Experiments on a large dataset of 111,888 surgeries with multiple outcomes and
an external high-resolution ICU dataset show that our model can achieve strong
predictive performance (i.e., high accuracy) and offer robust interpretations
(i.e., high transparency) for predicted outcomes based on intraoperative time
series.",http://arxiv.org/pdf/2210.04417v1,cs.LG
2022-10-08 13:37:55+00:00,Multi-Task Dynamical Systems,"['Alex Bird', 'Christopher K. I. Williams', 'Christopher Hawthorne']","Time series datasets are often composed of a variety of sequences from the
same domain, but from different entities, such as individuals, products, or
organizations. We are interested in how time series models can be specialized
to individual sequences (capturing the specific characteristics) while still
retaining statistical power by sharing commonalities across the sequences. This
paper describes the multi-task dynamical system (MTDS); a general methodology
for extending multi-task learning (MTL) to time series models. Our approach
endows dynamical systems with a set of hierarchical latent variables which can
modulate all model parameters. To our knowledge, this is a novel development of
MTL, and applies to time series both with and without control inputs. We apply
the MTDS to motion-capture data of people walking in various styles using a
multi-task recurrent neural network (RNN), and to patient drug-response data
using a multi-task pharmacodynamic model.",http://arxiv.org/pdf/2210.04023v1,cs.LG
2022-10-07 16:33:50+00:00,Koopman Neural Forecaster for Time Series with Temporal Distribution Shifts,"['Rui Wang', 'Yihe Dong', 'Sercan Ö. Arik', 'Rose Yu']","Temporal distributional shifts, with underlying dynamics changing over time,
frequently occur in real-world time series and pose a fundamental challenge for
deep neural networks (DNNs). In this paper, we propose a novel deep sequence
model based on the Koopman theory for time series forecasting: Koopman Neural
Forecaster (KNF) which leverages DNNs to learn the linear Koopman space and the
coefficients of chosen measurement functions. KNF imposes appropriate inductive
biases for improved robustness against distributional shifts, employing both a
global operator to learn shared characteristics and a local operator to capture
changing dynamics, as well as a specially-designed feedback loop to
continuously update the learned operators over time for rapidly varying
behaviors. We demonstrate that \ours{} achieves superior performance compared
to the alternatives, on multiple time series datasets that are shown to suffer
from distribution shifts.",http://arxiv.org/pdf/2210.03675v3,cs.LG
2022-10-06 17:50:07+00:00,Edge-Varying Fourier Graph Networks for Multivariate Time Series Forecasting,"['Kun Yi', 'Qi Zhang', 'Liang Hu', 'Hui He', 'Ning An', 'LongBing Cao', 'ZhenDong Niu']","The key problem in multivariate time series (MTS) analysis and forecasting
aims to disclose the underlying couplings between variables that drive the
co-movements. Considerable recent successful MTS methods are built with graph
neural networks (GNNs) due to their essential capacity for relational modeling.
However, previous work often used a static graph structure of time-series
variables for modeling MTS failing to capture their ever-changing correlations
over time. To this end, a fully-connected supra-graph connecting any two
variables at any two timestamps is adaptively learned to capture the
high-resolution variable dependencies via an efficient graph convolutional
network. Specifically, we construct the Edge-Varying Fourier Graph Networks
(EV-FGN) equipped with Fourier Graph Shift Operator (FGSO) which efficiently
performs graph convolution in the frequency domain. As a result, a
high-efficiency scale-free parameter learning scheme is derived for MTS
analysis and forecasting according to the convolution theorem. Extensive
experiments show that EV-FGN outperforms state-of-the-art methods on seven
real-world MTS datasets.",http://arxiv.org/pdf/2210.03093v2,cs.LG
2022-10-06 12:37:02+00:00,Temporal Spatial Decomposition and Fusion Network for Time Series Forecasting,"['Liwang Zhou', 'Jing Gao']","Feature engineering is required to obtain better results for time series
forecasting, and decomposition is a crucial one. One decomposition approach
often cannot be used for numerous forecasting tasks since the standard time
series decomposition lacks flexibility and robustness. Traditional feature
selection relies heavily on preexisting domain knowledge, has no generic
methodology, and requires a lot of labor. However, most time series prediction
models based on deep learning typically suffer from interpretability issue, so
the ""black box"" results lead to a lack of confidence. To deal with the above
issues forms the motivation of the thesis. In the paper we propose TSDFNet as a
neural network with self-decomposition mechanism and an attentive feature
fusion mechanism, It abandons feature engineering as a preprocessing convention
and creatively integrates it as an internal module with the deep model. The
self-decomposition mechanism empowers TSDFNet with extensible and adaptive
decomposition capabilities for any time series, users can choose their own
basis functions to decompose the sequence into temporal and generalized spatial
dimensions. Attentive feature fusion mechanism has the ability to capture the
importance of external variables and the causality with target variables. It
can automatically suppress the unimportant features while enhancing the
effective ones, so that users do not have to struggle with feature selection.
Moreover, TSDFNet is easy to look into the ""black box"" of the deep neural
network by feature visualization and analyze the prediction results. We
demonstrate performance improvements over existing widely accepted models on
more than a dozen datasets, and three experiments showcase the interpretability
of TSDFNet.",http://arxiv.org/pdf/2210.03122v1,cs.LG
2022-10-06 12:10:57+00:00,Inference on Causal Effects of Interventions in Time using Gaussian Processes,"['Gianluca Giudice', 'Sara Geneletti', 'Konstantinos Kalogeropoulos']","This paper focuses on drawing inference on the causal impact of an
intervention at a specific time point, as manifested in an outcome variable
over time. We operate on the interrupted time series framework and expand on
approaches such as the synthetic control (Abadie 2003) and Bayesian structural
time series (Brodersen et al 2015), by replacing the underlying dynamic linear
regression model with a non-parametric formulation based on Gaussian Processes.
The developed models possess a high degree of flexibility posing very little
limitations on the functional form and allow to incorporate uncertainty,
stemming from its estimation, under the Bayesian framework. We introduce two
families of non-parametric structural time series models either operating on
the trajectory of the outcome variable alone, or in a multivariate setting
using multiple output Gaussian processes. The paper engages closely with a case
study focusing on the impact of the accelerated UK vaccination schedule, as
contrasted with the rest of Europe, to illustrate the methodology and present
the implementation procedure.",http://arxiv.org/pdf/2210.02850v1,stat.ME
2022-10-05 14:22:24+00:00,Efficient probabilistic reconciliation of forecasts for real-valued and count time series,"['Lorenzo Zambon', 'Dario Azzimonti', 'Giorgio Corani']","Hierarchical time series are common in several applied fields. The forecasts
for these time series are required to be coherent, that is, to satisfy the
constraints given by the hierarchy. The most popular technique to enforce
coherence is called reconciliation, which adjusts the base forecasts computed
for each time series. However, recent works on probabilistic reconciliation
present several limitations. In this paper, we propose a new approach based on
conditioning to reconcile any type of forecast distribution. We then introduce
a new algorithm, called Bottom-Up Importance Sampling, to efficiently sample
from the reconciled distribution. It can be used for any base forecast
distribution: discrete, continuous, or in the form of samples, providing a
major speedup compared to the current methods. Experiments on several temporal
hierarchies show a significant improvement over base probabilistic forecasts.",http://arxiv.org/pdf/2210.02286v3,stat.ML
2022-10-05 12:19:51+00:00,TimesNet: Temporal 2D-Variation Modeling for General Time Series Analysis,"['Haixu Wu', 'Tengge Hu', 'Yong Liu', 'Hang Zhou', 'Jianmin Wang', 'Mingsheng Long']","Time series analysis is of immense importance in extensive applications, such
as weather forecasting, anomaly detection, and action recognition. This paper
focuses on temporal variation modeling, which is the common key problem of
extensive analysis tasks. Previous methods attempt to accomplish this directly
from the 1D time series, which is extremely challenging due to the intricate
temporal patterns. Based on the observation of multi-periodicity in time
series, we ravel out the complex temporal variations into the multiple
intraperiod- and interperiod-variations. To tackle the limitations of 1D time
series in representation capability, we extend the analysis of temporal
variations into the 2D space by transforming the 1D time series into a set of
2D tensors based on multiple periods. This transformation can embed the
intraperiod- and interperiod-variations into the columns and rows of the 2D
tensors respectively, making the 2D-variations to be easily modeled by 2D
kernels. Technically, we propose the TimesNet with TimesBlock as a task-general
backbone for time series analysis. TimesBlock can discover the
multi-periodicity adaptively and extract the complex temporal variations from
transformed 2D tensors by a parameter-efficient inception block. Our proposed
TimesNet achieves consistent state-of-the-art in five mainstream time series
analysis tasks, including short- and long-term forecasting, imputation,
classification, and anomaly detection. Code is available at this repository:
https://github.com/thuml/TimesNet.",http://arxiv.org/pdf/2210.02186v3,cs.LG
2022-10-05 12:05:01+00:00,Feature Importance for Time Series Data: Improving KernelSHAP,"['Mattia Villani', 'Joshua Lockhart', 'Daniele Magazzeni']","Feature importance techniques have enjoyed widespread attention in the
explainable AI literature as a means of determining how trained machine
learning models make their predictions. We consider Shapley value based
approaches to feature importance, applied in the context of time series data.
We present closed form solutions for the SHAP values of a number of time series
models, including VARMAX. We also show how KernelSHAP can be applied to time
series tasks, and how the feature importances that come from this technique can
be combined to perform ""event detection"". Finally, we explore the use of Time
Consistent Shapley values for feature importance.",http://arxiv.org/pdf/2210.02176v1,cs.LG
2022-10-05 08:31:05+00:00,Tripletformer for Probabilistic Interpolation of Asynchronous Time Series,"['Vijaya Krishna Yalavarthi', 'Johannes Burchert', 'Lars Schmidt-thieme']","Asynchronous time series are often observed in several applications such as
health care, astronomy, and climate science, and pose a significant challenge
to the standard deep learning architectures. Interpolation of asynchronous time
series is vital for many real-world tasks like root cause analysis, and medical
diagnosis. In this paper, we propose a novel encoder-decoder architecture
called Tripletformer, which works on the set of observations where each set
element is a triple of time, channel, and value, for the probabilistic
interpolation of the asynchronous time series. Both the encoder and the decoder
of the Tripletformer are modeled using attention layers and fully connected
layers and are invariant to the order in which set elements are presented. The
proposed Tripletformer is compared with a range of baselines over multiple
real-world and synthetic asynchronous time series datasets, and the
experimental results attest that it produces more accurate and certain
interpolations. We observe an improvement in negative loglikelihood error up to
33% over real and 800% over synthetic asynchronous time series datasets
compared to the state-of-the-art model using the Tripletformer.",http://arxiv.org/pdf/2210.02091v1,cs.LG
2022-10-05 08:29:33+00:00,Transformer-based conditional generative adversarial network for multivariate time series generation,"['Abdellah Madane', 'Mohamed-djallel Dilmi', 'Florent Forest', 'Hanane Azzag', 'Mustapha Lebbah', 'Jerome Lacaille']","Conditional generation of time-dependent data is a task that has much
interest, whether for data augmentation, scenario simulation, completing
missing data, or other purposes. Recent works proposed a Transformer-based Time
series generative adversarial network (TTS-GAN) to address the limitations of
recurrent neural networks. However, this model assumes a unimodal distribution
and tries to generate samples around the expectation of the real data
distribution. One of its limitations is that it may generate a random
multivariate time series; it may fail to generate samples in the presence of
multiple sub-components within an overall distribution. One could train models
to fit each sub-component separately to overcome this limitation. Our work
extends the TTS-GAN by conditioning its generated output on a particular
encoded context allowing the use of one model to fit a mixture distribution
with multiple sub-components. Technically, it is a conditional generative
adversarial network that models realistic multivariate time series under
different types of conditions, such as categorical variables or multivariate
time series. We evaluate our model on UniMiB Dataset, which contains
acceleration data following the XYZ axes of human activities collected using
Smartphones. We use qualitative evaluations and quantitative metrics such as
Principal Component Analysis (PCA), and we introduce a modified version of the
Frechet inception distance (FID) to measure the performance of our model and
the statistical similarities between the generated and the real data
distributions. We show that this transformer-based CGAN can generate realistic
high-dimensional and long data sequences under different kinds of conditions.",http://arxiv.org/pdf/2210.02089v1,cs.LG
2022-10-05 06:18:06+00:00,GT-GAN: General Purpose Time Series Synthesis with Generative Adversarial Networks,"['Jinsung Jeon', 'Jeonghak Kim', 'Haryong Song', 'Seunghyeon Cho', 'Noseong Park']","Time series synthesis is an important research topic in the field of deep
learning, which can be used for data augmentation. Time series data types can
be broadly classified into regular or irregular. However, there are no existing
generative models that show good performance for both types without any model
changes. Therefore, we present a general purpose model capable of synthesizing
regular and irregular time series data. To our knowledge, we are the first
designing a general purpose time series synthesis model, which is one of the
most challenging settings for time series synthesis. To this end, we design a
generative adversarial network-based method, where many related techniques are
carefully integrated into a single framework, ranging from neural
ordinary/controlled differential equations to continuous time-flow processes.
Our method outperforms all existing methods.",http://arxiv.org/pdf/2210.02040v3,cs.LG
2022-10-05 04:32:12+00:00,DEGAN: Time Series Anomaly Detection using Generative Adversarial Network Discriminators and Density Estimation,"['Yueyan Gu', 'Farrokh Jazizadeh']","Developing efficient time series anomaly detection techniques is important to
maintain service quality and provide early alarms. Generative neural network
methods are one class of the unsupervised approaches that are achieving
increasing attention in recent years. In this paper, we have proposed an
unsupervised Generative Adversarial Network (GAN)-based anomaly detection
framework, DEGAN. It relies solely on normal time series data as input to train
a well-configured discriminator (D) into a standalone anomaly predictor. In
this framework, time series data is processed by the sliding window method.
Expected normal patterns in data are leveraged to develop a generator (G)
capable of generating normal data patterns. Normal data is also utilized in
hyperparameter tuning and D model selection steps. Validated D models are then
extracted and applied to evaluate unseen (testing) time series and identify
patterns that have anomalous characteristics. Kernel density estimation (KDE)
is applied to data points that are likely to be anomalous to generate
probability density functions on the testing time series. The segments with the
highest relative probabilities are detected as anomalies. To evaluate the
performance, we tested on univariate acceleration time series for five miles of
a Class I railroad track. We implemented the framework to detect the real
anomalous observations identified by operators. The results show that
leveraging the framework with a CNN D architecture results in average best
recall and precision of 80% and 86%, respectively, which demonstrates that a
well-trained standalone D model has the potential to be a reliable anomaly
detector. Moreover, the influence of GAN hyperparameters, GAN architectures,
sliding window sizes, clustering of time series, and model validation with
labeled/unlabeled data were also investigated.",http://arxiv.org/pdf/2210.02449v1,cs.LG
2022-10-04 03:06:21+00:00,MTSMAE: Masked Autoencoders for Multivariate Time-Series Forecasting,"['Peiwang Tang', 'Xianchao Zhang']","Large-scale self-supervised pre-training Transformer architecture have
significantly boosted the performance for various tasks in natural language
processing (NLP) and computer vision (CV). However, there is a lack of
researches on processing multivariate time-series by pre-trained Transformer,
and especially, current study on masking time-series for self-supervised
learning is still a gap. Different from language and image processing, the
information density of time-series increases the difficulty of research. The
challenge goes further with the invalidity of the previous patch embedding and
mask methods. In this paper, according to the data characteristics of
multivariate time-series, a patch embedding method is proposed, and we present
an self-supervised pre-training approach based on Masked Autoencoders (MAE),
called MTSMAE, which can improve the performance significantly over supervised
learning without pre-training. Evaluating our method on several common
multivariate time-series datasets from different fields and with different
characteristics, experiment results demonstrate that the performance of our
method is significantly better than the best method currently available.",http://arxiv.org/pdf/2210.02199v1,cs.LG
2022-10-02 06:58:49+00:00,Grouped self-attention mechanism for a memory-efficient Transformer,"['Bumjun Jung', 'Yusuke Mukuta', 'Tatsuya Harada']","Time-series data analysis is important because numerous real-world tasks such
as forecasting weather, electricity consumption, and stock market involve
predicting data that vary over time. Time-series data are generally recorded
over a long period of observation with long sequences owing to their periodic
characteristics and long-range dependencies over time. Thus, capturing
long-range dependency is an important factor in time-series data forecasting.
To solve these problems, we proposed two novel modules, Grouped Self-Attention
(GSA) and Compressed Cross-Attention (CCA). With both modules, we achieved a
computational space and time complexity of order $O(l)$ with a sequence length
$l$ under small hyperparameter limitations, and can capture locality while
considering global information. The results of experiments conducted on
time-series datasets show that our proposed model efficiently exhibited reduced
computational complexity and performance comparable to or better than existing
methods.",http://arxiv.org/pdf/2210.00440v2,cs.LG
2022-10-01 13:02:43+00:00,Solar Power Time Series Forecasting Utilising Wavelet Coefficients,"['Sarah Almaghrabi', 'Mashud Rana', 'Margaret Hamilton', 'Mohammad Saiedur Rahaman']","Accurate and reliable prediction of Photovoltaic (PV) power output is
critical to electricity grid stability and power dispatching capabilities.
However, Photovoltaic (PV) power generation is highly volatile and unstable due
to different reasons. The Wavelet Transform (WT) has been utilised in time
series applications, such as Photovoltaic (PV) power prediction, to model the
stochastic volatility and reduce prediction errors. Yet the existing Wavelet
Transform (WT) approach has a limitation in terms of time complexity. It
requires reconstructing the decomposed components and modelling them separately
and thus needs more time for reconstruction, model configuration and training.
The aim of this study is to improve the efficiency of applying Wavelet
Transform (WT) by proposing a new method that uses a single simplified model.
Given a time series and its Wavelet Transform (WT) coefficients, it trains one
model with the coefficients as features and the original time series as labels.
This eliminates the need for component reconstruction and training numerous
models. This work contributes to the day-ahead aggregated solar Photovoltaic
(PV) power time series prediction problem by proposing and comprehensively
evaluating a new approach of employing WT. The proposed approach is evaluated
using 17 months of aggregated solar Photovoltaic (PV) power data from two
real-world datasets. The evaluation includes the use of a variety of prediction
models, including Linear Regression, Random Forest, Support Vector Regression,
and Convolutional Neural Networks. The results indicate that using a
coefficients-based strategy can give predictions that are comparable to those
obtained using the components-based approach while requiring fewer models and
less computational time.",http://arxiv.org/pdf/2210.00269v1,cs.LG
2022-09-30 20:54:49+00:00,A Multi-label Time Series Classification Approach for Non-intrusive Water End-Use Monitoring,"['Dimitris Papatheodoulou', 'Pavlos Pavlou', 'Stelios G. Vrachimis', 'Kleanthis Malialis', 'Demetrios G. Eliades', 'Theocharis Theocharides']","Numerous real-world problems from a diverse set of application areas exist
that exhibit temporal dependencies. We focus on a specific type of time series
classification which we refer to as aggregated time series classification. We
consider an aggregated sequence of a multi-variate time series, and propose a
methodology to make predictions based solely on the aggregated information. As
a case study, we apply our methodology to the challenging problem of household
water end-use dissagregation when using non-intrusive water monitoring. Our
methodology does not require a-priori identification of events, and to our
knowledge, it is considered for the first time. We conduct an extensive
experimental study using a residential water-use simulator, involving different
machine learning classifiers, multi-label classification methods, and
successfully demonstrate the effectiveness of our methodology.",http://arxiv.org/pdf/2210.00089v1,cs.LG
2022-09-30 16:50:35+00:00,Hierarchies Everywhere -- Managing & Measuring Uncertainty in Hierarchical Time Series,"['Ross Hollyman', 'Fotios Petropoulos', 'Michael E. Tipping']","We examine the problem of making reconciled forecasts of large collections of
related time series through a behavioural/Bayesian lens. Our approach
explicitly acknowledges and exploits the 'connectedness' of the series in terms
of time-series characteristics and forecast accuracy as well as hierarchical
structure. By making maximal use of the available information, and by
significantly reducing the dimensionality of the hierarchical forecasting
problem, we show how to improve the accuracy of the reconciled forecasts. In
contrast to existing approaches, our structure allows the analysis and
assessment of the forecast value added at each hierarchical level. Our
reconciled forecasts are inherently probabilistic, whether probabilistic base
forecasts are used or not.",http://arxiv.org/pdf/2209.15583v1,stat.ME
2022-09-28 20:49:11+00:00,Masked Multi-Step Multivariate Time Series Forecasting with Future Information,"['Yiwei Fu', 'Honggang Wang', 'Nurali Virani']","In this paper, we introduce Masked Multi-Step Multivariate Forecasting
(MMMF), a novel and general self-supervised learning framework for time series
forecasting with known future information. In many real-world forecasting
scenarios, some future information is known, e.g., the weather information when
making a short-to-mid-term electricity demand forecast, or the oil price
forecasts when making an airplane departure forecast. Existing machine learning
forecasting frameworks can be categorized into (1) sample-based approaches
where each forecast is made independently, and (2) time series regression
approaches where the future information is not fully incorporated. To overcome
the limitations of existing approaches, we propose MMMF, a framework to train
any neural network model capable of generating a sequence of outputs, that
combines both the temporal information from the past and the known information
about the future to make better predictions. Experiments are performed on two
real-world datasets for (1) mid-term electricity demand forecasting, and (2)
two-month ahead flight departures forecasting. They show that the proposed MMMF
framework outperforms not only sample-based methods but also existing time
series forecasting models with the exact same base models. Furthermore, once a
neural network model is trained with MMMF, its inference speed is similar to
that of the same model trained with traditional regression formulations, thus
making MMMF a better alternative to existing regression-trained time series
forecasting models if there is some available future information.",http://arxiv.org/pdf/2209.14413v1,cs.LG
2022-09-28 09:06:42+00:00,Explainable classification of astronomical uncertain time series,"['Michael Franklin Mbouopda', 'Emille E O Ishida', 'Engelbert Mephu Nguifo', 'Emmanuel Gangler']","Exploring the expansion history of the universe, understanding its
evolutionary stages, and predicting its future evolution are important goals in
astrophysics. Today, machine learning tools are used to help achieving these
goals by analyzing transient sources, which are modeled as uncertain time
series. Although black-box methods achieve appreciable performance, existing
interpretable time series methods failed to obtain acceptable performance for
this type of data. Furthermore, data uncertainty is rarely taken into account
in these methods. In this work, we propose an uncertaintyaware subsequence
based model which achieves a classification comparable to that of
state-of-the-art methods. Unlike conformal learning which estimates model
uncertainty on predictions, our method takes data uncertainty as additional
input. Moreover, our approach is explainable-by-design, giving domain experts
the ability to inspect the model and explain its predictions. The
explainability of the proposed method has also the potential to inspire new
developments in theoretical astrophysics modeling by suggesting important
subsequences which depict details of light curve shapes. The dataset, the
source code of our experiment, and the results are made available on a public
repository.",http://arxiv.org/pdf/2210.00869v1,cs.LG
2022-09-28 08:58:55+00:00,Experimental study of time series forecasting methods for groundwater level prediction,"['Michael Franklin Mbouopda', 'Thomas Guyet', 'Nicolas Labroche', 'Abel Henriot']","Groundwater level prediction is an applied time series forecasting task with
important social impacts to optimize water management as well as preventing
some natural disasters: for instance, floods or severe droughts. Machine
learning methods have been reported in the literature to achieve this task, but
they are only focused on the forecast of the groundwater level at a single
location. A global forecasting method aims at exploiting the groundwater level
time series from a wide range of locations to produce predictions at a single
place or at several places at a time. Given the recent success of global
forecasting methods in prestigious competitions, it is meaningful to assess
them on groundwater level prediction and see how they are compared to local
methods. In this work, we created a dataset of 1026 groundwater level time
series. Each time series is made of daily measurements of groundwater levels
and two exogenous variables, rainfall and evapotranspiration. This dataset is
made available to the communities for reproducibility and further evaluation.
To identify the best configuration to effectively predict groundwater level for
the complete set of time series, we compared different predictors including
local and global time series forecasting methods. We assessed the impact of
exogenous variables. Our result analysis shows that the best predictions are
obtained by training a global method on past groundwater levels and rainfall
data.",http://arxiv.org/pdf/2209.13927v1,cs.LG
2022-09-24 12:49:48+00:00,An implimentation of the Differential Filter for Computing Gradient and Hessian of the Log-likelihood of Nonstationary Time Series Models,['Genshiro Kitagawa'],"The state-space model and the Kalman filter provide us with unified and
computationaly efficient procedure for computing the log-likelihood of the
diverse type of time series models. This paper presents an algorithm for
computing the gradient and the Hessian matrix of the log-likelihood by
extending the Kalman filter without resorting to the numerical difference.
Different from the previous paper(Kitagawa 2020), it is assumed that the
observation noise variance R=1. It is known that for univariate time series, by
maximizing the log-likelihood of this restricted model, we can obtain the same
estimates as the ones for the original state-space model. By this modification,
the algorithm for computing the gradient and the Hessian becomes somewhat
complicated. However, the dimension of the parameter vector is reduce by one
and thus has a significant merit in estimating the parameter of the state-space
model especially for relatively low dimentional parameter vector. Three
examples of nonstationary time seirres models, i.e., trend model, statndard
seasonal adjustment model and the seasonal adjustment model with AR componet
are presented to exemplified the specification of structural matrices.",http://arxiv.org/pdf/2209.11997v1,stat.ME
2022-09-23 09:43:58+00:00,Time Series Causal Link Estimation under Hidden Confounding using Knockoff Interventions,"['Violeta Teodora Trifunov', 'Maha Shadaydeh', 'Joachim Denzler']","Latent variables often mask cause-effect relationships in observational data
which provokes spurious links that may be misinterpreted as causal. This
problem sparks great interest in the fields such as climate science and
economics. We propose to estimate confounded causal links of time series using
Sequential Causal Effect Variational Autoencoder (SCEVAE) while applying
Knockoff interventions. Knockoff variables have the same distribution as the
originals and preserve the correlation to other variables. This allows for
counterfactuals that are more faithful to the observational distribution. We
show the advantage of Knockoff interventions by applying SCEVAE to synthetic
datasets with both linear and nonlinear causal links. Moreover, we apply SCEVAE
with Knockoffs to real aerosol-cloud-climate observational time series data. We
compare our results on synthetic data to those of a time series deconfounding
method both with and without estimated confounders. We show that our method
outperforms this benchmark by comparing both methods to the ground truth. For
the real data analysis, we rely on expert knowledge of causal links and
demonstrate how using suitable proxy variables improves the causal link
estimation in the presence of hidden confounders.",http://arxiv.org/pdf/2209.11497v2,cs.LG
2022-09-22 21:19:27+00:00,Optimal Stopping with Gaussian Processes,"['Kshama Dwarakanath', 'Danial Dervovic', 'Peyman Tavallali', 'Svitlana S Vyetrenko', 'Tucker Balch']","We propose a novel group of Gaussian Process based algorithms for fast
approximate optimal stopping of time series with specific applications to
financial markets. We show that structural properties commonly exhibited by
financial time series (e.g., the tendency to mean-revert) allow the use of
Gaussian and Deep Gaussian Process models that further enable us to
analytically evaluate optimal stopping value functions and policies. We
additionally quantify uncertainty in the value function by propagating the
price model through the optimal stopping analysis. We compare and contrast our
proposed methods against a sampling-based method, as well as a deep learning
based benchmark that is currently considered the state-of-the-art in the
literature. We show that our family of algorithms outperforms benchmarks on
three historical time series datasets that include intra-day and end-of-day
equity stock prices as well as the daily US treasury yield curve rates.",http://arxiv.org/pdf/2209.14738v2,stat.ML
2022-09-22 20:42:19+00:00,StyleTime: Style Transfer for Synthetic Time Series Generation,"['Yousef El-Laham', 'Svitlana Vyetrenko']","Neural style transfer is a powerful computer vision technique that can
incorporate the artistic ""style"" of one image to the ""content"" of another. The
underlying theory behind the approach relies on the assumption that the style
of an image is represented by the Gram matrix of its features, which is
typically extracted from pre-trained convolutional neural networks (e.g.,
VGG-19). This idea does not straightforwardly extend to time series stylization
since notions of style for two-dimensional images are not analogous to notions
of style for one-dimensional time series. In this work, a novel formulation of
time series style transfer is proposed for the purpose of synthetic data
generation and enhancement. We introduce the concept of stylized features for
time series, which is directly related to the time series realism properties,
and propose a novel stylization algorithm, called StyleTime, that uses explicit
feature extraction techniques to combine the underlying content (trend) of one
time series with the style (distributional properties) of another. Further, we
discuss evaluation metrics, and compare our work to existing state-of-the-art
time series generation and augmentation schemes. To validate the effectiveness
of our methods, we use stylized synthetic data as a means for data augmentation
to improve the performance of recurrent neural network models on several
forecasting tasks.",http://arxiv.org/pdf/2209.11306v1,cs.LG
2022-09-22 06:06:56+00:00,STING: Self-attention based Time-series Imputation Networks using GAN,"['Eunkyu Oh', 'Taehun Kim', 'Yunhu Ji', 'Sushil Khyalia']","Time series data are ubiquitous in real-world applications. However, one of
the most common problems is that the time series data could have missing values
by the inherent nature of the data collection process. So imputing missing
values from multivariate (correlated) time series data is imperative to improve
a prediction performance while making an accurate data-driven decision.
Conventional works for imputation simply delete missing values or fill them
based on mean/zero. Although recent works based on deep neural networks have
shown remarkable results, they still have a limitation to capture the complex
generation process of the multivariate time series. In this paper, we propose a
novel imputation method for multivariate time series data, called STING
(Self-attention based Time-series Imputation Networks using GAN). We take
advantage of generative adversarial networks and bidirectional recurrent neural
networks to learn latent representations of the time series. In addition, we
introduce a novel attention mechanism to capture the weighted correlations of
the whole sequence and avoid potential bias brought by unrelated ones.
Experimental results on three real-world datasets demonstrate that STING
outperforms the existing state-of-the-art methods in terms of imputation
accuracy as well as downstream tasks with the imputed values therein.",http://arxiv.org/pdf/2209.10801v1,cs.LG
2022-09-21 21:14:28+00:00,Contrastive Learning for Time Series on Dynamic Graphs,"['Yitian Zhang', 'Florence Regol', 'Antonios Valkanas', 'Mark Coates']","There have been several recent efforts towards developing representations for
multivariate time-series in an unsupervised learning framework. Such
representations can prove beneficial in tasks such as activity recognition,
health monitoring, and anomaly detection. In this paper, we consider a setting
where we observe time-series at each node in a dynamic graph. We propose a
framework called GraphTNC for unsupervised learning of joint representations of
the graph and the time-series. Our approach employs a contrastive learning
strategy. Based on an assumption that the time-series and graph evolution
dynamics are piecewise smooth, we identify local windows of time where the
signals exhibit approximate stationarity. We then train an encoding that allows
the distribution of signals within a neighborhood to be distinguished from the
distribution of non-neighboring signals. We first demonstrate the performance
of our proposed framework using synthetic data, and subsequently we show that
it can prove beneficial for the classification task with real-world datasets.",http://arxiv.org/pdf/2209.10662v1,cs.LG
2022-09-21 18:23:03+00:00,DeepVARwT: Deep Learning for a VAR Model with Trend,"['Xixi Li', 'Jingsong Yuan']","The vector autoregressive (VAR) model has been used to describe the
dependence within and across multiple time series. This is a model for
stationary time series which can be extended to allow the presence of a
deterministic trend in each series. Detrending the data either parametrically
or nonparametrically before fitting the VAR model gives rise to more errors in
the latter part. In this study, we propose a new approach called DeepVARwT that
employs deep learning methodology for maximum likelihood estimation of the
trend and the dependence structure at the same time. A Long Short-Term Memory
(LSTM) network is used for this purpose. To ensure the stability of the model,
we enforce the causality condition on the autoregressive coefficients using the
transformation of Ansley & Kohn (1986). We provide a simulation study and an
application to real data. In the simulation study, we use realistic trend
functions generated from real data and compare the estimates with true
function/parameter values. In the real data application, we compare the
prediction performance of this model with state-of-the-art models in the
literature.",http://arxiv.org/pdf/2209.10587v2,stat.ME
2022-09-21 15:04:27+00:00,Modeling and Simulating Dependence in Networks Using Topological Data Analysis,"['Anass El Yaagoubi Bourakna', 'Moo K. Chung', 'Hernando Ombao']","Topological data analysis (TDA) approaches are becoming increasingly popular
for studying the dependence patterns in multivariate time series data. In
particular, various dependence patterns in brain networks may be linked to
specific tasks and cognitive processes, which can be altered by various
neurological and cognitive impairments such as Alzheimer's and Parkinson's
diseases, as well as attention deficit hyperactivity disorder (ADHD). Because
there is no ground-truth with known dependence patterns in real brain signals,
testing new TDA methods on multivariate time series is still a challenge.
Simulations are crucial for evaluating the performance of proposed TDA methods
and testing procedures as well as for creating computation-based confidence
intervals. To our knowledge, there are no methods that simulate multivariate
time series data with specific and manually imposed connectivity patterns. In
this paper we present a novel approach to simulate multivariate time series
with specific number of cycles/holes in its dependence network. Furthermore, we
also provide a procedure for generating higher dimensional topological
features.",http://arxiv.org/pdf/2209.10416v1,stat.ME
2022-09-20 10:15:35+00:00,PromptCast: A New Prompt-based Learning Paradigm for Time Series Forecasting,"['Hao Xue', 'Flora D. Salim']","This paper presents a new perspective on time series forecasting. In existing
time series forecasting methods, the models take a sequence of numerical values
as input and yield numerical values as output. The existing SOTA models are
largely based on the Transformer architecture, modified with multiple encoding
mechanisms to incorporate the context and semantics around the historical data.
Inspired by the successes of pre-trained language foundation models, we pose a
question about whether these models can also be adapted to solve time-series
forecasting. Thus, we propose a new forecasting paradigm: prompt-based time
series forecasting (PromptCast). In this novel task, the numerical input and
output are transformed into prompts and the forecasting task is framed in a
sentence-to-sentence manner, making it possible to directly apply language
models for forecasting purposes. To support and facilitate the research of this
task, we also present a large-scale dataset (PISA) that includes three
real-world forecasting scenarios. We evaluate different SOTA numerical-based
forecasting methods and language generation models. The benchmark results with
various forecasting settings demonstrate the proposed PromptCast with language
generation models is a promising research direction. Additionally, in
comparison to conventional numerical-based forecasting, PromptCast shows a much
better generalization ability under the zero-shot setting.",http://arxiv.org/pdf/2210.08964v4,stat.ME
2022-09-20 08:23:49+00:00,An Attention Free Long Short-Term Memory for Time Series Forecasting,"['Hugo Inzirillo', 'Ludovic De Villelongue']","Deep learning is playing an increasingly important role in time series
analysis. We focused on time series forecasting using attention free mechanism,
a more efficient framework, and proposed a new architecture for time series
prediction for which linear models seem to be unable to capture the time
dependence. We proposed an architecture built using attention free LSTM layers
that overcome linear models for conditional variance prediction. Our findings
confirm the validity of our model, which also allowed to improve the prediction
capacity of a LSTM, while improving the efficiency of the learning task.",http://arxiv.org/pdf/2209.09548v1,cs.LG
2022-09-18 17:59:04+00:00,Koopman-theoretic Approach for Identification of Exogenous Anomalies in Nonstationary Time-series Data,"['Alex Mallen', 'Christoph A. Keller', 'J. Nathan Kutz']","In many scenarios, it is necessary to monitor a complex system via a
time-series of observations and determine when anomalous exogenous events have
occurred so that relevant actions can be taken. Determining whether current
observations are abnormal is challenging. It requires learning an extrapolative
probabilistic model of the dynamics from historical data, and using a limited
number of current observations to make a classification. We leverage recent
advances in long-term probabilistic forecasting, namely {\em Deep Probabilistic
Koopman}, to build a general method for classifying anomalies in
multi-dimensional time-series data. We also show how to utilize models with
domain knowledge of the dynamics to reduce type I and type II error. We
demonstrate our proposed method on the important real-world task of global
atmospheric pollution monitoring, integrating it with NASA's Global Earth
System Model. The system successfully detects localized anomalies in air
quality due to events such as COVID-19 lockdowns and wildfires.",http://arxiv.org/pdf/2209.08618v1,cs.LG
2022-09-17 22:58:46+00:00,Neighborhood VAR: Efficient estimation of multivariate timeseries with neighborhood information,"['Zhihao Hu', 'Shyam Ranganathan', 'Yang Shao', 'Xinwei Deng']","In data science, vector autoregression (VAR) models are popular in modeling
multivariate time series in the environmental sciences and other applications.
However, these models are computationally complex with the number of parameters
scaling quadratically with the number of time series.
  In this work, we propose a so-called neighborhood vector autoregression
(NVAR) model to efficiently analyze large-dimensional multivariate time series.
  We assume that the time series have underlying neighborhood relationships,
e.g., spatial or network, among them based on the inherent setting of the
problem. When this neighborhood information is available or can be summarized
using a distance matrix, we demonstrate that our proposed NVAR method provides
a computationally efficient and theoretically sound estimation of model
parameters. The performance of the proposed method is compared with other
existing approaches in both simulation studies and a real application of stream
nitrogen study.",http://arxiv.org/pdf/2209.08421v1,stat.ME
2022-09-17 21:40:02+00:00,DynaConF: Dynamic Forecasting of Non-Stationary Time-Series,"['Siqi Liu', 'Andreas Lehrmann']","Deep learning models have shown impressive results in a variety of time
series forecasting tasks, where modeling the conditional distribution of the
future given the past is the essence. However, when this conditional
distribution is non-stationary, it poses challenges for these models to learn
consistently and to predict accurately. In this work, we propose a new method
to model non-stationary conditional distributions over time by clearly
decoupling stationary conditional distribution modeling from non-stationary
dynamics modeling. Our method is based on a Bayesian dynamic model that can
adapt to conditional distribution changes and a deep conditional distribution
model that can handle large multivariate time series using a factorized output
space. Our experimental results on synthetic and popular public datasets show
that our model can adapt to non-stationary time series better than
state-of-the-art deep learning solutions.",http://arxiv.org/pdf/2209.08411v1,cs.LG
2022-09-15 20:50:20+00:00,Neuro-symbolic Models for Interpretable Time Series Classification using Temporal Logic Description,"['Ruixuan Yan', 'Tengfei Ma', 'Achille Fokoue', 'Maria Chang', 'Agung Julius']","Most existing Time series classification (TSC) models lack interpretability
and are difficult to inspect. Interpretable machine learning models can aid in
discovering patterns in data as well as give easy-to-understand insights to
domain specialists. In this study, we present Neuro-Symbolic Time Series
Classification (NSTSC), a neuro-symbolic model that leverages signal temporal
logic (STL) and neural network (NN) to accomplish TSC tasks using multi-view
data representation and expresses the model as a human-readable, interpretable
formula. In NSTSC, each neuron is linked to a symbolic expression, i.e., an STL
(sub)formula. The output of NSTSC is thus interpretable as an STL formula akin
to natural language, describing temporal and logical relations hidden in the
data. We propose an NSTSC-based classifier that adopts a decision-tree approach
to learn formula structures and accomplish a multiclass TSC task. The proposed
smooth activation functions for wSTL allow the model to be learned in an
end-to-end fashion. We test NSTSC on a real-world wound healing dataset from
mice and benchmark datasets from the UCR time-series repository, demonstrating
that NSTSC achieves comparable performance with the state-of-the-art models.
Furthermore, NSTSC can generate interpretable formulas that match with domain
knowledge.",http://arxiv.org/pdf/2209.09114v1,cs.LG
2022-09-15 05:56:36+00:00,Efficient learning of nonlinear prediction models with time-series privileged information,"['Bastian Jung', 'Fredrik D Johansson']","In domains where sample sizes are limited, efficient learning algorithms are
critical. Learning using privileged information (LuPI) offers increased sample
efficiency by allowing prediction models access to auxiliary information at
training time which is unavailable when the models are used. In recent work, it
was shown that for prediction in linear-Gaussian dynamical systems, a LuPI
learner with access to intermediate time series data is never worse and often
better in expectation than any unbiased classical learner. We provide new
insights into this analysis and generalize it to nonlinear prediction tasks in
latent dynamical systems, extending theoretical guarantees to the case where
the map connecting latent variables and observations is known up to a linear
transform. In addition, we propose algorithms based on random features and
representation learning for the case when this map is unknown. A suite of
empirical results confirm theoretical findings and show the potential of using
privileged time-series information in nonlinear prediction.",http://arxiv.org/pdf/2209.07067v3,cs.LG
2022-09-15 03:36:31+00:00,Out-of-Distribution Representation Learning for Time Series Classification,"['Wang Lu', 'Jindong Wang', 'Xinwei Sun', 'Yiqiang Chen', 'Xing Xie']","Time series classification is an important problem in real world. Due to its
non-stationary property that the distribution changes over time, it remains
challenging to build models for generalization to unseen distributions. In this
paper, we propose to view the time series classification problem from the
distribution perspective. We argue that the temporal complexity attributes to
the unknown latent distributions within. To this end, we propose DIVERSIFY to
learn generalized representations for time series classification. DIVERSIFY
takes an iterative process: it first obtains the worst-case distribution
scenario via adversarial training, then matches the distributions of the
obtained sub-domains. We also present some theoretical insights. We conduct
experiments on gesture recognition, speech commands recognition, wearable
stress and affect detection, and sensor-based human activity recognition with a
total of seven datasets in different settings. Results demonstrate that
DIVERSIFY significantly outperforms other baselines and effectively
characterizes the latent distributions by qualitative and quantitative
analysis. Code is available at: https://github.com/microsoft/robustlearn.",http://arxiv.org/pdf/2209.07027v4,cs.LG
2022-09-15 03:14:59+00:00,FRANS: Automatic Feature Extraction for Time Series Forecasting,"['Alexey Chernikov', 'Chang Wei Tan', 'Pablo Montero-Manso', 'Christoph Bergmeir']","Feature extraction methods help in dimensionality reduction and capture
relevant information. In time series forecasting (TSF), features can be used as
auxiliary information to achieve better accuracy. Traditionally, features used
in TSF are handcrafted, which requires domain knowledge and significant
data-engineering work. In this research, we first introduce a notion of static
and dynamic features, which then enables us to develop our autonomous Feature
Retrieving Autoregressive Network for Static features (FRANS) that does not
require domain knowledge. The method is based on a CNN classifier that is
trained to create for each series a collective and unique class representation
either from parts of the series or, if class labels are available, from a set
of series of the same class. It allows to discriminate series with similar
behaviour but from different classes and makes the features extracted from the
classifier to be maximally discriminatory. We explore the interpretability of
our features, and evaluate the prediction capabilities of the method within the
forecasting meta-learning environment FFORMA. Our results show that our
features lead to improvement in accuracy in most situations. Once trained our
approach creates features orders of magnitude faster than statistical methods.",http://arxiv.org/pdf/2209.07018v1,cs.LG
2022-09-14 03:02:22+00:00,TSFool: Crafting Highly-imperceptible Adversarial Time Series through Multi-objective Black-box Attack to Fool RNN Classifiers,"['Yanyun Wang', 'Dehui Du', 'Yuanhao Liu']","Neural network (NN) classifiers are vulnerable to adversarial attacks.
Although the existing gradient-based attacks achieve state-of-the-art
performance in feed-forward NNs and image recognition tasks, they do not
perform as well on time series classification with recurrent neural network
(RNN) models. This is because the cyclical structure of RNN prevents direct
model differentiation and the visual sensitivity of time series data to
perturbations challenges the traditional local optimization objective of the
adversarial attack. In this paper, a black-box method called TSFool is proposed
to efficiently craft highly-imperceptible adversarial time series for RNN
classifiers. We propose a novel global optimization objective named Camouflage
Coefficient to consider the imperceptibility of adversarial samples from the
perspective of class distribution, and accordingly refine the adversarial
attack as a multi-objective optimization problem to enhance the perturbation
quality. To get rid of the dependence on gradient information, we also propose
a new idea that introduces a representation model for RNN to capture deeply
embedded vulnerable samples having otherness between their features and latent
manifold, based on which the optimization solution can be heuristically
approximated. Experiments on 10 UCR datasets are conducted to confirm that
TSFool averagely outperforms existing methods with a 46.3% higher attack
success rate, 87.4% smaller perturbation and 25.6% better Camouflage
Coefficient at a similar time cost.",http://arxiv.org/pdf/2209.06388v2,cs.LG
2022-09-12 15:05:57+00:00,An Evaluation of Low Overhead Time Series Preprocessing Techniques for Downstream Machine Learning,"['Matthew L. Weiss', 'Joseph McDonald', 'David Bestor', 'Charles Yee', 'Daniel Edelman', 'Michael Jones', 'Andrew Prout', 'Andrew Bowne', 'Lindsey McEvoy', 'Vijay Gadepally', 'Siddharth Samsi']","In this paper we address the application of pre-processing techniques to
multi-channel time series data with varying lengths, which we refer to as the
alignment problem, for downstream machine learning. The misalignment of
multi-channel time series data may occur for a variety of reasons, such as
missing data, varying sampling rates, or inconsistent collection times. We
consider multi-channel time series data collected from the MIT SuperCloud High
Performance Computing (HPC) center, where different job start times and varying
run times of HPC jobs result in misaligned data. This misalignment makes it
challenging to build AI/ML approaches for tasks such as compute workload
classification. Building on previous supervised classification work with the
MIT SuperCloud Dataset, we address the alignment problem via three broad, low
overhead approaches: sampling a fixed subset from a full time series,
performing summary statistics on a full time series, and sampling a subset of
coefficients from time series mapped to the frequency domain. Our best
performing models achieve a classification accuracy greater than 95%,
outperforming previous approaches to multi-channel time series classification
with the MIT SuperCloud Dataset by 5%. These results indicate our low overhead
approaches to solving the alignment problem, in conjunction with standard
machine learning techniques, are able to achieve high levels of classification
accuracy, and serve as a baseline for future approaches to addressing the
alignment problem, such as kernel methods.",http://arxiv.org/pdf/2209.05300v1,cs.LG
2022-09-10 10:44:25+00:00,A Comparative Study on Unsupervised Anomaly Detection for Time Series: Experiments and Analysis,"['Yan Zhao', 'Liwei Deng', 'Xuanhao Chen', 'Chenjuan Guo', 'Bin Yang', 'Tung Kieu', 'Feiteng Huang', 'Torben Bach Pedersen', 'Kai Zheng', 'Christian S. Jensen']","The continued digitization of societal processes translates into a
proliferation of time series data that cover applications such as fraud
detection, intrusion detection, and energy management, where anomaly detection
is often essential to enable reliability and safety. Many recent studies target
anomaly detection for time series data. Indeed, area of time series anomaly
detection is characterized by diverse data, methods, and evaluation strategies,
and comparisons in existing studies consider only part of this diversity, which
makes it difficult to select the best method for a particular problem setting.
To address this shortcoming, we introduce taxonomies for data, methods, and
evaluation strategies, provide a comprehensive overview of unsupervised time
series anomaly detection using the taxonomies, and systematically evaluate and
compare state-of-the-art traditional as well as deep learning techniques. In
the empirical study using nine publicly available datasets, we apply the most
commonly-used performance evaluation metrics to typical methods under a fair
implementation standard. Based on the structuring offered by the taxonomies, we
report on empirical studies and provide guidelines, in the form of comparative
tables, for choosing the methods most suitable for particular application
settings. Finally, we propose research directions for this dynamic field.",http://arxiv.org/pdf/2209.04635v1,cs.LG
2022-09-10 00:06:29+00:00,Deep Baseline Network for Time Series Modeling and Anomaly Detection,"['Cheng Ge', 'Xi Chen', 'Ming Wang', 'Jin Wang']","Deep learning has seen increasing applications in time series in recent
years. For time series anomaly detection scenarios, such as in finance,
Internet of Things, data center operations, etc., time series usually show very
flexible baselines depending on various external factors. Anomalies unveil
themselves by lying far away from the baseline. However, the detection is not
always easy due to some challenges including baseline shifting, lacking of
labels, noise interference, real time detection in streaming data, result
interpretability, etc. In this paper, we develop a novel deep architecture to
properly extract the baseline from time series, namely Deep Baseline Network
(DBLN). By using this deep network, we can easily locate the baseline position
and then provide reliable and interpretable anomaly detection result. Empirical
evaluation on both synthetic and public real-world datasets shows that our
purely unsupervised algorithm achieves superior performance compared with
state-of-art methods and has good practical applications.",http://arxiv.org/pdf/2209.04561v2,cs.LG
2022-09-08 17:39:38+00:00,W-Transformers : A Wavelet-based Transformer Framework for Univariate Time Series Forecasting,"['Lena Sasal', 'Tanujit Chakraborty', 'Abdenour Hadid']","Deep learning utilizing transformers has recently achieved a lot of success
in many vital areas such as natural language processing, computer vision,
anomaly detection, and recommendation systems, among many others. Among several
merits of transformers, the ability to capture long-range temporal dependencies
and interactions is desirable for time series forecasting, leading to its
progress in various time series applications. In this paper, we build a
transformer model for non-stationary time series. The problem is challenging
yet crucially important. We present a novel framework for univariate time
series representation learning based on the wavelet-based transformer encoder
architecture and call it W-Transformer. The proposed W-Transformers utilize a
maximal overlap discrete wavelet transformation (MODWT) to the time series data
and build local transformers on the decomposed datasets to vividly capture the
nonstationarity and long-range nonlinear dependencies in the time series.
Evaluating our framework on several publicly available benchmark time series
datasets from various domains and with diverse characteristics, we demonstrate
that it performs, on average, significantly better than the baseline
forecasters for short-term and long-term forecasting, even for datasets that
consist of only a few hundred training samples.",http://arxiv.org/pdf/2209.03945v1,cs.LG
2022-09-08 15:36:16+00:00,Valuing Players Over Time,"['Tiago Mendes-Neves', 'Luís Meireles', 'João Mendes-Moreira']","In soccer (or association football), players quickly go from heroes to
zeroes, or vice-versa. Performance is not a static measure but a somewhat
volatile one. Analyzing performance as a time series rather than a stationary
point in time is crucial to making better decisions. This paper introduces and
explores I-VAEP and O-VAEP models to evaluate actions and rate players'
intention and execution. Then, we analyze these ratings over time and propose
use cases to fundament our option of treating player ratings as a continuous
problem. As a result, we present who were the best players and how their
performance evolved, define volatility metrics to measure a player's
consistency, and build a player development curve to assist decision-making.",http://arxiv.org/pdf/2209.03882v1,cs.LG
2022-09-03 20:14:31+00:00,Learning Differential Operators for Interpretable Time Series Modeling,"['Yingtao Luo', 'Chang Xu', 'Yang Liu', 'Weiqing Liu', 'Shun Zheng', 'Jiang Bian']","Modeling sequential patterns from data is at the core of various time series
forecasting tasks. Deep learning models have greatly outperformed many
traditional models, but these black-box models generally lack explainability in
prediction and decision making. To reveal the underlying trend with
understandable mathematical expressions, scientists and economists tend to use
partial differential equations (PDEs) to explain the highly nonlinear dynamics
of sequential patterns. However, it usually requires domain expert knowledge
and a series of simplified assumptions, which is not always practical and can
deviate from the ever-changing world. Is it possible to learn the differential
relations from data dynamically to explain the time-evolving dynamics? In this
work, we propose an learning framework that can automatically obtain
interpretable PDE models from sequential data. Particularly, this framework is
comprised of learnable differential blocks, named $P$-blocks, which is proved
to be able to approximate any time-evolving complex continuous functions in
theory. Moreover, to capture the dynamics shift, this framework introduces a
meta-learning controller to dynamically optimize the hyper-parameters of a
hybrid PDE model. Extensive experiments on times series forecasting of
financial, engineering, and health data show that our model can provide
valuable interpretability and achieve comparable performance to
state-of-the-art models. From empirical studies, we find that learning a few
differential operators may capture the major trend of sequential dynamics
without massive computational complexity.",http://arxiv.org/pdf/2209.01491v1,cs.LG
2022-09-02 17:49:34+00:00,Estimation of Correlation Matrices from Limited time series Data using Machine Learning,"['Nikhil Easaw', 'Woo Seok Lee', 'Prashant Singh Lohiya', 'Sarika Jalan', 'Priodyuti Pradhan']","Correlation matrices contain a wide variety of spatio-temporal information
about a dynamical system. Predicting correlation matrices from partial time
series information of a few nodes characterizes the spatio-temporal dynamics of
the entire underlying system. This information can help to predict the
underlying network structure, e.g., inferring neuronal connections from spiking
data, deducing causal dependencies between genes from expression data, and
discovering long spatial range influences in climate variations. Traditional
methods of predicting correlation matrices utilize time series data of all the
nodes of the underlying networks. Here, we use a supervised machine learning
technique to predict the correlation matrix of entire systems from finite time
series information of a few randomly selected nodes. The accuracy of the
prediction validates that only a limited time series of a subset of the entire
system is enough to make good correlation matrix predictions. Furthermore,
using an unsupervised learning algorithm, we furnish insights into the success
of the predictions from our model. Finally, we employ the machine learning
model developed here to real-world data sets.",http://arxiv.org/pdf/2209.01198v4,cs.LG
2022-08-31 17:44:08+00:00,Multiscale Non-stationary Causal Structure Learning from Time Series Data,"[""Gabriele D'Acunto"", 'Gianmarco De Francisci Morales', 'Paolo Bajardi', 'Francesco Bonchi']","This paper introduces a new type of causal structure, namely multiscale
non-stationary directed acyclic graph (MN-DAG), that generalizes DAGs to the
time-frequency domain. Our contribution is twofold. First, by leveraging
results from spectral and causality theories, we expose a novel probabilistic
generative model, which allows to sample an MN-DAG according to user-specified
priors concerning the time-dependence and multiscale properties of the causal
graph. Second, we devise a Bayesian method for the estimation of MN-DAGs, by
means of stochastic variational inference (SVI), called Multiscale
Non-Stationary Causal Structure Learner (MN-CASTLE). In addition to direct
observations, MN-CASTLE exploits information from the decomposition of the
total power spectrum of time series over different time resolutions. In our
experiments, we first use the proposed model to generate synthetic data
according to a latent MN-DAG, showing that the data generated reproduces
well-known features of time series in different domains. Then we compare our
learning method MN-CASTLE against baseline models on synthetic data generated
with different multiscale and non-stationary settings, confirming the good
performance of MN-CASTLE. Finally, we show some insights derived from the
application of MN-CASTLE to study the causal structure of 7 global equity
markets during the Covid-19 pandemic.",http://arxiv.org/pdf/2208.14989v1,cs.LG
2022-08-31 15:23:10+00:00,ARMA Cell: A Modular and Effective Approach for Neural Autoregressive Modeling,"['Philipp Schiele', 'Christoph Berninger', 'David Rügamer']","The autoregressive moving average (ARMA) model is a classical, and arguably
one of the most studied approaches to model time series data. It has compelling
theoretical properties and is widely used among practitioners. More recent deep
learning approaches popularize recurrent neural networks (RNNs) and, in
particular, long short-term memory (LSTM) cells that have become one of the
best performing and most common building blocks in neural time series modeling.
While advantageous for time series data or sequences with long-term effects,
complex RNN cells are not always a must and can sometimes even be inferior to
simpler recurrent approaches. In this work, we introduce the ARMA cell, a
simpler, modular, and effective approach for time series modeling in neural
networks. This cell can be used in any neural network architecture where
recurrent structures are present and naturally handles multivariate time series
using vector autoregression. We also introduce the ConvARMA cell as a natural
successor for spatially-correlated time series. Our experiments show that the
proposed methodology is competitive with popular alternatives in terms of
performance while being more robust and compelling due to its simplicity.",http://arxiv.org/pdf/2208.14919v1,cs.LG
2022-08-30 15:23:45+00:00,Denoising Architecture for Unsupervised Anomaly Detection in Time-Series,"['Wadie Skaf', 'Tomáš Horváth']","Anomalies in time-series provide insights of critical scenarios across a
range of industries, from banking and aerospace to information technology,
security, and medicine. However, identifying anomalies in time-series data is
particularly challenging due to the imprecise definition of anomalies, the
frequent absence of labels, and the enormously complex temporal correlations
present in such data. The LSTM Autoencoder is an Encoder-Decoder scheme for
Anomaly Detection based on Long Short Term Memory Networks that learns to
reconstruct time-series behavior and then uses reconstruction error to identify
abnormalities. We introduce the Denoising Architecture as a complement to this
LSTM Encoder-Decoder model and investigate its effect on real-world as well as
artificially generated datasets. We demonstrate that the proposed architecture
increases both the accuracy and the training speed, thereby, making the LSTM
Autoencoder more efficient for unsupervised anomaly detection tasks.",http://arxiv.org/pdf/2208.14337v1,cs.LG
2022-08-30 13:04:48+00:00,Persistence Initialization: A novel adaptation of the Transformer architecture for Time Series Forecasting,"['Espen Haugsdal', 'Erlend Aune', 'Massimiliano Ruocco']","Time series forecasting is an important problem, with many real world
applications. Ensembles of deep neural networks have recently achieved
impressive forecasting accuracy, but such large ensembles are impractical in
many real world settings. Transformer models been successfully applied to a
diverse set of challenging problems. We propose a novel adaptation of the
original Transformer architecture focusing on the task of time series
forecasting, called Persistence Initialization. The model is initialized as a
naive persistence model by using a multiplicative gating mechanism combined
with a residual skip connection. We use a decoder Transformer with ReZero
normalization and Rotary positional encodings, but the adaptation is applicable
to any auto-regressive neural network model. We evaluate our proposed
architecture on the challenging M4 dataset, achieving competitive performance
compared to ensemble based methods. We also compare against existing recently
proposed Transformer models for time series forecasting, showing superior
performance on the M4 dataset. Extensive ablation studies show that Persistence
Initialization leads to better performance and faster convergence. As the size
of the model increases, only the models with our proposed adaptation gain in
performance. We also perform an additional ablation study to determine the
importance of the choice of normalization and positional encoding, and find
both the use of Rotary encodings and ReZero normalization to be essential for
good forecasting performance.",http://arxiv.org/pdf/2208.14236v1,cs.LG
2022-08-25 07:41:23+00:00,Time Series Clustering with an EM algorithm for Mixtures of Linear Gaussian State Space Models,"['Ryohei Umatani', 'Takashi Imai', 'Kaoru Kawamoto', 'Shutaro Kunimasa']","In this paper, we consider the task of clustering a set of individual time
series while modeling each cluster, that is, model-based time series
clustering. The task requires a parametric model with sufficient flexibility to
describe the dynamics in various time series. To address this problem, we
propose a novel model-based time series clustering method with mixtures of
linear Gaussian state space models, which have high flexibility. The proposed
method uses a new expectation-maximization algorithm for the mixture model to
estimate the model parameters, and determines the number of clusters using the
Bayesian information criterion. Experiments on a simulated dataset demonstrate
the effectiveness of the method in clustering, parameter estimation, and model
selection. The method is applied to real datasets commonly used to evaluate
time series clustering methods. Results showed that the proposed method
produces clustering results that are as accurate or more accurate than those
obtained using previous methods.",http://arxiv.org/pdf/2208.11907v3,cs.LG
2022-08-24 08:47:36+00:00,DCSF: Deep Convolutional Set Functions for Classification of Asynchronous Time Series,"['Vijaya Krishna Yalavarthi', 'Johannes Burchert', 'Lars Schmidt-Thieme']","Asynchronous Time Series is a multivariate time series where all the channels
are observed asynchronously-independently, making the time series extremely
sparse when aligning them. We often observe this effect in applications with
complex observation processes, such as health care, climate science, and
astronomy, to name a few. Because of the asynchronous nature, they pose a
significant challenge to deep learning architectures, which presume that the
time series presented to them are regularly sampled, fully observed, and
aligned with respect to time. This paper proposes a novel framework, that we
call Deep Convolutional Set Functions (DCSF), which is highly scalable and
memory efficient, for the asynchronous time series classification task. With
the recent advancements in deep set learning architectures, we introduce a
model that is invariant to the order in which time series' channels are
presented to it. We explore convolutional neural networks, which are well
researched for the closely related problem-classification of regularly sampled
and fully observed time series, for encoding the set elements. We evaluate DCSF
for AsTS classification, and online (per time point) AsTS classification. Our
extensive experiments on multiple real-world and synthetic datasets verify that
the suggested model performs substantially better than a range of
state-of-the-art models in terms of accuracy and run time.",http://arxiv.org/pdf/2208.11374v1,cs.LG
2022-08-24 01:55:50+00:00,Towards an Awareness of Time Series Anomaly Detection Models' Adversarial Vulnerability,"['Shahroz Tariq', 'Binh M. Le', 'Simon S. Woo']","Time series anomaly detection is extensively studied in statistics,
economics, and computer science. Over the years, numerous methods have been
proposed for time series anomaly detection using deep learning-based methods.
Many of these methods demonstrate state-of-the-art performance on benchmark
datasets, giving the false impression that these systems are robust and
deployable in many practical and industrial real-world scenarios. In this
paper, we demonstrate that the performance of state-of-the-art anomaly
detection methods is degraded substantially by adding only small adversarial
perturbations to the sensor data. We use different scoring metrics such as
prediction errors, anomaly, and classification scores over several public and
private datasets ranging from aerospace applications, server machines, to
cyber-physical systems in power plants. Under well-known adversarial attacks
from Fast Gradient Sign Method (FGSM) and Projected Gradient Descent (PGD)
methods, we demonstrate that state-of-the-art deep neural networks (DNNs) and
graph neural networks (GNNs) methods, which claim to be robust against
anomalies and have been possibly integrated in real-life systems, have their
performance drop to as low as 0%. To the best of our understanding, we
demonstrate, for the first time, the vulnerabilities of anomaly detection
systems against adversarial attacks. The overarching goal of this research is
to raise awareness towards the adversarial vulnerabilities of time series
anomaly detectors.",http://arxiv.org/pdf/2208.11264v1,cs.LG
2022-08-23 21:40:40+00:00,Transfer Learning-based State of Health Estimation for Lithium-ion Battery with Cycle Synchronization,"['Kate Qi Zhou', 'Yan Qin', 'Chau Yuen']","Accurately estimating a battery's state of health (SOH) helps prevent
battery-powered applications from failing unexpectedly. With the superiority of
reducing the data requirement of model training for new batteries, transfer
learning (TL) emerges as a promising machine learning approach that applies
knowledge learned from a source battery, which has a large amount of data.
However, the determination of whether the source battery model is reasonable
and which part of information can be transferred for SOH estimation are rarely
discussed, despite these being critical components of a successful TL. To
address these challenges, this paper proposes an interpretable TL-based SOH
estimation method by exploiting the temporal dynamic to assist transfer
learning, which consists of three parts. First, with the help of dynamic time
warping, the temporal data from the discharge time series are synchronized,
yielding the warping path of the cycle-synchronized time series responsible for
capacity degradation over cycles. Second, the canonical variates retrieved from
the spatial path of the cycle-synchronized time series are used for
distribution similarity analysis between the source and target batteries.
Third, when the distribution similarity is within the predefined threshold, a
comprehensive target SOH estimation model is constructed by transferring the
common temporal dynamics from the source SOH estimation model and compensating
the errors with a residual model from the target battery. Through a widely-used
open-source benchmark dataset, the estimation error of the proposed method
evaluated by the root mean squared error is as low as 0.0034 resulting in a 77%
accuracy improvement compared with existing methods.",http://arxiv.org/pdf/2208.11204v1,cs.LG
2022-08-23 14:00:31+00:00,Inter- and Intra-Series Embeddings Fusion Network for Epidemiological Forecasting,"['Feng Xie', 'Zhong Zhang', 'Xuechen Zhao', 'Bin Zhou', 'Yusong Tan']","The accurate forecasting of infectious epidemic diseases is the key to
effective control of the epidemic situation in a region. Most existing methods
ignore potential dynamic dependencies between regions or the importance of
temporal dependencies and inter-dependencies between regions for prediction. In
this paper, we propose an Inter- and Intra-Series Embeddings Fusion Network
(SEFNet) to improve epidemic prediction performance. SEFNet consists of two
parallel modules, named Inter-Series Embedding Module and Intra-Series
Embedding Module. In Inter-Series Embedding Module, a multi-scale unified
convolution component called Region-Aware Convolution is proposed, which
cooperates with self-attention to capture dynamic dependencies between time
series obtained from multiple regions. The Intra-Series Embedding Module uses
Long Short-Term Memory to capture temporal relationships within each time
series. Subsequently, we learn the influence degree of two embeddings and fuse
them with the parametric-matrix fusion method. To further improve the
robustness, SEFNet also integrates a traditional autoregressive component in
parallel with nonlinear neural networks. Experiments on four real-world
epidemic-related datasets show SEFNet is effective and outperforms
state-of-the-art baselines.",http://arxiv.org/pdf/2208.11515v1,cs.LG
2022-08-22 17:33:31+00:00,Shapelet-Based Counterfactual Explanations for Multivariate Time Series,"['Omar Bahri', 'Soukaina Filali Boubrahimi', 'Shah Muhammad Hamdi']","As machine learning and deep learning models have become highly prevalent in
a multitude of domains, the main reservation in their adoption for
decision-making processes is their black-box nature. The Explainable Artificial
Intelligence (XAI) paradigm has gained a lot of momentum lately due to its
ability to reduce models opacity. XAI methods have not only increased
stakeholders' trust in the decision process but also helped developers ensure
its fairness. Recent efforts have been invested in creating transparent models
and post-hoc explanations. However, fewer methods have been developed for time
series data, and even less when it comes to multivariate datasets. In this
work, we take advantage of the inherent interpretability of shapelets to
develop a model agnostic multivariate time series (MTS) counterfactual
explanation algorithm. Counterfactuals can have a tremendous impact on making
black-box models explainable by indicating what changes have to be performed on
the input to change the final decision. We test our approach on a real-life
solar flare prediction dataset and prove that our approach produces
high-quality counterfactuals. Moreover, a comparison to the only MTS
counterfactual generation algorithm shows that, in addition to being visually
interpretable, our explanations are superior in terms of proximity, sparsity,
and plausibility.",http://arxiv.org/pdf/2208.10462v1,cs.LG
2022-08-21 03:41:19+00:00,Stop&Hop: Early Classification of Irregular Time Series,"['Thomas Hartvigsen', 'Walter Gerych', 'Jidapa Thadajarassiri', 'Xiangnan Kong', 'Elke Rundensteiner']","Early classification algorithms help users react faster to their machine
learning model's predictions. Early warning systems in hospitals, for example,
let clinicians improve their patients' outcomes by accurately predicting
infections. While early classification systems are advancing rapidly, a major
gap remains: existing systems do not consider irregular time series, which have
uneven and often-long gaps between their observations. Such series are
notoriously pervasive in impactful domains like healthcare. We bridge this gap
and study early classification of irregular time series, a new setting for
early classifiers that opens doors to more real-world problems. Our solution,
Stop&Hop, uses a continuous-time recurrent network to model ongoing irregular
time series in real time, while an irregularity-aware halting policy, trained
with reinforcement learning, predicts when to stop and classify the streaming
series. By taking real-valued step sizes, the halting policy flexibly decides
exactly when to stop ongoing series in real time. This way, Stop&Hop seamlessly
integrates information contained in the timing of observations, a new and vital
source for early classification in this setting, with the time series values to
provide early classifications for irregular time series. Using four synthetic
and three real-world datasets, we demonstrate that Stop&Hop consistently makes
earlier and more-accurate predictions than state-of-the-art alternatives
adapted to this new problem. Our code is publicly available at
https://github.com/thartvigsen/StopAndHop.",http://arxiv.org/pdf/2208.09795v1,cs.LG
2022-08-19 15:29:43+00:00,Diffusion-based Time Series Imputation and Forecasting with Structured State Space Models,"['Juan Miguel Lopez Alcaraz', 'Nils Strodthoff']","The imputation of missing values represents a significant obstacle for many
real-world data analysis pipelines. Here, we focus on time series data and put
forward SSSD, an imputation model that relies on two emerging technologies,
(conditional) diffusion models as state-of-the-art generative models and
structured state space models as internal model architecture, which are
particularly suited to capture long-term dependencies in time series data. We
demonstrate that SSSD matches or even exceeds state-of-the-art probabilistic
imputation and forecasting performance on a broad range of data sets and
different missingness scenarios, including the challenging blackout-missing
scenarios, where prior approaches failed to provide meaningful results.",http://arxiv.org/pdf/2208.09399v3,cs.LG
2022-08-19 12:25:56+00:00,Expressing Multivariate Time Series as Graphs with Time Series Attention Transformer,"['William T. Ng', 'K. Siu', 'Albert C. Cheung', 'Michael K. Ng']","A reliable and efficient representation of multivariate time series is
crucial in various downstream machine learning tasks. In multivariate time
series forecasting, each variable depends on its historical values and there
are inter-dependencies among variables as well. Models have to be designed to
capture both intra- and inter-relationships among the time series. To move
towards this goal, we propose the Time Series Attention Transformer (TSAT) for
multivariate time series representation learning. Using TSAT, we represent both
temporal information and inter-dependencies of multivariate time series in
terms of edge-enhanced dynamic graphs. The intra-series correlations are
represented by nodes in a dynamic graph; a self-attention mechanism is modified
to capture the inter-series correlations by using the super-empirical mode
decomposition (SMD) module. We applied the embedded dynamic graphs to times
series forecasting problems, including two real-world datasets and two
benchmark datasets. Extensive experiments show that TSAT clearly outerperforms
six state-of-the-art baseline methods in various forecasting horizons. We
further visualize the embedded dynamic graphs to illustrate the graph
representation power of TSAT. We share our code at
https://github.com/RadiantResearch/TSAT.",http://arxiv.org/pdf/2208.09300v1,cs.LG
2022-08-19 09:34:11+00:00,An Unsupervised Short- and Long-Term Mask Representation for Multivariate Time Series Anomaly Detection,"['Qiucheng Miao', 'Chuanfu Xu', 'Jun Zhan', 'Dong Zhu', 'Chengkun Wu']","Anomaly detection of multivariate time series is meaningful for system
behavior monitoring. This paper proposes an anomaly detection method based on
unsupervised Short- and Long-term Mask Representation learning (SLMR). The main
idea is to extract short-term local dependency patterns and long-term global
trend patterns of the multivariate time series by using multi-scale residual
dilated convolution and Gated Recurrent Unit(GRU) respectively. Furthermore,
our approach can comprehend temporal contexts and feature correlations by
combining spatial-temporal masked self-supervised representation learning and
sequence split. It considers the importance of features is different, and we
introduce the attention mechanism to adjust the contribution of each feature.
Finally, a forecasting-based model and a reconstruction-based model are
integrated to focus on single timestamp prediction and latent representation of
time series. Experiments show that the performance of our method outperforms
other state-of-the-art models on three real-world datasets. Further analysis
shows that our method is good at interpretability.",http://arxiv.org/pdf/2208.09240v1,cs.LG
2022-08-18 14:46:05+00:00,Network inference via process motifs for lagged correlation in linear stochastic processes,"['Alice C. Schwarze', 'Sara M. Ichinaga', 'Bingni W. Brunton']","A major challenge for causal inference from time-series data is the trade-off
between computational feasibility and accuracy. Motivated by process motifs for
lagged covariance in an autoregressive model with slow mean-reversion, we
propose to infer networks of causal relations via pairwise edge measure (PEMs)
that one can easily compute from lagged correlation matrices. Motivated by
contributions of process motifs to covariance and lagged variance, we formulate
two PEMs that correct for confounding factors and for reverse causation. To
demonstrate the performance of our PEMs, we consider network interference from
simulations of linear stochastic processes, and we show that our proposed PEMs
can infer networks accurately and efficiently. Specifically, for slightly
autocorrelated time-series data, our approach achieves accuracies higher than
or similar to Granger causality, transfer entropy, and convergent crossmapping
-- but with much shorter computation time than possible with any of these
methods. Our fast and accurate PEMs are easy-to-implement methods for network
inference with a clear theoretical underpinning. They provide promising
alternatives to current paradigms for the inference of linear models from
time-series data, including Granger causality, vector-autoregression, and
sparse inverse covariance estimation.",http://arxiv.org/pdf/2208.08871v2,stat.ML
2022-08-18 11:32:04+00:00,Efficient data-driven gap filling of satellite image time series using deep neural networks with partial convolutions,['Marius Appel'],"The abundance of gaps in satellite image time series often complicates the
application of deep learning models such as convolutional neural networks for
spatiotemporal modeling. Based on previous work in computer vision on image
inpainting, this paper shows how three-dimensional spatiotemporal partial
convolutions can be used as layers in neural networks to fill gaps in satellite
image time series. To evaluate the approach, we apply a U-Net-like model on
incomplete image time series of quasi-global carbon monoxide observations from
the Sentinel-5P satellite. Prediction errors were comparable to two considered
statistical approaches while computation times for predictions were up to three
orders of magnitude faster, making the approach applicable to process large
amounts of satellite data. Partial convolutions can be added as layers to other
types of neural networks, making it relatively easy to integrate with existing
deep learning models. However, the approach does not quantify prediction errors
and further research is needed to understand and improve model transferability.
The implementation of spatiotemporal partial convolutions and the U-Net-like
model is available as open-source software.",http://arxiv.org/pdf/2208.08781v1,cs.LG
2022-08-15 10:22:15+00:00,Grasping Core Rules of Time Series through Pure Models,"['Gedi Liu', 'Yifeng Jiang', 'Yi Ouyang', 'Keyang Zhong', 'Yang Wang']","Time series underwent the transition from statistics to deep learning, as did
many other machine learning fields. Although it appears that the accuracy has
been increasing as the model is updated in a number of publicly available
datasets, it typically only increases the scale by several times in exchange
for a slight difference in accuracy. Through this experiment, we point out a
different line of thinking, time series, especially long-term forecasting, may
differ from other fields. It is not necessary to use extensive and complex
models to grasp all aspects of time series, but to use pure models to grasp the
core rules of time series changes. With this simple but effective idea, we
created PureTS, a network with three pure linear layers that achieved
state-of-the-art in 80% of the long sequence prediction tasks while being
nearly the lightest model and having the fastest running speed. On this basis,
we discuss the potential of pure linear layers in both phenomena and essence.
The ability to understand the core law contributes to the high precision of
long-distance prediction, and reasonable fluctuation prevents it from
distorting the curve in multi-step prediction like mainstream deep learning
models, which is summarized as a pure linear neural network that avoids
over-fluctuating. Finally, we suggest the fundamental design standards for
lightweight long-step time series tasks: input and output should try to have
the same dimension, and the structure avoids fragmentation and complex
operations.",http://arxiv.org/pdf/2208.07105v1,cs.LG
2022-08-14 17:00:47+00:00,Confidence-Guided Learning Process for Continuous Classification of Time Series,"['Chenxi Sun', 'Moxian Song', 'Derun Can', 'Baofeng Zhang', 'Shenda Hong', 'Hongyan Li']","In the real world, the class of a time series is usually labeled at the final
time, but many applications require to classify time series at every time
point. e.g. the outcome of a critical patient is only determined at the end,
but he should be diagnosed at all times for timely treatment. Thus, we propose
a new concept: Continuous Classification of Time Series (CCTS). It requires the
model to learn data in different time stages. But the time series evolves
dynamically, leading to different data distributions. When a model learns
multi-distribution, it always forgets or overfits. We suggest that meaningful
learning scheduling is potential due to an interesting observation: Measured by
confidence, the process of model learning multiple distributions is similar to
the process of human learning multiple knowledge. Thus, we propose a novel
Confidence-guided method for CCTS (C3TS). It can imitate the alternating human
confidence described by the Dunning-Kruger Effect. We define the objective-
confidence to arrange data, and the self-confidence to control the learning
duration. Experiments on four real-world datasets show that C3TS is more
accurate than all baselines for CCTS.",http://arxiv.org/pdf/2208.06883v1,cs.LG
2022-08-13 10:22:12+00:00,Self-supervised Contrastive Representation Learning for Semi-supervised Time-Series Classification,"['Emadeldeen Eldele', 'Mohamed Ragab', 'Zhenghua Chen', 'Min Wu', 'Chee-Keong Kwoh', 'Xiaoli Li', 'Cuntai Guan']","Learning time-series representations when only unlabeled data or few labeled
samples are available can be a challenging task. Recently, contrastive
self-supervised learning has shown great improvement in extracting useful
representations from unlabeled data via contrasting different augmented views
of data. In this work, we propose a novel Time-Series representation learning
framework via Temporal and Contextual Contrasting (TS-TCC) that learns
representations from unlabeled data with contrastive learning. Specifically, we
propose time-series-specific weak and strong augmentations and use their views
to learn robust temporal relations in the proposed temporal contrasting module,
besides learning discriminative representations by our proposed contextual
contrasting module. Additionally, we conduct a systematic study of time-series
data augmentation selection, which is a key part of contrastive learning. We
also extend TS-TCC to the semi-supervised learning settings and propose a
Class-Aware TS-TCC (CA-TCC) that benefits from the available few labeled data
to further improve representations learned by TS-TCC. Specifically, we leverage
the robust pseudo labels produced by TS-TCC to realize a class-aware
contrastive loss. Extensive experiments show that the linear evaluation of the
features learned by our proposed framework performs comparably with the fully
supervised training. Additionally, our framework shows high efficiency in the
few labeled data and transfer learning scenarios. The code is publicly
available at \url{https://github.com/emadeldeen24/CA-TCC}.",http://arxiv.org/pdf/2208.06616v3,cs.LG
2022-08-12 07:29:29+00:00,Feature-Based Time-Series Analysis in R using the theft Package,"['Trent Henderson', 'Ben D. Fulcher']","Time series are measured and analyzed across the sciences. One method of
quantifying the structure of time series is by calculating a set of summary
statistics or `features', and then representing a time series in terms of its
properties as a feature vector. The resulting feature space is interpretable
and informative, and enables conventional statistical learning approaches,
including clustering, regression, and classification, to be applied to
time-series datasets. Many open-source software packages for computing sets of
time-series features exist across multiple programming languages, including
catch22 (22 features: Matlab, R, Python, Julia), feasts (42 features: R),
tsfeatures (63 features: R), Kats (40 features: Python), tsfresh (779 features:
Python), and TSFEL (390 features: Python). However, there are several issues:
(i) a singular access point to these packages is not currently available; (ii)
to access all feature sets, users must be fluent in multiple languages; and
(iii) these feature-extraction packages lack extensive accompanying
methodological pipelines for performing feature-based time-series analysis,
such as applications to time-series classification. Here we introduce a
solution to these issues in an R software package called theft: Tools for
Handling Extraction of Features from Time series. theft is a unified and
extendable framework for computing features from the six open-source
time-series feature sets listed above. It also includes a suite of functions
for processing and interpreting the performance of extracted features,
including extensive data-visualization templates, low-dimensional projections,
and time-series classification operations. With an increasing volume and
complexity of time-series datasets in the sciences and industry, theft provides
a standardized framework for comprehensively quantifying and interpreting
informative structure in time series.",http://arxiv.org/pdf/2208.06146v4,stat.ML
2022-08-11 14:05:51+00:00,HyperTime: Implicit Neural Representation for Time Series,"['Elizabeth Fons', 'Alejandro Sztrajman', 'Yousef El-laham', 'Alexandros Iosifidis', 'Svitlana Vyetrenko']","Implicit neural representations (INRs) have recently emerged as a powerful
tool that provides an accurate and resolution-independent encoding of data.
Their robustness as general approximators has been shown in a wide variety of
data sources, with applications on image, sound, and 3D scene representation.
However, little attention has been given to leveraging these architectures for
the representation and analysis of time series data. In this paper, we analyze
the representation of time series using INRs, comparing different activation
functions in terms of reconstruction accuracy and training convergence speed.
We show how these networks can be leveraged for the imputation of time series,
with applications on both univariate and multivariate data. Finally, we propose
a hypernetwork architecture that leverages INRs to learn a compressed latent
representation of an entire time series dataset. We introduce an FFT-based loss
to guide training so that all frequencies are preserved in the time series. We
show that this network can be used to encode time series as INRs, and their
embeddings can be interpolated to generate new time series from existing ones.
We evaluate our generative method by using it for data augmentation, and show
that it is competitive against current state-of-the-art approaches for
augmentation of time series.",http://arxiv.org/pdf/2208.05836v1,cs.LG
2022-08-10 11:25:58+00:00,TSInterpret: A unified framework for time series interpretability,"['Jacqueline Höllig', 'Cedric Kulbach', 'Steffen Thoma']","With the increasing application of deep learning algorithms to time series
classification, especially in high-stake scenarios, the relevance of
interpreting those algorithms becomes key. Although research in time series
interpretability has grown, accessibility for practitioners is still an
obstacle. Interpretability approaches and their visualizations are diverse in
use without a unified API or framework. To close this gap, we introduce
TSInterpret an easily extensible open-source Python library for interpreting
predictions of time series classifiers that combines existing interpretation
approaches into one unified framework. The library features (i)
state-of-the-art interpretability algorithms, (ii) exposes a unified API
enabling users to work with explanations consistently and provides (iii)
suitable visualizations for each explanation.",http://arxiv.org/pdf/2208.05280v2,cs.LG
2022-08-09 11:21:10+00:00,Representation learning of rare temporal conditions for travel time prediction,"['Niklas Petersen', 'Filipe Rodrigues', 'Francisco Pereira']","Predicting travel time under rare temporal conditions (e.g., public holidays,
school vacation period, etc.) constitutes a challenge due to the limitation of
historical data. If at all available, historical data often form a
heterogeneous time series due to high probability of other changes over long
periods of time (e.g., road works, introduced traffic calming initiatives,
etc.). This is especially prominent in cities and suburban areas. We present a
vector-space model for encoding rare temporal conditions, that allows coherent
representation learning across different temporal conditions. We show increased
performance for travel time prediction over different baselines when utilizing
the vector-space encoding for representing the temporal setting.",http://arxiv.org/pdf/2208.04667v1,stat.ML
2022-08-08 20:32:28+00:00,Recovering the Graph Underlying Networked Dynamical Systems under Partial Observability: A Deep Learning Approach,"['Sérgio Machado', 'Anirudh Sridhar', 'Paulo Gil', 'Jorge Henriques', 'José M. F. Moura', 'Augusto Santos']","We study the problem of graph structure identification, i.e., of recovering
the graph of dependencies among time series. We model these time series data as
components of the state of linear stochastic networked dynamical systems. We
assume partial observability, where the state evolution of only a subset of
nodes comprising the network is observed. We devise a new feature vector
computed from the observed time series and prove that these features are
linearly separable, i.e., there exists a hyperplane that separates the cluster
of features associated with connected pairs of nodes from those associated with
disconnected pairs. This renders the features amenable to train a variety of
classifiers to perform causal inference. In particular, we use these features
to train Convolutional Neural Networks (CNNs). The resulting causal inference
mechanism outperforms state-of-the-art counterparts w.r.t. sample-complexity.
The trained CNNs generalize well over structurally distinct networks (dense or
sparse) and noise-level profiles. Remarkably, they also generalize well to
real-world networks while trained over a synthetic network (realization of a
random graph). Finally, the proposed method consistently reconstructs the graph
in a pairwise manner, that is, by deciding if an edge or arrow is present or
absent in each pair of nodes, from the corresponding time series of each pair.
This fits the framework of large-scale systems, where observation or processing
of all nodes in the network is prohibitive.",http://arxiv.org/pdf/2208.04405v3,cs.LG
2022-08-08 09:48:41+00:00,Rank and Factor Loadings Estimation in Time Series Tensor Factor Model by Pre-averaging,"['Weilin Chen', 'Clifford Lam']","Tensor time series data appears naturally in a lot of fields, including
finance and economics. As a major dimension reduction tool, similar to its
factor model counterpart, the idiosyncratic components of a tensor time series
factor model can exhibit serial correlations, especially in financial and
economic applications. This rules out a lot of state-of-the-art methods that
assume white idiosyncratic components, or even independent/Gaussian data. While
the traditional higher order orthogonal iteration (HOOI) is proved to be
convergent to a set of factor loading matrices, the closeness of them to the
true underlying factor loading matrices are in general not established, or only
under some strict circumstances like having i.i.d. Gaussian noises (Zhang and
Xia, 2018). Under the presence of serial and cross-correlations in the
idiosyncratic components and time series variables with only bounded fourth
order moments, we propose a pre-averaging method that accumulates information
from tensor fibres for better estimating all the factor loading spaces. The
estimated directions corresponding to the strongest factors are then used for
projecting the data for a potentially improved re-estimation of the factor
loading spaces themselves, with theoretical guarantees and rate of convergence
spelt out. We also propose a new rank estimation method which utilizes
correlation information from the projected data, in the same spirit as Fan, Guo
and Zheng (2022) for factor models with independent data. Extensive simulation
results reveal competitive performance of our rank and factor loading
estimators relative to other state-of-the-art or traditional alternatives. A
set of matrix-valued portfolio return data is also analyzed.",http://arxiv.org/pdf/2208.04012v1,stat.ME
2022-08-06 06:00:45+00:00,AUTOSHAPE: An Autoencoder-Shapelet Approach for Time Series Clustering,"['Guozhong Li', 'Byron Choi', 'Jianliang Xu', 'Sourav S Bhowmick', 'Daphne Ngar-yin Mah', 'Grace Lai-Hung Wong']","Time series shapelets are discriminative subsequences that have been recently
found effective for time series clustering (TSC). The shapelets are convenient
for interpreting the clusters. Thus, the main challenge for TSC is to discover
high-quality variable-length shapelets to discriminate different clusters. In
this paper, we propose a novel autoencoder-shapelet approach (AUTOSHAPE), which
is the first study to take the advantage of both autoencoder and shapelet for
determining shapelets in an unsupervised manner. An autoencoder is specially
designed to learn high-quality shapelets. More specifically, for guiding the
latent representation learning, we employ the latest self-supervised loss to
learn the unified embeddings for variable-length shapelet candidates (time
series subsequences) of different variables, and propose the diversity loss to
select the discriminating embeddings in the unified space. We introduce the
reconstruction loss to recover shapelets in the original time series space for
clustering. Finally, we adopt Davies Bouldin index (DBI) to inform AUTOSHAPE of
the clustering performance during learning. We present extensive experiments on
AUTOSHAPE. To evaluate the clustering performance on univariate time series
(UTS), we compare AUTOSHAPE with 15 representative methods using UCR archive
datasets. To study the performance of multivariate time series (MTS), we
evaluate AUTOSHAPE on 30 UEA archive datasets with 5 competitive methods. The
results validate that AUTOSHAPE is the best among all the methods compared. We
interpret clusters with shapelets, and can obtain interesting intuitions about
clusters in two UTS case studies and one MTS case study, respectively.",http://arxiv.org/pdf/2208.04313v2,cs.LG
2022-08-03 14:38:19+00:00,Detecting Multivariate Time Series Anomalies with Zero Known Label,"['Qihang Zhou', 'Jiming Chen', 'Haoyu Liu', 'Shibo He', 'Wenchao Meng']","Multivariate time series anomaly detection has been extensively studied under
the semi-supervised setting, where a training dataset with all normal instances
is required. However, preparing such a dataset is very laborious since each
single data instance should be fully guaranteed to be normal. It is, therefore,
desired to explore multivariate time series anomaly detection methods based on
the dataset without any label knowledge. In this paper, we propose MTGFlow, an
unsupervised anomaly detection approach for multivariate time series anomaly
detection via dynamic graph and entity-aware normalizing flow, leaning only on
a widely accepted hypothesis that abnormal instances exhibit sparse densities
than the normal. However, the complex interdependencies among entities and the
diverse inherent characteristics of each entity pose significant challenges on
the density estimation, let alone to detect anomalies based on the estimated
possibility distribution. To tackle these problems, we propose to learn the
mutual and dynamic relations among entities via a graph structure learning
model, which helps to model accurate distribution of multivariate time series.
Moreover, taking account of distinct characteristics of the individual
entities, an entity-aware normalizing flow is developed to describe each entity
into a parameterized normal distribution, thereby producing fine-grained
density estimation. Incorporating these two strategies, MTGFlow achieves
superior anomaly detection performance. Experiments on five public datasets
with seven baselines are conducted, MTGFlow outperforms the SOTA methods by up
to 5.0 AUROC\%. Codes will be released at
https://github.com/zqhang/Detecting-Multivariate-Time-Series-Anomalies-with-Zero-Known-Label.",http://arxiv.org/pdf/2208.02108v3,cs.LG
2022-08-03 08:34:31+00:00,EgPDE-Net: Building Continuous Neural Networks for Time Series Prediction with Exogenous Variables,"['Penglei Gao', 'Xi Yang', 'Rui Zhang', 'Ping Guo', 'John Y. Goulermas', 'Kaizhu Huang']","While exogenous variables have a major impact on performance improvement in
time series analysis, inter-series correlation and time dependence among them
are rarely considered in the present continuous methods. The dynamical systems
of multivariate time series could be modelled with complex unknown partial
differential equations (PDEs) which play a prominent role in many disciplines
of science and engineering. In this paper, we propose a continuous-time model
for arbitrary-step prediction to learn an unknown PDE system in multivariate
time series whose governing equations are parameterised by self-attention and
gated recurrent neural networks. The proposed model,
\underline{E}xogenous-\underline{g}uided \underline{P}artial
\underline{D}ifferential \underline{E}quation Network (EgPDE-Net), takes
account of the relationships among the exogenous variables and their effects on
the target series. Importantly, the model can be reduced into a regularised
ordinary differential equation (ODE) problem with special designed
regularisation guidance, which makes the PDE problem tractable to obtain
numerical solutions and feasible to predict multiple future values of the
target series at arbitrary time points. Extensive experiments demonstrate that
our proposed model could achieve competitive accuracy over strong baselines: on
average, it outperforms the best baseline by reducing $9.85\%$ on RMSE and
$13.98\%$ on MAE for arbitrary-step prediction.",http://arxiv.org/pdf/2208.01913v2,cs.LG
2022-08-02 19:52:02+00:00,On optimal block resampling for Gaussian-subordinated long-range dependent processes,"['Qihao Zhang', 'Soumendra N. Lahiri', 'Daniel J. Nordman']","Block-based resampling estimators have been intensively investigated for
weakly dependent time processes, which has helped to inform implementation
(e.g., best block sizes). However, little is known about resampling performance
and block sizes under strong or long-range dependence. To establish guideposts
in block selection, we consider a broad class of strongly dependent time
processes, formed by a transformation of a stationary long-memory Gaussian
series, and examine block-based resampling estimators for the variance of the
prototypical sample mean; extensions to general statistical functionals are
also considered. Unlike weak dependence, the properties of resampling
estimators under strong dependence are shown to depend intricately on the
nature of non-linearity in the time series (beyond Hermite ranks) in addition
the long-memory coefficient and block size. Additionally, the intuition has
often been that optimal block sizes should be larger under strong dependence
(say $O(n^{1/2})$ for a sample size $n$) than the optimal order $O(n^{1/3})$
known under weak dependence. This intuition turns out to be largely incorrect,
though a block order $O(n^{1/2})$ may be reasonable (and even optimal) in many
cases, owing to non-linearity in a long-memory time series. While optimal block
sizes are more complex under long-range dependence compared to short-range, we
provide a consistent data-driven rule for block selection, and numerical
studies illustrate that the guides for block selection perform well in other
block-based problems with long-memory time series, such as distribution
estimation and strategies for testing Hermite rank.",http://arxiv.org/pdf/2208.01713v1,math.ST
2022-08-01 21:51:16+00:00,Interpretable Time Series Clustering Using Local Explanations,"['Ozan Ozyegen', 'Nicholas Prayogo', 'Mucahit Cevik', 'Ayse Basar']","This study focuses on exploring the use of local interpretability methods for
explaining time series clustering models. Many of the state-of-the-art
clustering models are not directly explainable. To provide explanations for
these clustering algorithms, we train classification models to estimate the
cluster labels. Then, we use interpretability methods to explain the decisions
of the classification models. The explanations are used to obtain insights into
the clustering models. We perform a detailed numerical study to test the
proposed approach on multiple datasets, clustering models, and classification
models. The analysis of the results shows that the proposed approach can be
used to explain time series clustering models, specifically when the underlying
classification model is accurate. Lastly, we provide a detailed analysis of the
results, discussing how our approach can be used in a real-life scenario.",http://arxiv.org/pdf/2208.01152v1,cs.LG
2022-08-01 17:25:09+00:00,Predicting Future Mosquito Larval Habitats Using Time Series Climate Forecasting and Deep Learning,"['Christopher Sun', 'Jay Nimbalkar', 'Ravnoor Bedi']","Mosquito habitat ranges are projected to expand due to climate change. This
investigation aims to identify future mosquito habitats by analyzing preferred
ecological conditions of mosquito larvae. After assembling a data set with
atmospheric records and larvae observations, a neural network is trained to
predict larvae counts from ecological inputs. Time series forecasting is
conducted on these variables and climate projections are passed into the
initial deep learning model to generate location-specific larvae abundance
predictions. The results support the notion of regional ecosystem-driven
changes in mosquito spread, with high-elevation regions in particular
experiencing an increase in susceptibility to mosquito infestation.",http://arxiv.org/pdf/2208.01436v2,cs.LG
2022-08-01 10:24:15+00:00,On the Impact of Serial Dependence on Penalized Regression Methods,"['Simone Tonini', 'Francesca Chiaromonte', 'Alessandro Giovannelli']","This paper characterizes the impact of covariate serial dependence on the
non-asymptotic estimation error bound of penalized regressions (PRs). Focusing
on the direct relationship between the degree of cross-correlation between
covariates and the estimation error bound of PRs, we show that orthogonal or
weakly cross-correlated stationary AR processes can exhibit high spurious
correlations caused by serial dependence. We provide analytical results on the
distribution of the sample cross-correlation in the case of two orthogonal
Gaussian AR(1) processes, and extend and validate them through an extensive
simulation study. Furthermore, we introduce a new procedure to mitigate
spurious correlations in a time series setting, applying PRs to pre-whitened
(ARMA filtered) time series. We show that under mild assumptions our procedure
allows both to reduce the estimation error and to develop an effective
forecasting strategy. The estimation accuracy of our proposal is validated
through additional simulations, as well as an empirical application to a large
set of monthly macroeconomic time series relative to the Euro Area.",http://arxiv.org/pdf/2208.00727v3,math.ST
2022-07-27 17:23:14+00:00,Conformal Prediction Bands for Two-Dimensional Functional Time Series,"['Niccolò Ajroldi', 'Jacopo Diquigiovanni', 'Matteo Fontana', 'Simone Vantini']","Time evolving surfaces can be modeled as two-dimensional Functional time
series, exploiting the tools of Functional data analysis. Leveraging this
approach, a forecasting framework for such complex data is developed. The main
focus revolves around Conformal Prediction, a versatile nonparametric paradigm
used to quantify uncertainty in prediction problems. Building upon recent
variations of Conformal Prediction for Functional time series, a probabilistic
forecasting scheme for two-dimensional functional time series is presented,
while providing an extension of Functional Autoregressive Processes of order
one to this setting. Estimation techniques for the latter process are
introduced and their performance are compared in terms of the resulting
prediction regions. Finally, the proposed forecasting procedure and the
uncertainty quantification technique are applied to a real dataset, collecting
daily observations of Sea Level Anomalies of the Black Sea",http://arxiv.org/pdf/2207.13656v2,stat.ME
2022-07-27 10:39:00+00:00,Time Series Forecasting Models Copy the Past: How to Mitigate,"['Chrysoula Kosma', 'Giannis Nikolentzos', 'Nancy Xu', 'Michalis Vazirgiannis']","Time series forecasting is at the core of important application domains
posing significant challenges to machine learning algorithms. Recently neural
network architectures have been widely applied to the problem of time series
forecasting. Most of these models are trained by minimizing a loss function
that measures predictions' deviation from the real values. Typical loss
functions include mean squared error (MSE) and mean absolute error (MAE). In
the presence of noise and uncertainty, neural network models tend to replicate
the last observed value of the time series, thus limiting their applicability
to real-world data. In this paper, we provide a formal definition of the above
problem and we also give some examples of forecasts where the problem is
observed. We also propose a regularization term penalizing the replication of
previously seen values. We evaluate the proposed regularization term both on
synthetic and real-world datasets. Our results indicate that the regularization
term mitigates to some extent the aforementioned problem and gives rise to more
robust models.",http://arxiv.org/pdf/2207.13441v1,cs.LG
2022-07-25 20:06:36+00:00,Benchmark time series data sets for PyTorch -- the torchtime package,"['Philip Darke', 'Paolo Missier', 'Jaume Bacardit']","The development of models for Electronic Health Record data is an area of
active research featuring a small number of public benchmark data sets.
Researchers typically write custom data processing code but this hinders
reproducibility and can introduce errors. The Python package torchtime provides
reproducible implementations of commonly used PhysioNet and UEA & UCR time
series classification repository data sets for PyTorch. Features are provided
for working with irregularly sampled and partially observed time series of
unequal length. It aims to simplify access to PhysioNet data and enable fair
comparisons of models in this exciting area of research.",http://arxiv.org/pdf/2207.12503v2,cs.LG
2022-07-25 13:43:13+00:00,Calibrated One-class Classification for Unsupervised Time Series Anomaly Detection,"['Hongzuo Xu', 'Yijie Wang', 'Songlei Jian', 'Qing Liao', 'Yongjun Wang', 'Guansong Pang']","Unsupervised time series anomaly detection is instrumental in monitoring and
alarming potential faults of target systems in various domains. Current
state-of-the-art time series anomaly detectors mainly focus on devising
advanced neural network structures and new reconstruction/prediction learning
objectives to learn data normality (normal patterns and behaviors) as
accurately as possible. However, these one-class learning methods can be
deceived by unknown anomalies in the training data (i.e., anomaly
contamination). Further, their normality learning also lacks knowledge about
the anomalies of interest. Consequently, they often learn a biased, inaccurate
normality boundary. This paper proposes a novel one-class learning approach,
named calibrated one-class classification, to tackle this problem. Our
one-class classifier is calibrated in two ways: (1) by adaptively penalizing
uncertain predictions, which helps eliminate the impact of anomaly
contamination while accentuating the predictions that the one-class model is
confident in, and (2) by discriminating the normal samples from native anomaly
examples that are generated to simulate genuine time series abnormal behaviors
on the basis of original data. These two calibrations result in
contamination-tolerant, anomaly-informed one-class learning, yielding a
significantly improved normality modeling. Extensive experiments on six
real-world datasets show that our model substantially outperforms twelve
state-of-the-art competitors and obtains 6% - 31% F1 score improvement. The
source code is available at \url{https://github.com/xuhongzuo/couta}.",http://arxiv.org/pdf/2207.12201v1,cs.LG
2022-07-25 13:04:05+00:00,dCAM: Dimension-wise Class Activation Map for Explaining Multivariate Data Series Classification,"['Paul Boniol', 'Mohammed Meftah', 'Emmanuel Remy', 'Themis Palpanas']","Data series classification is an important and challenging problem in data
science. Explaining the classification decisions by finding the discriminant
parts of the input that led the algorithm to some decisions is a real need in
many applications. Convolutional neural networks perform well for the data
series classification task; though, the explanations provided by this type of
algorithm are poor for the specific case of multivariate data series.
Addressing this important limitation is a significant challenge. In this paper,
we propose a novel method that solves this problem by highlighting both the
temporal and dimensional discriminant information. Our contribution is
two-fold: we first describe a convolutional architecture that enables the
comparison of dimensions; then, we propose a method that returns dCAM, a
Dimension-wise Class Activation Map specifically designed for multivariate time
series (and CNN-based models). Experiments with several synthetic and real
datasets demonstrate that dCAM is not only more accurate than previous
approaches, but the only viable solution for discriminant feature discovery and
classification explanation in multivariate time series. This paper has appeared
in SIGMOD'22.",http://arxiv.org/pdf/2207.12165v1,cs.LG
2022-07-24 16:41:14+00:00,CODiT: Conformal Out-of-Distribution Detection in Time-Series Data,"['Ramneet Kaur', 'Kaustubh Sridhar', 'Sangdon Park', 'Susmit Jha', 'Anirban Roy', 'Oleg Sokolsky', 'Insup Lee']","Machine learning models are prone to making incorrect predictions on inputs
that are far from the training distribution. This hinders their deployment in
safety-critical applications such as autonomous vehicles and healthcare. The
detection of a shift from the training distribution of individual datapoints
has gained attention. A number of techniques have been proposed for such
out-of-distribution (OOD) detection. But in many applications, the inputs to a
machine learning model form a temporal sequence. Existing techniques for OOD
detection in time-series data either do not exploit temporal relationships in
the sequence or do not provide any guarantees on detection. We propose using
deviation from the in-distribution temporal equivariance as the non-conformity
measure in conformal anomaly detection framework for OOD detection in
time-series data.Computing independent predictions from multiple conformal
detectors based on the proposed measure and combining these predictions by
Fisher's method leads to the proposed detector CODiT with guarantees on false
detection in time-series data. We illustrate the efficacy of CODiT by achieving
state-of-the-art results on computer vision datasets in autonomous driving. We
also show that CODiT can be used for OOD detection in non-vision datasets by
performing experiments on the physiological GAIT sensory dataset. Code, data,
and trained models are available at
https://github.com/kaustubhsridhar/time-series-OOD.",http://arxiv.org/pdf/2207.11769v1,cs.LG
2022-07-24 07:45:05+00:00,Clustering of bivariate satellite time series: a quantile approach,"['Victor Muthama Musau', 'Carlo Gaetan', 'Paolo Girardi']","Clustering has received much attention in Statistics and Machine learning
with the aim of developing statistical models and autonomous algorithms which
are capable of acquiring information from raw data in order to perform
exploratory analysis.Several techniques have been developed to cluster sampled
univariate vectors only considering the average value over the whole period and
as such they have not been able to explore fully the underlying distribution as
well as other features of the data, especially in presence of structured time
series. We propose a model-based clustering technique that is based on quantile
regression permitting us to cluster bivariate time series at different quantile
levels. We model the within cluster density using asymmetric Laplace
distribution allowing us to take into account asymmetry in the distribution of
the data. We evaluate the performance of the proposed technique through a
simulation study. The method is then applied to cluster time series observed
from Glob-colour satellite data related to trophic status indices with aim of
evaluating their temporal dynamics in order to identify homogeneous areas, in
terms of trophic status, in the Gulf of Gabes.",http://arxiv.org/pdf/2207.11682v1,stat.ME
2022-07-23 10:32:37+00:00,Time Series Prediction under Distribution Shift using Differentiable Forgetting,"['Stefanos Bennett', 'Jase Clarkson']","Time series prediction is often complicated by distribution shift which
demands adaptive models to accommodate time-varying distributions. We frame
time series prediction under distribution shift as a weighted empirical risk
minimisation problem. The weighting of previous observations in the empirical
risk is determined by a forgetting mechanism which controls the trade-off
between the relevancy and effective sample size that is used for the estimation
of the predictive model. In contrast to previous work, we propose a
gradient-based learning method for the parameters of the forgetting mechanism.
This speeds up optimisation and therefore allows more expressive forgetting
mechanisms.",http://arxiv.org/pdf/2207.11486v1,cs.LG
2022-07-23 08:58:57+00:00,Anomaly Detection for Fraud in Cryptocurrency Time Series,"['Eran Kaufman', 'Andrey Iaremenko']","Since the inception of Bitcoin in 2009, the market of cryptocurrencies has
grown beyond initial expectations as daily trades exceed $10 billion. As
industries become automated, the need for an automated fraud detector becomes
very apparent. Detecting anomalies in real time prevents potential accidents
and economic losses. Anomaly detection in multivariate time series data poses a
particular challenge because it requires simultaneous consideration of temporal
dependencies and relationships between variables. Identifying an anomaly in
real time is not an easy task specifically because of the exact anomalistic
behavior they observe. Some points may present pointwise global or local
anomalistic behavior, while others may be anomalistic due to their frequency or
seasonal behavior or due to a change in the trend. In this paper we suggested
working on real time series of trades of Ethereum from specific accounts and
surveyed a large variety of different algorithms traditional and new. We
categorized them according to the strategy and the anomalistic behavior which
they search and showed that when bundling them together to different groups,
they can prove to be a good real-time detector with an alarm time of no longer
than a few seconds and with very high confidence.",http://arxiv.org/pdf/2207.11466v1,cs.LG
2022-07-23 02:23:17+00:00,Simultaneous Inference for Time Series Functional Linear Regression,"['Yan Cui', 'Zhou Zhou']","We consider the problem of joint simultaneous confidence band (JSCB)
construction for regression coefficient functions of time series
scalar-on-function linear regression when the regression model is estimated by
roughness penalization approach with flexible choices of orthonormal basis
functions. A simple and unified multiplier bootstrap methodology is proposed
for the JSCB construction which is shown to achieve the correct coverage
probability asymptotically. Furthermore, the JSCB is asymptotically robust to
inconsistently estimated standard deviations of the model. The proposed
methodology is applied to a time series data set of electricity market to
visually investigate and formally test the overall regression relationship as
well as perform model validation.",http://arxiv.org/pdf/2207.11392v2,stat.ME
2022-07-22 13:11:42+00:00,Latent Space Unsupervised Semantic Segmentation,"['Knut J. Strømmen', 'Jim Tørresen', 'Ulysse Côté-Allard']","The development of compact and energy-efficient wearable sensors has led to
an increase in the availability of biosignals. To analyze these continuously
recorded, and often multidimensional, time series at scale, being able to
conduct meaningful unsupervised data segmentation is an auspicious target. A
common way to achieve this is to identify change-points within the time series
as the segmentation basis. However, traditional change-point detection
algorithms often come with drawbacks, limiting their real-world applicability.
Notably, they generally rely on the complete time series to be available and
thus cannot be used for real-time applications. Another common limitation is
that they poorly (or cannot) handle the segmentation of multidimensional time
series. Consequently, the main contribution of this work is to propose a novel
unsupervised segmentation algorithm for multidimensional time series named
Latent Space Unsupervised Semantic Segmentation (LS-USS), which was designed to
work easily with both online and batch data. When comparing LS-USS against
other state-of-the-art change-point detection algorithms on a variety of
real-world datasets, in both the offline and real-time setting, LS-USS
systematically achieves on par or better performances.",http://arxiv.org/pdf/2207.11067v2,cs.LG
2022-07-22 08:34:31+00:00,Respecting Time Series Properties Makes Deep Time Series Forecasting Perfect,"['Li Shen', 'Yuning Wei', 'Yangzhu Wang']","How to handle time features shall be the core question of any time series
forecasting model. Ironically, it is often ignored or misunderstood by
deep-learning based models, even those baselines which are state-of-the-art.
This behavior makes their inefficient, untenable and unstable. In this paper,
we rigorously analyze three prevalent but deficient/unfounded deep time series
forecasting mechanisms or methods from the view of time series properties,
including normalization methods, multivariate forecasting and input sequence
length. Corresponding corollaries and solutions are given on both empirical and
theoretical basis. We thereby propose a novel time series forecasting network,
i.e. RTNet, on the basis of aforementioned analysis. It is general enough to be
combined with both supervised and self-supervised forecasting format. Thanks to
the core idea of respecting time series properties, no matter in which
forecasting format, RTNet shows obviously superior forecasting performances
compared with dozens of other SOTA time series forecasting baselines in three
real-world benchmark datasets. By and large, it even occupies less time
complexity and memory usage while acquiring better forecasting accuracy. The
source code is available at https://github.com/OrigamiSL/RTNet.",http://arxiv.org/pdf/2207.10941v1,cs.LG
2022-07-21 14:51:58+00:00,MQRetNN: Multi-Horizon Time Series Forecasting with Retrieval Augmentation,"['Sitan Yang', 'Carson Eisenach', 'Dhruv Madeka']","Multi-horizon probabilistic time series forecasting has wide applicability to
real-world tasks such as demand forecasting. Recent work in neural time-series
forecasting mainly focus on the use of Seq2Seq architectures. For example,
MQTransformer - an improvement of MQCNN - has shown the state-of-the-art
performance in probabilistic demand forecasting. In this paper, we consider
incorporating cross-entity information to enhance model performance by adding a
cross-entity attention mechanism along with a retrieval mechanism to select
which entities to attend over. We demonstrate how our new neural architecture,
MQRetNN, leverages the encoded contexts from a pretrained baseline model on the
entire population to improve forecasting accuracy. Using MQCNN as the baseline
model (due to computational constraints, we do not use MQTransformer), we first
show on a small demand forecasting dataset that it is possible to achieve ~3%
improvement in test loss by adding a cross-entity attention mechanism where
each entity attends to all others in the population. We then evaluate the model
with our proposed retrieval methods - as a means of approximating an attention
over a large population - on a large-scale demand forecasting application with
over 2 million products and observe ~1% performance gain over the MQCNN
baseline.",http://arxiv.org/pdf/2207.10517v2,cs.LG
2022-07-19 22:00:41+00:00,Robust Multivariate Time-Series Forecasting: Adversarial Attacks and Defense Mechanisms,"['Linbo Liu', 'Youngsuk Park', 'Trong Nghia Hoang', 'Hilaf Hasson', 'Jun Huan']","This work studies the threats of adversarial attack on multivariate
probabilistic forecasting models and viable defense mechanisms. Our studies
discover a new attack pattern that negatively impact the forecasting of a
target time series via making strategic, sparse (imperceptible) modifications
to the past observations of a small number of other time series. To mitigate
the impact of such attack, we have developed two defense strategies. First, we
extend a previously developed randomized smoothing technique in classification
to multivariate forecasting scenarios. Second, we develop an adversarial
training algorithm that learns to create adversarial examples and at the same
time optimizes the forecasting model to improve its robustness against such
adversarial simulation. Extensive experiments on real-world datasets confirm
that our attack schemes are powerful and our defense algorithms are more
effective compared with baseline defense mechanisms.",http://arxiv.org/pdf/2207.09572v3,cs.LG
2022-07-17 12:54:10+00:00,Task-aware Similarity Learning for Event-triggered Time Series,"['Shaoyu Dou', 'Kai Yang', 'Yang Jiao', 'Chengbo Qiu', 'Kui Ren']","Time series analysis has achieved great success in diverse applications such
as network security, environmental monitoring, and medical informatics.
Learning similarities among different time series is a crucial problem since it
serves as the foundation for downstream analysis such as clustering and anomaly
detection. It often remains unclear what kind of distance metric is suitable
for similarity learning due to the complex temporal dynamics of the time series
generated from event-triggered sensing, which is common in diverse
applications, including automated driving, interactive healthcare, and smart
home automation. The overarching goal of this paper is to develop an
unsupervised learning framework that is capable of learning task-aware
similarities among unlabeled event-triggered time series. From the machine
learning vantage point, the proposed framework harnesses the power of both
hierarchical multi-scale sequence autoencoders and Gaussian Mixture Model (GMM)
to effectively learn the low-dimensional representations from the time series.
Finally, the obtained similarity measure can be easily visualized for
explaining. The proposed framework aspires to offer a stepping stone that gives
rise to a systematic approach to model and learn similarities among a multitude
of event-triggered time series. Through extensive qualitative and quantitative
experiments, it is revealed that the proposed method outperforms
state-of-the-art methods considerably.",http://arxiv.org/pdf/2207.08159v1,cs.LG
2022-07-16 10:35:14+00:00,Transfer learning for time series classification using synthetic data generation,"['Yarden Rotem', 'Nathaniel Shimoni', 'Lior Rokach', 'Bracha Shapira']","In this paper, we propose an innovative Transfer learning for Time series
classification method. Instead of using an existing dataset from the UCR
archive as the source dataset, we generated a 15,000,000 synthetic univariate
time series dataset that was created using our unique synthetic time series
generator algorithm which can generate data with diverse patterns and angles
and different sequence lengths. Furthermore, instead of using classification
tasks provided by the UCR archive as the source task as previous studies did,we
used our own 55 regression tasks as the source tasks, which produced better
results than selecting classification tasks from the UCR archive",http://arxiv.org/pdf/2207.07897v1,cs.LG
2022-07-16 04:05:15+00:00,Generalizable Memory-driven Transformer for Multivariate Long Sequence Time-series Forecasting,"['Xiaoyun Zhao', 'Rui Liu', 'Mingjie Li', 'Guangsi Shi', 'Mingfei Han', 'Changlin Li', 'Ling Chen', 'Xiaojun Chang']","Multivariate long sequence time-series forecasting (M-LSTF) is a practical
but challenging problem. Unlike traditional timer-series forecasting tasks,
M-LSTF tasks are more challenging from two aspects: 1) M-LSTF models need to
learn time-series patterns both within and between multiple time features; 2)
Under the rolling forecasting setting, the similarity between two consecutive
training samples increases with the increasing prediction length, which makes
models more prone to overfitting. In this paper, we propose a generalizable
memory-driven Transformer to target M-LSTF problems. Specifically, we first
propose a global-level memory component to drive the forecasting procedure by
integrating multiple time-series features. In addition, we adopt a progressive
fashion to train our model to increase its generalizability, in which we
gradually introduce Bernoulli noises to training samples. Extensive experiments
have been performed on five different datasets across multiple fields.
Experimental results demonstrate that our approach can be seamlessly plugged
into varying Transformer-based models to improve their performances up to
roughly 30%. Particularly, this is the first work to specifically focus on the
M-LSTF tasks to the best of our knowledge.",http://arxiv.org/pdf/2207.07827v3,cs.LG
2022-07-15 10:49:07+00:00,Data Segmentation for Time Series Based on a General Moving Sum Approach,"['Claudia Kirch', 'Kerstin Reckruehm']","In this paper we propose new methodology for the data segmentation, also
known as multiple change point problem, in a general framework including
classic mean change scenarios, changes in linear regression but also changes in
the time series structure such as in the parameters of Poisson-autoregressive
time series. In particular, we derive a general theory based on estimating
equations proving consistency for the number of change points as well as rates
of convergence for the estimators of the locations of the change points. More
precisely, two different types of MOSUM (moving sum) statistics are considered:
A MOSUM-Wald statistic based on differences of local estimators and a
MOSUM-score statistic based on a global estimator. The latter is usually
computationally less involved in particular in non-linear problems where no
closed form of the estimator is known such that numerical methods are required.
Finally, we evaluate the methodology by means of simulated data as well as
using some geophysical well-log data.",http://arxiv.org/pdf/2207.07396v1,stat.ME
2022-07-14 07:15:06+00:00,Rethinking Attention Mechanism in Time Series Classification,"['Bowen Zhao', 'Huanlai Xing', 'Xinhan Wang', 'Fuhong Song', 'Zhiwen Xiao']","Attention-based models have been widely used in many areas, such as computer
vision and natural language processing. However, relevant applications in time
series classification (TSC) have not been explored deeply yet, causing a
significant number of TSC algorithms still suffer from general problems of
attention mechanism, like quadratic complexity. In this paper, we promote the
efficiency and performance of the attention mechanism by proposing our flexible
multi-head linear attention (FMLA), which enhances locality awareness by
layer-wise interactions with deformable convolutional blocks and online
knowledge distillation. What's more, we propose a simple but effective mask
mechanism that helps reduce the noise influence in time series and decrease the
redundancy of the proposed FMLA by masking some positions of each given series
proportionally. To stabilize this mechanism, samples are forwarded through the
model with random mask layers several times and their outputs are aggregated to
teach the same model with regular mask layers. We conduct extensive experiments
on 85 UCR2018 datasets to compare our algorithm with 11 well-known ones and the
results show that our algorithm has comparable performance in terms of top-1
accuracy. We also compare our model with three Transformer-based models with
respect to the floating-point operations per second and number of parameters
and find that our algorithm achieves significantly better efficiency with lower
complexity.",http://arxiv.org/pdf/2207.07564v1,cs.LG
2022-07-13 08:43:05+00:00,Learning Deep Time-index Models for Time Series Forecasting,"['Gerald Woo', 'Chenghao Liu', 'Doyen Sahoo', 'Akshat Kumar', 'Steven Hoi']","Deep learning has been actively applied to time series forecasting, leading
to a deluge of new methods, belonging to the class of historical-value models.
Yet, despite the attractive properties of time-index models, such as being able
to model the continuous nature of underlying time series dynamics, little
attention has been given to them. Indeed, while naive deep time-index models
are far more expressive than the manually predefined function representations
of classical time-index models, they are inadequate for forecasting, being
unable to generalize to unseen time steps due to the lack of inductive bias. In
this paper, we propose DeepTime, a meta-optimization framework to learn deep
time-index models which overcome these limitations, yielding an efficient and
accurate forecasting model. Extensive experiments on real world datasets in the
long sequence time-series forecasting setting demonstrate that our approach
achieves competitive results with state-of-the-art methods, and is highly
efficient. Code is available at https://github.com/salesforce/DeepTime.",http://arxiv.org/pdf/2207.06046v4,cs.LG
2022-07-12 19:41:58+00:00,Functional Spherical Autocorrelation: A Robust Estimate of the Autocorrelation of a Functional Time Series,"['Chi-Kuang Yeh', 'Gregory Rice', 'Joel A. Dubin']","We propose a new autocorrelation measure for functional time series that we
term spherical autocorrelation. It is based on measuring the average angle
between lagged pairs of series after having been projected onto the unit
sphere. This new measure enjoys several complimentary advantages compared to
existing autocorrelation measures for functional data, since it both 1)
describes a notion of sign or direction of serial dependence in the series, and
2) is more robust to outliers. The asymptotic properties of estimators of the
spherical autocorrelation are established, and are used to construct confidence
intervals and portmanteau white noise tests. These confidence intervals and
tests are shown to be effective in simulation experiments, and demonstrated in
applications to model selection for daily electricity price curves, and
measuring the volatility in densely observed asset price data.",http://arxiv.org/pdf/2207.05806v1,stat.ME
2022-07-12 17:30:02+00:00,Improved Batching Strategy For Irregular Time-Series ODE,"['Ting Fung Lam', 'Yony Bresler', 'Ahmed Khorshid', 'Nathan Perlmutter']","Irregular time series data are prevalent in the real world and are
challenging to model with a simple recurrent neural network (RNN). Hence, a
model that combines the use of ordinary differential equations (ODE) and RNN
was proposed (ODE-RNN) to model irregular time series with higher accuracy, but
it suffers from high computational costs. In this paper, we propose an
improvement in the runtime on ODE-RNNs by using a different efficient batching
strategy. Our experiments show that the new models reduce the runtime of
ODE-RNN significantly ranging from 2 times up to 49 times depending on the
irregularity of the data while maintaining comparable accuracy. Hence, our
model can scale favorably for modeling larger irregular data sets.",http://arxiv.org/pdf/2207.05708v1,cs.LG
2022-07-12 14:10:01+00:00,Markovian Gaussian Process Variational Autoencoders,"['Harrison Zhu', 'Carles Balsells Rodas', 'Yingzhen Li']","Sequential VAEs have been successfully considered for many high-dimensional
time series modelling problems, with many variant models relying on
discrete-time mechanisms such as recurrent neural networks (RNNs). On the other
hand, continuous-time methods have recently gained attraction, especially in
the context of irregularly-sampled time series, where they can better handle
the data than discrete-time methods. One such class are Gaussian process
variational autoencoders (GPVAEs), where the VAE prior is set as a Gaussian
process (GP). However, a major limitation of GPVAEs is that it inherits the
cubic computational cost as GPs, making it unattractive to practioners. In this
work, we leverage the equivalent discrete state space representation of
Markovian GPs to enable linear time GPVAE training via Kalman filtering and
smoothing. For our model, Markovian GPVAE (MGPVAE), we show on a variety of
high-dimensional temporal and spatiotemporal tasks that our method performs
favourably compared to existing approaches whilst being computationally highly
scalable.",http://arxiv.org/pdf/2207.05543v3,cs.LG
2022-07-12 10:18:36+00:00,Wasserstein multivariate auto-regressive models for modeling distributional time series and its application in graph learning,['Yiye Jiang'],"We propose a new auto-regressive model for the statistical analysis of
multivariate distributional time series. The data of interest consist of a
collection of multiple series of probability measures supported over a bounded
interval of the real line, and that are indexed by distinct time instants. The
probability measures are modelled as random objects in the Wasserstein space.
We establish the auto-regressive model in the tangent space at the Lebesgue
measure by first centering all the raw measures so that their Fr\'echet means
turn to be the Lebesgue measure. Using the theory of iterated random function
systems, results on the existence, uniqueness and stationarity of the solution
of such a model are provided. We also propose a consistent estimator for the
model coefficient. In addition to the analysis of simulated data, the proposed
model is illustrated with two real data sets made of observations from age
distribution in different countries and bike sharing network in Paris. Finally,
due to the positive and boundedness constraints that we impose on the model
coefficients, the proposed estimator that is learned under these constraints,
naturally has a sparse structure. The sparsity allows furthermore the
application of the proposed model in learning a graph of temporal dependency
from the multivariate distributional time series.",http://arxiv.org/pdf/2207.05442v2,stat.ML
2022-07-12 08:58:44+00:00,Dateformer: Time-modeling Transformer for Longer-term Series Forecasting,"['Julong Young', 'Junhui Chen', 'Feihu Huang', 'Jian Peng']","Transformers have demonstrated impressive strength in long-term series
forecasting.
  Existing prediction research mostly focused on mapping past short sub-series
(lookback window) to future series (forecast window). The longer training
dataset time series will be discarded, once training is completed. Models can
merely rely on lookback window information for inference, which impedes models
from analyzing time series from a global perspective. And these windows used by
Transformers are quite narrow because they must model each time-step therein.
Under this point-wise processing style, broadening windows will rapidly exhaust
their model capacity. This, for fine-grained time series, leads to a bottleneck
in information input and prediction output, which is mortal to long-term series
forecasting. To overcome the barrier, we propose a brand-new methodology to
utilize Transformer for time series forecasting. Specifically, we split time
series into patches by day and reform point-wise to patch-wise processing,
which considerably enhances the information input and output of Transformers.
To further help models leverage the whole training set's global information
during inference, we distill the information, store it in time representations,
and replace series with time representations as the main modeling entities. Our
designed time-modeling Transformer -- Dateformer yields state-of-the-art
accuracy on 7 real-world datasets with a 33.6\% relative improvement and
extends the maximum forecast range to half-year.",http://arxiv.org/pdf/2207.05397v2,cs.LG
2022-07-10 02:48:34+00:00,Domain Adaptation Under Behavioral and Temporal Shifts for Natural Time Series Mobile Activity Recognition,"['Garrett Wilson', 'Janardhan Rao Doppa', 'Diane J. Cook']","Increasingly, human behavior is captured on mobile devices, leading to an
increased interest in automated human activity recognition. However, existing
datasets typically consist of scripted movements. Our long-term goal is to
perform mobile activity recognition in natural settings. We collect a dataset
to support this goal with activity categories that are relevant for downstream
tasks such as health monitoring and intervention. Because of the large
variations present in human behavior, we collect data from many participants
across two different age groups. Because human behavior can change over time,
we also collect data from participants over a month's time to capture the
temporal drift. We hypothesize that mobile activity recognition can benefit
from unsupervised domain adaptation algorithms. To address this need and test
this hypothesis, we analyze the performance of domain adaptation across people
and across time. We then enhance unsupervised domain adaptation with
contrastive learning and with weak supervision when label proportions are
available. The dataset is available at
https://github.com/WSU-CASAS/smartwatch-data",http://arxiv.org/pdf/2207.04367v1,cs.LG
2022-07-09 17:23:00+00:00,Dynamic Time Warping based Adversarial Framework for Time-Series Domain,"['Taha Belkhouja', 'Yan Yan', 'Janardhan Rao Doppa']","Despite the rapid progress on research in adversarial robustness of deep
neural networks (DNNs), there is little principled work for the time-series
domain. Since time-series data arises in diverse applications including mobile
health, finance, and smart grid, it is important to verify and improve the
robustness of DNNs for the time-series domain. In this paper, we propose a
novel framework for the time-series domain referred as {\em Dynamic Time
Warping for Adversarial Robustness (DTW-AR)} using the dynamic time warping
measure. Theoretical and empirical evidence is provided to demonstrate the
effectiveness of DTW over the standard Euclidean distance metric employed in
prior methods for the image domain. We develop a principled algorithm justified
by theoretical analysis to efficiently create diverse adversarial examples
using random alignment paths. Experiments on diverse real-world benchmarks show
the effectiveness of DTW-AR to fool DNNs for time-series data and to improve
their robustness using adversarial training. The source code of DTW-AR
algorithms is available at https://github.com/tahabelkhouja/DTW-AR",http://arxiv.org/pdf/2207.04308v2,cs.LG
2022-07-09 17:22:34+00:00,Adversarial Framework with Certified Robustness for Time-Series Domain via Statistical Features,"['Taha Belkhouja', 'Janardhan Rao Doppa']","Time-series data arises in many real-world applications (e.g., mobile health)
and deep neural networks (DNNs) have shown great success in solving them.
Despite their success, little is known about their robustness to adversarial
attacks. In this paper, we propose a novel adversarial framework referred to as
Time-Series Attacks via STATistical Features (TSA-STAT)}. To address the unique
challenges of time-series domain, TSA-STAT employs constraints on statistical
features of the time-series data to construct adversarial examples. Optimized
polynomial transformations are used to create attacks that are more effective
(in terms of successfully fooling DNNs) than those based on additive
perturbations. We also provide certified bounds on the norm of the statistical
features for constructing adversarial examples. Our experiments on diverse
real-world benchmark datasets show the effectiveness of TSA-STAT in fooling
DNNs for time-series domain and in improving their robustness. The source code
of TSA-STAT algorithms is available at
https://github.com/tahabelkhouja/Time-Series-Attacks-via-STATistical-Features",http://arxiv.org/pdf/2207.04307v1,cs.LG
2022-07-09 17:21:21+00:00,Out-of-Distribution Detection in Time-Series Domain: A Novel Seasonal Ratio Scoring Approach,"['Taha Belkhouja', 'Yan Yan', 'Janardhan Rao Doppa']","Safe deployment of time-series classifiers for real-world applications relies
on the ability to detect the data which is not generated from the same
distribution as training data. This task is referred to as out-of-distribution
(OOD) detection. We consider the novel problem of OOD detection for the
time-series domain. We discuss the unique challenges posed by time-series data
and explain why prior methods from the image domain will perform poorly.
Motivated by these challenges, this paper proposes a novel {\em Seasonal Ratio
Scoring (SRS)} approach. SRS consists of three key algorithmic steps. First,
each input is decomposed into class-wise semantic component and remainder.
Second, this decomposition is employed to estimate the class-wise conditional
likelihoods of the input and remainder using deep generative models. The
seasonal ratio score is computed from these estimates. Third, a threshold
interval is identified from the in-distribution data to detect OOD examples.
Experiments on diverse real-world benchmarks demonstrate that the SRS method is
well-suited for time-series OOD detection when compared to baseline methods.
Open-source code for SRS method is provided at
https://github.com/tahabelkhouja/SRS",http://arxiv.org/pdf/2207.04306v3,cs.LG
2022-07-09 17:21:03+00:00,Training Robust Deep Models for Time-Series Domain: Novel Algorithms and Theoretical Analysis,"['Taha Belkhouja', 'Yan Yan', 'Janardhan Rao Doppa']","Despite the success of deep neural networks (DNNs) for real-world
applications over time-series data such as mobile health, little is known about
how to train robust DNNs for time-series domain due to its unique
characteristics compared to images and text data. In this paper, we propose a
novel algorithmic framework referred as RObust Training for Time-Series (RO-TS)
to create robust DNNs for time-series classification tasks. Specifically, we
formulate a min-max optimization problem over the model parameters by
explicitly reasoning about the robustness criteria in terms of additive
perturbations to time-series inputs measured by the global alignment kernel
(GAK) based distance. We also show the generality and advantages of our
formulation using the summation structure over time-series alignments by
relating both GAK and dynamic time warping (DTW). This problem is an instance
of a family of compositional min-max optimization problems, which are
challenging and open with unclear theoretical guarantee. We propose a
principled stochastic compositional alternating gradient descent ascent
(SCAGDA) algorithm for this family of optimization problems. Unlike traditional
methods for time-series that require approximate computation of distance
measures, SCAGDA approximates the GAK based distance on-the-fly using a moving
average approach. We theoretically analyze the convergence rate of SCAGDA and
provide strong theoretical support for the estimation of GAK based distance.
Our experiments on real-world benchmarks demonstrate that RO-TS creates more
robust DNNs when compared to adversarial training using prior methods that rely
on data augmentation or new definitions of loss functions. We also demonstrate
the importance of GAK for time-series data over the Euclidean distance. The
source code of RO-TS algorithms is available at
https://github.com/tahabelkhouja/Robust-Training-for-Time-Series",http://arxiv.org/pdf/2207.04305v2,cs.LG
2022-07-08 14:46:47+00:00,Causal Discovery using Model Invariance through Knockoff Interventions,"['Wasim Ahmad', 'Maha Shadaydeh', 'Joachim Denzler']","Cause-effect analysis is crucial to understand the underlying mechanism of a
system. We propose to exploit model invariance through interventions on the
predictors to infer causality in nonlinear multivariate systems of time series.
We model nonlinear interactions in time series using DeepAR and then expose the
model to different environments using Knockoffs-based interventions to test
model invariance. Knockoff samples are pairwise exchangeable, in-distribution
and statistically null variables generated without knowing the response. We
test model invariance where we show that the distribution of the response
residual does not change significantly upon interventions on non-causal
predictors. We evaluate our method on real and synthetically generated time
series. Overall our method outperforms other widely used causality methods,
i.e, VAR Granger causality, VARLiNGAM and PCMCI+.",http://arxiv.org/pdf/2207.04055v1,cs.LG
2022-07-08 14:33:16+00:00,Memory-free Online Change-point Detection: A Novel Neural Network Approach,"['Zahra Atashgahi', 'Decebal Constantin Mocanu', 'Raymond Veldhuis', 'Mykola Pechenizkiy']","Change-point detection (CPD), which detects abrupt changes in the data
distribution, is recognized as one of the most significant tasks in time series
analysis. Despite the extensive literature on offline CPD, unsupervised online
CPD still suffers from major challenges, including scalability, hyperparameter
tuning, and learning constraints. To mitigate some of these challenges, in this
paper, we propose a novel deep learning approach for unsupervised online CPD
from multi-dimensional time series, named Adaptive LSTM-Autoencoder
Change-Point Detection (ALACPD). ALACPD exploits an LSTM-autoencoder-based
neural network to perform unsupervised online CPD. It continuously adapts to
the incoming samples without keeping the previously received input, thus being
memory-free. We perform an extensive evaluation on several real-world time
series CPD benchmarks. We show that ALACPD, on average, ranks first among
state-of-the-art CPD algorithms in terms of quality of the time series
segmentation, and it is on par with the best performer in terms of the accuracy
of the estimated change-points. The implementation of ALACPD is available
online on Github\footnote{\url{https://github.com/zahraatashgahi/ALACPD}}.",http://arxiv.org/pdf/2207.03932v1,cs.LG
2022-07-08 07:15:13+00:00,Convolutional Neural Networks for Time-dependent Classification of Variable-length Time Series,"['Azusa Sawada', 'Taiki Miyagawa', 'Akinori F. Ebihara', 'Shoji Yachida', 'Toshinori Hosoi']","Time series data are often obtained only within a limited time range due to
interruptions during observation process. To classify such partial time series,
we need to account for 1) the variable-length data drawn from 2) different
timestamps. To address the first problem, existing convolutional neural
networks use global pooling after convolutional layers to cancel the length
differences. This architecture suffers from the trade-off between incorporating
entire temporal correlations in long data and avoiding feature collapse for
short data. To resolve this tradeoff, we propose Adaptive Multi-scale Pooling,
which aggregates features from an adaptive number of layers, i.e., only the
first few layers for short data and more layers for long data. Furthermore, to
address the second problem, we introduce Temporal Encoding, which embeds the
observation timestamps into the intermediate features. Experiments on our
private dataset and the UCR/UEA time series archive show that our modules
improve classification accuracy especially on short data obtained as partial
time series.",http://arxiv.org/pdf/2207.03718v2,cs.LG
2022-07-07 06:59:38+00:00,Semi-unsupervised Learning for Time Series Classification,"['Padraig Davidson', 'Michael Steininger', 'André Huhn', 'Anna Krause', 'Andreas Hotho']","Time series are ubiquitous and therefore inherently hard to analyze and
ultimately to label or cluster. With the rise of the Internet of Things (IoT)
and its smart devices, data is collected in large amounts any given second. The
collected data is rich in information, as one can detect accidents (e.g. cars)
in real time, or assess injury/sickness over a given time span (e.g. health
devices). Due to its chaotic nature and massive amounts of datapoints,
timeseries are hard to label manually. Furthermore new classes within the data
could emerge over time (contrary to e.g. handwritten digits), which would
require relabeling the data. In this paper we present SuSL4TS, a deep
generative Gaussian mixture model for semi-unsupervised learning, to classify
time series data. With our approach we can alleviate manual labeling steps,
since we can detect sparsely labeled classes (semi-supervised) and identify
emerging classes hidden in the data (unsupervised). We demonstrate the efficacy
of our approach with established time series classification datasets from
different domains.",http://arxiv.org/pdf/2207.03119v3,cs.LG
2022-07-06 18:09:50+00:00,Don't overfit the history -- Recursive time series data augmentation,"['Amine Mohamed Aboussalah', 'Min-Jae Kwon', 'Raj G Patel', 'Cheng Chi', 'Chi-Guhn Lee']","Time series observations can be seen as realizations of an underlying
dynamical system governed by rules that we typically do not know. For time
series learning tasks, we need to understand that we fit our model on available
data, which is a unique realized history. Training on a single realization
often induces severe overfitting lacking generalization. To address this issue,
we introduce a general recursive framework for time series augmentation, which
we call Recursive Interpolation Method, denoted as RIM. New samples are
generated using a recursive interpolation function of all previous values in
such a way that the enhanced samples preserve the original inherent time series
dynamics. We perform theoretical analysis to characterize the proposed RIM and
to guarantee its test performance. We apply RIM to diverse real world time
series cases to achieve strong performance over non-augmented data on
regression, classification, and reinforcement learning tasks.",http://arxiv.org/pdf/2207.02891v3,cs.LG
2022-07-06 09:58:58+00:00,Adaptive deep learning for nonlinear time series models,"['Daisuke Kurisu', 'Riku Fukami', 'Yuta Koike']","In this paper, we develop a general theory for adaptive nonparametric
estimation of the mean function of a non-stationary and nonlinear time series
model using deep neural networks (DNNs). We first consider two types of DNN
estimators, non-penalized and sparse-penalized DNN estimators, and establish
their generalization error bounds for general non-stationary time series. We
then derive minimax lower bounds for estimating mean functions belonging to a
wide class of nonlinear autoregressive (AR) models that include nonlinear
generalized additive AR, single index, and threshold AR models. Building upon
the results, we show that the sparse-penalized DNN estimator is adaptive and
attains the minimax optimal rates up to a poly-logarithmic factor for many
nonlinear AR models. Through numerical simulations, we demonstrate the
usefulness of the DNN methods for estimating nonlinear AR models with intrinsic
low-dimensional structures and discontinuous or rough mean functions, which is
consistent with our theory.",http://arxiv.org/pdf/2207.02546v2,math.ST
2022-07-04 16:41:23+00:00,The martingale Z-test,['Kenneth D. Harris'],"We describe a statistical test for association of two autocorrelated time
series, one of which generated randomly at each time point from a known but
possibly history-dependent distribution. The null hypothesis is that at each
time point, the two variables are independent, conditional on history until
that time point. We define a test statistic that is a martingale under the null
hypothesis and describe an asymptotic test for it based on the martingale
central limit theorem. If we reject this null hypothesis, we may infer an
immediate causal effect of the randomized variable on the measured variable.",http://arxiv.org/pdf/2207.02893v1,stat.ME
2022-07-04 15:08:06+00:00,Deep Contrastive One-Class Time Series Anomaly Detection,"['Rui Wang', 'Chongwei Liu', 'Xudong Mou', 'Kai Gao', 'Xiaohui Guo', 'Pin Liu', 'Tianyu Wo', 'Xudong Liu']","The accumulation of time-series data and the absence of labels make
time-series Anomaly Detection (AD) a self-supervised deep learning task.
Single-normality-assumption-based methods, which reveal only a certain aspect
of the whole normality, are incapable of tasks involved with a large number of
anomalies. Specifically, Contrastive Learning (CL) methods distance negative
pairs, many of which consist of both normal samples, thus reducing the AD
performance. Existing multi-normality-assumption-based methods are usually
two-staged, firstly pre-training through certain tasks whose target may differ
from AD, limiting their performance. To overcome the shortcomings, a deep
Contrastive One-Class Anomaly detection method of time series (COCA) is
proposed by authors, following the normality assumptions of CL and one-class
classification. It treats the original and reconstructed representations as the
positive pair of negative-sample-free CL, namely ""sequence contrast"". Next,
invariance terms and variance terms compose a contrastive one-class loss
function in which the loss of the assumptions is optimized by invariance terms
simultaneously and the ""hypersphere collapse"" is prevented by variance terms.
In addition, extensive experiments on two real-world time-series datasets show
the superior performance of the proposed method achieves state-of-the-art.",http://arxiv.org/pdf/2207.01472v3,cs.LG
2022-07-03 12:16:54+00:00,Comparative Analysis of Time Series Forecasting Approaches for Household Electricity Consumption Prediction,"['Muhammad Bilal', 'Hyeok Kim', 'Muhammad Fayaz', 'Pravin Pawar']","As a result of increasing population and globalization, the demand for energy
has greatly risen. Therefore, accurate energy consumption forecasting has
become an essential prerequisite for government planning, reducing power
wastage and stable operation of the energy management system. In this work we
present a comparative analysis of major machine learning models for time series
forecasting of household energy consumption. Specifically, we use Weka, a data
mining tool to first apply models on hourly and daily household energy
consumption datasets available from Kaggle data science community. The models
applied are: Multilayer Perceptron, K Nearest Neighbor regression, Support
Vector Regression, Linear Regression, and Gaussian Processes. Secondly, we also
implemented time series forecasting models, ARIMA and VAR, in python to
forecast household energy consumption of selected South Korean households with
and without weather data. Our results show that the best methods for the
forecasting of energy consumption prediction are Support Vector Regression
followed by Multilayer Perceptron and Gaussian Process Regression.",http://arxiv.org/pdf/2207.01019v1,cs.LG
2022-07-02 06:14:11+00:00,Scheduling Planting Time Through Developing an Optimization Model and Analysis of Time Series Growing Degree Units,"['Javad Ansarifar', 'Faezeh Akhavizadegan', 'Lizhi Wang']","Producing higher-quality crops within shortened breeding cycles ensures
global food availability and security, but this improvement intensifies
logistical and productivity challenges for seed industries in the year-round
breeding process due to the storage limitations. In the 2021 Syngenta crop
challenge in analytics, Syngenta raised the problem to design an optimization
model for the planting time scheduling in the 2020 year-round breeding process
so that there is a consistent harvest quantity each week. They released a
dataset that contained 2569 seed populations with their planting windows,
required growing degree units for harvesting, and their harvest quantities at
two sites. To address this challenge, we developed a new framework that
consists of a weather time series model and an optimization model to schedule
the planting time. A deep recurrent neural network was designed to predict the
weather into the future, and a Gaussian process model on top of the time-series
model was developed to model the uncertainty of forecasted weather. The
proposed optimization models also scheduled the seed population's planting time
at the fewest number of weeks with a more consistent weekly harvest quantity.
Using the proposed optimization models can decrease the required capacity by
69% at site 0 and up to 51% at site 1 compared to the original planting time.",http://arxiv.org/pdf/2207.00745v1,cs.LG
2022-06-30 18:16:11+00:00,K-ARMA Models for Clustering Time Series Data,"['Derek O. Hoare', 'David S. Matteson', 'Martin T. Wells']","We present an approach to clustering time series data using a model-based
generalization of the K-Means algorithm which we call K-Models. We prove the
convergence of this general algorithm and relate it to the hard-EM algorithm
for mixture modeling. We then apply our method first with an AR($p$) clustering
example and show how the clustering algorithm can be made robust to outliers
using a least-absolute deviations criteria. We then build our clustering
algorithm up for ARMA($p,q$) models and extend this to ARIMA($p,d,q$) models.
We develop a goodness of fit statistic for the models fitted to clusters based
on the Ljung-Box statistic. We perform experiments with simulated data to show
how the algorithm can be used for outlier detection, detecting distributional
drift, and discuss the impact of initialization method on empty clusters. We
also perform experiments on real data which show that our method is competitive
with other existing methods for similar time series clustering tasks.",http://arxiv.org/pdf/2207.00039v1,stat.ME
2022-06-30 06:00:13+00:00,A Causal Approach to Detecting Multivariate Time-series Anomalies and Root Causes,"['Wenzhuo Yang', 'Kun Zhang', 'Steven C. H. Hoi']","Detecting anomalies and the corresponding root causes in multivariate time
series plays an important role in monitoring the behaviors of various
real-world systems, e.g., IT system operations or manufacturing industry.
Previous anomaly detection approaches model the joint distribution without
considering the underlying mechanism of multivariate time series, making them
computationally hungry and hard to identify root causes. In this paper, we
formulate the anomaly detection problem from a causal perspective and view
anomalies as instances that do not follow the regular causal mechanism to
generate the multivariate data. We then propose a causality-based framework for
detecting anomalies and root causes. It first learns the causal structure from
data and then infers whether an instance is an anomaly relative to the local
causal mechanism whose conditional distribution can be directly estimated from
data. In light of the modularity property of causal systems (the causal
processes to generate different variables are irrelevant modules), the original
problem is divided into a series of separate, simpler, and low-dimensional
anomaly detection problems so that where an anomaly happens (root causes) can
be directly identified. We evaluate our approach with both simulated and public
datasets as well as a case study on real-world AIOps applications, showing its
efficacy, robustness, and practical feasibility.",http://arxiv.org/pdf/2206.15033v2,cs.LG
2022-06-29 10:31:36+00:00,Imaging the time series of one single referenced EEG electrode for Epileptic Seizures Risk Analysis,"['Tiago Leal', 'Antonio Dourado', 'Fabio Lopes', 'Cesar Teixeira']","The time series captured by a single scalp electrode (plus the reference
electrode) of refractory epileptic patients is used to forecast seizures
susceptibility. The time series is preprocessed, segmented, and each segment
transformed into an image, using three different known methods: Recurrence
Plot, Gramian Angular Field, Markov Transition Field. The likelihood of the
occurrence of a seizure in a future predefined time window is computed by
averaging the output of the softmax layer of a CNN, differently from the usual
consideration of the output of the classification layer. By thresholding this
likelihood, seizure forecasting has better performance. Interestingly, for
almost every patient, the best threshold was different from 50%. The results
show that this technique can predict with good results for some seizures and
patients. However, more tests, namely more patients and more seizures, are
needed to better understand the real potential of this technique.",http://arxiv.org/pdf/2206.14520v1,cs.LG
2022-06-29 00:56:32+00:00,State space model multiple imputation for missing data in non-stationary multivariate time series with application in digital Psychiatry,"['Xiaoxuan Cai', 'Xinru Wang', 'Li Zeng', 'Habiballah Rahimi Eichi', 'Dost Ongur', 'Lisa Dixon', 'Justin T. Baker', 'Jukka-Pekka Onnela', 'Linda Valeri']","Mobile technology enables unprecedented continuous monitoring of an
individual's behavior, social interactions, symptoms, and other health
conditions, presenting an enormous opportunity for therapeutic advancements and
scientific discoveries regarding the etiology of psychiatric illness.
Continuous collection of mobile data results in the generation of a new type of
data: entangled multivariate time series of outcome, exposure, and covariates.
Missing data is a pervasive problem in biomedical and social science research,
and the Ecological Momentary Assessment (EMA) using mobile devices in
psychiatric research is no exception. However, the complex structure of
multivariate time series introduces new challenges in handling missing data for
proper causal inference. Data imputation is commonly recommended to enhance
data utility and estimation efficiency. The majority of available imputation
methods are either designed for longitudinal data with limited follow-up times
or for stationary time series, which are incompatible with potentially
non-stationary time series. In the field of psychiatry, non-stationary data are
frequently encountered as symptoms and treatment regimens may experience
dramatic changes over time. To address missing data in possibly non-stationary
multivariate time series, we propose a novel multiple imputation strategy based
on the state space model (SSMmp) and a more computationally efficient variant
(SSMimpute). We demonstrate their advantages over other widely used missing
data strategies by evaluating their theoretical properties and empirical
performance in simulations of both stationary and non-stationary time series,
subject to various missing mechanisms. We apply the SSMimpute to investigate
the association between social network size and negative mood using a
multi-year observational smartphone study of bipolar patients, controlling for
confounding variables.",http://arxiv.org/pdf/2206.14343v2,stat.ME
2022-06-29 00:51:44+00:00,Intrinsic Anomaly Detection for Multi-Variate Time Series,"['Stephan Rabanser', 'Tim Januschowski', 'Kashif Rasul', 'Oliver Borchert', 'Richard Kurle', 'Jan Gasthaus', 'Michael Bohlke-Schneider', 'Nicolas Papernot', 'Valentin Flunkert']","We introduce a novel, practically relevant variation of the anomaly detection
problem in multi-variate time series: intrinsic anomaly detection. It appears
in diverse practical scenarios ranging from DevOps to IoT, where we want to
recognize failures of a system that operates under the influence of a
surrounding environment. Intrinsic anomalies are changes in the functional
dependency structure between time series that represent an environment and time
series that represent the internal state of a system that is placed in said
environment. We formalize this problem, provide under-studied public and new
purpose-built data sets for it, and present methods that handle intrinsic
anomaly detection. These address the short-coming of existing anomaly detection
methods that cannot differentiate between expected changes in the system's
state and unexpected ones, i.e., changes in the system that deviate from the
environment's influence. Our most promising approach is fully unsupervised and
combines adversarial learning and time series representation learning, thereby
addressing problems such as label sparsity and subjectivity, while allowing to
navigate and improve notoriously problematic anomaly detection data sets.",http://arxiv.org/pdf/2206.14342v1,cs.LG
2022-06-28 08:11:12+00:00,Learning the Evolutionary and Multi-scale Graph Structure for Multivariate Time Series Forecasting,"['Junchen Ye', 'Zihan Liu', 'Bowen Du', 'Leilei Sun', 'Weimiao Li', 'Yanjie Fu', 'Hui Xiong']","Recent studies have shown great promise in applying graph neural networks for
multivariate time series forecasting, where the interactions of time series are
described as a graph structure and the variables are represented as the graph
nodes. Along this line, existing methods usually assume that the graph
structure (or the adjacency matrix), which determines the aggregation manner of
graph neural network, is fixed either by definition or self-learning. However,
the interactions of variables can be dynamic and evolutionary in real-world
scenarios. Furthermore, the interactions of time series are quite different if
they are observed at different time scales. To equip the graph neural network
with a flexible and practical graph structure, in this paper, we investigate
how to model the evolutionary and multi-scale interactions of time series. In
particular, we first provide a hierarchical graph structure cooperated with the
dilated convolution to capture the scale-specific correlations among time
series. Then, a series of adjacency matrices are constructed under a recurrent
manner to represent the evolving correlations at each layer. Moreover, a
unified neural network is provided to integrate the components above to get the
final prediction. In this way, we can capture the pair-wise correlations and
temporal dependency simultaneously. Finally, experiments on both single-step
and multi-step forecasting tasks demonstrate the superiority of our method over
the state-of-the-art approaches.",http://arxiv.org/pdf/2206.13816v1,cs.LG
2022-06-28 01:01:34+00:00,TTS-CGAN: A Transformer Time-Series Conditional GAN for Biosignal Data Augmentation,"['Xiaomin Li', 'Anne Hee Hiong Ngu', 'Vangelis Metsis']","Signal measurement appearing in the form of time series is one of the most
common types of data used in medical machine learning applications. Such
datasets are often small in size, expensive to collect and annotate, and might
involve privacy issues, which hinders our ability to train large,
state-of-the-art deep learning models for biomedical applications. For
time-series data, the suite of data augmentation strategies we can use to
expand the size of the dataset is limited by the need to maintain the basic
properties of the signal. Generative Adversarial Networks (GANs) can be
utilized as another data augmentation tool. In this paper, we present TTS-CGAN,
a transformer-based conditional GAN model that can be trained on existing
multi-class datasets and generate class-specific synthetic time-series
sequences of arbitrary length. We elaborate on the model architecture and
design strategies. Synthetic sequences generated by our model are
indistinguishable from real ones, and can be used to complement or replace real
signals of the same type, thus achieving the goal of data augmentation. To
evaluate the quality of the generated data, we modify the wavelet coherence
metric to be able to compare the similarity between two sets of signals, and
also conduct a case study where a mix of synthetic and real data are used to
train a deep learning model for sequence classification. Together with other
visualization techniques and qualitative evaluation approaches, we demonstrate
that TTS-CGAN generated synthetic data are similar to real data, and that our
model performs better than the other state-of-the-art GAN models built for
time-series data generation.",http://arxiv.org/pdf/2206.13676v1,cs.LG
2022-06-26 13:52:43+00:00,fETSmcs: Feature-based ETS model component selection,"['Lingzhi Qi', 'Xixi Li', 'Qiang Wang', 'Suling Jia']","The well-developed ETS (ExponenTial Smoothing or Error, Trend, Seasonality)
method incorporating a family of exponential smoothing models in state space
representation has been widely used for automatic forecasting. The existing ETS
method uses information criteria for model selection by choosing an optimal
model with the smallest information criterion among all models fitted to a
given time series. The ETS method under such a model selection scheme suffers
from computational complexity when applied to large-scale time series data. To
tackle this issue, we propose an efficient approach for ETS model selection by
training classifiers on simulated data to predict appropriate model component
forms for a given time series. We provide a simulation study to show the model
selection ability of the proposed approach on simulated data. We evaluate our
approach on the widely used forecasting competition data set M4, in terms of
both point forecasts and prediction intervals. To demonstrate the practical
value of our method, we showcase the performance improvements from our approach
on a monthly hospital data set.",http://arxiv.org/pdf/2206.12882v1,stat.ME
2022-06-24 13:30:48+00:00,Bayesian Circular Lattice Filters for Computationally Efficient Estimation of Multivariate Time-Varying Autoregressive Models,"['Yuelei Sui', 'Scott H. Holan', 'Wen-Hsi Yang']","Nonstationary time series data exist in various scientific disciplines,
including environmental science, biology, signal processing, econometrics,
among others. Many Bayesian models have been developed to handle nonstationary
time series. The time-varying vector autoregressive (TV-VAR) model is a
well-established model for multivariate nonstationary time series.
Nevertheless, in most cases, the large number of parameters presented by the
model results in a high computational burden, ultimately limiting its usage.
This paper proposes a computationally efficient multivariate Bayesian Circular
Lattice Filter to extend the usage of the TV-VAR model to a broader class of
high-dimensional problems. Our fully Bayesian framework allows both the
autoregressive (AR) coefficients and innovation covariance to vary over time.
Our estimation method is based on the Bayesian lattice filter (BLF), which is
extremely computationally efficient and stable in univariate cases. To
illustrate the effectiveness of our approach, we conduct a comprehensive
comparison with other competing methods through simulation studies and find
that, in most cases, our approach performs superior in terms of average squared
error between the estimated and true time-varying spectral density. Finally, we
demonstrate our methodology through applications to quarterly Gross Domestic
Product (GDP) data and Northern California wind data.",http://arxiv.org/pdf/2206.12280v1,stat.ME
2022-06-24 06:53:11+00:00,TreeDRNet:A Robust Deep Model for Long Term Time Series Forecasting,"['Tian Zhou', 'Jianqing Zhu', 'Xue Wang', 'Ziqing Ma', 'Qingsong Wen', 'Liang Sun', 'Rong Jin']","Various deep learning models, especially some latest Transformer-based
approaches, have greatly improved the state-of-art performance for long-term
time series forecasting.However, those transformer-based models suffer a severe
deterioration performance with prolonged input length, which prohibits them
from using extended historical info.Moreover, these methods tend to handle
complex examples in long-term forecasting with increased model complexity,
which often leads to a significant increase in computation and less robustness
in performance(e.g., overfitting). We propose a novel neural network
architecture, called TreeDRNet, for more effective long-term forecasting.
Inspired by robust regression, we introduce doubly residual link structure to
make prediction more robust.Built upon Kolmogorov-Arnold representation
theorem, we explicitly introduce feature selection, model ensemble, and a tree
structure to further utilize the extended input sequence, which improves the
robustness and representation power of TreeDRNet. Unlike previous deep models
for sequential forecasting work, TreeDRNet is built entirely on multilayer
perceptron and thus enjoys high computational efficiency. Our extensive
empirical studies show that TreeDRNet is significantly more effective than
state-of-the-art methods, reducing prediction errors by 20% to 40% for
multivariate time series. In particular, TreeDRNet is over 10 times more
efficient than transformer-based methods. The code will be released soon.",http://arxiv.org/pdf/2206.12106v1,cs.LG
2022-06-23 07:56:27+00:00,Utilizing Expert Features for Contrastive Learning of Time-Series Representations,"['Manuel Nonnenmacher', 'Lukas Oldenburg', 'Ingo Steinwart', 'David Reeb']","We present an approach that incorporates expert knowledge for time-series
representation learning. Our method employs expert features to replace the
commonly used data transformations in previous contrastive learning approaches.
We do this since time-series data frequently stems from the industrial or
medical field where expert features are often available from domain experts,
while transformations are generally elusive for time-series data. We start by
proposing two properties that useful time-series representations should fulfill
and show that current representation learning approaches do not ensure these
properties. We therefore devise ExpCLR, a novel contrastive learning approach
built on an objective that utilizes expert features to encourage both
properties for the learned representation. Finally, we demonstrate on three
real-world time-series datasets that ExpCLR surpasses several state-of-the-art
methods for both unsupervised and semi-supervised representation learning.",http://arxiv.org/pdf/2206.11517v1,cs.LG
2022-06-20 09:17:35+00:00,The Generalized Method of Wavelet Moments with Exogenous Inputs: a Fast Approach for the Analysis of GNSS Position Time Series,"['Davide A. Cucci', 'Lionel Voirol', 'Gaël Kermarrec', 'Jean-Philippe Montillet', 'Stéphane Guerrier']","The Global Navigation Satellite System (GNSS) daily position time series are
often described as the sum of stochastic processes and geophysical signals
which allow studying global and local geodynamical effects such as plate
tectonics, earthquakes, or ground water variations. In this work we propose to
extend the Generalized Method of Wavelet Moments (GMWM) to estimate the
parameters of linear models with correlated residuals. This statistical
inferential framework is applied to GNSS daily position time series data to
jointly estimate functional (geophysical) as well as stochastic noise models.
Our method is called GMWMX, with X standing for eXogeneous variable: it is
semi-parametric, computationally efficient and scalable. Unlike standard
methods such as the widely used Maximum Likelihood Estimator (MLE), our
methodology offers statistical guarantees, such as consistency and asymptotic
normality, without relying on strong parametric assumptions. At the Gaussian
model, our results show that the estimated parameters are similar to the ones
obtained with the MLE. The computational performances of our approach has
important practical implications. Indeed, the estimation of the parameters of
large networks of thousands of GNSS stations quickly becomes computationally
prohibitive. Compared to standard methods, the processing time of the GMWMX is
over $1000$ times faster and allows the estimation of large scale problems
within minutes on a standard computer. We validate the performances of our
method via Monte-Carlo simulations by generating GNSS daily position time
series with missing observations and we consider composite stochastic noise
models including processes presenting long-range dependence such as power-law
or Mat\'ern processes. The advantages of our method are also illustrated using
real time series from GNSS stations located in the Eastern part of the USA.",http://arxiv.org/pdf/2206.09668v1,stat.ME
2022-06-19 20:17:15+00:00,Traffic-Twitter Transformer: A Nature Language Processing-joined Framework For Network-wide Traffic Forecasting,"['Meng-Ju Tsai', 'Zhiyong Cui', 'Hao Yang', 'Cole Kopca', 'Sophie Tien', 'Yinhai Wang']","With accurate and timely traffic forecasting, the impacted traffic conditions
can be predicted in advance to guide agencies and residents to respond to
changes in traffic patterns appropriately. However, existing works on traffic
forecasting mainly relied on historical traffic patterns confining to
short-term prediction, under 1 hour, for instance. To better manage future
roadway capacity and accommodate social and human impacts, it is crucial to
propose a flexible and comprehensive framework to predict physical-aware
long-term traffic conditions for public users and transportation agencies. In
this paper, the gap of robust long-term traffic forecasting was bridged by
taking social media features into consideration. A correlation study and a
linear regression model were first implemented to evaluate the significance of
the correlation between two time-series data, traffic intensity and Twitter
data intensity. Two time-series data were then fed into our proposed
social-aware framework, Traffic-Twitter Transformer, which integrated Nature
Language representations into time-series records for long-term traffic
prediction. Experimental results in the Great Seattle Area showed that our
proposed model outperformed baseline models in all evaluation matrices. This
NLP-joined social-aware framework can become a valuable implement of
network-wide traffic prediction and management for traffic agencies.",http://arxiv.org/pdf/2206.11078v3,cs.LG
2022-06-18 19:57:46+00:00,Scalable Classifier-Agnostic Channel Selection for Multivariate Time Series Classification,"['Bhaskar Dhariyal', 'Thach Le Nguyen', 'Georgiana Ifrim']","Accuracy is a key focus of current work in time series classification.
However, speed and data reduction in many applications is equally important,
especially when the data scale and storage requirements increase rapidly.
Current MTSC algorithms need hundreds of compute hours to complete training and
prediction. This is due to the nature of multivariate time series data, which
grows with the number of time series, their length and the number of channels.
In many applications, not all the channels are useful for the classification
task; hence we require methods that can efficiently select useful channels and
thus save computational resources. We propose and evaluate two methods for
channel selection. Our techniques work by representing each class by a
prototype time series and performing channel selection based on the prototype
distance between classes. The main hypothesis is that useful channels enable
better separation between classes; hence, channels with the higher distance
between class prototypes are more useful. On the UEA Multivariate Time Series
Classification (MTSC) benchmark, we show that these techniques achieve
significant data reduction and classifier speedup for similar levels of
classification accuracy. Channel selection is applied as a pre-processing step
before training state-of-the-art MTSC algorithms and saves about 70\% of
computation time and data storage, with preserved accuracy. Furthermore, our
methods enable even efficient classifiers, such as ROCKET, to achieve better
accuracy than using no channel selection or forward channel selection. To
further study the impact of our techniques, we present experiments on
classifying synthetic multivariate time series datasets with more than 100
channels, as well as a real-world case study on a dataset with 50 channels. Our
channel selection methods lead to significant data reduction with preserved or
improved accuracy.",http://arxiv.org/pdf/2206.09274v2,cs.LG
2022-06-18 04:24:36+00:00,Pre-training Enhanced Spatial-temporal Graph Neural Network for Multivariate Time Series Forecasting,"['Zezhi Shao', 'Zhao Zhang', 'Fei Wang', 'Yongjun Xu']","Multivariate Time Series (MTS) forecasting plays a vital role in a wide range
of applications. Recently, Spatial-Temporal Graph Neural Networks (STGNNs) have
become increasingly popular MTS forecasting methods. STGNNs jointly model the
spatial and temporal patterns of MTS through graph neural networks and
sequential models, significantly improving the prediction accuracy. But limited
by model complexity, most STGNNs only consider short-term historical MTS data,
such as data over the past one hour. However, the patterns of time series and
the dependencies between them (i.e., the temporal and spatial patterns) need to
be analyzed based on long-term historical MTS data. To address this issue, we
propose a novel framework, in which STGNN is Enhanced by a scalable time series
Pre-training model (STEP). Specifically, we design a pre-training model to
efficiently learn temporal patterns from very long-term history time series
(e.g., the past two weeks) and generate segment-level representations. These
representations provide contextual information for short-term time series input
to STGNNs and facilitate modeling dependencies between time series. Experiments
on three public real-world datasets demonstrate that our framework is capable
of significantly enhancing downstream STGNNs, and our pre-training model aptly
captures temporal patterns.",http://arxiv.org/pdf/2206.09113v2,cs.LG
2022-06-16 12:02:12+00:00,Closed-Form Diffeomorphic Transformations for Time Series Alignment,"['Iñigo Martinez', 'Elisabeth Viles', 'Igor G. Olaizola']","Time series alignment methods call for highly expressive, differentiable and
invertible warping functions which preserve temporal topology, i.e
diffeomorphisms. Diffeomorphic warping functions can be generated from the
integration of velocity fields governed by an ordinary differential equation
(ODE). Gradient-based optimization frameworks containing diffeomorphic
transformations require to calculate derivatives to the differential equation's
solution with respect to the model parameters, i.e. sensitivity analysis.
Unfortunately, deep learning frameworks typically lack
automatic-differentiation-compatible sensitivity analysis methods; and implicit
functions, such as the solution of ODE, require particular care. Current
solutions appeal to adjoint sensitivity methods, ad-hoc numerical solvers or
ResNet's Eulerian discretization. In this work, we present a closed-form
expression for the ODE solution and its gradient under continuous
piecewise-affine (CPA) velocity functions. We present a highly optimized
implementation of the results on CPU and GPU. Furthermore, we conduct extensive
experiments on several datasets to validate the generalization ability of our
model to unseen data for time-series joint alignment. Results show significant
improvements both in terms of efficiency and accuracy.",http://arxiv.org/pdf/2206.08107v1,cs.LG
2022-06-16 07:34:14+00:00,Cyclocopula Technique to Study the Relationship Between Two Cyclostationary Time Series with Fractional Brownian Motion Errors,"['Mohammadreza Mahmoudi', 'Amir Mosavi']","Detection of the relationship between two time series is so important in
environmental and hydrological studies. Several parametric and non-parametric
approaches can be applied to detect relationships. These techniques are usually
sensitive to stationarity assumptions. In this research, a new copula-based
method is introduced to detect the relationship between two cylostationary time
series with fractional Brownian motion (fBm) errors. The numerical studies
verify the performance of the introduced approach.",http://arxiv.org/pdf/2206.07976v1,stat.ME
2022-06-16 06:13:53+00:00,When Rigidity Hurts: Soft Consistency Regularization for Probabilistic Hierarchical Time Series Forecasting,"['Harshavardhan Kamarthi', 'Lingkai Kong', 'Alexander Rodríguez', 'Chao Zhang', 'B. Aditya Prakash']","Probabilistic hierarchical time-series forecasting is an important variant of
time-series forecasting, where the goal is to model and forecast multivariate
time-series that have underlying hierarchical relations. Most methods focus on
point predictions and do not provide well-calibrated probabilistic forecasts
distributions. Recent state-of-art probabilistic forecasting methods also
impose hierarchical relations on point predictions and samples of distribution
which does not account for coherency of forecast distributions. Previous works
also silently assume that datasets are always consistent with given
hierarchical relations and do not adapt to real-world datasets that show
deviation from this assumption. We close both these gap and propose PROFHiT,
which is a fully probabilistic hierarchical forecasting model that jointly
models forecast distribution of entire hierarchy. PROFHiT uses a flexible
probabilistic Bayesian approach and introduces a novel Distributional Coherency
regularization to learn from hierarchical relations for entire forecast
distribution that enables robust and calibrated forecasts as well as adapt to
datasets of varying hierarchical consistency. On evaluating PROFHiT over wide
range of datasets, we observed 41-88% better performance in accuracy and
significantly better calibration. Due to modeling the coherency over full
distribution, we observed that PROFHiT can robustly provide reliable forecasts
even if up to 10% of input time-series data is missing where other methods'
performance severely degrade by over 70%.",http://arxiv.org/pdf/2206.07940v4,cs.LG
2022-06-13 15:23:31+00:00,Contrastive Learning for Unsupervised Domain Adaptation of Time Series,"['Yilmazcan Ozyurt', 'Stefan Feuerriegel', 'Ce Zhang']","Unsupervised domain adaptation (UDA) aims at learning a machine learning
model using a labeled source domain that performs well on a similar yet
different, unlabeled target domain. UDA is important in many applications such
as medicine, where it is used to adapt risk scores across different patient
cohorts. In this paper, we develop a novel framework for UDA of time series
data, called CLUDA. Specifically, we propose a contrastive learning framework
to learn contextual representations in multivariate time series, so that these
preserve label information for the prediction task. In our framework, we
further capture the variation in the contextual representations between source
and target domain via a custom nearest-neighbor contrastive learning. To the
best of our knowledge, ours is the first framework to learn domain-invariant,
contextual representation for UDA of time series data. We evaluate our
framework using a wide range of time series datasets to demonstrate its
effectiveness and show that it achieves state-of-the-art performance for time
series UDA.",http://arxiv.org/pdf/2206.06243v4,cs.LG
2022-06-11 10:34:29+00:00,DRAformer: Differentially Reconstructed Attention Transformer for Time-Series Forecasting,"['Benhan Li', 'Shengdong Du', 'Tianrui Li', 'Jie Hu', 'Zhen Jia']","Time-series forecasting plays an important role in many real-world scenarios,
such as equipment life cycle forecasting, weather forecasting, and traffic flow
forecasting. It can be observed from recent research that a variety of
transformer-based models have shown remarkable results in time-series
forecasting. However, there are still some issues that limit the ability of
transformer-based models on time-series forecasting tasks: (i) learning
directly on raw data is susceptible to noise due to its complex and unstable
feature representation; (ii) the self-attention mechanisms pay insufficient
attention to changing features and temporal dependencies. In order to solve
these two problems, we propose a transformer-based differentially reconstructed
attention model DRAformer. Specifically, DRAformer has the following
innovations: (i) learning against differenced sequences, which preserves clear
and stable sequence features by differencing and highlights the changing
properties of sequences; (ii) the reconstructed attention: integrated distance
attention exhibits sequential distance through a learnable Gaussian kernel,
distributed difference attention calculates distribution difference by mapping
the difference sequence to the adaptive feature space, and the combination of
the two effectively focuses on the sequences with prominent associations; (iii)
the reconstructed decoder input, which extracts sequence features by
integrating variation information and temporal correlations, thereby obtaining
a more comprehensive sequence representation. Extensive experiments on four
large-scale datasets demonstrate that DRAformer outperforms state-of-the-art
baselines.",http://arxiv.org/pdf/2206.05495v1,cs.LG
2022-06-10 23:15:32+00:00,Modeling Multivariate Positive-Valued Time Series Using R-INLA,"['Chiranjit Dutta', 'Nalini Ravishanker', 'Sumanta Basu']","In this paper we describe fast Bayesian statistical analysis of vector
positive-valued time series, with application to interesting financial data
streams. We discuss a flexible level correlated model (LCM) framework for
building hierarchical models for vector positive-valued time series. The LCM
allows us to combine marginal gamma distributions for the positive-valued
component responses, while accounting for association among the components at a
latent level. We use integrated nested Laplace approximation (INLA) for fast
approximate Bayesian modeling via the R-INLA package, building custom functions
to handle this setup. We use the proposed method to model interdependencies
between realized volatility measures from several stock indexes.",http://arxiv.org/pdf/2206.05374v2,stat.ME
2022-06-08 17:54:26+00:00,Scaleformer: Iterative Multi-scale Refining Transformers for Time Series Forecasting,"['Amin Shabani', 'Amir Abdi', 'Lili Meng', 'Tristan Sylvain']","The performance of time series forecasting has recently been greatly improved
by the introduction of transformers. In this paper, we propose a general
multi-scale framework that can be applied to the state-of-the-art
transformer-based time series forecasting models (FEDformer, Autoformer, etc.).
By iteratively refining a forecasted time series at multiple scales with shared
weights, introducing architecture adaptations, and a specially-designed
normalization scheme, we are able to achieve significant performance
improvements, from 5.5% to 38.5% across datasets and transformer architectures,
with minimal additional computational overhead. Via detailed ablation studies,
we demonstrate the effectiveness of each of our contributions across the
architecture and methodology. Furthermore, our experiments on various public
datasets demonstrate that the proposed improvements outperform their
corresponding baseline counterparts. Our code is publicly available in
https://github.com/BorealisAI/scaleformer.",http://arxiv.org/pdf/2206.04038v4,cs.LG
2022-06-08 15:44:53+00:00,Classification of Stochastic Processes with Topological Data Analysis,"['İsmail Güzel', 'Atabey Kaygun']","In this study, we examine if engineered topological features can distinguish
time series sampled from different stochastic processes with different noise
characteristics, in both balanced and unbalanced sampling schemes. We compare
our classification results against the results of the same classification tasks
built on statistical and raw features. We conclude that in classification tasks
of time series, different machine learning models built on engineered
topological features perform consistently better than those built on standard
statistical and raw features.",http://arxiv.org/pdf/2206.03973v1,stat.ML
2022-06-07 13:49:40+00:00,On the balance between the training time and interpretability of neural ODE for time series modelling,"['Yakov Golovanev', 'Alexander Hvatov']","Most machine learning methods are used as a black box for modelling. We may
try to extract some knowledge from physics-based training methods, such as
neural ODE (ordinary differential equation). Neural ODE has advantages like a
possibly higher class of represented functions, the extended interpretability
compared to black-box machine learning models, ability to describe both trend
and local behaviour. Such advantages are especially critical for time series
with complicated trends. However, the known drawback is the high training time
compared to the autoregressive models and long-short term memory (LSTM)
networks widely used for data-driven time series modelling. Therefore, we
should be able to balance interpretability and training time to apply neural
ODE in practice. The paper shows that modern neural ODE cannot be reduced to
simpler models for time-series modelling applications. The complexity of neural
ODE is compared to or exceeds the conventional time-series modelling tools. The
only interpretation that could be extracted is the eigenspace of the operator,
which is an ill-posed problem for a large system. Spectra could be extracted
using different classical analysis methods that do not have the drawback of
extended time. Consequently, we reduce the neural ODE to a simpler linear form
and propose a new view on time-series modelling using combined neural networks
and an ODE system approach.",http://arxiv.org/pdf/2206.03304v1,cs.LG
2022-06-07 00:49:16+00:00,Robust Time Series Dissimilarity Measure for Outlier Detection and Periodicity Detection,"['Xiaomin Song', 'Qingsong Wen', 'Yan Li', 'Liang Sun']","Dynamic time warping (DTW) is an effective dissimilarity measure in many time
series applications. Despite its popularity, it is prone to noises and
outliers, which leads to singularity problem and bias in the measurement. The
time complexity of DTW is quadratic to the length of time series, making it
inapplicable in real-time applications. In this paper, we propose a novel time
series dissimilarity measure named RobustDTW to reduce the effects of noises
and outliers. Specifically, the RobustDTW estimates the trend and optimizes the
time warp in an alternating manner by utilizing our designed temporal graph
trend filtering. To improve efficiency, we propose a multi-level framework that
estimates the trend and the warp function at a lower resolution, and then
repeatedly refines them at a higher resolution. Based on the proposed
RobustDTW, we further extend it to periodicity detection and outlier time
series detection. Experiments on real-world datasets demonstrate the superior
performance of RobustDTW compared to DTW variants in both outlier time series
detection and periodicity detection.",http://arxiv.org/pdf/2206.02956v1,cs.LG
2022-06-05 19:51:51+00:00,Frequency Domain Statistical Inference for High-Dimensional Time Series,"['Jonas Krampe', 'Efstathios Paparoditis']","Analyzing time series in the frequency domain enables the development of
powerful tools for investigating the second-order characteristics of
multivariate processes. Parameters like the spectral density matrix and its
inverse, the coherence or the partial coherence, encode comprehensively the
complex linear relations between the component processes of the multivariate
system. In this paper, we develop inference procedures for such parameters in a
high-dimensional, time series setup. Towards this goal, we first focus on the
derivation of consistent estimators of the coherence and, more importantly, of
the partial coherence which possess manageable limiting distributions that are
suitable for testing purposes. Statistical tests of the hypothesis that the
maximum over frequencies of the coherence, respectively, of the partial
coherence, do not exceed a prespecified threshold value are developed. Our
approach allows for testing hypotheses for individual coherences and/or partial
coherences as well as for multiple testing of large sets of such parameters. In
the latter case, a consistent procedure to control the false discovery rate is
developed. The finite sample performance of the inference procedures introduced
is investigated by means of simulations and applications to the construction of
graphical interaction models for brain connectivity based on EEG data are
presented.",http://arxiv.org/pdf/2206.02250v2,stat.ME
2022-06-05 04:45:57+00:00,Using Connectome Features to Constrain Echo State Networks,"['Jacob Morra', 'Mark Daley']","We report an improvement to the conventional Echo State Network (ESN) across
three benchmark chaotic time-series prediction tasks using fruit fly connectome
data alone. We also investigate the impact of key connectome-derived structural
features on prediction performance -- uniquely bridging neurobiological
structure and machine learning function; and find that both increasing the
global average clustering coefficient and modifying the position of weights --
by permuting their synapse-synapse partners -- can lead to increased model
variance and (in some cases) degraded performance. In all we consider four
topological point modifications to a connectome-derived ESN reservoir (null
model): namely, we alter the network sparsity, re-draw nonzero weights from a
uniform distribution, permute nonzero weight positions, and increase the
network global average clustering coefficient. We compare the four resulting
ESN model classes -- and the null model -- with a conventional ESN by
conducting time-series prediction experiments on size-variants of the
Mackey-Glass 17 (MG-17), Lorenz, and Rossler chaotic time series; denoting each
model's performance and variance across train-validate trials.",http://arxiv.org/pdf/2206.02094v2,cs.LG
2022-06-04 13:03:35+00:00,Geodesic Properties of a Generalized Wasserstein Embedding for Time Series Analysis,"['Shiying Li', 'Abu Hasnat Mohammad Rubaiyat', 'Gustavo K. Rohde']","Transport-based metrics and related embeddings (transforms) have recently
been used to model signal classes where nonlinear structures or variations are
present. In this paper, we study the geodesic properties of time series data
with a generalized Wasserstein metric and the geometry related to their signed
cumulative distribution transforms in the embedding space. Moreover, we show
how understanding such geometric characteristics can provide added
interpretability to certain time series classifiers, and be an inspiration for
more robust classifiers.",http://arxiv.org/pdf/2206.01984v2,cs.LG
2022-06-03 12:10:48+00:00,Constraints on parameter choices for successful reservoir computing,"['L. Storm', 'K. Gustavsson', 'B. Mehlig']","Echo-state networks are simple models of discrete dynamical systems driven by
a time series. By selecting network parameters such that the dynamics of the
network is contractive, characterized by a negative maximal Lyapunov exponent,
the network may synchronize with the driving signal. Exploiting this
synchronization, the echo-state network may be trained to autonomously
reproduce the input dynamics, enabling time-series prediction. However, while
synchronization is a necessary condition for prediction, it is not sufficient.
Here, we study what other conditions are necessary for successful time-series
prediction. We identify two key parameters for prediction performance, and
conduct a parameter sweep to find regions where prediction is successful. These
regions differ significantly depending on whether full or partial phase space
information about the input is provided to the network during training. We
explain how these regions emerge.",http://arxiv.org/pdf/2206.02575v1,cs.LG
2022-06-02 08:47:06+00:00,Generating Sparse Counterfactual Explanations For Multivariate Time Series,"['Jana Lang', 'Martin Giese', 'Winfried Ilg', 'Sebastian Otte']","Since neural networks play an increasingly important role in critical
sectors, explaining network predictions has become a key research topic.
Counterfactual explanations can help to understand why classifier models decide
for particular class assignments and, moreover, how the respective input
samples would have to be modified such that the class prediction changes.
Previous approaches mainly focus on image and tabular data. In this work we
propose SPARCE, a generative adversarial network (GAN) architecture that
generates SPARse Counterfactual Explanations for multivariate time series. Our
approach provides a custom sparsity layer and regularizes the counterfactual
loss function in terms of similarity, sparsity, and smoothness of trajectories.
We evaluate our approach on real-world human motion datasets as well as a
synthetic time series interpretability benchmark. Although we make
significantly sparser modifications than other approaches, we achieve
comparable or better performance on all metrics. Moreover, we demonstrate that
our approach predominantly modifies salient time steps and features, leaving
non-salient inputs untouched.",http://arxiv.org/pdf/2206.00931v2,cs.LG
2022-06-01 20:17:11+00:00,SolarGAN: Synthetic Annual Solar Irradiance Time Series on Urban Building Facades via Deep Generative Networks,"['Yufei Zhang', 'Arno Schlüter', 'Christoph Waibel']","Building Integrated Photovoltaics (BIPV) is a promising technology to
decarbonize urban energy systems via harnessing solar energy available on
building envelopes. While methods to assess solar irradiation, especially on
rooftops, are well established, the assessment on building facades usually
involves a higher effort due to more complex urban features and obstructions.
The drawback of existing physics-based simulation programs is that they require
significant manual modelling effort and computing time for generating time
resolved deterministic results. Yet, solar irradiation is highly intermittent
and representing its inherent uncertainty may be required for designing robust
BIPV energy systems. Targeting on these drawbacks, this paper proposes a
data-driven model based on Deep Generative Networks (DGN) to efficiently
generate high-fidelity stochastic ensembles of annual hourly solar irradiance
time series on building facades with uncompromised spatiotemporal resolution at
the urban scale. The only input required is easily obtainable, simple fisheye
images as categorical shading masks captured from 3D models. In principle, even
actual photographs of urban contexts can be utilized, given they are
semantically segmented. Our validations exemplify the high fidelity of the
generated time series when compared to the physics-based simulator. To
demonstrate the model's relevance for urban energy planning, we showcase its
potential for generative design by parametrically altering characteristic
features of the urban environment and producing corresponding time series on
building facades under different climatic contexts in real-time.",http://arxiv.org/pdf/2206.00747v2,cs.LG
2022-05-31 15:43:46+00:00,VQ-AR: Vector Quantized Autoregressive Probabilistic Time Series Forecasting,"['Kashif Rasul', 'Young-Jin Park', 'Max Nihlén Ramström', 'Kyung-Min Kim']","Time series models aim for accurate predictions of the future given the past,
where the forecasts are used for important downstream tasks like business
decision making. In practice, deep learning based time series models come in
many forms, but at a high level learn some continuous representation of the
past and use it to output point or probabilistic forecasts. In this paper, we
introduce a novel autoregressive architecture, VQ-AR, which instead learns a
\emph{discrete} set of representations that are used to predict the future.
Extensive empirical comparison with other competitive deep learning models
shows that surprisingly such a discrete set of representations gives
state-of-the-art or equivalent results on a wide variety of time series
datasets. We also highlight the shortcomings of this approach, explore its
zero-shot generalization capabilities, and present an ablation study on the
number of representations. The full source code of the method will be available
at the time of publication with the hope that researchers can further
investigate this important but overlooked inductive bias for the time series
domain.",http://arxiv.org/pdf/2205.15894v1,cs.LG
2022-05-31 15:21:21+00:00,SOM-CPC: Unsupervised Contrastive Learning with Self-Organizing Maps for Structured Representations of High-Rate Time Series,"['Iris A. M. Huijben', 'Arthur A. Nijdam', 'Sebastiaan Overeem', 'Merel M. van Gilst', 'Ruud J. G. van Sloun']","Continuous monitoring with an ever-increasing number of sensors has become
ubiquitous across many application domains. However, acquired time series are
typically high-dimensional and difficult to interpret. Expressive deep learning
(DL) models have gained popularity for dimensionality reduction, but the
resulting latent space often remains difficult to interpret. In this work we
propose SOM-CPC, a model that visualizes data in an organized 2D manifold,
while preserving higher-dimensional information. We address a largely
unexplored and challenging set of scenarios comprising high-rate time series,
and show on both synthetic and real-life data (physiological data and audio
recordings) that SOM-CPC outperforms strong baselines like DL-based feature
extraction, followed by conventional dimensionality reduction techniques, and
models that jointly optimize a DL model and a Self-Organizing Map (SOM).
SOM-CPC has great potential to acquire a better understanding of latent
patterns in high-rate data streams.",http://arxiv.org/pdf/2205.15875v2,cs.LG
2022-05-31 05:41:58+00:00,Robust Projection based Anomaly Extraction (RPE) in Univariate Time-Series,"['Mostafa Rahmani', 'Anoop Deoras', 'Laurent Callot']","This paper presents a novel, closed-form, and data/computation efficient
online anomaly detection algorithm for time-series data. The proposed method,
dubbed RPE, is a window-based method and in sharp contrast to the existing
window-based methods, it is robust to the presence of anomalies in its window
and it can distinguish the anomalies in time-stamp level. RPE leverages the
linear structure of the trajectory matrix of the time-series and employs a
robust projection step which makes the algorithm able to handle the presence of
multiple arbitrarily large anomalies in its window. A closed-form/non-iterative
algorithm for the robust projection step is provided and it is proved that it
can identify the corrupted time-stamps. RPE is a great candidate for the
applications where a large training data is not available which is the common
scenario in the area of time-series. An extensive set of numerical experiments
show that RPE can outperform the existing approaches with a notable margin.",http://arxiv.org/pdf/2205.15548v1,stat.ML
2022-05-30 15:32:55+00:00,A Review and Evaluation of Elastic Distance Functions for Time Series Clustering,"['Chris Holder', 'Matthew Middlehurst', 'Anthony Bagnall']","Time series clustering is the act of grouping time series data without
recourse to a label. Algorithms that cluster time series can be classified into
two groups: those that employ a time series specific distance measure; and
those that derive features from time series. Both approaches usually rely on
traditional clustering algorithms such as $k$-means. Our focus is on distance
based time series that employ elastic distance measures, i.e. distances that
perform some kind of realignment whilst measuring distance. We describe nine
commonly used elastic distance measures and compare their performance with
k-means and k-medoids clustering. Our findings are surprising. The most popular
technique, dynamic time warping (DTW), performs worse than Euclidean distance
with k-means, and even when tuned, is no better. Using k-medoids rather than
k-means improved the clusterings for all nine distance measures. DTW is not
significantly better than Euclidean distance with k-medoids. Generally,
distance measures that employ editing in conjunction with warping perform
better, and one distance measure, the move-split-merge (MSM) method, is the
best performing measure of this study. We also compare to clustering with DTW
using barycentre averaging (DBA). We find that DBA does improve DTW k-means,
but that the standard DBA is still worse than using MSM. Our conclusion is to
recommend MSM with k-medoids as the benchmark algorithm for clustering time
series with elastic distance measures. We provide implementations in the aeon
toolkit, results and guidance on reproducing results on the associated GitHub
repository.",http://arxiv.org/pdf/2205.15181v2,cs.LG
2022-05-28 12:27:27+00:00,Non-stationary Transformers: Exploring the Stationarity in Time Series Forecasting,"['Yong Liu', 'Haixu Wu', 'Jianmin Wang', 'Mingsheng Long']","Transformers have shown great power in time series forecasting due to their
global-range modeling ability. However, their performance can degenerate
terribly on non-stationary real-world data in which the joint distribution
changes over time. Previous studies primarily adopt stationarization to
attenuate the non-stationarity of original series for better predictability.
But the stationarized series deprived of inherent non-stationarity can be less
instructive for real-world bursty events forecasting. This problem, termed
over-stationarization in this paper, leads Transformers to generate
indistinguishable temporal attentions for different series and impedes the
predictive capability of deep models. To tackle the dilemma between series
predictability and model capability, we propose Non-stationary Transformers as
a generic framework with two interdependent modules: Series Stationarization
and De-stationary Attention. Concretely, Series Stationarization unifies the
statistics of each input and converts the output with restored statistics for
better predictability. To address the over-stationarization problem,
De-stationary Attention is devised to recover the intrinsic non-stationary
information into temporal dependencies by approximating distinguishable
attentions learned from raw series. Our Non-stationary Transformers framework
consistently boosts mainstream Transformers by a large margin, which reduces
MSE by 49.43% on Transformer, 47.34% on Informer, and 46.89% on Reformer,
making them the state-of-the-art in time series forecasting. Code is available
at this repository: https://github.com/thuml/Nonstationary_Transformers.",http://arxiv.org/pdf/2205.14415v3,cs.LG
2022-05-27 17:13:05+00:00,Efficient Forecasting of Large Scale Hierarchical Time Series via Multilevel Clustering,"['Xing Han', 'Tongzheng Ren', 'Jing Hu', 'Joydeep Ghosh', 'Nhat Ho']","We propose a novel approach to the problem of clustering hierarchically
aggregated time-series data, which has remained an understudied problem though
it has several commercial applications. We first group time series at each
aggregated level, while simultaneously leveraging local and global information.
The proposed method can cluster hierarchical time series (HTS) with different
lengths and structures. For common two-level hierarchies, we employ a combined
objective for local and global clustering over spaces of discrete probability
measures, using Wasserstein distance coupled with Soft-DTW divergence. For
multi-level hierarchies, we present a bottom-up procedure that progressively
leverages lower-level information for higher-level clustering. Our final goal
is to improve both the accuracy and speed of forecasts for a larger number of
HTS needed for a real-world application. To attain this goal, each time series
is first assigned the forecast for its cluster representative, which can be
considered as a ""shrinkage prior"" for the set of time series it represents.
Then this base forecast can be quickly fine-tuned to adjust to the specifics of
that time series. We empirically show that our method substantially improves
performance in terms of both speed and accuracy for large-scale forecasting
tasks involving much HTS.",http://arxiv.org/pdf/2205.14104v1,cs.LG
2022-05-27 03:09:55+00:00,Generating multivariate time series with COmmon Source CoordInated GAN (COSCI-GAN),"['Ali Seyfi', 'Jean-Francois Rajotte', 'Raymond T. Ng']","Generating multivariate time series is a promising approach for sharing
sensitive data in many medical, financial, and IoT applications. A common type
of multivariate time series originates from a single source such as the
biometric measurements from a medical patient. This leads to complex dynamical
patterns between individual time series that are hard to learn by typical
generation models such as GANs. There is valuable information in those patterns
that machine learning models can use to better classify, predict or perform
other downstream tasks. We propose a novel framework that takes time series'
common origin into account and favors channel/feature relationships
preservation. The two key points of our method are: 1) the individual time
series are generated from a common point in latent space and 2) a central
discriminator favors the preservation of inter-channel/feature dynamics. We
demonstrate empirically that our method helps preserve channel/feature
correlations and that our synthetic data performs very well in downstream tasks
with medical and financial data.",http://arxiv.org/pdf/2205.13741v2,cs.LG
2022-05-26 16:40:48+00:00,Learning to Reconstruct Missing Data from Spatiotemporal Graphs with Sparse Observations,"['Ivan Marisca', 'Andrea Cini', 'Cesare Alippi']","Modeling multivariate time series as temporal signals over a (possibly
dynamic) graph is an effective representational framework that allows for
developing models for time series analysis. In fact, discrete sequences of
graphs can be processed by autoregressive graph neural networks to recursively
learn representations at each discrete point in time and space. Spatiotemporal
graphs are often highly sparse, with time series characterized by multiple,
concurrent, and long sequences of missing data, e.g., due to the unreliable
underlying sensor network. In this context, autoregressive models can be
brittle and exhibit unstable learning dynamics. The objective of this paper is,
then, to tackle the problem of learning effective models to reconstruct, i.e.,
impute, missing data points by conditioning the reconstruction only on the
available observations. In particular, we propose a novel class of
attention-based architectures that, given a set of highly sparse discrete
observations, learn a representation for points in time and space by exploiting
a spatiotemporal propagation architecture aligned with the imputation task.
Representations are trained end-to-end to reconstruct observations w.r.t. the
corresponding sensor and its neighboring nodes. Compared to the state of the
art, our model handles sparse data without propagating prediction errors or
requiring a bidirectional model to encode forward and backward time
dependencies. Empirical results on representative benchmarks show the
effectiveness of the proposed method.",http://arxiv.org/pdf/2205.13479v2,cs.LG
2022-05-25 18:54:25+00:00,TSEM: Temporally Weighted Spatiotemporal Explainable Neural Network for Multivariate Time Series,"['Anh-Duy Pham', 'Anastassia Kuestenmacher', 'Paul G. Ploeger']","Deep learning has become a one-size-fits-all solution for technical and
business domains thanks to its flexibility and adaptability. It is implemented
using opaque models, which unfortunately undermines the outcome
trustworthiness. In order to have a better understanding of the behavior of a
system, particularly one driven by time series, a look inside a deep learning
model so-called posthoc eXplainable Artificial Intelligence (XAI) approaches,
is important. There are two major types of XAI for time series data, namely
model-agnostic and model-specific. Model-specific approach is considered in
this work. While other approaches employ either Class Activation Mapping (CAM)
or Attention Mechanism, we merge the two strategies into a single system,
simply called the Temporally Weighted Spatiotemporal Explainable Neural Network
for Multivariate Time Series (TSEM). TSEM combines the capabilities of RNN and
CNN models in such a way that RNN hidden units are employed as attention
weights for the CNN feature maps temporal axis. The result shows that TSEM
outperforms XCM. It is similar to STAM in terms of accuracy, while also
satisfying a number of interpretability criteria, including causality,
fidelity, and spatiotemporality.",http://arxiv.org/pdf/2205.13012v2,cs.LG
2022-05-25 16:51:09+00:00,Analytics of Business Time Series Using Machine Learning and Bayesian Inference,['Bohdan M. Pavlyshenko'],"In the survey we consider the case studies on sales time series forecasting,
the deep learning approach for forecasting non-stationary time series using
time trend correction, dynamic price and supply optimization using Q-learning,
Bitcoin price modeling, COVID-19 spread impact on stock market, using social
networks signals in analytics. The use of machine learning and Bayesian
inference in predictive analytics has been analyzed.",http://arxiv.org/pdf/2205.12905v2,cs.LG
2022-05-25 13:16:18+00:00,Towards Symbolic Time Series Representation Improved by Kernel Density Estimators,"['Matej Kloska', 'Viera Rozinajova']","This paper deals with symbolic time series representation. It builds up on
the popular mapping technique Symbolic Aggregate approXimation algorithm (SAX),
which is extensively utilized in sequence classification, pattern mining,
anomaly detection, time series indexing and other data mining tasks. However,
the disadvantage of this method is, that it works reliably only for time series
with Gaussian-like distribution. In our previous work we have proposed an
improvement of SAX, called dwSAX, which can deal with Gaussian as well as
non-Gaussian data distribution. Recently we have made further progress in our
solution - edwSAX. Our goal was to optimally cover the information space by
means of sufficient alphabet utilization; and to satisfy lower bounding
criterion as tight as possible. We describe here our approach, including
evaluation on commonly employed tasks such as time series reconstruction error
and Euclidean distance lower bounding with promising improvements over SAX.",http://arxiv.org/pdf/2205.12960v1,cs.LG
2022-05-24 03:28:52+00:00,MOSPAT: AutoML based Model Selection and Parameter Tuning for Time Series Anomaly Detection,"['Sourav Chatterjee', 'Rohan Bopardikar', 'Marius Guerard', 'Uttam Thakore', 'Xiaodong Jiang']","Organizations leverage anomaly and changepoint detection algorithms to detect
changes in user behavior or service availability and performance. Many
off-the-shelf detection algorithms, though effective, cannot readily be used in
large organizations where thousands of users monitor millions of use cases and
metrics with varied time series characteristics and anomaly patterns. The
selection of algorithm and parameters needs to be precise for each use case:
manual tuning does not scale, and automated tuning requires ground truth, which
is rarely available.
  In this paper, we explore MOSPAT, an end-to-end automated machine learning
based approach for model and parameter selection, combined with a generative
model to produce labeled data. Our scalable end-to-end system allows individual
users in large organizations to tailor time-series monitoring to their specific
use case and data characteristics, without expert knowledge of anomaly
detection algorithms or laborious manual labeling. Our extensive experiments on
real and synthetic data demonstrate that this method consistently outperforms
using any single algorithm.",http://arxiv.org/pdf/2205.11755v1,cs.LG
2022-05-23 21:06:27+00:00,Forecasting of Non-Stationary Sales Time Series Using Deep Learning,['Bohdan M. Pavlyshenko'],"The paper describes the deep learning approach for forecasting non-stationary
time series with using time trend correction in a neural network model. Along
with the layers for predicting sales values, the neural network model includes
a subnetwork block for the prediction weight for a time trend term which is
added to a predicted sales value. The time trend term is considered as a
product of the predicted weight value and normalized time value. The results
show that the forecasting accuracy can be essentially improved for
non-stationary sales with time trends using the trend correction block in the
deep learning model.",http://arxiv.org/pdf/2205.11636v1,cs.LG
2022-05-23 20:13:08+00:00,Interpretable Feature Engineering for Time Series Predictors using Attention Networks,"['Tianjie Wang', 'Jie Chen', 'Joel Vaughan', 'Vijayan N. Nair']","Regression problems with time-series predictors are common in banking and
many other areas of application. In this paper, we use multi-head attention
networks to develop interpretable features and use them to achieve good
predictive performance. The customized attention layer explicitly uses
multiplicative interactions and builds feature-engineering heads that capture
temporal dynamics in a parsimonious manner. Convolutional layers are used to
combine multivariate time series. We also discuss methods for handling static
covariates in the modeling process. Visualization and explanation tools are
used to interpret the results and explain the relationship between the inputs
and the extracted features. Both simulation and real dataset are used to
illustrate the usefulness of the methodology. Keyword: Attention heads, Deep
neural networks, Interpretable feature engineering",http://arxiv.org/pdf/2205.12723v1,cs.LG
2022-05-23 10:04:21+00:00,Time-series Transformer Generative Adversarial Networks,"['Padmanaba Srinivasan', 'William J. Knottenbelt']","Many real-world tasks are plagued by limitations on data: in some instances
very little data is available and in others, data is protected by privacy
enforcing regulations (e.g. GDPR). We consider limitations posed specifically
on time-series data and present a model that can generate synthetic time-series
which can be used in place of real data. A model that generates synthetic
time-series data has two objectives: 1) to capture the stepwise conditional
distribution of real sequences, and 2) to faithfully model the joint
distribution of entire real sequences. Autoregressive models trained via
maximum likelihood estimation can be used in a system where previous
predictions are fed back in and used to predict future ones; in such models,
errors can accrue over time. Furthermore, a plausible initial value is required
making MLE based models not really generative. Many downstream tasks learn to
model conditional distributions of the time-series, hence, synthetic data drawn
from a generative model must satisfy 1) in addition to performing 2). We
present TsT-GAN, a framework that capitalises on the Transformer architecture
to satisfy the desiderata and compare its performance against five
state-of-the-art models on five datasets and show that TsT-GAN achieves higher
predictive performance on all datasets.",http://arxiv.org/pdf/2205.11164v1,cs.LG
2022-05-23 08:59:42+00:00,GraphAD: A Graph Neural Network for Entity-Wise Multivariate Time-Series Anomaly Detection,"['Xu Chen', 'Qiu Qiu', 'Changshan Li', 'Kunqing Xie']","In recent years, the emergence and development of third-party platforms have
greatly facilitated the growth of the Online to Offline (O2O) business.
However, the large amount of transaction data raises new challenges for
retailers, especially anomaly detection in operating conditions. Thus,
platforms begin to develop intelligent business assistants with embedded
anomaly detection methods to reduce the management burden on retailers.
Traditional time-series anomaly detection methods capture underlying patterns
from the perspectives of time and attributes, ignoring the difference between
retailers in this scenario. Besides, similar transaction patterns extracted by
the platforms can also provide guidance to individual retailers and enrich
their available information without privacy issues. In this paper, we pose an
entity-wise multivariate time-series anomaly detection problem that considers
the time-series of each unique entity. To address this challenge, we propose
GraphAD, a novel multivariate time-series anomaly detection model based on the
graph neural network. GraphAD decomposes the Key Performance Indicator (KPI)
into stable and volatility components and extracts their patterns in terms of
attributes, entities and temporal perspectives via graph neural networks. We
also construct a real-world entity-wise multivariate time-series dataset from
the business data of Ele.me. The experimental results on this dataset show that
GraphAD significantly outperforms existing anomaly detection methods.",http://arxiv.org/pdf/2205.11139v1,cs.LG
2022-05-22 22:44:41+00:00,Deep Direct Discriminative Decoders for High-dimensional Time-series Data Analysis,"['Mohammad R. Rezaei', 'Milos R. Popovic', 'Milad Lankarany', 'Ali Yousefi']","The state-space models (SSMs) are widely utilized in the analysis of
time-series data. SSMs rely on an explicit definition of the state and
observation processes. Characterizing these processes is not always easy and
becomes a modeling challenge when the dimension of observed data grows or the
observed data distribution deviates from the normal distribution. Here, we
propose a new formulation of SSM for high-dimensional observation processes. We
call this solution the deep direct discriminative decoder (D4). The D4 brings
deep neural networks' expressiveness and scalability to the SSM formulation
letting us build a novel solution that efficiently estimates the underlying
state processes through high-dimensional observation signal. We demonstrate the
D4 solutions in simulated and real data such as Lorenz attractors, Langevin
dynamics, random walk dynamics, and rat hippocampus spiking neural data and
show that the D4 performs better than traditional SSMs and RNNs. The D4 can be
applied to a broader class of time-series data where the connection between
high-dimensional observation and the underlying latent process is hard to
characterize.",http://arxiv.org/pdf/2205.10947v2,cs.LG
2022-05-20 15:29:29+00:00,Persistent Homology of Coarse Grained State Space Networks,"['Audun D. Myers', 'Max M. Chumley', 'Firas A. Khasawneh', 'Elizabeth Munch']","This work is dedicated to the topological analysis of complex transitional
networks for dynamic state detection. Transitional networks are formed from
time series data and they leverage graph theory tools to reveal information
about the underlying dynamic system. However, traditional tools can fail to
summarize the complex topology present in such graphs. In this work, we
leverage persistent homology from topological data analysis to study the
structure of these networks. We contrast dynamic state detection from time
series using a coarse-grained state-space network (CGSSN) and topological data
analysis (TDA) to two state of the art approaches: ordinal partition networks
(OPNs) combined with TDA and the standard application of persistent homology to
the time-delay embedding of the signal. We show that the CGSSN captures rich
information about the dynamic state of the underlying dynamical system as
evidenced by a significant improvement in dynamic state detection and noise
robustness in comparison to OPNs. We also show that because the computational
time of CGSSN is not linearly dependent on the signal's length, it is more
computationally efficient than applying TDA to the time-delay embedding of the
time series.",http://arxiv.org/pdf/2206.02530v2,stat.ML
2022-05-20 03:31:03+00:00,Conformal Prediction with Temporal Quantile Adjustments,"['Zhen Lin', 'Shubhendu Trivedi', 'Jimeng Sun']","We develop Temporal Quantile Adjustment (TQA), a general method to construct
efficient and valid prediction intervals (PIs) for regression on
cross-sectional time series data. Such data is common in many domains,
including econometrics and healthcare. A canonical example in healthcare is
predicting patient outcomes using physiological time-series data, where a
population of patients composes a cross-section. Reliable PI estimators in this
setting must address two distinct notions of coverage: cross-sectional coverage
across a cross-sectional slice, and longitudinal coverage along the temporal
dimension for each time series. Recent works have explored adapting Conformal
Prediction (CP) to obtain PIs in the time series context. However, none handles
both notions of coverage simultaneously. CP methods typically query a
pre-specified quantile from the distribution of nonconformity scores on a
calibration set. TQA adjusts the quantile to query in CP at each time $t$,
accounting for both cross-sectional and longitudinal coverage in a
theoretically-grounded manner. The post-hoc nature of TQA facilitates its use
as a general wrapper around any time series regression model. We validate TQA's
performance through extensive experimentation: TQA generally obtains efficient
PIs and improves longitudinal coverage while preserving cross-sectional
coverage.",http://arxiv.org/pdf/2205.09940v2,stat.ML
2022-05-20 02:15:14+00:00,Self-Supervised Time Series Representation Learning via Cross Reconstruction Transformer,"['Wenrui Zhang', 'Ling Yang', 'Shijia Geng', 'Shenda Hong']","Unsupervised/self-supervised representation learning in time series is
critical since labeled samples are usually scarce in real-world scenarios.
Existing approaches mainly leverage the contrastive learning framework, which
automatically learns to understand the similar and dissimilar data pairs.
Nevertheless, they are restricted to the prior knowledge of constructing pairs,
cumbersome sampling policy, and unstable performances when encountering
sampling bias. Also, few works have focused on effectively modeling across
temporal-spectral relations to extend the capacity of representations. In this
paper, we aim at learning representations for time series from a new
perspective and propose Cross Reconstruction Transformer (CRT) to solve the
aforementioned problems in a unified way. CRT achieves time series
representation learning through a cross-domain dropping-reconstruction task.
Specifically, we transform time series into the frequency domain and randomly
drop certain parts in both time and frequency domains. Dropping can maximally
preserve the global context compared to cropping and masking. Then a
transformer architecture is utilized to adequately capture the cross-domain
correlations between temporal and spectral information through reconstructing
data in both domains, which is called Dropped Temporal-Spectral Modeling. To
discriminate the representations in global latent space, we propose Instance
Discrimination Constraint to reduce the mutual information between different
time series and sharpen the decision boundaries. Additionally, we propose a
specified curriculum learning strategy to optimize the CRT, which progressively
increases the dropping ratio in the training process.",http://arxiv.org/pdf/2205.09928v2,cs.LG
2022-05-19 22:10:35+00:00,Time Series Anomaly Detection via Reinforcement Learning-Based Model Selection,"['Jiuqi Elise Zhang', 'Di Wu', 'Benoit Boulet']","Time series anomaly detection has been recognized as of critical importance
for the reliable and efficient operation of real-world systems. Many anomaly
detection methods have been developed based on various assumptions on anomaly
characteristics. However, due to the complex nature of real-world data,
different anomalies within a time series usually have diverse profiles
supporting different anomaly assumptions. This makes it difficult to find a
single anomaly detector that can consistently outperform other models. In this
work, to harness the benefits of different base models, we propose a
reinforcement learning-based model selection framework. Specifically, we first
learn a pool of different anomaly detection models, and then utilize
reinforcement learning to dynamically select a candidate model from these base
models. Experiments on real-world data have demonstrated that the proposed
strategy can indeed outplay all baseline models in terms of overall
performance.",http://arxiv.org/pdf/2205.09884v4,cs.LG
2022-05-19 14:07:54+00:00,Jacobian Granger Causal Neural Networks for Analysis of Stationary and Nonstationary Data,"['Suryadi', 'Yew-Soon Ong', 'Lock Yue Chew']","Granger causality is a commonly used method for uncovering information flow
and dependencies in a time series. Here we introduce JGC (Jacobian Granger
Causality), a neural network-based approach to Granger causality using the
Jacobian as a measure of variable importance, and propose a thresholding
procedure for inferring Granger causal variables using this measure. The
resulting approach performs consistently well compared to other approaches in
identifying Granger causal variables, the associated time lags, as well as
interaction signs. Lastly, through the inclusion of a time variable, we show
that this approach is able to learn the temporal dependencies for nonstationary
systems whose Granger causal structures change in time.",http://arxiv.org/pdf/2205.09573v1,cs.LG
2022-05-16 07:53:42+00:00,Multi-scale Attention Flow for Probabilistic Time Series Forecasting,"['Shibo Feng', 'Chunyan Miao', 'Ke Xu', 'Jiaxiang Wu', 'Pengcheng Wu', 'Yang Zhang', 'Peilin Zhao']","The probability prediction of multivariate time series is a notoriously
challenging but practical task. On the one hand, the challenge is how to
effectively capture the cross-series correlations between interacting time
series, to achieve accurate distribution modeling. On the other hand, we should
consider how to capture the contextual information within time series more
accurately to model multivariate temporal dynamics of time series. In this
work, we proposed a novel non-autoregressive deep learning model, called
Multi-scale Attention Normalizing Flow(MANF), where we integrate multi-scale
attention and relative position information and the multivariate data
distribution is represented by the conditioned normalizing flow. Additionally,
compared with autoregressive modeling methods, our model avoids the influence
of cumulative error and does not increase the time complexity. Extensive
experiments demonstrate that our model achieves state-of-the-art performance on
many popular multivariate datasets.",http://arxiv.org/pdf/2205.07493v3,cs.LG
2022-05-11 14:03:25+00:00,Efficient Automated Deep Learning for Time Series Forecasting,"['Difan Deng', 'Florian Karl', 'Frank Hutter', 'Bernd Bischl', 'Marius Lindauer']","Recent years have witnessed tremendously improved efficiency of Automated
Machine Learning (AutoML), especially Automated Deep Learning (AutoDL) systems,
but recent work focuses on tabular, image, or NLP tasks. So far, little
attention has been paid to general AutoDL frameworks for time series
forecasting, despite the enormous success in applying different novel
architectures to such tasks. In this paper, we propose an efficient approach
for the joint optimization of neural architecture and hyperparameters of the
entire data processing pipeline for time series forecasting. In contrast to
common NAS search spaces, we designed a novel neural architecture search space
covering various state-of-the-art architectures, allowing for an efficient
macro-search over different DL approaches. To efficiently search in such a
large configuration space, we use Bayesian optimization with multi-fidelity
optimization. We empirically study several different budget types enabling
efficient multi-fidelity optimization on different forecasting datasets.
Furthermore, we compared our resulting system, dubbed \system, against several
established baselines and show that it significantly outperforms all of them
across several datasets.",http://arxiv.org/pdf/2205.05511v3,cs.LG
2022-05-10 05:18:45+00:00,Real-time Forecasting of Time Series in Financial Markets Using Sequentially Trained Many-to-one LSTMs,"['Kelum Gajamannage', 'Yonggi Park']","Financial markets are highly complex and volatile; thus, learning about such
markets for the sake of making predictions is vital to make early alerts about
crashes and subsequent recoveries. People have been using learning tools from
diverse fields such as financial mathematics and machine learning in the
attempt of making trustworthy predictions on such markets. However, the
accuracy of such techniques had not been adequate until artificial neural
network (ANN) frameworks were developed. Moreover, making accurate real-time
predictions of financial time series is highly subjective to the ANN
architecture in use and the procedure of training it. Long short-term memory
(LSTM) is a member of the recurrent neural network family which has been widely
utilized for time series predictions. Especially, we train two LSTMs with a
known length, say $T$ time steps, of previous data and predict only one time
step ahead. At each iteration, while one LSTM is employed to find the best
number of epochs, the second LSTM is trained only for the best number of epochs
to make predictions. We treat the current prediction as in the training set for
the next prediction and train the same LSTM. While classic ways of training
result in more error when the predictions are made further away in the test
period, our approach is capable of maintaining a superior accuracy as training
increases when it proceeds through the testing period. The forecasting accuracy
of our approach is validated using three time series from each of the three
diverse financial markets: stock, cryptocurrency, and commodity. The results
are compared with those of an extended Kalman filter, an autoregressive model,
and an autoregressive integrated moving average model.",http://arxiv.org/pdf/2205.04678v1,cs.LG
2022-05-09 05:06:58+00:00,Deep Federated Anomaly Detection for Multivariate Time Series Data,"['Wei Zhu', 'Dongjin Song', 'Yuncong Chen', 'Wei Cheng', 'Bo Zong', 'Takehiko Mizoguchi', 'Cristian Lumezanu', 'Haifeng Chen', 'Jiebo Luo']","Despite the fact that many anomaly detection approaches have been developed
for multivariate time series data, limited effort has been made on federated
settings in which multivariate time series data are heterogeneously distributed
among different edge devices while data sharing is prohibited. In this paper,
we investigate the problem of federated unsupervised anomaly detection and
present a Federated Exemplar-based Deep Neural Network (Fed-ExDNN) to conduct
anomaly detection for multivariate time series data on different edge devices.
Specifically, we first design an Exemplar-based Deep Neural network (ExDNN) to
learn local time series representations based on their compatibility with an
exemplar module which consists of hidden parameters learned to capture
varieties of normal patterns on each edge device. Next, a constrained
clustering mechanism (FedCC) is employed on the centralized server to align and
aggregate the parameters of different local exemplar modules to obtain a
unified global exemplar module. Finally, the global exemplar module is deployed
together with a shared feature encoder to each edge device and anomaly
detection is conducted by examining the compatibility of testing data to the
exemplar module. Fed-ExDNN captures local normal time series patterns with
ExDNN and aggregates these patterns by FedCC, and thus can handle the
heterogeneous data distributed over different edge devices simultaneously.
Thoroughly empirical studies on six public datasets show that ExDNN and
Fed-ExDNN can outperform state-of-the-art anomaly detection algorithms and
federated learning techniques.",http://arxiv.org/pdf/2205.04041v1,cs.LG
2022-05-08 04:50:16+00:00,Adaptive Graph Convolutional Network Framework for Multidimensional Time Series Prediction,['Ning Wang'],"In the real world, long sequence time-series forecasting (LSTF) is needed in
many cases, such as power consumption prediction and air quality
prediction.Multi-dimensional long time series model has more strict
requirements on the model, which not only needs to effectively capture the
accurate long-term dependence between input and output, but also needs to
capture the relationship between data of different dimensions.Recent research
shows that the Informer model based on Transformer has achieved excellent
performance in long time series prediction.However, this model still has some
deficiencies in multidimensional prediction,it cannot capture the relationship
between different dimensions well. We improved Informer to address its
shortcomings in multidimensional forecasting. First,we introduce an adaptive
graph neural network to capture hidden dimension dependencies in mostly time
series prediction. Secondly,we integrate adaptive graph convolutional networks
into various spatio-temporal series prediction models to solve the defect that
they cannot capture the relationship between different dimensions.
Thirdly,After experimental testing with multiple data sets, the accuracy of our
framework improved by about 10\% after being introduced into the model.",http://arxiv.org/pdf/2205.04885v1,cs.LG
2022-05-07 05:06:36+00:00,Time-Series Domain Adaptation via Sparse Associative Structure Alignment: Learning Invariance and Variance,"['Zijian Li', 'Ruichu Cai', 'Jiawei Chen', 'Yuguan Yan', 'Wei Chen', 'Keli Zhang', 'Junjian Ye']","Domain adaptation on time-series data is often encountered in the industry
but received limited attention in academia. Most of the existing domain
adaptation methods for time-series data borrow the ideas from the existing
methods for non-time series data to extract the domain-invariant
representation. However, two peculiar difficulties to time-series data have not
been solved. 1) It is not a trivial task to model the domain-invariant and
complex dependence among different timestamps. 2) The domain-variant
information is important but how to leverage them is almost underexploited.
Fortunately, the stableness of causal structures among different domains
inspires us to explore the structures behind the time-series data. Based on
this inspiration, we investigate the domain-invariant unweighted sparse
associative structures and the domain-variant strengths of the structures. To
achieve this, we propose Sparse Associative structure alignment by learning
Invariance and Variance (SASA-IV in short), a model that simultaneously aligns
the invariant unweighted spare associative structures and considers the variant
information for time-series unsupervised domain adaptation. Technologically, we
extract the domain-invariant unweighted sparse associative structures with a
unidirectional alignment restriction and embed the domain-variant strengths via
a well-designed autoregressive module. Experimental results not only testify
that our model yields state-of-the-art performance on three real-world datasets
but also provide some insightful discoveries on knowledge transfer.",http://arxiv.org/pdf/2205.03554v1,cs.LG
2022-05-05 14:28:38+00:00,LPC-AD: Fast and Accurate Multivariate Time Series Anomaly Detection via Latent Predictive Coding,"['Zhi Qi', 'Hong Xie', 'Ye Li', 'Jian Tan', 'FeiFei Li', 'John C. S. Lui']","This paper proposes LPC-AD, a fast and accurate multivariate time series
(MTS) anomaly detection method. LPC-AD is motivated by the ever-increasing
needs for fast and accurate MTS anomaly detection methods to support fast
troubleshooting in cloud computing, micro-service systems, etc. LPC-AD is fast
in the sense that its reduces the training time by as high as 38.2% compared to
the state-of-the-art (SOTA) deep learning methods that focus on training speed.
LPC-AD is accurate in the sense that it improves the detection accuracy by as
high as 18.9% compared to SOTA sophisticated deep learning methods that focus
on enhancing detection accuracy. Methodologically, LPC-AD contributes a generic
architecture LPC-Reconstruct for one to attain different trade-offs between
training speed and detection accuracy. More specifically, LPC-Reconstruct is
built on ideas from autoencoder for reducing redundancy in time series, latent
predictive coding for capturing temporal dependence in MTS, and randomized
perturbation for avoiding overfitting of anomalous dependence in the training
data. We present simple instantiations of LPC-Reconstruct to attain fast
training speed, where we propose a simple randomized perturbation method. The
superior performance of LPC-AD over SOTA methods is validated by extensive
experiments on four large real-world datasets. Experiment results also show the
necessity and benefit of each component of the LPC-Reconstruct architecture and
that LPC-AD is robust to hyper parameters.",http://arxiv.org/pdf/2205.08362v1,cs.LG
2022-05-05 05:01:55+00:00,DeepExtrema: A Deep Learning Approach for Forecasting Block Maxima in Time Series Data,"['Asadullah Hill Galib', 'Andrew McDonald', 'Tyler Wilson', 'Lifeng Luo', 'Pang-Ning Tan']","Accurate forecasting of extreme values in time series is critical due to the
significant impact of extreme events on human and natural systems. This paper
presents DeepExtrema, a novel framework that combines a deep neural network
(DNN) with generalized extreme value (GEV) distribution to forecast the block
maximum value of a time series. Implementing such a network is a challenge as
the framework must preserve the inter-dependent constraints among the GEV model
parameters even when the DNN is initialized. We describe our approach to
address this challenge and present an architecture that enables both
conditional mean and quantile prediction of the block maxima. The extensive
experiments performed on both real-world and synthetic data demonstrated the
superiority of DeepExtrema compared to other baseline methods.",http://arxiv.org/pdf/2205.02441v1,cs.LG
2022-05-04 20:13:59+00:00,GRU-TV: Time- and velocity-aware GRU for patient representation on multivariate clinical time-series data,"['Ningtao Liu', 'Ruoxi Gao', 'Jing Yuan', 'Calire Park', 'Shuwei Xing', 'Shuiping Gou']","Electronic health records (EHRs) are usually highly dimensional,
heterogeneous, and multimodal. Besides, the random recording of clinical
variables results in high missing rates and uneven time intervals between
adjacent records in the multivariate clinical time-series data extracted from
EHRs. Current works using clinical time-series data for patient representation
regard the patients' physiological status as a discrete process described by
sporadically collected records. However, changes in the patient's physiological
condition are continuous and dynamic processes. The perception of time and
velocity of change is crucial for patient representation learning. In this
study, we propose a time- and velocity-aware gated recurrent unit model
(GRU-TV) for patient representation learning of clinical multivariate
time-series data in a time-continuous manner. The neural ordinary differential
equations (ODEs) and velocity perception mechanism are applied to perceive the
time interval between adjacent records and changing rate of the patient's
physiological status, respectively. Our experiments on two real clinical EHR
datasets (PhysioNet2012, MIMIC-III) establish that GRU-TV is a robust model on
computer-aided diagnosis (CAD) tasks, especially on sequences with
high-variance time intervals.",http://arxiv.org/pdf/2205.04892v2,cs.LG
2022-05-04 14:55:42+00:00,MAD: Self-Supervised Masked Anomaly Detection Task for Multivariate Time Series,"['Yiwei Fu', 'Feng Xue']","In this paper, we introduce Masked Anomaly Detection (MAD), a general
self-supervised learning task for multivariate time series anomaly detection.
With the increasing availability of sensor data from industrial systems, being
able to detecting anomalies from streams of multivariate time series data is of
significant importance. Given the scarcity of anomalies in real-world
applications, the majority of literature has been focusing on modeling
normality. The learned normal representations can empower anomaly detection as
the model has learned to capture certain key underlying data regularities. A
typical formulation is to learn a predictive model, i.e., use a window of time
series data to predict future data values. In this paper, we propose an
alternative self-supervised learning task. By randomly masking a portion of the
inputs and training a model to estimate them using the remaining ones, MAD is
an improvement over the traditional left-to-right next step prediction (NSP)
task. Our experimental results demonstrate that MAD can achieve better anomaly
detection rates over traditional NSP approaches when using exactly the same
neural network (NN) base models, and can be modified to run as fast as NSP
models during test time on the same hardware, thus making it an ideal upgrade
for many existing NSP-based NN anomaly detection models.",http://arxiv.org/pdf/2205.02100v1,cs.LG
2022-04-29 00:17:52+00:00,Graph Learning from Multivariate Dependent Time Series via a Multi-Attribute Formulation,['Jitendra K Tugnait'],"We consider the problem of inferring the conditional independence graph (CIG)
of a high-dimensional stationary multivariate Gaussian time series. In a time
series graph, each component of the vector series is represented by distinct
node, and associations between components are represented by edges between the
corresponding nodes. We formulate the problem as one of multi-attribute graph
estimation for random vectors where a vector is associated with each node of
the graph. At each node, the associated random vector consists of a time series
component and its delayed copies. We present an alternating direction method of
multipliers (ADMM) solution to minimize a sparse-group lasso penalized negative
pseudo log-likelihood objective function to estimate the precision matrix of
the random vector associated with the entire multi-attribute graph. The time
series CIG is then inferred from the estimated precision matrix. A theoretical
analysis is provided. Numerical results illustrate the proposed approach which
outperforms existing frequency-domain approaches in correctly detecting the
graph edges.",http://arxiv.org/pdf/2205.00007v1,stat.ML
2022-04-28 20:41:49+00:00,"Triformer: Triangular, Variable-Specific Attentions for Long Sequence Multivariate Time Series Forecasting--Full Version","['Razvan-Gabriel Cirstea', 'Chenjuan Guo', 'Bin Yang', 'Tung Kieu', 'Xuanyi Dong', 'Shirui Pan']","A variety of real-world applications rely on far future information to make
decisions, thus calling for efficient and accurate long sequence multivariate
time series forecasting. While recent attention-based forecasting models show
strong abilities in capturing long-term dependencies, they still suffer from
two key limitations. First, canonical self attention has a quadratic complexity
w.r.t. the input time series length, thus falling short in efficiency. Second,
different variables' time series often have distinct temporal dynamics, which
existing studies fail to capture, as they use the same model parameter space,
e.g., projection matrices, for all variables' time series, thus falling short
in accuracy. To ensure high efficiency and accuracy, we propose Triformer, a
triangular, variable-specific attention. (i) Linear complexity: we introduce a
novel patch attention with linear complexity. When stacking multiple layers of
the patch attentions, a triangular structure is proposed such that the layer
sizes shrink exponentially, thus maintaining linear complexity. (ii)
Variable-specific parameters: we propose a light-weight method to enable
distinct sets of model parameters for different variables' time series to
enhance accuracy without compromising efficiency and memory usage. Strong
empirical evidence on four datasets from multiple domains justifies our design
choices, and it demonstrates that Triformer outperforms state-of-the-art
methods w.r.t. both accuracy and efficiency. This is an extended version of
""Triformer: Triangular, Variable-Specific Attentions for Long Sequence
Multivariate Time Series Forecasting"", to appear in IJCAI 2022 [Cirstea et al.,
2022a], including additional experimental results.",http://arxiv.org/pdf/2204.13767v1,cs.LG
2022-04-28 12:41:05+00:00,Fuzzy Cognitive Maps and Hidden Markov Models: Comparative Analysis of Efficiency within the Confines of the Time Series Classification Task,"['Jakub Michał Bilski', 'Agnieszka Jastrzębska']","Time series classification is one of the very popular machine learning tasks.
In this paper, we explore the application of Hidden Markov Model (HMM) for time
series classification. We distinguish between two modes of HMM application. The
first, in which a single model is built for each class. The second, in which
one HMM is built for each time series. We then transfer both approaches for
classifier construction to the domain of Fuzzy Cognitive Maps. The identified
four models, HMM NN (HMM, one per series), HMM 1C (HMM, one per class), FCM NN,
and FCM 1C are then studied in a series of experiments. We compare the
performance of different models and investigate the impact of their
hyperparameters on the time series classification accuracy. The empirical
evaluation shows a clear advantage of the one-model-per-series approach. The
results show that the choice between HMM and FCM should be dataset-dependent.",http://arxiv.org/pdf/2204.13455v1,cs.LG
2022-04-28 05:17:45+00:00,Transformers in Time-series Analysis: A Tutorial,"['Sabeen Ahmed', 'Ian E. Nielsen', 'Aakash Tripathi', 'Shamoon Siddiqui', 'Ghulam Rasool', 'Ravi P. Ramachandran']","Transformer architecture has widespread applications, particularly in Natural
Language Processing and computer vision. Recently Transformers have been
employed in various aspects of time-series analysis. This tutorial provides an
overview of the Transformer architecture, its applications, and a collection of
examples from recent research papers in time-series analysis. We delve into an
explanation of the core components of the Transformer, including the
self-attention mechanism, positional encoding, multi-head, and encoder/decoder.
Several enhancements to the initial, Transformer architecture are highlighted
to tackle time-series tasks. The tutorial also provides best practices and
techniques to overcome the challenge of effectively training Transformers for
time-series analysis.",http://arxiv.org/pdf/2205.01138v2,cs.LG
2022-04-27 21:13:22+00:00,Stopping time detection of wood panel compression: A functional time series approach,"['H. L. Shang', 'J. Cao', 'P. Sang']","We consider determining the optimal stopping time for the glue curing of wood
panels in an automatic process environment. Using the near-infrared
spectroscopy technology to monitor the manufacturing process ensures
substantial savings in energy and time. We collect a time series of curves from
a near-infrared spectrum probe consisting of 72 spectra and aim to detect an
optimal stopping time. We propose an estimation procedure to determine the
optimal stopping time of wood panel compression and the estimation uncertainty
associated with the estimated stopping time. Our method first divides the
entire data set into a training sample and a testing sample, then iteratively
computes integrated squared forecast errors based on the testing sample. We
then apply a structural break detection method with one breakpoint to determine
an estimated optimal stopping time from a univariate time series of the
integrated squared forecast errors. We also investigate the finite-sample
performance of the proposed method via a series of simulation studies.",http://arxiv.org/pdf/2204.13197v1,stat.ME
2022-04-26 16:49:06+00:00,Encoding Cardiopulmonary Exercise Testing Time Series as Images for Classification using Convolutional Neural Network,"['Yash Sharma', 'Nick Coronato', 'Donald E. Brown']","Exercise testing has been available for more than a half-century and is a
remarkably versatile tool for diagnostic and prognostic information of patients
for a range of diseases, especially cardiovascular and pulmonary. With rapid
advancements in technology, wearables, and learning algorithm in the last
decade, its scope has evolved. Specifically, Cardiopulmonary exercise testing
(CPX) is one of the most commonly used laboratory tests for objective
evaluation of exercise capacity and performance levels in patients. CPX
provides a non-invasive, integrative assessment of the pulmonary,
cardiovascular, and skeletal muscle systems involving the measurement of gas
exchanges. However, its assessment is challenging, requiring the individual to
process multiple time series data points, leading to simplification to peak
values and slopes. But this simplification can discard the valuable trend
information present in these time series. In this work, we encode the time
series as images using the Gramian Angular Field and Markov Transition Field
and use it with a convolutional neural network and attention pooling approach
for the classification of heart failure and metabolic syndrome patients. Using
GradCAMs, we highlight the discriminative features identified by the model.",http://arxiv.org/pdf/2204.12432v1,cs.LG
2022-04-26 05:51:19+00:00,Time Series Prediction by Multi-task GPR with Spatiotemporal Information Transformation,"['Peng Tao', 'Xiaohu Hao', 'Jie Cheng', 'Luonan Chen']","Making an accurate prediction of an unknown system only from a short-term
time series is difficult due to the lack of sufficient information, especially
in a multi-step-ahead manner. However, a high-dimensional short-term time
series contains rich dynamical information, and also becomes increasingly
available in many fields. In this work, by exploiting spatiotemporal
information (STI) transformation scheme that transforms such
high-dimensional/spatial information to temporal information, we developed a
new method called MT-GPRMachine to achieve accurate prediction from a
short-term time series. Specifically, we first construct a specific multi-task
GPR which is multiple linked STI mappings to transform high dimensional/spatial
information into temporal/dynamical information of any given target variable,
and then makes multi step-ahead prediction of the target variable by solving
those STI mappings. The multi-step-ahead prediction results on various
synthetic and real-world datasets clearly validated that MT-GPRMachine
outperformed other existing approaches.",http://arxiv.org/pdf/2204.12085v1,cs.LG
2022-04-24 15:23:25+00:00,Satellite Image Time Series Analysis for Big Earth Observation Data,"['Rolf Simoes', 'Gilberto Camara', 'Gilberto Queiroz', 'Felipe Souza', 'Pedro R. Andrade', 'Lorena Santos', 'Alexandre Carvalho', 'Karine Ferreira']","The development of analytical software for big Earth observation data faces
several challenges. Designers need to balance between conflicting factors.
Solutions that are efficient for specific hardware architectures can not be
used in other environments. Packages that work on generic hardware and open
standards will not have the same performance as dedicated solutions. Software
that assumes that its users are computer programmers are flexible but may be
difficult to learn for a wide audience. This paper describes sits, an
open-source R package for satellite image time series analysis using machine
learning. To allow experts to use satellite imagery to the fullest extent, sits
adopts a time-first, space-later approach. It supports the complete cycle of
data analysis for land classification. Its API provides a simple but powerful
set of functions. The software works in different cloud computing environments.
Satellite image time series are input to machine learning classifiers, and the
results are post-processed using spatial smoothing. Since machine learning
methods need accurate training data, sits includes methods for quality
assessment of training samples. The software also provides methods for
validation and accuracy measurement. The package thus comprises a production
environment for big EO data analysis. We show that this approach produces high
accuracy for land use and land cover maps through a case study in the Cerrado
biome, one of the world's fast moving agricultural frontiers for the year 2018.",http://arxiv.org/pdf/2204.11301v1,cs.LG
2022-04-23 17:52:13+00:00,Time Series Forecasting (TSF) Using Various Deep Learning Models,"['Jimeng Shi', 'Mahek Jain', 'Giri Narasimhan']","Time Series Forecasting (TSF) is used to predict the target variables at a
future time point based on the learning from previous time points. To keep the
problem tractable, learning methods use data from a fixed length window in the
past as an explicit input. In this paper, we study how the performance of
predictive models change as a function of different look-back window sizes and
different amounts of time to predict into the future. We also consider the
performance of the recent attention-based Transformer models, which has had
good success in the image processing and natural language processing domains.
In all, we compare four different deep learning methods (RNN, LSTM, GRU, and
Transformer) along with a baseline method. The dataset (hourly) we used is the
Beijing Air Quality Dataset from the UCI website, which includes a multivariate
time series of many factors measured on an hourly basis for a period of 5 years
(2010-14). For each model, we also report on the relationship between the
performance and the look-back window sizes and the number of predicted time
points into the future. Our experiments suggest that Transformer models have
the best performance with the lowest Mean Average Errors (MAE = 14.599, 23.273)
and Root Mean Square Errors (RSME = 23.573, 38.131) for most of our single-step
and multi-steps predictions. The best size for the look-back window to predict
1 hour into the future appears to be one day, while 2 or 4 days perform the
best to predict 3 hours into the future.",http://arxiv.org/pdf/2204.11115v1,cs.LG
2022-04-23 12:26:01+00:00,Dimension Reduction for time series with Variational AutoEncoders,"['William Todo', 'Beatrice Laurent', 'Jean-Michel Loubes', 'Merwann Selmani']","In this work, we explore dimensionality reduction techniques for univariate
and multivariate time series data. We especially conduct a comparison between
wavelet decomposition and convolutional variational autoencoders for dimension
reduction. We show that variational autoencoders are a good option for reducing
the dimension of high dimensional data like ECG. We make these comparisons on a
real world, publicly available, ECG dataset that has lots of variability and
use the reconstruction error as the metric. We then explore the robustness of
these models with noisy data whether for training or inference. These tests are
intended to reflect the problems that exist in real-world time series data and
the VAE was robust to both tests.",http://arxiv.org/pdf/2204.11060v1,cs.LG
2022-04-22 03:53:51+00:00,NLP Based Anomaly Detection for Categorical Time Series,"['Matthew Horak', 'Sowmya Chandrasekaran', 'Giovanni Tobar']","Identifying anomalies in large multi-dimensional time series is a crucial and
difficult task across multiple domains. Few methods exist in the literature
that address this task when some of the variables are categorical in nature. We
formalize an analogy between categorical time series and classical Natural
Language Processing and demonstrate the strength of this analogy for anomaly
detection and root cause investigation by implementing and testing three
different machine learning anomaly detection and root cause investigation
models based upon it.",http://arxiv.org/pdf/2204.10483v1,cs.LG
2022-04-21 21:32:28+00:00,Dirichlet Proportions Model for Hierarchically Coherent Probabilistic Forecasting,"['Abhimanyu Das', 'Weihao Kong', 'Biswajit Paria', 'Rajat Sen']","Probabilistic, hierarchically coherent forecasting is a key problem in many
practical forecasting applications -- the goal is to obtain coherent
probabilistic predictions for a large number of time series arranged in a
pre-specified tree hierarchy. In this paper, we present an end-to-end deep
probabilistic model for hierarchical forecasting that is motivated by a
classical top-down strategy. It jointly learns the distribution of the root
time series, and the (dirichlet) proportions according to which each parent
time-series is split among its children at any point in time. The resulting
forecasts are naturally coherent, and provide probabilistic predictions over
all time series in the hierarchy. We experiment on several public datasets and
demonstrate significant improvements of up to 26% on most datasets compared to
state-of-the-art baselines. Finally, we also provide theoretical justification
for the superiority of our top-down approach compared to the more traditional
bottom-up modeling.",http://arxiv.org/pdf/2204.10414v3,cs.LG
2022-04-21 20:32:20+00:00,STD: A Seasonal-Trend-Dispersion Decomposition of Time Series,['Grzegorz Dudek'],"The decomposition of a time series is an essential task that helps to
understand its very nature. It facilitates the analysis and forecasting of
complex time series expressing various hidden components such as the trend,
seasonal components, cyclic components and irregular fluctuations. Therefore,
it is crucial in many fields for forecasting and decision processes. In recent
years, many methods of time series decomposition have been developed, which
extract and reveal different time series properties. Unfortunately, they
neglect a very important property, i.e. time series variance. To deal with
heteroscedasticity in time series, the method proposed in this work -- a
seasonal-trend-dispersion decomposition (STD) -- extracts the trend, seasonal
component and component related to the dispersion of the time series. We define
STD decomposition in two ways: with and without an irregular component. We show
how STD can be used for time series analysis and forecasting.",http://arxiv.org/pdf/2204.10398v1,stat.ME
2022-04-21 09:40:30+00:00,A data filling methodology for time series based on CNN and (Bi)LSTM neural networks,"['Kostas Tzoumpas', 'Aaron Estrada', 'Pietro Miraglio', 'Pietro Zambelli']","In the process of collecting data from sensors, several circumstances can
affect their continuity and validity, resulting in alterations of the data or
loss of information. Although classical methods of statistics, such as
interpolation-like techniques, can be used to approximate the missing data in a
time series, the recent developments in Deep Learning (DL) have given impetus
to innovative and much more accurate forecasting techniques. In the present
paper, we develop two DL models aimed at filling data gaps, for the specific
case of internal temperature time series obtained from monitored apartments
located in Bolzano, Italy. The DL models developed in the present work are
based on the combination of Convolutional Neural Networks (CNNs), Long
Short-Term Memory Neural Networks (LSTMs), and Bidirectional LSTMs (BiLSTMs).
Two key features of our models are the use of both pre- and post-gap data, and
the exploitation of a correlated time series (the external temperature) in
order to predict the target one (the internal temperature). Our approach
manages to capture the fluctuating nature of the data and shows good accuracy
in reconstructing the target time series. In addition, our models significantly
improve the already good results from another DL architecture that is used as a
baseline for the present work.",http://arxiv.org/pdf/2204.09994v1,cs.LG
2022-04-19 19:38:27+00:00,Sintel: A Machine Learning Framework to Extract Insights from Signals,"['Sarah Alnegheimish', 'Dongyu Liu', 'Carles Sala', 'Laure Berti-Equille', 'Kalyan Veeramachaneni']","The detection of anomalies in time series data is a critical task with many
monitoring applications. Existing systems often fail to encompass an end-to-end
detection process, to facilitate comparative analysis of various anomaly
detection methods, or to incorporate human knowledge to refine output. This
precludes current methods from being used in real-world settings by
practitioners who are not ML experts. In this paper, we introduce Sintel, a
machine learning framework for end-to-end time series tasks such as anomaly
detection. The framework uses state-of-the-art approaches to support all steps
of the anomaly detection process. Sintel logs the entire anomaly detection
journey, providing detailed documentation of anomalies over time. It enables
users to analyze signals, compare methods, and investigate anomalies through an
interactive visualization tool, where they can annotate, modify, create, and
remove events. Using these annotations, the framework leverages human knowledge
to improve the anomaly detection pipeline. We demonstrate the usability,
efficiency, and effectiveness of Sintel through a series of experiments on
three public time series datasets, as well as one real-world use case involving
spacecraft experts tasked with anomaly analysis tasks. Sintel's framework,
code, and datasets are open-sourced at https://github.com/sintel-dev/.",http://arxiv.org/pdf/2204.09108v1,cs.LG
2022-04-19 10:02:49+00:00,LORD: Lower-Dimensional Embedding of Log-Signature in Neural Rough Differential Equations,"['Jaehoon Lee', 'Jinsung Jeon', 'Sheo yon Jhin', 'Jihyeon Hyeong', 'Jayoung Kim', 'Minju Jo', 'Kook Seungji', 'Noseong Park']","The problem of processing very long time-series data (e.g., a length of more
than 10,000) is a long-standing research problem in machine learning. Recently,
one breakthrough, called neural rough differential equations (NRDEs), has been
proposed and has shown that it is able to process such data. Their main concept
is to use the log-signature transform, which is known to be more efficient than
the Fourier transform for irregular long time-series, to convert a very long
time-series sample into a relatively shorter series of feature vectors.
However, the log-signature transform causes non-trivial spatial overheads. To
this end, we present the method of LOweR-Dimensional embedding of log-signature
(LORD), where we define an NRDE-based autoencoder to implant the higher-depth
log-signature knowledge into the lower-depth log-signature. We show that the
encoder successfully combines the higher-depth and the lower-depth
log-signature knowledge, which greatly stabilizes the training process and
increases the model accuracy. In our experiments with benchmark datasets, the
improvement ratio by our method is up to 75\% in terms of various
classification and forecasting evaluation metrics.",http://arxiv.org/pdf/2204.08781v1,cs.LG
2022-04-19 09:37:36+00:00,EXIT: Extrapolation and Interpolation-based Neural Controlled Differential Equations for Time-series Classification and Forecasting,"['Sheo Yon Jhin', 'Jaehoon Lee', 'Minju Jo', 'Seungji Kook', 'Jinsung Jeon', 'Jihyeon Hyeong', 'Jayoung Kim', 'Noseong Park']","Deep learning inspired by differential equations is a recent research trend
and has marked the state of the art performance for many machine learning
tasks. Among them, time-series modeling with neural controlled differential
equations (NCDEs) is considered as a breakthrough. In many cases, NCDE-based
models not only provide better accuracy than recurrent neural networks (RNNs)
but also make it possible to process irregular time-series. In this work, we
enhance NCDEs by redesigning their core part, i.e., generating a continuous
path from a discrete time-series input. NCDEs typically use interpolation
algorithms to convert discrete time-series samples to continuous paths.
However, we propose to i) generate another latent continuous path using an
encoder-decoder architecture, which corresponds to the interpolation process of
NCDEs, i.e., our neural network-based interpolation vs. the existing explicit
interpolation, and ii) exploit the generative characteristic of the decoder,
i.e., extrapolation beyond the time domain of original data if needed.
Therefore, our NCDE design can use both the interpolated and the extrapolated
information for downstream machine learning tasks. In our experiments with 5
real-world datasets and 12 baselines, our extrapolation and interpolation-based
NCDEs outperform existing baselines by non-trivial margins.",http://arxiv.org/pdf/2204.08771v2,cs.LG
2022-04-18 04:34:15+00:00,Multi-scale Anomaly Detection for Big Time Series of Industrial Sensors,"['Quan Ding', 'Shenghua Liu', 'Bin Zhou', 'Huawei Shen', 'Xueqi Cheng']","Given a multivariate big time series, can we detect anomalies as soon as they
occur? Many existing works detect anomalies by learning how much a time series
deviates away from what it should be in the reconstruction framework. However,
most models have to cut the big time series into small pieces empirically since
optimization algorithms cannot afford such a long series. The question is
raised: do such cuts pollute the inherent semantic segments, like incorrect
punctuation in sentences? Therefore, we propose a reconstruction-based anomaly
detection method, MissGAN, iteratively learning to decode and encode naturally
smooth time series in coarse segments, and finding out a finer segment from
low-dimensional representations based on HMM. As a result, learning from
multi-scale segments, MissGAN can reconstruct a meaningful and robust time
series, with the help of adversarial regularization and extra conditional
states. MissGAN does not need labels or only needs labels of normal instances,
making it widely applicable. Experiments on industrial datasets of real water
network sensors show our MissGAN outperforms the baselines with scalability.
Besides, we use a case study on the CMU Motion dataset to demonstrate that our
model can well distinguish unexpected gestures from a given conditional motion.",http://arxiv.org/pdf/2204.08159v1,cs.LG
2022-04-14 12:17:56+00:00,Dynamic Realized Beta Models Using Robust Realized Integrated Beta Estimator,"['Donggyu Kim', 'Minseog Oh', 'Minjeong Song', 'Yazhen Wang']","This paper introduces a unified parametric modeling approach for time-varying
market betas that can accommodate continuous-time diffusion and discrete-time
series models based on a continuous-time series regression model to better
capture the dynamic evolution of market betas. We call this the dynamic
realized beta (DR Beta). We first develop a non-parametric realized integrated
beta estimator using high-frequency financial data contaminated by
microstructure noises, which is robust to the stylized features, such as the
time-varying beta and the dependence structure of microstructure noises, and
construct the estimator's asymptotic properties. Then, with the robust realized
integrated beta estimator, we propose a quasi-likelihood procedure for
estimating the model parameters based on the combined high-frequency data and
low frequency dynamic structure. We also establish asymptotic theorems for the
proposed estimator and conduct a simulation study to check the performance of
finite samples of the estimator. The empirical study with the S&P 500 index and
the top 50 large trading volume stocks from the S&P 500 illustrates that the
proposed DR Beta model effectively accounts for dynamics in the market beta of
individual stocks and better predicts future market betas.",http://arxiv.org/pdf/2204.06914v1,stat.ME
2022-04-14 01:57:46+00:00,LSTM-Autoencoder based Anomaly Detection for Indoor Air Quality Time Series Data,"['Yuanyuan Wei', 'Julian Jang-Jaccard', 'Wen Xu', 'Fariza Sabrina', 'Seyit Camtepe', 'Mikael Boulic']","Anomaly detection for indoor air quality (IAQ) data has become an important
area of research as the quality of air is closely related to human health and
well-being. However, traditional statistics and shallow machine learning-based
approaches in anomaly detection in the IAQ area could not detect anomalies
involving the observation of correlations across several data points (i.e.,
often referred to as long-term dependences). We propose a hybrid deep learning
model that combines LSTM with Autoencoder for anomaly detection tasks in IAQ to
address this issue. In our approach, the LSTM network is comprised of multiple
LSTM cells that work with each other to learn the long-term dependences of the
data in a time-series sequence. Autoencoder identifies the optimal threshold
based on the reconstruction loss rates evaluated on every data across all
time-series sequences. Our experimental results, based on the Dunedin CO2
time-series dataset obtained through a real-world deployment of the schools in
New Zealand, demonstrate a very high and robust accuracy rate (99.50%) that
outperforms other similar models.",http://arxiv.org/pdf/2204.06701v1,cs.LG
2022-04-14 01:15:28+00:00,Time Series of Non-Additive Metrics: Identification and Interpretation of Contributing Factors of Variance by Linear Decomposition,['Alex Glushkovsky'],"The research paper addresses linear decomposition of time series of
non-additive metrics that allows for the identification and interpretation of
contributing factors (input features) of variance. Non-additive metrics, such
as ratios, are widely used in a variety of domains. It commonly requires
preceding aggregations of underlying variables that are used to calculate the
metric of interest. The latest poses a dimensionality challenge when the input
features and underlying variables are formed as two-dimensional arrays along
elements, such as account or customer identifications, and time points. It
rules out direct modeling of the time series of a non-additive metric as a
function of input features. The article discusses a five-step approach: (1)
segmentations of input features and the underlying variables of the metric that
are supported by unsupervised autoencoders, (2) univariate or joint fittings of
the metric by the aggregated input features on the segmented domains, (3)
transformations of pre-screened input features according to the fitted models,
(4) aggregation of the transformed features as time series, and (5) modelling
of the metric time series as a sum of constrained linear effects of the
aggregated features. Alternatively, approximation by numerical differentiation
has been considered to linearize the metric. It allows for element level
univariate or joint modeling of step (2). The process of these analytical steps
allows for a backward-looking explanatory decomposition of the metric as a sum
of time series of the survived input features. The paper includes a synthetic
example that studies loss-to-balance monthly rates of a hypothetical retail
credit portfolio. To validate that no latent factors other than the survived
input features have significant impacts on the metric, Statistical Process
Control has been introduced for the residual time series.",http://arxiv.org/pdf/2204.06688v1,cs.LG
2022-04-13 17:37:32+00:00,Time series features for supporting hydrometeorological explorations and predictions in ungauged locations using large datasets,"['Georgia Papacharalampous', 'Hristos Tyralis']","Regression-based frameworks for streamflow regionalization are built around
catchment attributes that traditionally originate from catchment hydrology,
flood frequency analysis and their interplay. In this work, we deviated from
this traditional path by formulating and extensively investigating the first
regression-based streamflow regionalization frameworks that largely emerge from
general-purpose time series features for data science and, more precisely, from
a large variety of such features. We focused on 28 features that included
(partial) autocorrelation, entropy, temporal variation, seasonality, trend,
lumpiness, stability, nonlinearity, linearity, spikiness, curvature and others.
We estimated these features for daily temperature, precipitation and streamflow
time series from 511 catchments, and then merged them within regionalization
contexts with traditional topographic, land cover, soil and geologic
attributes. Precipitation and temperature features (e.g., the spectral entropy,
seasonality strength and lag-1 autocorrelation of the precipitation time
series, and the stability and trend strength of the temperature time series)
were found to be useful predictors of many streamflow features. The same
applies to traditional attributes, such as the catchment mean elevation.
Relationships between predictor and dependent variables were also revealed,
while the spectral entropy, the seasonality strength and several
autocorrelation features of the streamflow time series were found to be more
regionalizable than others.",http://arxiv.org/pdf/2204.06540v2,stat.ME
2022-04-12 08:14:49+00:00,Detection of Long Range Dependence in the Time Domain for (In)Finite-Variance Time Series,"['Marco Oesting', 'Albert Rapp', 'Evgeny Spodarev']","Empirical detection of long range dependence (LRD) of a time series often
consists of deciding whether an estimate of the memory parameter $d$
corresponds to LRD. Surprisingly, the literature offers numerous spectral
domain estimators for $d$ but there are only a few estimators in the time
domain. Moreover, the latter estimators are criticized for relying on visual
inspection to determine an observation window $[n_1, n_2]$ for a linear
regression to run on. Theoretically motivated choices of $n_1$ and $n_2$ are
often missing for many time series models.
  In this paper, we take the well-known variance plot estimator and provide
rigorous asymptotic conditions on $[n_1, n_2]$ to ensure the estimator's
consistency under LRD. We establish these conditions for a large class of
square-integrable time series models. This large class enables one to use the
variance plot estimator to detect LRD for infinite-variance time series (after
suitable transformation). Thus, detection of LRD for infinite-variance time
series is another novelty of our paper. A simulation study indicates that the
variance plot estimator can detect LRD better than the popular spectral domain
GPH estimator.",http://arxiv.org/pdf/2204.05608v3,math.ST
2022-04-07 14:02:15+00:00,Few-Shot Forecasting of Time-Series with Heterogeneous Channels,"['Lukas Brinkmeyer', 'Rafael Rego Drumond', 'Johannes Burchert', 'Lars Schmidt-Thieme']","Learning complex time series forecasting models usually requires a large
amount of data, as each model is trained from scratch for each task/data set.
Leveraging learning experience with similar datasets is a well-established
technique for classification problems called few-shot classification. However,
existing approaches cannot be applied to time-series forecasting because i)
multivariate time-series datasets have different channels and ii) forecasting
is principally different from classification. In this paper we formalize the
problem of few-shot forecasting of time-series with heterogeneous channels for
the first time. Extending recent work on heterogeneous attributes in vector
data, we develop a model composed of permutation-invariant deep set-blocks
which incorporate a temporal embedding. We assemble the first meta-dataset of
40 multivariate time-series datasets and show through experiments that our
model provides a good generalization, outperforming baselines carried over from
simpler scenarios that either fail to learn across tasks or miss temporal
information.",http://arxiv.org/pdf/2204.03456v2,cs.LG
2022-04-07 10:24:12+00:00,Robust and Explainable Autoencoders for Unsupervised Time Series Outlier Detection---Extended Version,"['Tung Kieu', 'Bin Yang', 'Chenjuan Guo', 'Christian S. Jensen', 'Yan Zhao', 'Feiteng Huang', 'Kai Zheng']","Time series data occurs widely, and outlier detection is a fundamental
problem in data mining, which has numerous applications. Existing
autoencoder-based approaches deliver state-of-the-art performance on
challenging real-world data but are vulnerable to outliers and exhibit low
explainability. To address these two limitations, we propose robust and
explainable unsupervised autoencoder frameworks that decompose an input time
series into a clean time series and an outlier time series using autoencoders.
Improved explainability is achieved because clean time series are better
explained with easy-to-understand patterns such as trends and periodicities. We
provide insight into this by means of a post-hoc explainability analysis and
empirical studies. In addition, since outliers are separated from clean time
series iteratively, our approach offers improved robustness to outliers, which
in turn improves accuracy. We evaluate our approach on five real-world datasets
and report improvements over the state-of-the-art approaches in terms of
robustness and explainability.
  This is an extended version of ""Robust and Explainable Autoencoders for
Unsupervised Time Series Outlier Detection"", to appear in IEEE ICDE 2022.",http://arxiv.org/pdf/2204.03341v1,cs.LG
2022-04-06 10:59:48+00:00,High-dimensional time series segmentation via factor-adjusted vector autoregressive modelling,"['Haeran Cho', 'Hyeyoung Maeng', 'Idris A. Eckley', 'Paul Fearnhead']","Vector autoregressive (VAR) models are popularly adopted for modelling
high-dimensional time series, and their piecewise extensions allow for
structural changes in the data. In VAR modelling, the number of parameters grow
quadratically with the dimensionality which necessitates the sparsity
assumption in high dimensions. However, it is debatable whether such an
assumption is adequate for handling datasets exhibiting strong serial and
cross-sectional correlations. We propose a piecewise stationary time series
model that simultaneously allows for strong correlations as well as structural
changes, where pervasive serial and cross-sectional correlations are accounted
for by a time-varying factor structure, and any remaining idiosyncratic
dependence between the variables is handled by a piecewise stationary VAR
model. We propose an accompanying two-stage data segmentation methodology which
fully addresses the challenges arising from the latency of the component
processes. Its consistency in estimating both the total number and the
locations of the change points in the latent components, is established under
conditions considerably more general than those in the existing literature. We
demonstrate the competitive performance of the proposed methodology on
simulated datasets and an application to US blue chip stocks data.",http://arxiv.org/pdf/2204.02724v3,stat.ME
2022-04-06 09:48:59+00:00,VNIbCReg: VICReg with Neighboring-Invariance and better-Covariance Evaluated on Non-stationary Seismic Signal Time Series,"['Daesoo Lee', 'Erlend Aune', 'Nadège Langet', 'Jo Eidsvik']","One of the latest self-supervised learning (SSL) methods, VICReg, showed a
great performance both in the linear evaluation and the fine-tuning evaluation.
However, VICReg is proposed in computer vision and it learns by pulling
representations of random crops of an image while maintaining the
representation space by the variance and covariance loss. However, VICReg would
be ineffective on non-stationary time series where different parts/crops of
input should be differently encoded to consider the non-stationarity. Another
recent SSL proposal, Temporal Neighborhood Coding (TNC) is effective for
encoding non-stationary time series. This study shows that a combination of a
VICReg-style method and TNC is very effective for SSL on non-stationary time
series, where a non-stationary seismic signal time series is used as an
evaluation dataset.",http://arxiv.org/pdf/2204.02697v5,cs.LG
2022-04-04 16:32:49+00:00,Do Deep Neural Networks Contribute to Multivariate Time Series Anomaly Detection?,"['Julien Audibert', 'Pietro Michiardi', 'Frédéric Guyard', 'Sébastien Marti', 'Maria A. Zuluaga']","Anomaly detection in time series is a complex task that has been widely
studied. In recent years, the ability of unsupervised anomaly detection
algorithms has received much attention. This trend has led researchers to
compare only learning-based methods in their articles, abandoning some more
conventional approaches. As a result, the community in this field has been
encouraged to propose increasingly complex learning-based models mainly based
on deep neural networks. To our knowledge, there are no comparative studies
between conventional, machine learning-based and, deep neural network methods
for the detection of anomalies in multivariate time series. In this work, we
study the anomaly detection performance of sixteen conventional, machine
learning-based and, deep neural network approaches on five real-world open
datasets. By analyzing and comparing the performance of each of the sixteen
methods, we show that no family of methods outperforms the others. Therefore,
we encourage the community to reincorporate the three categories of methods in
the anomaly detection in multivariate time series benchmarks.",http://arxiv.org/pdf/2204.01637v1,cs.LG
2022-04-01 13:20:05+00:00,Synthetic Photovoltaic and Wind Power Forecasting Data,"['Stephan Vogt', 'Jens Schreiber', 'Bernhard Sick']","Photovoltaic and wind power forecasts in power systems with a high share of
renewable energy are essential in several applications. These include stable
grid operation, profitable power trading, and forward-looking system planning.
However, there is a lack of publicly available datasets for research on machine
learning based prediction methods. This paper provides an openly accessible
time series dataset with realistic synthetic power data. Other publicly and
non-publicly available datasets often lack precise geographic coordinates,
timestamps, or static power plant information, e.g., to protect business
secrets. On the opposite, this dataset provides these. The dataset comprises
120 photovoltaic and 273 wind power plants with distinct sides all over Germany
from 500 days in hourly resolution. This large number of available sides allows
forecasting experiments to include spatial correlations and run experiments in
transfer and multi-task learning. It includes side-specific, power
source-dependent, non-synthetic input features from the ICON-EU weather model.
A simulation of virtual power plants with physical models and actual
meteorological measurements provides realistic synthetic power measurement time
series. These time series correspond to the power output of virtual power
plants at the location of the respective weather measurements. Since the
synthetic time series are based exclusively on weather measurements, possible
errors in the weather forecast are comparable to those in actual power data. In
addition to the data description, we evaluate the quality of
weather-prediction-based power forecasts by comparing simplified physical
models and a machine learning model. This experiment shows that forecasts
errors on the synthetic power data are comparable to real-world historical
power measurements.",http://arxiv.org/pdf/2204.00411v1,cs.LG
2022-04-01 12:34:26+00:00,When to Classify Events in Open Times Series?,"['Youssef Achenchabe', 'Alexis Bondu', 'Antoine Cornuéjols', 'Vincent Lemaire']","In numerous applications, for instance in predictive maintenance, there is a
pression to predict events ahead of time with as much accuracy as possible
while not delaying the decision unduly. This translates in the optimization of
a trade-off between earliness and accuracy of the decisions, that has been the
subject of research for time series of finite length and with a unique label.
And this has led to powerful algorithms for Early Classification of Time Series
(ECTS). This paper, for the first time, investigates such a trade-off when
events of different classes occur in a streaming fashion, with no predefined
end. In the Early Classification in Open Time Series problem (ECOTS), the task
is to predict events, i.e. their class and time interval, at the moment that
optimizes the accuracy vs. earliness trade-off. Interestingly, we find that
ECTS algorithms can be sensibly adapted in a principled way to this new
problem. We illustrate our methodology by transforming two state-of-the-art
ECTS algorithms for the ECOTS scenario. Among the wide variety of applications
that this new approach opens up, we develop a predictive maintenance use case
that optimizes alarm triggering times, thus demonstrating the power of this new
approach.",http://arxiv.org/pdf/2204.00392v2,cs.LG
2022-03-30 13:18:34+00:00,A Novel First-Order Autoregressive Moving Average Model to Analyze Discrete-Time Series Irregularly Observed,"['Cesar Ojeda', 'Wilfredo Palma', 'Susana Eyheramendy', 'Felipe Elorrieta']","A novel first-order autoregressive moving average model for analyzing
discrete-time series observed at irregularly spaced times is introduced. Under
Gaussianity, it is established that the model is strictly stationary and
ergodic. In the general case, it is shown that the model is weakly stationary.
The lowest dimension of the state-space representation is given along with the
one-step linear predictors and their mean squared errors. The maximum
likelihood estimation procedure is discussed, and their finite-sample behavior
is assessed through Monte Carlo experiments. These experiments show that bias,
root mean squared error, and coefficient of variation are smaller when the
length of the series increases. Further, the method provides good estimations
for the standard errors, even with relatively small sample sizes. Also, the
irregularly spaced times seem to increase the estimation variability. The
application of the proposed model is made through two real-life examples. The
first is concerned with medical data, whereas the second describes an
astronomical data set analysis.",http://arxiv.org/pdf/2203.16281v1,stat.ME
2022-03-30 02:27:01+00:00,Theory of Acceleration of Decision Making by Correlated Time Sequences,"['Norihiro Okada', 'Tomoki Yamagami', 'Nicolas Chauvet', 'Yusuke Ito', 'Mikio Hasegawa', 'Makoto Naruse']","Photonic accelerators have been intensively studied to provide enhanced
information processing capability to benefit from the unique attributes of
physical processes. Recently, it has been reported that chaotically oscillating
ultrafast time series from a laser, called laser chaos, provide the ability to
solve multi-armed bandit (MAB) problems or decision-making problems at GHz
order. Furthermore, it has been confirmed that the negatively correlated
time-domain structure of laser chaos contributes to the acceleration of
decision-making. However, the underlying mechanism of why decision-making is
accelerated by correlated time series is unknown. In this study, we demonstrate
a theoretical model to account for accelerating decision-making by correlated
time sequence. We first confirm the effectiveness of the negative
autocorrelation inherent in time series for solving two-armed bandit problems
using Fourier transform surrogate methods. We propose a theoretical model that
concerns the correlated time series subjected to the decision-making system and
the internal status of the system therein in a unified manner, inspired by
correlated random walks. We demonstrate that the performance derived
analytically by the theory agrees well with the numerical simulations, which
confirms the validity of the proposed model and leads to optimal system design.
The present study paves the way for improving the effectiveness of correlated
time series for decision-making, impacting artificial intelligence and other
applications.",http://arxiv.org/pdf/2203.16004v4,cs.LG
2022-03-29 16:44:56+00:00,Towards Spatio-Temporal Aware Traffic Time Series Forecasting--Full Version,"['Razvan-Gabriel Cirstea', 'Bin Yang', 'Chenjuan Guo', 'Tung Kieu', 'Shirui Pan']","Traffic time series forecasting is challenging due to complex spatio-temporal
dynamics time series from different locations often have distinct patterns; and
for the same time series, patterns may vary across time, where, for example,
there exist certain periods across a day showing stronger temporal
correlations. Although recent forecasting models, in particular deep learning
based models, show promising results, they suffer from being spatio-temporal
agnostic. Such spatio-temporal agnostic models employ a shared parameter space
irrespective of the time series locations and the time periods and they assume
that the temporal patterns are similar across locations and do not evolve
across time, which may not always hold, thus leading to sub-optimal results. In
this work, we propose a framework that aims at turning spatio-temporal agnostic
models to spatio-temporal aware models. To do so, we encode time series from
different locations into stochastic variables, from which we generate
location-specific and time-varying model parameters to better capture the
spatio-temporal dynamics. We show how to integrate the framework with canonical
attentions to enable spatio-temporal aware attentions. Next, to compensate for
the additional overhead introduced by the spatio-temporal aware model parameter
generation process, we propose a novel window attention scheme, which helps
reduce the complexity from quadratic to linear, making spatio-temporal aware
attentions also have competitive efficiency. We show strong empirical evidence
on four traffic time series datasets, where the proposed spatio-temporal aware
attentions outperform state-of-the-art methods in term of accuracy and
efficiency. This is an extended version of ""Towards Spatio-Temporal Aware
Traffic Time Series Forecasting"", to appear in ICDE 2022 [1], including
additional experimental results.",http://arxiv.org/pdf/2203.15737v3,cs.LG
2022-03-28 18:14:04+00:00,DAMNETS: A Deep Autoregressive Model for Generating Markovian Network Time Series,"['Jase Clarkson', 'Mihai Cucuringu', 'Andrew Elliott', 'Gesine Reinert']","Generative models for network time series (also known as dynamic graphs) have
tremendous potential in fields such as epidemiology, biology and economics,
where complex graph-based dynamics are core objects of study. Designing
flexible and scalable generative models is a very challenging task due to the
high dimensionality of the data, as well as the need to represent temporal
dependencies and marginal network structure. Here we introduce DAMNETS, a
scalable deep generative model for network time series. DAMNETS outperforms
competing methods on all of our measures of sample quality, over both real and
synthetic data sets.",http://arxiv.org/pdf/2203.15009v2,stat.ML
2022-03-28 03:25:19+00:00,Enhancing Transformer Efficiency for Multivariate Time Series Classification,"['Yuqing Wang', 'Yun Zhao', 'Linda Petzold']","Most current multivariate time series (MTS) classification algorithms focus
on improving the predictive accuracy. However, for large-scale (either
high-dimensional or long-sequential) time series (TS) datasets, there is an
additional consideration: to design an efficient network architecture to reduce
computational costs such as training time and memory footprint. In this work we
propose a methodology based on module-wise pruning and Pareto analysis to
investigate the relationship between model efficiency and accuracy, as well as
its complexity. Comprehensive experiments on benchmark MTS datasets illustrate
the effectiveness of our method.",http://arxiv.org/pdf/2203.14472v1,cs.LG
2022-03-26 23:26:27+00:00,AutoTS: Automatic Time Series Forecasting Model Design Based on Two-Stage Pruning,"['Chunnan Wang', 'Xingyu Chen', 'Chengyue Wu', 'Hongzhi Wang']","Automatic Time Series Forecasting (TSF) model design which aims to help users
to efficiently design suitable forecasting model for the given time series data
scenarios, is a novel research topic to be urgently solved. In this paper, we
propose AutoTS algorithm trying to utilize the existing design skills and
design efficient search methods to effectively solve this problem. In AutoTS,
we extract effective design experience from the existing TSF works. We allow
the effective combination of design experience from different sources, so as to
create an effective search space containing a variety of TSF models to support
different TSF tasks. Considering the huge search space, in AutoTS, we propose a
two-stage pruning strategy to reduce the search difficulty and improve the
search efficiency. In addition, in AutoTS, we introduce the knowledge graph to
reveal associations between module options. We make full use of these
relational information to learn higher-level features of each module option, so
as to further improve the search quality. Extensive experimental results show
that AutoTS is well-suited for the TSF area. It is more efficient than the
existing neural architecture search algorithms, and can quickly design powerful
TSF model better than the manually designed ones.",http://arxiv.org/pdf/2203.14169v1,cs.LG
2022-03-25 13:58:10+00:00,HYDRA: Competing convolutional kernels for fast and accurate time series classification,"['Angus Dempster', 'Daniel F. Schmidt', 'Geoffrey I. Webb']","We demonstrate a simple connection between dictionary methods for time series
classification, which involve extracting and counting symbolic patterns in time
series, and methods based on transforming input time series using convolutional
kernels, namely ROCKET and its variants. We show that by adjusting a single
hyperparameter it is possible to move by degrees between models resembling
dictionary methods and models resembling ROCKET. We present HYDRA, a simple,
fast, and accurate dictionary method for time series classification using
competing convolutional kernels, combining key aspects of both ROCKET and
conventional dictionary methods. HYDRA is faster and more accurate than the
most accurate existing dictionary methods, and can be combined with ROCKET and
its variants to further improve the accuracy of these methods.",http://arxiv.org/pdf/2203.13652v1,cs.LG
2022-03-25 10:36:27+00:00,An Intelligent End-to-End Neural Architecture Search Framework for Electricity Forecasting Model Development,"['Jin Yang', 'Yingying Huang', 'Guangxin Jiang', 'Ying Chen']","Recent years have witnessed an exponential growth in developing deep learning
(DL) models for the time-series electricity forecasting in power systems.
However, most of the proposed models are designed based on the designers'
inherent knowledge and experience without elaborating on the suitability of the
proposed neural architectures. Moreover, these models cannot be self-adjusted
to the dynamically changing data patterns due to an inflexible design of their
structures. Even though several latest studies have considered application of
the neural architecture search (NAS) technique for obtaining a network with an
optimized structure in the electricity forecasting sector, their training
process is quite time-consuming, computationally expensive and not intelligent,
indicating that the NAS application in electricity forecasting area is still at
an infancy phase. In this research study, we propose an intelligent automated
architecture search (IAAS) framework for the development of time-series
electricity forecasting models. The proposed framework contains two primary
components, i.e., network function-preserving transformation operation and
reinforcement learning (RL)-based network transformation control. In the first
component, we introduce a theoretical function-preserving transformation of
recurrent neural networks (RNN) to the literature for capturing the hidden
temporal patterns within the time-series data. In the second component, we
develop three RL-based transformation actors and a net pool to intelligently
and effectively search a high-quality neural architecture. After conducting
comprehensive experiments on two publicly-available electricity load datasets
and two wind power datasets, we demonstrate that the proposed IAAS framework
significantly outperforms the ten existing models or methods in terms of
forecasting accuracy and stability.",http://arxiv.org/pdf/2203.13563v1,cs.LG
2022-03-24 01:11:50+00:00,Random Matrix Time Series,"['Peiyuan Teng', 'Min Xu']","In this paper, a time series model with coefficients that take values from
random matrix ensembles is proposed. Formal definitions, theoretical solutions,
and statistical properties are derived. Estimation and forecast methodologies
for random matrix time series are discussed with examples. Random matrix
differential equations and potential applications of the time series model are
suggested at the end.",http://arxiv.org/pdf/2203.12789v1,stat.ME
2022-03-24 00:45:05+00:00,"Spherical Autoregressive Models, With Application to Distributional and Compositional Time Series","['Changbo Zhu', 'Hans-Georg Müller']","We introduce a new class of autoregressive models for spherical time series,
where the dimension of the spheres on which the observations of the time series
are situated may be finite-dimensional or infinite-dimensional as in the case
of a general Hilbert sphere. Spherical time series arise in various settings.
We focus here on distributional and compositional time series. Applying a
square root transformation to the densities of the observations of a
distributional time series maps the distributional observations to the Hilbert
sphere, equipped with the Fisher-Rao metric. Likewise, applying a square root
transformation to the components of the observations of a compositional time
series maps the compositional observations to a finite-dimensional sphere,
equipped with the geodesic metric on spheres. The challenge in modeling such
time series lies in the intrinsic non-linearity of spheres and Hilbert spheres,
where conventional arithmetic operations such as addition or scalar
multiplication are no longer available. To address this difficulty, we consider
rotation operators to map observations on the sphere. Specifically, we
introduce a class of skew-symmetric operator such that the associated
exponential operators are rotation operators that for each given pair of points
on the sphere map one of the points to the other one. We exploit the fact that
the space of skew-symmetric operators is Hilbertian to develop autoregressive
modeling of geometric differences that correspond to rotations of spherical and
distributional time series. Motivating data for our methods include a time
series of yearly observations of bivariate distributions of the minimum/maximum
temperatures for a period of 120 days during each summer for the years
1990-2018 at Los Angeles (LAX) and John F. Kennedy (JFK) international
airports.",http://arxiv.org/pdf/2203.12783v1,stat.ME
2022-03-21 16:30:34+00:00,Diverse Counterfactual Explanations for Anomaly Detection in Time Series,"['Deborah Sulem', 'Michele Donini', 'Muhammad Bilal Zafar', 'Francois-Xavier Aubet', 'Jan Gasthaus', 'Tim Januschowski', 'Sanjiv Das', 'Krishnaram Kenthapadi', 'Cedric Archambeau']","Data-driven methods that detect anomalies in times series data are ubiquitous
in practice, but they are in general unable to provide helpful explanations for
the predictions they make. In this work we propose a model-agnostic algorithm
that generates counterfactual ensemble explanations for time series anomaly
detection models. Our method generates a set of diverse counterfactual
examples, i.e, multiple perturbed versions of the original time series that are
not considered anomalous by the detection model. Since the magnitude of the
perturbations is limited, these counterfactuals represent an ensemble of inputs
similar to the original time series that the model would deem normal. Our
algorithm is applicable to any differentiable anomaly detection model. We
investigate the value of our method on univariate and multivariate real-world
datasets and two deep-learning-based anomaly detection models, under several
explainability criteria previously proposed in other data domains such as
Validity, Plausibility, Closeness and Diversity. We show that our algorithm can
produce ensembles of counterfactual examples that satisfy these criteria and
thanks to a novel type of visualisation, can convey a richer interpretation of
a model's internal mechanism than existing methods. Moreover, we design a
sparse variant of our method to improve the interpretability of counterfactual
explanations for high-dimensional time series anomalies. In this setting, our
explanation is localised on only a few dimensions and can therefore be
communicated more efficiently to the model's user.",http://arxiv.org/pdf/2203.11103v1,cs.LG
2022-03-20 21:22:39+00:00,Nonstationary Temporal Matrix Factorization for Multivariate Time Series Forecasting,"['Xinyu Chen', 'Chengyuan Zhang', 'Xi-Le Zhao', 'Nicolas Saunier', 'Lijun Sun']","Modern time series datasets are often high-dimensional, incomplete/sparse,
and nonstationary. These properties hinder the development of scalable and
efficient solutions for time series forecasting and analysis. To address these
challenges, we propose a Nonstationary Temporal Matrix Factorization (NoTMF)
model, in which matrix factorization is used to reconstruct the whole time
series matrix and vector autoregressive (VAR) process is imposed on a properly
differenced copy of the temporal factor matrix. This approach not only
preserves the low-rank property of the data but also offers consistent temporal
dynamics. The learning process of NoTMF involves the optimization of two factor
matrices and a collection of VAR coefficient matrices. To efficiently solve the
optimization problem, we derive an alternating minimization framework, in which
subproblems are solved using conjugate gradient and least squares methods. In
particular, the use of conjugate gradient method offers an efficient routine
and allows us to apply NoTMF on large-scale problems. Through extensive
experiments on Uber movement speed dataset, we demonstrate the superior
accuracy and effectiveness of NoTMF over other baseline models. Our results
also confirm the importance of addressing the nonstationarity of real-world
time series data such as spatiotemporal traffic flow/speed.",http://arxiv.org/pdf/2203.10651v2,cs.LG
2022-03-19 22:59:23+00:00,IID Time Series Testing,['Andrey Sarantsev'],"Traditional white noise testing, for example the Ljung-Box test, studies only
the autocorrelation function (ACF). Time series can be heteroscedastic and
therefore not i.i.d. but still white noise (that is, with zero ACF). An example
of heteroscedasticity is financial time series: times of high variance
(financial crises) can alternate with times of low variance (calm times). Here,
absolute values of time series terms are not white noise. We could test for
white noise separately for original and absolute values, for example using
Ljung-Box tests for both. In this article, we create an omnibus test which
combines these two tests. Moreover, we create a general framework to create
various i.i.d. tests. We apply tests to simulated data, both autoregressive
linear and heteroscedastic.",http://arxiv.org/pdf/2203.10405v2,math.ST
2022-03-18 20:23:41+00:00,Performance of Deep Learning models with transfer learning for multiple-step-ahead forecasts in monthly time series,"['Martín Solís', 'Luis-Alexander Calvo-Valverde']","Deep Learning and transfer learning models are being used to generate time
series forecasts; however, there is scarce evidence about their performance
prediction that it is more evident for monthly time series. The purpose of this
paper is to compare Deep Learning models with transfer learning and without
transfer learning and other traditional methods used for monthly forecasts to
answer three questions about the suitability of Deep Learning and Transfer
Learning to generate predictions of time series. Time series of M4 and M3
competitions were used for the experiments. The results suggest that deep
learning models based on TCN, LSTM, and CNN with transfer learning tend to
surpass the performance prediction of other traditional methods. On the other
hand, TCN and LSTM, trained directly on the target time series, got similar or
better performance than traditional methods for some forecast horizons.",http://arxiv.org/pdf/2203.11196v2,cs.LG
2022-03-18 14:12:54+00:00,WOODS: Benchmarks for Out-of-Distribution Generalization in Time Series,"['Jean-Christophe Gagnon-Audet', 'Kartik Ahuja', 'Mohammad-Javad Darvishi-Bayazi', 'Pooneh Mousavi', 'Guillaume Dumas', 'Irina Rish']","Machine learning models often fail to generalize well under distributional
shifts. Understanding and overcoming these failures have led to a research
field of Out-of-Distribution (OOD) generalization. Despite being extensively
studied for static computer vision tasks, OOD generalization has been
underexplored for time series tasks. To shine light on this gap, we present
WOODS: eight challenging open-source time series benchmarks covering a diverse
range of data modalities, such as videos, brain recordings, and sensor signals.
We revise the existing OOD generalization algorithms for time series tasks and
evaluate them using our systematic framework. Our experiments show a large room
for improvement for empirical risk minimization and OOD generalization
algorithms on our datasets, thus underscoring the new challenges posed by time
series tasks. Code and documentation are available at
https://woods-benchmarks.github.io .",http://arxiv.org/pdf/2203.09978v2,cs.LG
2022-03-17 11:49:21+00:00,Mixing Up Contrastive Learning: Self-Supervised Representation Learning for Time Series,"['Kristoffer Wickstrøm', 'Michael Kampffmeyer', 'Karl Øyvind Mikalsen', 'Robert Jenssen']","The lack of labeled data is a key challenge for learning useful
representation from time series data. However, an unsupervised representation
framework that is capable of producing high quality representations could be of
great value. It is key to enabling transfer learning, which is especially
beneficial for medical applications, where there is an abundance of data but
labeling is costly and time consuming. We propose an unsupervised contrastive
learning framework that is motivated from the perspective of label smoothing.
The proposed approach uses a novel contrastive loss that naturally exploits a
data augmentation scheme in which new samples are generated by mixing two data
samples with a mixing component. The task in the proposed framework is to
predict the mixing component, which is utilized as soft targets in the loss
function. Experiments demonstrate the framework's superior performance compared
to other representation learning approaches on both univariate and multivariate
time series and illustrate its benefits for transfer learning for clinical time
series.",http://arxiv.org/pdf/2203.09270v1,stat.ML
2022-03-17 08:47:49+00:00,Recurrent Neural Networks for Forecasting Time Series with Multiple Seasonality: A Comparative Study,"['Grzegorz Dudek', 'Slawek Smyl', 'Paweł Pełka']","This paper compares recurrent neural networks (RNNs) with different types of
gated cells for forecasting time series with multiple seasonality. The cells we
compare include classical long short term memory (LSTM), gated recurrent unit
(GRU), modified LSTM with dilation, and two new cells we proposed recently,
which are equipped with dilation and attention mechanisms. To model the
temporal dependencies of different scales, our RNN architecture has multiple
dilated recurrent layers stacked with hierarchical dilations. The proposed RNN
produces both point forecasts and predictive intervals (PIs) for them. An
empirical study concerning short-term electrical load forecasting for 35
European countries confirmed that the new gated cells with dilation and
attention performed best.",http://arxiv.org/pdf/2203.09170v1,cs.LG
2022-03-15 23:55:05+00:00,ADATIME: A Benchmarking Suite for Domain Adaptation on Time Series Data,"['Mohamed Ragab', 'Emadeldeen Eldele', 'Wee Ling Tan', 'Chuan-Sheng Foo', 'Zhenghua Chen', 'Min Wu', 'Chee-Keong Kwoh', 'Xiaoli Li']","Unsupervised domain adaptation methods aim to generalize well on unlabeled
test data that may have a different (shifted) distribution from the training
data. Such methods are typically developed on image data, and their application
to time series data is less explored. Existing works on time series domain
adaptation suffer from inconsistencies in evaluation schemes, datasets, and
backbone neural network architectures. Moreover, labeled target data are often
used for model selection, which violates the fundamental assumption of
unsupervised domain adaptation. To address these issues, we develop a
benchmarking evaluation suite (AdaTime) to systematically and fairly evaluate
different domain adaptation methods on time series data. Specifically, we
standardize the backbone neural network architectures and benchmarking
datasets, while also exploring more realistic model selection approaches that
can work with no labeled data or just a few labeled samples. Our evaluation
includes adapting state-of-the-art visual domain adaptation methods to time
series data as well as the recent methods specifically developed for time
series data. We conduct extensive experiments to evaluate 11 state-of-the-art
methods on five representative datasets spanning 50 cross-domain scenarios. Our
results suggest that with careful selection of hyper-parameters, visual domain
adaptation methods are competitive with methods proposed for time series domain
adaptation. In addition, we find that hyper-parameters could be selected based
on realistic model selection approaches. Our work unveils practical insights
for applying domain adaptation methods on time series data and builds a solid
foundation for future works in the field. The code is available at
\href{https://github.com/emadeldeen24/AdaTime}{github.com/emadeldeen24/AdaTime}.",http://arxiv.org/pdf/2203.08321v2,cs.LG
2022-03-15 13:00:41+00:00,What is the best RNN-cell structure for forecasting each time series behavior?,"['Rohaifa Khaldi', 'Abdellatif El Afia', 'Raddouane Chiheb', 'Siham Tabik']","It is unquestionable that time series forecasting is of paramount importance
in many fields. The most used machine learning models to address time series
forecasting tasks are Recurrent Neural Networks (RNNs). Typically, those models
are built using one of the three most popular cells, ELMAN, Long-Short Term
Memory (LSTM), or Gated Recurrent Unit (GRU) cells, each cell has a different
structure and implies a different computational cost. However, it is not clear
why and when to use each RNN-cell structure. Actually, there is no
comprehensive characterization of all the possible time series behaviors and no
guidance on what RNN cell structure is the most suitable for each behavior. The
objective of this study is two-fold: it presents a comprehensive taxonomy of
all-time series behaviors (deterministic, random-walk, nonlinear, long-memory,
and chaotic), and provides insights into the best RNN cell structure for each
time series behavior. We conducted two experiments: (1) The first experiment
evaluates and analyzes the role of each component in the LSTM-Vanilla cell by
creating 11 variants based on one alteration in its basic architecture
(removing, adding, or substituting one cell component). (2) The second
experiment evaluates and analyzes the performance of 20 possible RNN-cell
structures. Our results showed that the MGU-SLIM3 cell is the most recommended
for deterministic and nonlinear behaviors, the MGU-SLIM2 cell is the most
suitable for random-walk behavior, FB1 cell is advocated for long-memory
behavior, and LSTM-SLIM1 for chaotic behavior.",http://arxiv.org/pdf/2203.07844v1,cs.LG
2022-03-11 16:29:48+00:00,Identifying Causal Effects using Instrumental Time Series: Nuisance IV and Correcting for the Past,"['Nikolaj Thams', 'Rikke Søndergaard', 'Sebastian Weichwald', 'Jonas Peters']","Instrumental variable (IV) regression relies on instruments to infer causal
effects from observational data with unobserved confounding. We consider IV
regression in time series models, such as vector auto-regressive (VAR)
processes. Direct applications of i.i.d. techniques are generally inconsistent
as they do not correctly adjust for dependencies in the past. In this paper, we
propose methodology for constructing identifying equations that can be used for
consistently estimating causal effects. To do so, we develop nuisance IV, which
can be of interest even in the i.i.d. case, as it generalizes existing IV
methods. We further propose a graph marginalization framework that allows us to
apply nuisance and other IV methods in a principled way to time series. Our
framework builds on the global Markov property, which we prove holds for VAR
processes. For VAR(1) processes, we prove identifiability conditions that
relate to Jordan forms and are different from the well-known rank conditions in
the i.i.d. case (they do not require as many instruments as covariates, for
example). We provide methods, prove their consistency, and show how the
inferred causal effect can be used for distribution generalization. Simulation
experiments corroborate our theoretical results. We provide ready-to-use Python
code.",http://arxiv.org/pdf/2203.06056v1,stat.ME
2022-03-10 14:11:35+00:00,Forecasting the abnormal events at well drilling with machine learning,"['Ekaterina Gurina', 'Nikita Klyuchnikov', 'Ksenia Antipova', 'Dmitry Koroteev']","We present a data-driven and physics-informed algorithm for drilling accident
forecasting. The core machine-learning algorithm uses the data from the
drilling telemetry representing the time-series. We have developed a
Bag-of-features representation of the time series that enables the algorithm to
predict the probabilities of six types of drilling accidents in real-time. The
machine-learning model is trained on the 125 past drilling accidents from 100
different Russian oil and gas wells. Validation shows that the model can
forecast 70% of drilling accidents with a false positive rate equals to 40%.
The model addresses partial prevention of the drilling accidents at the well
construction.",http://arxiv.org/pdf/2203.05378v1,cs.LG
2022-03-10 07:12:20+00:00,A Review of Open Source Software Tools for Time Series Analysis,"['Yunus Parvej Faniband', 'Iskandar Ishak', 'Sadiq M. Sait']","Time series data is used in a wide range of real world applications. In a
variety of domains , detailed analysis of time series data (via Forecasting and
Anomaly Detection) leads to a better understanding of how events associated
with a specific time instance behave. Time Series Analysis (TSA) is commonly
performed with plots and traditional models. Machine Learning (ML) approaches ,
on the other hand , have seen an increase in the state of the art for
Forecasting and Anomaly Detection because they provide comparable results when
time and data constraints are met. A number of time series toolboxes are
available that offer rich interfaces to specific model classes (ARIMA/filters ,
neural networks) or framework interfaces to isolated time series modelling
tasks (forecasting , feature extraction , annotation , classification).
Nonetheless , open source machine learning capabilities for time series remain
limited , and existing libraries are frequently incompatible with one another.
The goal of this paper is to provide a concise and user friendly overview of
the most important open source tools for time series analysis. This article
examines two related toolboxes (1) forecasting and (2) anomaly detection. This
paper describes a typical Time Series Analysis (TSA) framework with an
architecture and lists the main features of TSA framework. The tools are
categorized based on the criteria of analysis tasks completed , data
preparation methods employed , and evaluation methods for results generated.
This paper presents quantitative analysis and discusses the current state of
actively developed open source Time Series Analysis frameworks. Overall , this
article considered 60 time series analysis tools , and 32 of which provided
forecasting modules , and 21 packages included anomaly detection.",http://arxiv.org/pdf/2203.05195v1,cs.LG
2022-03-10 05:46:58+00:00,TiSAT: Time Series Anomaly Transformer,"['Keval Doshi', 'Shatha Abudalou', 'Yasin Yilmaz']","While anomaly detection in time series has been an active area of research
for several years, most recent approaches employ an inadequate evaluation
criterion leading to an inflated F1 score. We show that a rudimentary Random
Guess method can outperform state-of-the-art detectors in terms of this popular
but faulty evaluation criterion. In this work, we propose a proper evaluation
metric that measures the timeliness and precision of detecting sequential
anomalies. Moreover, most existing approaches are unable to capture temporal
features from long sequences. Self-attention based approaches, such as
transformers, have been demonstrated to be particularly efficient in capturing
long-range dependencies while being computationally efficient during training
and inference. We also propose an efficient transformer approach for anomaly
detection in time series and extensively evaluate our proposed approach on
several popular benchmark datasets.",http://arxiv.org/pdf/2203.05167v1,cs.LG
2022-03-09 18:15:12+00:00,Autoregressive models for time series of random sums of positive variables: application to tree growth as a function of climate and insect outbreaks,"['Zinsou Max Debaly', 'Philippe Marchand', 'Miguel Montoro Girona']","We present a broad class of semi-parametric models for time series of random
sums of positive variables. Our methodology allows the number of terms inside
the sum to be time-varying and is therefore well suited to many examples
encountered in the natural sciences. We study the stability properties of the
models and provide a valid statistical inference procedure to estimate the
model parameters. It is shown that the proposed quasi-maximum likelihood
estimator is consistent and asymptotically normally distributed. This work is
complemented by simulation results and applied to annual growth rate time
series of white spruce (Picea glauca) trees from a few dozen sites in Quebec
spanning 41 years, including one major spruce budworm (Choristoneura
fumiferana) outbreak from around 1968 to 1991. We found significant growth
reductions due to budworm-induced by defoliation up to two years in the past.
Our results also revealed positive effects of maximum temperature,
precipitation and the climate moisture index in the summer, as well as negative
effects of the climate moisture index in the spring and the maximum temperature
in the previous summer. However, considering the interaction of climate and
defoliation on growth did not improve the model's performance on this dataset.
This study represent a major advances and our result represent an useful tool
in the understanding of the combined effects of climate and insect defoliation
on tree growth in the face of climate change, where the frequency and the
severity of outbreaks, as well as an increase of temperature is expected.",http://arxiv.org/pdf/2203.04926v2,stat.ME
2022-03-09 17:53:47+00:00,Monitoring Time Series With Missing Values: a Deep Probabilistic Approach,"['Oshri Barazani', 'David Tolpin']","Systems are commonly monitored for health and security through collection and
streaming of multivariate time series. Advances in time series forecasting due
to adoption of multilayer recurrent neural network architectures make it
possible to forecast in high-dimensional time series, and identify and classify
novelties early, based on subtle changes in the trends. However, mainstream
approaches to multi-variate time series predictions do not handle well cases
when the ongoing forecast must include uncertainty, nor they are robust to
missing data. We introduce a new architecture for time series monitoring based
on combination of state-of-the-art methods of forecasting in high-dimensional
time series with full probabilistic handling of uncertainty. We demonstrate
advantage of the architecture for time series forecasting and novelty
detection, in particular with partially missing data, and empirically evaluate
and compare the architecture to state-of-the-art approaches on a real-world
data set.",http://arxiv.org/pdf/2203.04916v1,stat.ML
2022-03-08 11:44:12+00:00,LSTMSPLIT: Effective SPLIT Learning based LSTM on Sequential Time-Series Data,"['Lianlian Jiang', 'Yuexuan Wang', 'Wenyi Zheng', 'Chao Jin', 'Zengxiang Li', 'Sin G. Teo']","Federated learning (FL) and split learning (SL) are the two popular
distributed machine learning (ML) approaches that provide some data privacy
protection mechanisms. In the time-series classification problem, many
researchers typically use 1D convolutional neural networks (1DCNNs) based on
the SL approach with a single client to reduce the computational overhead at
the client-side while still preserving data privacy. Another method, recurrent
neural network (RNN), is utilized on sequentially partitioned data where
segments of multiple-segment sequential data are distributed across various
clients. However, to the best of our knowledge, it is still not much work done
in SL with long short-term memory (LSTM) network, even the LSTM network is
practically effective in processing time-series data. In this work, we propose
a new approach, LSTMSPLIT, that uses SL architecture with an LSTM network to
classify time-series data with multiple clients. The differential privacy (DP)
is applied to solve the data privacy leakage. The proposed method, LSTMSPLIT,
has achieved better or reasonable accuracy compared to the Split-1DCNN method
using the electrocardiogram dataset and the human activity recognition dataset.
Furthermore, the proposed method, LSTMSPLIT, can also achieve good accuracy
after applying differential privacy to preserve the user privacy of the cut
layer of the LSTMSPLIT.",http://arxiv.org/pdf/2203.04305v1,cs.LG
2022-03-08 10:44:30+00:00,Sparsification and Filtering for Spatial-temporal GNN in Multivariate Time-series,"['Yuanrong Wang', 'Tomaso Aste']","We propose an end-to-end architecture for multivariate time-series prediction
that integrates a spatial-temporal graph neural network with a matrix filtering
module. This module generates filtered (inverse) correlation graphs from
multivariate time series before inputting them into a GNN. In contrast with
existing sparsification methods adopted in graph neural network, our model
explicitly leverage time-series filtering to overcome the low signal-to-noise
ratio typical of complex systems data. We present a set of experiments, where
we predict future sales from a synthetic time-series sales dataset. The
proposed spatial-temporal graph neural network displays superior performances
with respect to baseline approaches, with no graphical information, and with
fully connected, disconnected graphs and unfiltered graphs.",http://arxiv.org/pdf/2203.03991v1,cs.LG
2022-03-07 14:16:56+00:00,Multivariate Time Series Forecasting with Latent Graph Inference,"['Victor Garcia Satorras', 'Syama Sundar Rangapuram', 'Tim Januschowski']","This paper introduces a new approach for Multivariate Time Series forecasting
that jointly infers and leverages relations among time series. Its modularity
allows it to be integrated with current univariate methods. Our approach allows
to trade-off accuracy and computational efficiency gradually via offering on
one extreme inference of a potentially fully-connected graph or on another
extreme a bipartite graph. In the potentially fully-connected case we consider
all pair-wise interactions among time-series which yields the best forecasting
accuracy. Conversely, the bipartite case leverages the dependency structure by
inter-communicating the N time series through a small set of K auxiliary nodes
that we introduce. This reduces the time and memory complexity w.r.t. previous
graph inference methods from O(N^2) to O(NK) with a small trade-off in
accuracy. We demonstrate the effectiveness of our model in a variety of
datasets where both of its variants perform better or very competitively to
previous graph inference methods in terms of forecasting accuracy and time
efficiency.",http://arxiv.org/pdf/2203.03423v1,cs.LG
2022-03-04 11:42:49+00:00,Dependence structure for the product of bi-dimensional finite-variance VAR(1) model components. An application to the cost of electricity load prediction errors,"['Joanna Janczura', 'Andrzej Puć', 'Łukasz Bielak', 'Agnieszka Wyłomańska']","In this paper we analyze the product of bi-dimensional VAR(1) model
components. For the introduced time series we derive general formulas for the
autocovariance function and study its properties for different cases of
cross-dependence between the VAR(1) model components. The theoretical results
are then illustrated in the simulation study for two types of bivariate
distributions of the residual series, namely the Gaussian and Student's t. We
also show a possible practical application of the obtained results based on the
data from the electricity market.",http://arxiv.org/pdf/2203.02249v1,stat.ME
2022-03-03 10:43:56+00:00,Early Time-Series Classification Algorithms: An Empirical Comparison,"['Charilaos Akasiadis', 'Evgenios Kladis', 'Evangelos Michelioudakis', 'Elias Alevizos', 'Alexander Artikis']","Early Time-Series Classification (ETSC) is the task of predicting the class
of incoming time-series by observing as few measurements as possible. Such
methods can be employed to obtain classification forecasts in many
time-critical applications. However, available techniques are not equally
suitable for every problem, since differentiations in the data characteristics
can impact algorithm performance in terms of earliness, accuracy, F1-score, and
training time. We evaluate six existing ETSC algorithms on publicly available
data, as well as on two newly introduced datasets originating from the life
sciences and maritime domains. Our goal is to provide a framework for the
evaluation and comparison of ETSC algorithms and to obtain intuition on how
such approaches perform on real-life applications. The presented framework may
also serve as a benchmark for new related techniques.",http://arxiv.org/pdf/2203.01628v1,cs.LG
2022-03-03 07:42:25+00:00,Comparison of LSTM autoencoder based deep learning enabled Bayesian inference using two time series reconstruction approaches,['Saumik Dana'],"In this work, we use a combination of Bayesian inference, Markov chain Monte
Carlo and deep learning in the form of LSTM autoencoders to build and test a
framework to provide robust estimates of injection rate from ground surface
data in coupled flow and geomechanics problems. We use LSTM autoencoders to
reconstruct the displacement time series for grid points on the top surface of
a faulting due to water injection problem. We then deploy this LSTM autoencoder
based model instead of the high fidelity model in the Bayesian inference
framework to estimate injection rate from displacement input.",http://arxiv.org/pdf/2203.01936v1,cs.LG
2022-03-02 09:43:18+00:00,Boosted Ensemble Learning based on Randomized NNs for Time Series Forecasting,['Grzegorz Dudek'],"Time series forecasting is a challenging problem particularly when a time
series expresses multiple seasonality, nonlinear trend and varying variance. In
this work, to forecast complex time series, we propose ensemble learning which
is based on randomized neural networks, and boosted in three ways. These
comprise ensemble learning based on residuals, corrected targets and opposed
response. The latter two methods are employed to ensure similar forecasting
tasks are solved by all ensemble members, which justifies the use of exactly
the same base models at all stages of ensembling. Unification of the tasks for
all members simplifies ensemble learning and leads to increased forecasting
accuracy. This was confirmed in an experimental study involving forecasting
time series with triple seasonality, in which we compare our three variants of
ensemble boosting. The strong points of the proposed ensembles based on RandNNs
are extremely rapid training and pattern-based time series representation,
which extracts relevant information from time series.",http://arxiv.org/pdf/2203.00980v1,cs.LG
2022-02-28 11:17:49+00:00,Bayesian Hierarchical Copula Model for Financial Time series,"['Paolo Onorati', 'Brunero Liseo']","We discuss a Bayesian hierarchical copula model for clusters of financial
time series. A similar approach has been developed in Zhuang et al. (2020).
However, the prior distributions proposed there do not always provide a proper
posterior. In order to circumvent the problem, we adopt a proper global-local
shrinkage prior, which is also able to account for potential dependence
structure among different clusters. The performance of the proposed model is
presented through simulations and a real data analysis.",http://arxiv.org/pdf/2202.13689v1,stat.ME
2022-02-27 22:58:32+00:00,ONE-NAS: An Online NeuroEvolution based Neural Architecture Search for Time Series Forecasting,"['Zimeng Lyu', 'Travis Desell']","Time series forecasting (TSF) is one of the most important tasks in data
science, as accurate time series (TS) predictions can drive and advance a wide
variety of domains including finance, transportation, health care, and power
systems. However, real-world utilization of machine learning (ML) models for
TSF suffers due to pretrained models being able to learn and adapt to
unpredictable patterns as previously unseen data arrives over longer time
scales. To address this, models must be periodically retained or redesigned,
which takes significant human and computational resources. This work presents
the Online NeuroEvolution based Neural Architecture Search (ONE-NAS) algorithm,
which to the authors' knowledge is the first neural architecture search
algorithm capable of automatically designing and training new recurrent neural
networks (RNNs) in an online setting. Without any pretraining, ONE-NAS utilizes
populations of RNNs which are continuously updated with new network structures
and weights in response to new multivariate input data. ONE-NAS is tested on
real-world large-scale multivariate wind turbine data as well a univariate Dow
Jones Industrial Average (DJIA) dataset, and is shown to outperform traditional
statistical time series forecasting, including naive, moving average, and
exponential smoothing methods, as well as state of the art online ARIMA
strategies.",http://arxiv.org/pdf/2202.13471v1,cs.LG
2022-02-25 14:01:13+00:00,Novel techniques for improving NNetEn entropy calculation for short and noisy time series,"['Hanif Heidari', 'Andrei Velichko', 'Murugappan Murugappan', 'Muhammad E. H. Chowdhury']","Entropy is a fundamental concept in the field of information theory. During
measurement, conventional entropy measures are susceptible to length and
amplitude changes in time series. A new entropy metric, neural network entropy
(NNetEn), has been developed to overcome these limitations. NNetEn entropy is
computed using a modified LogNNet neural network classification model. The
algorithm contains a reservoir matrix of N=19625 elements that must be filled
with the given data. The contribution of this paper is threefold. Firstly, this
work investigates different methods of filling the reservoir with time series
(signal) elements. The reservoir filling method determines the accuracy of the
entropy estimation by convolution of the study time series and LogNNet test
data. The present study proposes 6 methods for filling the reservoir for time
series. Two of them (Method 3 and Method 6) employ the novel approach of
stretching the time series to create intermediate elements that complement it,
but do not change its dynamics. The most reliable methods for short time series
are Method 3 and Method 5. The second part of the study examines the influence
of noise and constant bias on entropy values. Our study examines three
different time series data types (chaotic, periodic, and binary) with different
dynamic properties, Signal to Noise Ratio (SNR), and offsets. The NNetEn
entropy calculation errors are less than 10% when SNR is greater than 30 dB,
and entropy decreases with an increase in the bias component. The third part of
the article analyzes real-time biosignal EEG data collected from emotion
recognition experiments. The NNetEn measures show robustness under
low-amplitude noise using various filters. Thus, NNetEn measures entropy
effectively when applied to real-world environments with ambient noise, white
noise, and 1/f noise.",http://arxiv.org/pdf/2202.12703v2,cs.LG
2022-02-25 01:50:22+00:00,Stacked Residuals of Dynamic Layers for Time Series Anomaly Detection,"['L. Zancato', 'A. Achille', 'G. Paolini', 'A. Chiuso', 'S. Soatto']","We present an end-to-end differentiable neural network architecture to
perform anomaly detection in multivariate time series by incorporating a
Sequential Probability Ratio Test on the prediction residual. The architecture
is a cascade of dynamical systems designed to separate linearly predictable
components of the signal such as trends and seasonality, from the non-linear
ones. The former are modeled by local Linear Dynamic Layers, and their residual
is fed to a generic Temporal Convolutional Network that also aggregates global
statistics from different time series as context for the local predictions of
each one. The last layer implements the anomaly detector, which exploits the
temporal structure of the prediction residuals to detect both isolated point
anomalies and set-point changes. It is based on a novel application of the
classic CUMSUM algorithm, adapted through the use of a variational
approximation of f-divergences. The model automatically adapts to the time
scales of the observed signals. It approximates a SARIMA model at the get-go,
and auto-tunes to the statistics of the signal and its covariates, without the
need for supervision, as more data is observed. The resulting system, which we
call STRIC, outperforms both state-of-the-art robust statistical methods and
deep neural network architectures on multiple anomaly detection benchmarks.",http://arxiv.org/pdf/2202.12457v1,cs.LG
2022-02-25 00:29:30+00:00,Long-Term Missing Value Imputation for Time Series Data Using Deep Neural Networks,"['Jangho Park', 'Juliane Muller', 'Bhavna Arora', 'Boris Faybishenko', 'Gilberto Pastorello', 'Charuleka Varadharajan', 'Reetik Sahu', 'Deborah Agarwal']","We present an approach that uses a deep learning model, in particular, a
MultiLayer Perceptron (MLP), for estimating the missing values of a variable in
multivariate time series data. We focus on filling a long continuous gap (e.g.,
multiple months of missing daily observations) rather than on individual
randomly missing observations. Our proposed gap filling algorithm uses an
automated method for determining the optimal MLP model architecture, thus
allowing for optimal prediction performance for the given time series. We
tested our approach by filling gaps of various lengths (three months to three
years) in three environmental datasets with different time series
characteristics, namely daily groundwater levels, daily soil moisture, and
hourly Net Ecosystem Exchange. We compared the accuracy of the gap-filled
values obtained with our approach to the widely-used R-based time series gap
filling methods ImputeTS and mtsdi. The results indicate that using an MLP for
filling a large gap leads to better results, especially when the data behave
nonlinearly. Thus, our approach enables the use of datasets that have a large
gap in one variable, which is common in many long-term environmental monitoring
observations.",http://arxiv.org/pdf/2202.12441v1,cs.LG
2022-02-24 05:46:26+00:00,Robust Probabilistic Time Series Forecasting,"['TaeHo Yoon', 'Youngsuk Park', 'Ernest K. Ryu', 'Yuyang Wang']","Probabilistic time series forecasting has played critical role in
decision-making processes due to its capability to quantify uncertainties. Deep
forecasting models, however, could be prone to input perturbations, and the
notion of such perturbations, together with that of robustness, has not even
been completely established in the regime of probabilistic forecasting. In this
work, we propose a framework for robust probabilistic time series forecasting.
First, we generalize the concept of adversarial input perturbations, based on
which we formulate the concept of robustness in terms of bounded Wasserstein
deviation. Then we extend the randomized smoothing technique to attain robust
probabilistic forecasters with theoretical robustness certificates against
certain classes of adversarial perturbations. Lastly, extensive experiments
demonstrate that our methods are empirically effective in enhancing the
forecast quality under additive adversarial attacks and forecast consistency
under supplement of noisy observations.",http://arxiv.org/pdf/2202.11910v1,cs.LG
2022-02-23 22:29:11+00:00,NeuroView-RNN: It's About Time,"['CJ Barberan', 'Sina Alemohammad', 'Naiming Liu', 'Randall Balestriero', 'Richard G. Baraniuk']","Recurrent Neural Networks (RNNs) are important tools for processing
sequential data such as time-series or video. Interpretability is defined as
the ability to be understood by a person and is different from explainability,
which is the ability to be explained in a mathematical formulation. A key
interpretability issue with RNNs is that it is not clear how each hidden state
per time step contributes to the decision-making process in a quantitative
manner. We propose NeuroView-RNN as a family of new RNN architectures that
explains how all the time steps are used for the decision-making process. Each
member of the family is derived from a standard RNN architecture by
concatenation of the hidden steps into a global linear classifier. The global
linear classifier has all the hidden states as the input, so the weights of the
classifier have a linear mapping to the hidden states. Hence, from the weights,
NeuroView-RNN can quantify how important each time step is to a particular
decision. As a bonus, NeuroView-RNN also offers higher accuracy in many cases
compared to the RNNs and their variants. We showcase the benefits of
NeuroView-RNN by evaluating on a multitude of diverse time-series datasets.",http://arxiv.org/pdf/2202.11811v1,cs.LG
2022-02-23 18:23:07+00:00,Learning Fast and Slow for Online Time Series Forecasting,"['Quang Pham', 'Chenghao Liu', 'Doyen Sahoo', 'Steven C. H. Hoi']","The fast adaptation capability of deep neural networks in non-stationary
environments is critical for online time series forecasting. Successful
solutions require handling changes to new and recurring patterns. However,
training deep neural forecaster on the fly is notoriously challenging because
of their limited ability to adapt to non-stationary environments and the
catastrophic forgetting of old knowledge. In this work, inspired by the
Complementary Learning Systems (CLS) theory, we propose Fast and Slow learning
Networks (FSNet), a holistic framework for online time-series forecasting to
simultaneously deal with abrupt changing and repeating patterns. Particularly,
FSNet improves the slowly-learned backbone by dynamically balancing fast
adaptation to recent changes and retrieving similar old knowledge. FSNet
achieves this mechanism via an interaction between two complementary components
of an adapter to monitor each layer's contribution to the lost, and an
associative memory to support remembering, updating, and recalling repeating
events. Extensive experiments on real and synthetic datasets validate FSNet's
efficacy and robustness to both new and recurring patterns. Our code is
available at \url{https://github.com/salesforce/fsnet}.",http://arxiv.org/pdf/2202.11672v2,cs.LG
2022-02-23 10:33:12+00:00,A Differential Attention Fusion Model Based on Transformer for Time Series Forecasting,"['Benhan Li', 'Shengdong Du', 'Tianrui Li']","Time series forecasting is widely used in the fields of equipment life cycle
forecasting, weather forecasting, traffic flow forecasting, and other fields.
Recently, some scholars have tried to apply Transformer to time series
forecasting because of its powerful parallel training ability. However, the
existing Transformer methods do not pay enough attention to the small time
segments that play a decisive role in prediction, making it insensitive to
small changes that affect the trend of time series, and it is difficult to
effectively learn continuous time-dependent features. To solve this problem, we
propose a differential attention fusion model based on Transformer, which
designs the differential layer, neighbor attention, sliding fusion mechanism,
and residual layer on the basis of classical Transformer architecture.
Specifically, the differences of adjacent time points are extracted and focused
by difference and neighbor attention. The sliding fusion mechanism fuses
various features of each time point so that the data can participate in
encoding and decoding without losing important information. The residual layer
including convolution and LSTM further learns the dependence between time
points and enables our model to carry out deeper training. A large number of
experiments on three datasets show that the prediction results produced by our
method are favorably comparable to the state-of-the-art.",http://arxiv.org/pdf/2202.11402v1,cs.LG
2022-02-23 08:49:35+00:00,Preformer: Predictive Transformer with Multi-Scale Segment-wise Correlations for Long-Term Time Series Forecasting,"['Dazhao Du', 'Bing Su', 'Zhewei Wei']","Transformer-based methods have shown great potential in long-term time series
forecasting. However, most of these methods adopt the standard point-wise
self-attention mechanism, which not only becomes intractable for long-term
forecasting since its complexity increases quadratically with the length of
time series, but also cannot explicitly capture the predictive dependencies
from contexts since the corresponding key and value are transformed from the
same point. This paper proposes a predictive Transformer-based model called
{\em Preformer}. Preformer introduces a novel efficient {\em Multi-Scale
Segment-Correlation} mechanism that divides time series into segments and
utilizes segment-wise correlation-based attention for encoding time series. A
multi-scale structure is developed to aggregate dependencies at different
temporal scales and facilitate the selection of segment length. Preformer
further designs a predictive paradigm for decoding, where the key and value
come from two successive segments rather than the same segment. In this way, if
a key segment has a high correlation score with the query segment, its
successive segment contributes more to the prediction of the query segment.
Extensive experiments demonstrate that our Preformer outperforms other
Transformer-based methods.",http://arxiv.org/pdf/2202.11356v1,cs.LG
2022-02-23 03:26:22+00:00,Deep Recurrent Modelling of Granger Causality with Latent Confounding,"['Zexuan Yin', 'Paolo Barucca']","Inferring causal relationships in observational time series data is an
important task when interventions cannot be performed. Granger causality is a
popular framework to infer potential causal mechanisms between different time
series. The original definition of Granger causality is restricted to linear
processes and leads to spurious conclusions in the presence of a latent
confounder. In this work, we harness the expressive power of recurrent neural
networks and propose a deep learning-based approach to model non-linear Granger
causality by directly accounting for latent confounders. Our approach leverages
multiple recurrent neural networks to parameterise predictive distributions and
we propose the novel use of a dual-decoder setup to conduct the Granger tests.
We demonstrate the model performance on non-linear stochastic time series for
which the latent confounder influences the cause and effect with different time
lags; results show the effectiveness of our model compared to existing
benchmarks.",http://arxiv.org/pdf/2202.11286v1,cs.LG
2022-02-22 10:58:26+00:00,Combating Distribution Shift for Accurate Time Series Forecasting via Hypernetworks,"['Wenying Duan', 'Xiaoxi He', 'Lu Zhou', 'Lothar Thiele', 'Hong Rao']","Time series forecasting has widespread applications in urban life ranging
from air quality monitoring to traffic analysis. However, accurate time series
forecasting is challenging because real-world time series suffer from the
distribution shift problem, where their statistical properties change over
time. Despite extensive solutions to distribution shifts in domain adaptation
or generalization, they fail to function effectively in unknown,
constantly-changing distribution shifts, which are common in time series. In
this paper, we propose Hyper Time- Series Forecasting (HTSF), a
hypernetwork-based framework for accurate time series forecasting under
distribution shift. HTSF jointly learns the time-varying distributions and the
corresponding forecasting models in an end-to-end fashion. Specifically, HTSF
exploits the hyper layers to learn the best characterization of the
distribution shifts, generating the model parameters for the main layers to
make accurate predictions. We implement HTSF as an extensible framework that
can incorporate diverse time series forecasting models such as RNNs and
Transformers. Extensive experiments on 9 benchmarks demonstrate that HTSF
achieves state-of-the-art performances.",http://arxiv.org/pdf/2202.10808v2,cs.LG
2022-02-21 05:47:22+00:00,Recurrent Auto-Encoder With Multi-Resolution Ensemble and Predictive Coding for Multivariate Time-Series Anomaly Detection,"['Heejeong Choi', 'Subin Kim', 'Pilsung Kang']","As large-scale time-series data can easily be found in real-world
applications, multivariate time-series anomaly detection has played an
essential role in diverse industries. It enables productivity improvement and
maintenance cost reduction by preventing malfunctions and detecting anomalies
based on time-series data. However, multivariate time-series anomaly detection
is challenging because real-world time-series data exhibit complex temporal
dependencies. For this task, it is crucial to learn a rich representation that
effectively contains the nonlinear temporal dynamics of normal behavior. In
this study, we propose an unsupervised multivariate time-series anomaly
detection model named RAE-MEPC which learns informative normal representations
based on multi-resolution ensemble and predictive coding. We introduce
multi-resolution ensemble encoding to capture the multi-scale dependency from
the input time series. The encoder hierarchically aggregates the temporal
features extracted from the sub-encoders with different encoding lengths. From
these encoded features, the reconstruction decoder reconstructs the input time
series based on multi-resolution ensemble decoding where lower-resolution
information helps to decode sub-decoders with higher-resolution outputs.
Predictive coding is further introduced to encourage the model to learn the
temporal dependencies of the time series. Experiments on real-world benchmark
datasets show that the proposed model outperforms the benchmark models for
multivariate time-series anomaly detection.",http://arxiv.org/pdf/2202.10001v1,cs.LG
2022-02-18 14:45:58+00:00,A multivariate extension of the Misspecification-Resistant Information Criterion,"['Gery Andrés Díaz Rubio', 'Simone Giannerini', 'Greta Goracci']","The Misspecification-Resistant Information Criterion (MRIC) proposed in
[H.-L. Hsu, C.-K. Ing, H. Tong: On model selection from a finite family of
possibly misspecified time series models. The Annals of Statistics. 47 (2),
1061--1087 (2019)] is a model selection criterion for univariate parametric
time series that enjoys both the property of consistency and asymptotic
efficiency. In this article we extend the MRIC to the case where the response
is a multivariate time series and the predictor is univariate. The extension
requires novel derivations based upon random matrix theory. We obtain an
asymptotic expression for the mean squared prediction error matrix, the
vectorial MRIC and prove the consistency of its method-of-moments estimator.
Moreover, we prove its asymptotic efficiency. Finally, we show with an example
that, in presence of misspecification, the vectorial MRIC identifies the best
predictive model whereas traditional information criteria like AIC or BIC fail
to achieve the task.",http://arxiv.org/pdf/2202.09225v1,math.ST
2022-02-17 16:54:20+00:00,Ensemble Conformalized Quantile Regression for Probabilistic Time Series Forecasting,"['Vilde Jensen', 'Filippo Maria Bianchi', 'Stian Norman Anfinsen']","This paper presents a novel probabilistic forecasting method called ensemble
conformalized quantile regression (EnCQR). EnCQR constructs distribution-free
and approximately marginally valid prediction intervals (PIs), which are
suitable for nonstationary and heteroscedastic time series data. EnCQR can be
applied on top of a generic forecasting model, including deep learning
architectures. EnCQR exploits a bootstrap ensemble estimator, which enables the
use of conformal predictors for time series by removing the requirement of data
exchangeability. The ensemble learners are implemented as generic machine
learning algorithms performing quantile regression, which allow the length of
the PIs to adapt to local variability in the data. In the experiments, we
predict time series characterized by a different amount of heteroscedasticity.
The results demonstrate that EnCQR outperforms models based only on quantile
regression or conformal prediction, and it provides sharper, more informative,
and valid PIs.",http://arxiv.org/pdf/2202.08756v2,cs.LG
2022-02-17 08:40:42+00:00,SAITS: Self-Attention-based Imputation for Time Series,"['Wenjie Du', 'David Cote', 'Yan Liu']","Missing data in time series is a pervasive problem that puts obstacles in the
way of advanced analysis. A popular solution is imputation, where the
fundamental challenge is to determine what values should be filled in. This
paper proposes SAITS, a novel method based on the self-attention mechanism for
missing value imputation in multivariate time series. Trained by a
joint-optimization approach, SAITS learns missing values from a weighted
combination of two diagonally-masked self-attention (DMSA) blocks. DMSA
explicitly captures both the temporal dependencies and feature correlations
between time steps, which improves imputation accuracy and training speed.
Meanwhile, the weighted-combination design enables SAITS to dynamically assign
weights to the learned representations from two DMSA blocks according to the
attention map and the missingness information. Extensive experiments
quantitatively and qualitatively demonstrate that SAITS outperforms the
state-of-the-art methods on the time-series imputation task efficiently and
reveal SAITS' potential to improve the learning performance of pattern
recognition models on incomplete time-series data from the real world. The code
is open source on GitHub at https://github.com/WenjieDu/SAITS.",http://arxiv.org/pdf/2202.08516v5,cs.LG
2022-02-17 02:17:31+00:00,Multivariate Time Series Forecasting with Dynamic Graph Neural ODEs,"['Ming Jin', 'Yu Zheng', 'Yuan-Fang Li', 'Siheng Chen', 'Bin Yang', 'Shirui Pan']","Multivariate time series forecasting has long received significant attention
in real-world applications, such as energy consumption and traffic prediction.
While recent methods demonstrate good forecasting abilities, they have three
fundamental limitations. (i) Discrete neural architectures: Interlacing
individually parameterized spatial and temporal blocks to encode rich
underlying patterns leads to discontinuous latent state trajectories and higher
forecasting numerical errors. (ii) High complexity: Discrete approaches
complicate models with dedicated designs and redundant parameters, leading to
higher computational and memory overheads. (iii) Reliance on graph priors:
Relying on predefined static graph structures limits their effectiveness and
practicability in real-world applications. In this paper, we address all the
above limitations by proposing a continuous model to forecast
$\textbf{M}$ultivariate $\textbf{T}$ime series with dynamic $\textbf{G}$raph
neural $\textbf{O}$rdinary $\textbf{D}$ifferential $\textbf{E}$quations
($\texttt{MTGODE}$). Specifically, we first abstract multivariate time series
into dynamic graphs with time-evolving node features and unknown graph
structures. Then, we design and solve a neural ODE to complement missing graph
topologies and unify both spatial and temporal message passing, allowing deeper
graph propagation and fine-grained temporal information aggregation to
characterize stable and precise latent spatial-temporal dynamics. Our
experiments demonstrate the superiorities of $\texttt{MTGODE}$ from various
perspectives on five time series benchmark datasets.",http://arxiv.org/pdf/2202.08408v2,cs.LG
2022-02-16 13:33:13+00:00,HDC-MiniROCKET: Explicit Time Encoding in Time Series Classification with Hyperdimensional Computing,"['Kenny Schlegel', 'Peer Neubert', 'Peter Protzel']","Classification of time series data is an important task for many application
domains. One of the best existing methods for this task, in terms of accuracy
and computation time, is MiniROCKET. In this work, we extend this approach to
provide better global temporal encodings using hyperdimensional computing (HDC)
mechanisms. HDC (also known as Vector Symbolic Architectures, VSA) is a general
method to explicitly represent and process information in high-dimensional
vectors. It has previously been used successfully in combination with deep
neural networks and other signal processing algorithms. We argue that the
internal high-dimensional representation of MiniROCKET is well suited to be
complemented by the algebra of HDC. This leads to a more general formulation,
HDC-MiniROCKET, where the original algorithm is only a special case. We will
discuss and demonstrate that HDC-MiniROCKET can systematically overcome
catastrophic failures of MiniROCKET on simple synthetic datasets. These results
are confirmed by experiments on the 128 datasets from the UCR time series
classification benchmark. The extension with HDC can achieve considerably
better results on datasets with high temporal dependence without increasing the
computational effort for inference.",http://arxiv.org/pdf/2202.08055v1,cs.LG
2022-02-16 09:40:13+00:00,TimeREISE: Time-series Randomized Evolving Input Sample Explanation,"['Dominique Mercier', 'Andreas Dengel', 'Sheraz Ahmed']","Deep neural networks are one of the most successful classifiers across
different domains. However, due to their limitations concerning
interpretability their use is limited in safety critical context. The research
field of explainable artificial intelligence addresses this problem. However,
most of the interpretability methods are aligned to the image modality by
design. The paper introduces TimeREISE a model agnostic attribution method
specifically aligned to success in the context of time series classification.
The method shows superior performance compared to existing approaches
concerning different well-established measurements. TimeREISE is applicable to
any time series classification network, its runtime does not scale in a linear
manner concerning the input shape and it does not rely on prior data knowledge.",http://arxiv.org/pdf/2202.07952v2,cs.LG
2022-02-16 07:09:04+00:00,Auxiliary Cross-Modal Representation Learning with Triplet Loss Functions for Online Handwriting Recognition,"['Felix Ott', 'David Rügamer', 'Lucas Heublein', 'Bernd Bischl', 'Christopher Mutschler']","Cross-modal representation learning learns a shared embedding between two or
more modalities to improve performance in a given task compared to using only
one of the modalities. Cross-modal representation learning from different data
types -- such as images and time-series data (e.g., audio or text data) --
requires a deep metric learning loss that minimizes the distance between the
modality embeddings. In this paper, we propose to use the contrastive or
triplet loss, which uses positive and negative identities to create sample
pairs with different labels, for cross-modal representation learning between
image and time-series modalities (CMR-IS). By adapting the triplet loss for
cross-modal representation learning, higher accuracy in the main (time-series
classification) task can be achieved by exploiting additional information of
the auxiliary (image classification) task. We present a triplet loss with a
dynamic margin for single label and sequence-to-sequence classification tasks.
We perform extensive evaluations on synthetic image and time-series data, and
on data for offline handwriting recognition (HWR) and on online HWR from
sensor-enhanced pens for classifying written words. Our experiments show an
improved classification accuracy, faster convergence, and better
generalizability due to an improved cross-modal representation. Furthermore,
the more suitable generalizability leads to a better adaptability between
writers for online HWR.",http://arxiv.org/pdf/2202.07901v3,cs.LG
2022-02-16 04:42:53+00:00,Graph-Augmented Normalizing Flows for Anomaly Detection of Multiple Time Series,"['Enyan Dai', 'Jie Chen']","Anomaly detection is a widely studied task for a broad variety of data types;
among them, multiple time series appear frequently in applications, including
for example, power grids and traffic networks. Detecting anomalies for multiple
time series, however, is a challenging subject, owing to the intricate
interdependencies among the constituent series. We hypothesize that anomalies
occur in low density regions of a distribution and explore the use of
normalizing flows for unsupervised anomaly detection, because of their superior
quality in density estimation. Moreover, we propose a novel flow model by
imposing a Bayesian network among constituent series. A Bayesian network is a
directed acyclic graph (DAG) that models causal relationships; it factorizes
the joint probability of the series into the product of easy-to-evaluate
conditional probabilities. We call such a graph-augmented normalizing flow
approach GANF and propose joint estimation of the DAG with flow parameters. We
conduct extensive experiments on real-world datasets and demonstrate the
effectiveness of GANF for density estimation, anomaly detection, and
identification of time series distribution drift.",http://arxiv.org/pdf/2202.07857v2,cs.LG
2022-02-15 17:19:44+00:00,Deep Generative model with Hierarchical Latent Factors for Time Series Anomaly Detection,"['Cristian Challu', 'Peihong Jiang', 'Ying Nian Wu', 'Laurent Callot']","Multivariate time series anomaly detection has become an active area of
research in recent years, with Deep Learning models outperforming previous
approaches on benchmark datasets. Among reconstruction-based models, most
previous work has focused on Variational Autoencoders and Generative
Adversarial Networks. This work presents DGHL, a new family of generative
models for time series anomaly detection, trained by maximizing the observed
likelihood by posterior sampling and alternating back-propagation. A top-down
Convolution Network maps a novel hierarchical latent space to time series
windows, exploiting temporal dynamics to encode information efficiently.
Despite relying on posterior sampling, it is computationally more efficient
than current approaches, with up to 10x shorter training times than RNN based
models. Our method outperformed current state-of-the-art models on four popular
benchmark datasets. Finally, DGHL is robust to variable features between
entities and accurate even with large proportions of missing values, settings
with increasing relevance with the advent of IoT. We demonstrate the superior
robustness of DGHL with novel occlusion experiments in this literature. Our
code is available at https://github.com/cchallu/dghl.",http://arxiv.org/pdf/2202.07586v2,cs.LG
2022-02-15 09:57:01+00:00,Adaptive Conformal Predictions for Time Series,"['Margaux Zaffran', 'Aymeric Dieuleveut', 'Olivier Féron', 'Yannig Goude', 'Julie Josse']","Uncertainty quantification of predictive models is crucial in decision-making
problems. Conformal prediction is a general and theoretically sound answer.
However, it requires exchangeable data, excluding time series. While recent
works tackled this issue, we argue that Adaptive Conformal Inference (ACI,
Gibbs and Cand{\`e}s, 2021), developed for distribution-shift time series, is a
good procedure for time series with general dependency. We theoretically
analyse the impact of the learning rate on its efficiency in the exchangeable
and auto-regressive case. We propose a parameter-free method, AgACI, that
adaptively builds upon ACI based on online expert aggregation. We lead
extensive fair simulations against competing methods that advocate for ACI's
use in time series. We conduct a real case study: electricity price
forecasting. The proposed aggregation algorithm provides efficient prediction
intervals for day-ahead forecasting. All the code and data to reproduce the
experiments is made available.",http://arxiv.org/pdf/2202.07282v1,stat.ML
2022-02-15 01:43:27+00:00,Transformers in Time Series: A Survey,"['Qingsong Wen', 'Tian Zhou', 'Chaoli Zhang', 'Weiqi Chen', 'Ziqing Ma', 'Junchi Yan', 'Liang Sun']","Transformers have achieved superior performances in many tasks in natural
language processing and computer vision, which also triggered great interest in
the time series community. Among multiple advantages of Transformers, the
ability to capture long-range dependencies and interactions is especially
attractive for time series modeling, leading to exciting progress in various
time series applications. In this paper, we systematically review Transformer
schemes for time series modeling by highlighting their strengths as well as
limitations. In particular, we examine the development of time series
Transformers in two perspectives. From the perspective of network structure, we
summarize the adaptations and modifications that have been made to Transformers
in order to accommodate the challenges in time series analysis. From the
perspective of applications, we categorize time series Transformers based on
common tasks including forecasting, anomaly detection, and classification.
Empirically, we perform robust analysis, model size analysis, and
seasonal-trend decomposition analysis to study how Transformers perform in time
series. Finally, we discuss and suggest future directions to provide useful
research guidance. To the best of our knowledge, this paper is the first work
to comprehensively and systematically summarize the recent advances of
Transformers for modeling time series data. We hope this survey will ignite
further research interests in time series Transformers.",http://arxiv.org/pdf/2202.07125v5,cs.LG
2022-02-14 10:28:51+00:00,"Statistical Inference for the Dynamic Time Warping Distance, with Application to Abnormal Time-Series Detection","['Vo Nguyen Le Duy', 'Ichiro Takeuchi']","We study statistical inference on the similarity/distance between two
time-series under uncertain environment by considering a statistical hypothesis
test on the distance obtained from Dynamic Time Warping (DTW) algorithm. The
sampling distribution of the DTW distance is too difficult to derive because it
is obtained based on the solution of the DTW algorithm, which is complicated.
To circumvent this difficulty, we propose to employ the conditional selective
inference framework, which enables us to derive a valid inference method on the
DTW distance. To our knowledge, this is the first method that can provide a
valid p-value to quantify the statistical significance of the DTW distance,
which is helpful for high-stake decision making such as abnormal time-series
detection problems. We evaluate the performance of the proposed inference
method on both synthetic and real-world datasets.",http://arxiv.org/pdf/2202.06593v3,stat.ML
2022-02-11 23:30:49+00:00,POT-flavored estimator of Pickands dependence function,['Nan Zou'],"This work proposes an estimator with both Peak-Over-Threshold and
Block-Maxima flavors, uses it to estimate the Pickands dependence function of
bivariate time series, and illustrates how it brings down the asymptotic bias
and the overall mean squared error.",http://arxiv.org/pdf/2202.05935v1,stat.ME
2022-02-11 14:55:56+00:00,InterpretTime: a new approach for the systematic evaluation of neural-network interpretability in time series classification,"['Hugues Turbé', 'Mina Bjelogrlic', 'Christian Lovis', 'Gianmarco Mengaldo']","We present a novel approach to evaluate the performance of interpretability
methods for time series classification, and propose a new strategy to assess
the similarity between domain experts and machine data interpretation. The
novel approach leverages a new family of synthetic datasets and introduces new
interpretability evaluation metrics. The approach addresses several common
issues encountered in the literature, and clearly depicts how well an
interpretability method is capturing neural network's data usage, providing a
systematic interpretability evaluation framework. The new methodology
highlights the superiority of Shapley Value Sampling and Integrated Gradients
for interpretability in time-series classification tasks.",http://arxiv.org/pdf/2202.05656v1,cs.LG
2022-02-09 17:06:20+00:00,Nowcasting with leading indicators applied to COVID-19 fatalities in Sweden,"['Fanny Bergström', 'Felix Günther', 'Michael Höhle', 'Tom Britton']","The real-time analysis of infectious disease surveillance data, e.g., in the
form of a time-series of reported cases or fatalities, is essential in
obtaining situational awareness about the current dynamics of an adverse health
event such as the COVID-19 pandemic. This real-time analysis is complicated by
reporting delays that lead to underreporting of the number of events for the
most recent time points (e.g., days or weeks). This can lead to misconceptions
by the interpreter, e.g., the media or the public, as was the case with the
time-series of reported fatalities during the COVID-19 pandemic in Sweden.
Nowcasting methods provide real-time estimates of the complete number of events
using the incomplete time-series of currently reported events by using
information about the reporting delays from the past. Here, we consider
nowcasting the number of COVID-19-related fatalities in Sweden. We propose a
flexible Bayesian approach, extending existing nowcasting methods by
incorporating regression components to accommodate additional information
provided by leading indicators such as time-series of the number of reported
cases and ICU admissions. By a retrospective evaluation, we show that the
inclusion of ICU admissions as a leading signal improved the nowcasting
performance of case fatalities for COVID-19 in Sweden compared to existing
methods.",http://arxiv.org/pdf/2202.04569v3,stat.ME
2022-02-08 18:58:53+00:00,Time Series Anomaly Detection by Cumulative Radon Features,['Yedid Hoshen'],"Detecting anomalous time series is key for scientific, medical and industrial
tasks, but is challenging due to its inherent unsupervised nature. In recent
years, progress has been made on this task by learning increasingly more
complex features, often using deep neural networks. In this work, we argue that
shallow features suffice when combined with distribution distance measures. Our
approach models each time series as a high dimensional empirical distribution
of features, where each time-point constitutes a single sample. Modeling the
distance between a test time series and the normal training set therefore
requires efficiently measuring the distance between multivariate probability
distributions. We show that by parameterizing each time series using cumulative
Radon features, we are able to efficiently and effectively model the
distribution of normal time series. Our theoretically grounded but
simple-to-implement approach is evaluated on multiple datasets and shown to
achieve better results than established, classical methods as well as complex,
state-of-the-art deep learning methods. Code is provided.",http://arxiv.org/pdf/2202.04067v1,cs.LG
2022-02-08 15:51:31+00:00,Detecting Anomalies within Time Series using Local Neural Transformations,"['Tim Schneider', 'Chen Qiu', 'Marius Kloft', 'Decky Aspandi Latif', 'Steffen Staab', 'Stephan Mandt', 'Maja Rudolph']","We develop a new method to detect anomalies within time series, which is
essential in many application domains, reaching from self-driving cars,
finance, and marketing to medical diagnosis and epidemiology. The method is
based on self-supervised deep learning that has played a key role in
facilitating deep anomaly detection on images, where powerful image
transformations are available. However, such transformations are widely
unavailable for time series. Addressing this, we develop Local Neural
Transformations(LNT), a method learning local transformations of time series
from data. The method produces an anomaly score for each time step and thus can
be used to detect anomalies within time series. We prove in a theoretical
analysis that our novel training objective is more suitable for transformation
learning than previous deep Anomaly detection(AD) methods. Our experiments
demonstrate that LNT can find anomalies in speech segments from the LibriSpeech
data set and better detect interruptions to cyber-physical systems than
previous work. Visualization of the learned transformations gives insight into
the type of transformations that LNT learns.",http://arxiv.org/pdf/2202.03944v2,cs.LG
2022-02-08 14:04:08+00:00,Unsupervised Time-Series Representation Learning with Iterative Bilinear Temporal-Spectral Fusion,"['Ling Yang', 'Shenda Hong']","Unsupervised/self-supervised time series representation learning is a
challenging problem because of its complex dynamics and sparse annotations.
Existing works mainly adopt the framework of contrastive learning with the
time-based augmentation techniques to sample positives and negatives for
contrastive training. Nevertheless, they mostly use segment-level augmentation
derived from time slicing, which may bring about sampling bias and incorrect
optimization with false negatives due to the loss of global context. Besides,
they all pay no attention to incorporate the spectral information in feature
representation. In this paper, we propose a unified framework, namely Bilinear
Temporal-Spectral Fusion (BTSF). Specifically, we firstly utilize the
instance-level augmentation with a simple dropout on the entire time series for
maximally capturing long-term dependencies. We devise a novel iterative
bilinear temporal-spectral fusion to explicitly encode the affinities of
abundant time-frequency pairs, and iteratively refines representations in a
fusion-and-squeeze manner with Spectrum-to-Time (S2T) and Time-to-Spectrum
(T2S) Aggregation modules. We firstly conducts downstream evaluations on three
major tasks for time series including classification, forecasting and anomaly
detection. Experimental results shows that our BTSF consistently significantly
outperforms the state-of-the-art methods.",http://arxiv.org/pdf/2202.04770v3,cs.LG
2022-02-08 14:02:41+00:00,Spectral Propagation Graph Network for Few-shot Time Series Classification,"['Ling Yang', 'Shenda Hong', 'Luxia Zhang']","Few-shot Time Series Classification (few-shot TSC) is a challenging problem
in time series analysis. It is more difficult to classify when time series of
the same class are not completely consistent in spectral domain or time series
of different classes are partly consistent in spectral domain. To address this
problem, we propose a novel method named Spectral Propagation Graph Network
(SPGN) to explicitly model and propagate the spectrum-wise relations between
different time series with graph network. To the best of our knowledge, SPGN is
the first to utilize spectral comparisons in different intervals and involve
spectral propagation across all time series with graph networks for few-shot
TSC. SPGN first uses bandpass filter to expand time series in spectral domain
for calculating spectrum-wise relations between time series. Equipped with
graph networks, SPGN then integrates spectral relations with label information
to make spectral propagation. The further study conveys the bi-directional
effect between spectral relations acquisition and spectral propagation. We
conduct extensive experiments on few-shot TSC benchmarks. SPGN outperforms
state-of-the-art results by a large margin in $4\% \sim 13\%$. Moreover, SPGN
surpasses them by around $12\%$ and $9\%$ under cross-domain and cross-way
settings respectively.",http://arxiv.org/pdf/2202.04769v3,cs.LG
2022-02-08 04:25:29+00:00,Contrastive predictive coding for Anomaly Detection in Multi-variate Time Series Data,"['Theivendiram Pranavan', 'Terence Sim', 'Arulmurugan Ambikapathi', 'Savitha Ramasamy']","Anomaly detection in multi-variate time series (MVTS) data is a huge
challenge as it requires simultaneous representation of long term temporal
dependencies and correlations across multiple variables. More often, this is
solved by breaking the complexity through modeling one dependency at a time. In
this paper, we propose a Time-series Representational Learning through
Contrastive Predictive Coding (TRL-CPC) towards anomaly detection in MVTS data.
First, we jointly optimize an encoder, an auto-regressor and a non-linear
transformation function to effectively learn the representations of the MVTS
data sets, for predicting future trends. It must be noted that the context
vectors are representative of the observation window in the MTVS. Next, the
latent representations for the succeeding instants obtained through non-linear
transformations of these context vectors, are contrasted with the latent
representations of the encoder for the multi-variables such that the density
for the positive pair is maximized. Thus, the TRL-CPC helps to model the
temporal dependencies and the correlations of the parameters for a healthy
signal pattern. Finally, fitting the latent representations are fit into a
Gaussian scoring function to detect anomalies. Evaluation of the proposed
TRL-CPC on three MVTS data sets against SOTA anomaly detection methods shows
the superiority of TRL-CPC.",http://arxiv.org/pdf/2202.03639v1,cs.LG
2022-02-07 22:01:58+00:00,Structured Time Series Prediction without Structural Prior,"['Darko Drakulic', 'Jean-Marc Andreoli']","Time series prediction is a widespread and well studied problem with
applications in many domains (medical, geoscience, network analysis, finance,
econometry etc.). In the case of multivariate time series, the key to good
performances is to properly capture the dependencies between the variates.
Often, these variates are structured, i.e. they are localised in an abstract
space, usually representing an aspect of the physical world, and prediction
amounts to a form of diffusion of the information across that space over time.
Several neural network models of diffusion have been proposed in the
literature. However, most of the existing proposals rely on some a priori
knowledge on the structure of the space, usually in the form of a graph
weighing the pairwise diffusion capacity of its points. We argue that this
piece of information can often be dispensed with, since data already contains
the diffusion capacity information, and in a more reliable form than that
obtained from the usually largely hand-crafted graphs. We propose instead a
fully data-driven model which does not rely on such a graph, nor any other
prior structural information. We conduct a first set of experiments to measure
the impact on performance of a structural prior, as used in baseline models,
and show that, except at very low data levels, it remains negligible, and
beyond a threshold, it may even become detrimental. We then investigate,
through a second set of experiments, the capacity of our model in two respects:
treatment of missing data and domain adaptation.",http://arxiv.org/pdf/2202.03539v1,cs.LG
2022-02-07 21:37:29+00:00,TACTiS: Transformer-Attentional Copulas for Time Series,"['Alexandre Drouin', 'Étienne Marcotte', 'Nicolas Chapados']","The estimation of time-varying quantities is a fundamental component of
decision making in fields such as healthcare and finance. However, the
practical utility of such estimates is limited by how accurately they quantify
predictive uncertainty. In this work, we address the problem of estimating the
joint predictive distribution of high-dimensional multivariate time series. We
propose a versatile method, based on the transformer architecture, that
estimates joint distributions using an attention-based decoder that provably
learns to mimic the properties of non-parametric copulas. The resulting model
has several desirable properties: it can scale to hundreds of time series,
supports both forecasting and interpolation, can handle unaligned and
non-uniformly sampled data, and can seamlessly adapt to missing data during
training. We demonstrate these properties empirically and show that our model
produces state-of-the-art predictions on multiple real-world datasets.",http://arxiv.org/pdf/2202.03528v2,cs.LG
2022-02-07 16:22:33+00:00,Forecasting Environmental Data: An example to ground-level ozone concentration surfaces,"['Alexander Gleim', 'Nazarii Salish']","Environmental problems are receiving increasing attention in socio-economic
and health studies. This in turn fosters advances in recording and data
collection of many related real-life processes. Available tools for data
processing are often found too restrictive as they do not account for the rich
nature of such data sets. In this paper, we propose a new statistical
perspective on forecasting spatial environmental data collected sequentially
over time. We treat this data set as a surface (functional) time series with a
possibly complicated geographical domain. By employing novel techniques from
functional data analysis we develop a new forecasting methodology. Our approach
consists of two steps. In the first step, time series of surfaces are
reconstructed from measurements sampled over some spatial domain using a finite
element spline smoother. In the second step, we adapt the dynamic functional
factor model to forecast a surface time series. The advantage of this approach
is that we can account for and explore simultaneously spatial as well as
temporal dependencies in the data. A forecasting study of ground-level ozone
concentration over the geographical domain of Germany demonstrates the
practical value of this new perspective, where we compare our approach with
standard functional benchmark models.",http://arxiv.org/pdf/2202.03332v1,stat.ME
2022-02-06 07:09:57+00:00,Robust Anomaly Detection for Time-series Data,"['Min Hu', 'Yi Wang', 'Xiaowei Feng', 'Shengchen Zhou', 'Zhaoyu Wu', 'Yuan Qin']","Time-series anomaly detection plays a vital role in monitoring complex
operation conditions. However, the detection accuracy of existing approaches is
heavily influenced by pattern distribution, existence of multiple normal
patterns, dynamical features representation, and parameter settings. For the
purpose of improving the robustness and guaranteeing the accuracy, this
research combined the strengths of negative selection, unthresholded recurrence
plots, and an extreme learning machine autoencoder and then proposed robust
anomaly detection for time-series data (RADTD), which can automatically learn
dynamical features in time series and recognize anomalies with low label
dependency and high robustness. Yahoo benchmark datasets and three tunneling
engineering simulation experiments were used to evaluate the performance of
RADTD. The experiments showed that in benchmark datasets RADTD possessed higher
accuracy and robustness than recurrence qualification analysis and extreme
learning machine autoencoder, respectively, and that RADTD accurately detected
the occurrence of tunneling settlement accidents, indicating its remarkable
performance in accuracy and robustness.",http://arxiv.org/pdf/2202.02721v1,cs.LG
2022-02-06 03:05:47+00:00,TTS-GAN: A Transformer-based Time-Series Generative Adversarial Network,"['Xiaomin Li', 'Vangelis Metsis', 'Huangyingrui Wang', 'Anne Hee Hiong Ngu']","Signal measurements appearing in the form of time series are one of the most
common types of data used in medical machine learning applications. However,
such datasets are often small, making the training of deep neural network
architectures ineffective. For time-series, the suite of data augmentation
tricks we can use to expand the size of the dataset is limited by the need to
maintain the basic properties of the signal. Data generated by a Generative
Adversarial Network (GAN) can be utilized as another data augmentation tool.
RNN-based GANs suffer from the fact that they cannot effectively model long
sequences of data points with irregular temporal relations. To tackle these
problems, we introduce TTS-GAN, a transformer-based GAN which can successfully
generate realistic synthetic time-series data sequences of arbitrary length,
similar to the real ones. Both the generator and discriminator networks of the
GAN model are built using a pure transformer encoder architecture. We use
visualizations and dimensionality reduction techniques to demonstrate the
similarity of real and generated time-series data. We also compare the quality
of our generated data with the best existing alternative, which is an RNN-based
time-series GAN.",http://arxiv.org/pdf/2202.02691v2,cs.LG
2022-02-04 21:54:10+00:00,Self-Adaptive Forecasting for Improved Deep Learning on Non-Stationary Time-Series,"['Sercan O. Arik', 'Nathanael C. Yoder', 'Tomas Pfister']","Real-world time-series datasets often violate the assumptions of standard
supervised learning for forecasting -- their distributions evolve over time,
rendering the conventional training and model selection procedures suboptimal.
In this paper, we propose a novel method, Self-Adaptive Forecasting (SAF), to
modify the training of time-series forecasting models to improve their
performance on forecasting tasks with such non-stationary time-series data. SAF
integrates a self-adaptation stage prior to forecasting based on `backcasting',
i.e. predicting masked inputs backward in time. This is a form of test-time
training that creates a self-supervised learning problem on test samples before
performing the prediction task. In this way, our method enables efficient
adaptation of encoded representations to evolving distributions, leading to
superior generalization. SAF can be integrated with any canonical
encoder-decoder based time-series architecture such as recurrent neural
networks or attention-based architectures. On synthetic and real-world datasets
in domains where time-series data are known to be notoriously non-stationary,
such as healthcare and finance, we demonstrate a significant benefit of SAF in
improving forecasting accuracy.",http://arxiv.org/pdf/2202.02403v3,cs.LG
2022-02-04 17:46:04+00:00,Decoupling Local and Global Representations of Time Series,"['Sana Tonekaboni', 'Chun-Liang Li', 'Sercan Arik', 'Anna Goldenberg', 'Tomas Pfister']","Real-world time series data are often generated from several sources of
variation. Learning representations that capture the factors contributing to
this variability enables a better understanding of the data via its underlying
generative process and improves performance on downstream machine learning
tasks. This paper proposes a novel generative approach for learning
representations for the global and local factors of variation in time series.
The local representation of each sample models non-stationarity over time with
a stochastic process prior, and the global representation of the sample encodes
the time-independent characteristics. To encourage decoupling between the
representations, we introduce counterfactual regularization that minimizes the
mutual information between the two variables. In experiments, we demonstrate
successful recovery of the true local and global variability factors on
simulated data, and show that representations learned using our method yield
superior performance on downstream tasks on real-world datasets. We believe
that the proposed way of defining representations is beneficial for data
modelling and yields better insights into the complexity of real-world data.",http://arxiv.org/pdf/2202.02262v2,cs.LG
2022-02-03 17:26:27+00:00,Review of automated time series forecasting pipelines,"['Stefan Meisenbacher', 'Marian Turowski', 'Kaleb Phipps', 'Martin Rätz', 'Dirk Müller', 'Veit Hagenmeyer', 'Ralf Mikut']","Time series forecasting is fundamental for various use cases in different
domains such as energy systems and economics. Creating a forecasting model for
a specific use case requires an iterative and complex design process. The
typical design process includes the five sections (1) data pre-processing, (2)
feature engineering, (3) hyperparameter optimization, (4) forecasting method
selection, and (5) forecast ensembling, which are commonly organized in a
pipeline structure. One promising approach to handle the ever-growing demand
for time series forecasts is automating this design process. The present paper,
thus, analyzes the existing literature on automated time series forecasting
pipelines to investigate how to automate the design process of forecasting
models. Thereby, we consider both Automated Machine Learning (AutoML) and
automated statistical forecasting methods in a single forecasting pipeline. For
this purpose, we firstly present and compare the proposed automation methods
for each pipeline section. Secondly, we analyze the automation methods
regarding their interaction, combination, and coverage of the five pipeline
sections. For both, we discuss the literature, identify problems, give
recommendations, and suggest future research. This review reveals that the
majority of papers only cover two or three of the five pipeline sections. We
conclude that future research has to holistically consider the automation of
the forecasting pipeline to enable the large-scale application of time series
forecasting.",http://arxiv.org/pdf/2202.01712v1,cs.LG
2022-02-03 13:17:38+00:00,CoST: Contrastive Learning of Disentangled Seasonal-Trend Representations for Time Series Forecasting,"['Gerald Woo', 'Chenghao Liu', 'Doyen Sahoo', 'Akshat Kumar', 'Steven Hoi']","Deep learning has been actively studied for time series forecasting, and the
mainstream paradigm is based on the end-to-end training of neural network
architectures, ranging from classical LSTM/RNNs to more recent TCNs and
Transformers. Motivated by the recent success of representation learning in
computer vision and natural language processing, we argue that a more promising
paradigm for time series forecasting, is to first learn disentangled feature
representations, followed by a simple regression fine-tuning step -- we justify
such a paradigm from a causal perspective. Following this principle, we propose
a new time series representation learning framework for time series forecasting
named CoST, which applies contrastive learning methods to learn disentangled
seasonal-trend representations. CoST comprises both time domain and frequency
domain contrastive losses to learn discriminative trend and seasonal
representations, respectively. Extensive experiments on real-world datasets
show that CoST consistently outperforms the state-of-the-art methods by a
considerable margin, achieving a 21.3% improvement in MSE on multivariate
benchmarks. It is also robust to various choices of backbone encoders, as well
as downstream regressors. Code is available at
https://github.com/salesforce/CoST.",http://arxiv.org/pdf/2202.01575v3,cs.LG
2022-02-03 02:50:44+00:00,ETSformer: Exponential Smoothing Transformers for Time-series Forecasting,"['Gerald Woo', 'Chenghao Liu', 'Doyen Sahoo', 'Akshat Kumar', 'Steven Hoi']","Transformers have been actively studied for time-series forecasting in recent
years. While often showing promising results in various scenarios, traditional
Transformers are not designed to fully exploit the characteristics of
time-series data and thus suffer some fundamental limitations, e.g., they
generally lack of decomposition capability and interpretability, and are
neither effective nor efficient for long-term forecasting. In this paper, we
propose ETSFormer, a novel time-series Transformer architecture, which exploits
the principle of exponential smoothing in improving Transformers for
time-series forecasting. In particular, inspired by the classical exponential
smoothing methods in time-series forecasting, we propose the novel exponential
smoothing attention (ESA) and frequency attention (FA) to replace the
self-attention mechanism in vanilla Transformers, thus improving both accuracy
and efficiency. Based on these, we redesign the Transformer architecture with
modular decomposition blocks such that it can learn to decompose the
time-series data into interpretable time-series components such as level,
growth and seasonality. Extensive experiments on various time-series benchmarks
validate the efficacy and advantages of the proposed method. Code is available
at https://github.com/salesforce/ETSformer.",http://arxiv.org/pdf/2202.01381v2,cs.LG
2022-02-02 09:55:55+00:00,Inverse covariance operators of multivariate nonstationary time series,"['Jonas Krampe', 'Suhasini Subba Rao']","For multivariate stationary time series many important properties, such as
partial correlation, graphical models and autoregressive representations are
encoded in the inverse of its spectral density matrix. This is not true for
nonstationary time series, where the pertinent information lies in the inverse
infinite dimensional covariance matrix operator associated with the
multivariate time series. This necessitates the study of the covariance of a
multivariate nonstationary time series and its relationship to its inverse. We
show that if the rows/columns of the infinite dimensional covariance matrix
decay at a certain rate then the rate (up to a factor) transfers to the
rows/columns of the inverse covariance matrix. This is used to obtain a
nonstationary autoregressive representation of the time series and a
Baxter-type bound between the parameters of the autoregressive infinite
representation and the corresponding finite autoregressive projection. The
aforementioned results lay the foundation for the subsequent analysis of
locally stationary time series. In particular, we show that smoothness
properties on the covariance matrix transfer to (i) the inverse covariance (ii)
the parameters of the vector autoregressive representation and (iii) the
partial covariances. All results are set up in such a way that the constants
involved depend only on the eigenvalue of the covariance matrix and can be
applied in the high-dimensional settings with non-diverging eigenvalues.",http://arxiv.org/pdf/2202.00933v3,math.ST
2022-01-31 14:29:45+00:00,Some asymptotic results for time series model selection,['William Kengne'],"We consider the model selection problem for a large class of time series
models, including, multivariate count processes, causal processes with
exogenous covariates. A procedure based on a general penalized contrast is
proposed. Some asymptotic results for weak and strong consistency are
established. The non consistency issue is addressed, and a class of penalty
term, that does not ensure consistency is provided. Examples of continuous
valued and multivariate count autoregressive time series are considered.",http://arxiv.org/pdf/2201.13273v1,math.ST
2022-01-30 06:24:25+00:00,FEDformer: Frequency Enhanced Decomposed Transformer for Long-term Series Forecasting,"['Tian Zhou', 'Ziqing Ma', 'Qingsong Wen', 'Xue Wang', 'Liang Sun', 'Rong Jin']","Although Transformer-based methods have significantly improved
state-of-the-art results for long-term series forecasting, they are not only
computationally expensive but more importantly, are unable to capture the
global view of time series (e.g. overall trend). To address these problems, we
propose to combine Transformer with the seasonal-trend decomposition method, in
which the decomposition method captures the global profile of time series while
Transformers capture more detailed structures. To further enhance the
performance of Transformer for long-term prediction, we exploit the fact that
most time series tend to have a sparse representation in well-known basis such
as Fourier transform, and develop a frequency enhanced Transformer. Besides
being more effective, the proposed method, termed as Frequency Enhanced
Decomposed Transformer ({\bf FEDformer}), is more efficient than standard
Transformer with a linear complexity to the sequence length. Our empirical
studies with six benchmark datasets show that compared with state-of-the-art
methods, FEDformer can reduce prediction error by $14.8\%$ and $22.6\%$ for
multivariate and univariate time series, respectively. Code is publicly
available at https://github.com/MAZiqing/FEDformer.",http://arxiv.org/pdf/2201.12740v3,cs.LG
2022-01-28 11:23:58+00:00,The FreshPRINCE: A Simple Transformation Based Pipeline Time Series Classifier,"['Matthew Middlehurst', 'Anthony Bagnall']","There have recently been significant advances in the accuracy of algorithms
proposed for time series classification (TSC). However, a commonly asked
question by real world practitioners and data scientists less familiar with the
research topic, is whether the complexity of the algorithms considered state of
the art is really necessary. Many times the first approach suggested is a
simple pipeline of summary statistics or other time series feature extraction
approaches such as TSFresh, which in itself is a sensible question; in
publications on TSC algorithms generalised for multiple problem types, we
rarely see these approaches considered or compared against. We experiment with
basic feature extractors using vector based classifiers shown to be effective
with continuous attributes in current state-of-the-art time series classifiers.
We test these approaches on the UCR time series dataset archive, looking to see
if TSC literature has overlooked the effectiveness of these approaches. We find
that a pipeline of TSFresh followed by a rotation forest classifier, which we
name FreshPRINCE, performs best. It is not state of the art, but it is
significantly more accurate than nearest neighbour with dynamic time warping,
and represents a reasonable benchmark for future comparison.",http://arxiv.org/pdf/2201.12048v1,cs.LG
2022-01-28 06:17:24+00:00,Time-Series Anomaly Detection with Implicit Neural Representation,"['Kyeong-Joong Jeong', 'Yong-Min Shin']","Detecting anomalies in multivariate time-series data is essential in many
real-world applications. Recently, various deep learning-based approaches have
shown considerable improvements in time-series anomaly detection. However,
existing methods still have several limitations, such as long training time due
to their complex model designs or costly tuning procedures to find optimal
hyperparameters (e.g., sliding window length) for a given dataset. In our
paper, we propose a novel method called Implicit Neural Representation-based
Anomaly Detection (INRAD). Specifically, we train a simple multi-layer
perceptron that takes time as input and outputs corresponding values at that
time. Then we utilize the representation error as an anomaly score for
detecting anomalies. Experiments on five real-world datasets demonstrate that
our proposed method outperforms other state-of-the-art methods in performance,
training speed, and robustness.",http://arxiv.org/pdf/2201.11950v1,cs.LG
2022-01-27 18:57:49+00:00,Robust Augmentation for Multivariate Time Series Classification,"['Hong Yang', 'Travis Desell']","Neural networks are capable of learning powerful representations of data, but
they are susceptible to overfitting due to the number of parameters. This is
particularly challenging in the domain of time series classification, where
datasets may contain fewer than 100 training examples. In this paper, we show
that the simple methods of cutout, cutmix, mixup, and window warp improve the
robustness and overall performance in a statistically significant way for
convolutional, recurrent, and self-attention based architectures for time
series classification. We evaluate these methods on 26 datasets from the
University of East Anglia Multivariate Time Series Classification (UEA MTSC)
archive and analyze how these methods perform on different types of time series
data.. We show that the InceptionTime network with augmentation improves
accuracy by 1% to 45% in 18 different datasets compared to without
augmentation. We also show that augmentation improves accuracy for recurrent
and self attention based architectures.",http://arxiv.org/pdf/2201.11739v1,cs.LG
2022-01-24 19:03:43+00:00,Ordinal-Quadruplet: Retrieval of Missing Classes in Ordinal Time Series,"['Jurijs Nazarovs', 'Cristian Lumezanu', 'Qianying Ren', 'Yuncong Chen', 'Takehiko Mizoguchi', 'Dongjin Song', 'Haifeng Chen']","In this paper, we propose an ordered time series classification framework
that is robust against missing classes in the training data, i.e., during
testing we can prescribe classes that are missing during training. This
framework relies on two main components: (1) our newly proposed
ordinal-quadruplet loss, which forces the model to learn latent representation
while preserving the ordinal relation among labels, (2) testing procedure,
which utilizes the property of latent representation (order preservation). We
conduct experiments based on real world multivariate time series data and show
the significant improvement in the prediction of missing labels even with 40%
of the classes are missing from training. Compared with the well-known triplet
loss optimization augmented with interpolation for missing information, in some
cases, we nearly double the accuracy.",http://arxiv.org/pdf/2201.09907v1,cs.LG
2022-01-24 13:35:37+00:00,Balanced Graph Structure Learning for Multivariate Time Series Forecasting,"['Weijun Chen', 'Yanze Wang', 'Chengshuo Du', 'Zhenglong Jia', 'Feng Liu', 'Ran Chen']","Accurate forecasting of multivariate time series is an extensively studied
subject in finance, transportation, and computer science. Fully mining the
correlation and causation between the variables in a multivariate time series
exhibits noticeable results in improving the performance of a time series
model. Recently, some models have explored the dependencies between variables
through end-to-end graph structure learning without the need for predefined
graphs. However, current models do not incorporate the trade-off between
efficiency and flexibility and lack the guidance of domain knowledge in the
design of graph structure learning algorithms. This paper alleviates the above
issues by proposing Balanced Graph Structure Learning for Forecasting (BGSLF),
a novel deep learning model that joins graph structure learning and
forecasting. Technically, BGSLF leverages the spatial information into
convolutional operations and extracts temporal dynamics using the diffusion
convolutional recurrent network. The proposed framework balance the trade-off
between efficiency and flexibility by introducing Multi-Graph Generation
Network (MGN) and Graph Selection Module. In addition, a method named Smooth
Sparse Unit (SSU) is designed to sparse the learned graph structures, which
conforms to the sparse spatial correlations in the real world. Extensive
experiments on four real-world datasets demonstrate that our model achieves
state-of-the-art performances with minor trainable parameters. Code will be
made publicly available.",http://arxiv.org/pdf/2201.09686v2,cs.LG
2022-01-23 04:01:43+00:00,An Attention-based ConvLSTM Autoencoder with Dynamic Thresholding for Unsupervised Anomaly Detection in Multivariate Time Series,"['Tareq Tayeh', 'Sulaiman Aburakhia', 'Ryan Myers', 'Abdallah Shami']","As a substantial amount of multivariate time series data is being produced by
the complex systems in Smart Manufacturing, improved anomaly detection
frameworks are needed to reduce the operational risks and the monitoring burden
placed on the system operators. However, building such frameworks is
challenging, as a sufficiently large amount of defective training data is often
not available and frameworks are required to capture both the temporal and
contextual dependencies across different time steps while being robust to
noise. In this paper, we propose an unsupervised Attention-based Convolutional
Long Short-Term Memory (ConvLSTM) Autoencoder with Dynamic Thresholding
(ACLAE-DT) framework for anomaly detection and diagnosis in multivariate time
series. The framework starts by pre-processing and enriching the data, before
constructing feature images to characterize the system statuses across
different time steps by capturing the inter-correlations between pairs of time
series. Afterwards, the constructed feature images are fed into an
attention-based ConvLSTM autoencoder, which aims to encode the constructed
feature images and capture the temporal behavior, followed by decoding the
compressed knowledge representation to reconstruct the feature images input.
The reconstruction errors are then computed and subjected to a
statistical-based, dynamic thresholding mechanism to detect and diagnose the
anomalies. Evaluation results conducted on real-life manufacturing data
demonstrate the performance strengths of the proposed approach over
state-of-the-art methods under different experimental settings.",http://arxiv.org/pdf/2201.09172v1,cs.LG
2022-01-20 16:39:57+00:00,Lead-lag detection and network clustering for multivariate time series with an application to the US equity market,"['Stefanos Bennett', 'Mihai Cucuringu', 'Gesine Reinert']","In multivariate time series systems, it has been observed that certain groups
of variables partially lead the evolution of the system, while other variables
follow this evolution with a time delay; the result is a lead-lag structure
amongst the time series variables. In this paper, we propose a method for the
detection of lead-lag clusters of time series in multivariate systems. We
demonstrate that the web of pairwise lead-lag relationships between time series
can be helpfully construed as a directed network, for which there exist
suitable algorithms for the detection of pairs of lead-lag clusters with high
pairwise imbalance. Within our framework, we consider a number of choices for
the pairwise lead-lag metric and directed network clustering components. Our
framework is validated on both a synthetic generative model for multivariate
lead-lag time series systems and daily real-world US equity prices data. We
showcase that our method is able to detect statistically significant lead-lag
clusters in the US equity market. We study the nature of these clusters in the
context of the empirical finance literature on lead-lag relations and
demonstrate how these can be used for the construction of predictive financial
signals.",http://arxiv.org/pdf/2201.08283v1,stat.ML
2022-01-18 06:43:32+00:00,Online Time Series Anomaly Detection with State Space Gaussian Processes,"['Christian Bock', 'François-Xavier Aubet', 'Jan Gasthaus', 'Andrey Kan', 'Ming Chen', 'Laurent Callot']","We propose r-ssGPFA, an unsupervised online anomaly detection model for uni-
and multivariate time series building on the efficient state space formulation
of Gaussian processes. For high-dimensional time series, we propose an
extension of Gaussian process factor analysis to identify the common latent
processes of the time series, allowing us to detect anomalies efficiently in an
interpretable manner. We gain explainability while speeding up computations by
imposing an orthogonality constraint on the mapping from the latent to the
observed. Our model's robustness is improved by using a simple heuristic to
skip Kalman updates when encountering anomalous observations. We investigate
the behaviour of our model on synthetic data and show on standard benchmark
datasets that our method is competitive with state-of-the-art methods while
being computationally cheaper.",http://arxiv.org/pdf/2201.06763v1,cs.LG
2022-01-16 05:37:02+00:00,Fractional SDE-Net: Generation of Time Series Data with Long-term Memory,"['Kohei Hayashi', 'Kei Nakagawa']","In this paper, we focus on the generation of time-series data using neural
networks. It is often the case that input time-series data have only one
realized (and usually irregularly sampled) path, which makes it difficult to
extract time-series characteristics, and its noise structure is more
complicated than i.i.d. type. Time series data, especially from hydrology,
telecommunications, economics, and finance, exhibit long-term memory also
called long-range dependency (LRD). The main purpose of this paper is to
artificially generate time series with the help of neural networks, making the
LRD of paths into account. We propose fSDE-Net: neural fractional Stochastic
Differential Equation Network. It generalizes the neural stochastic
differential equation model by using fractional Brownian motion with a Hurst
index larger than half, which exhibits the LRD property. We derive the solver
of fSDE-Net and theoretically analyze the existence and uniqueness of the
solution to fSDE-Net. Our experiments with artificial and real time-series data
demonstrate that the fSDE-Net model can replicate distributional properties
well.",http://arxiv.org/pdf/2201.05974v2,cs.LG
2022-01-14 22:51:24+00:00,An efficient aggregation method for the symbolic representation of temporal data,"['Xinye Chen', 'Stefan Güttel']","Symbolic representations are a useful tool for the dimension reduction of
temporal data, allowing for the efficient storage of and information retrieval
from time series. They can also enhance the training of machine learning
algorithms on time series data through noise reduction and reduced sensitivity
to hyperparameters. The adaptive Brownian bridge-based aggregation (ABBA)
method is one such effective and robust symbolic representation, demonstrated
to accurately capture important trends and shapes in time series. However, in
its current form the method struggles to process very large time series. Here
we present a new variant of the ABBA method, called fABBA. This variant
utilizes a new aggregation approach tailored to the piecewise representation of
time series. By replacing the k-means clustering used in ABBA with a
sorting-based aggregation technique, and thereby avoiding repeated
sum-of-squares error computations, the computational complexity is
significantly reduced. In contrast to the original method, the new approach
does not require the number of time series symbols to be specified in advance.
Through extensive tests we demonstrate that the new method significantly
outperforms ABBA with a considerable reduction in runtime while also
outperforming the popular SAX and 1d-SAX representations in terms of
reconstruction accuracy. We further demonstrate that fABBA can compress other
data types such as images.",http://arxiv.org/pdf/2201.05697v1,cs.LG
2022-01-14 19:23:24+00:00,Imputing Missing Observations with Time Sliced Synthetic Minority Oversampling Technique,"['Andrew Baumgartner', 'Sevda Molani', 'Qi Wei', 'Jennifer Hadlock']","We present a simple yet novel time series imputation technique with the goal
of constructing an irregular time series that is uniform across every sample in
a data set. Specifically, we fix a grid defined by the midpoints of
non-overlapping bins (dubbed ""slices"") of observation times and ensure that
each sample has values for all of the features at that given time. This allows
one to both impute fully missing observations to allow uniform time series
classification across the entire data and, in special cases, to impute
individually missing features. To do so, we slightly generalize the well-known
class imbalance algorithm SMOTE \cite{smote} to allow component wise nearest
neighbor interpolation that preserves correlations when there are no missing
features. We visualize the method in the simplified setting of 2-dimensional
uncoupled harmonic oscillators. Next, we use tSMOTE to train an Encoder/Decoder
long-short term memory (LSTM) model with Logistic Regression for predicting and
classifying distinct trajectories of different 2D oscillators. After
illustrating the the utility of tSMOTE in this context, we use the same
architecture to train a clinical model for COVID-19 disease severity on an
imputed data set. Our experiments show an improvement over standard mean and
median imputation techniques by allowing a wider class of patient trajectories
to be recognized by the model, as well as improvement over aggregated
classification models.",http://arxiv.org/pdf/2201.05634v1,cs.LG
2022-01-14 14:02:19+00:00,Multi-head Temporal Attention-Augmented Bilinear Network for Financial time series prediction,"['Mostafa Shabani', 'Dat Thanh Tran', 'Martin Magris', 'Juho Kanniainen', 'Alexandros Iosifidis']","Financial time-series forecasting is one of the most challenging domains in
the field of time-series analysis. This is mostly due to the highly
non-stationary and noisy nature of financial time-series data. With progressive
efforts of the community to design specialized neural networks incorporating
prior domain knowledge, many financial analysis and forecasting problems have
been successfully tackled. The temporal attention mechanism is a neural layer
design that recently gained popularity due to its ability to focus on important
temporal events. In this paper, we propose a neural layer based on the ideas of
temporal attention and multi-head attention to extend the capability of the
underlying neural network in focusing simultaneously on multiple temporal
instances. The effectiveness of our approach is validated using large-scale
limit-order book market data to forecast the direction of mid-price movements.
Our experiments show that the use of multi-head temporal attention modules
leads to enhanced prediction performances compared to baseline models.",http://arxiv.org/pdf/2201.05459v1,cs.LG
2022-01-14 08:24:44+00:00,IDEA: Interpretable Dynamic Ensemble Architecture for Time Series Prediction,"['Mengyue Zha', 'Kani Chen', 'Tong Zhang']","We enhance the accuracy and generalization of univariate time series point
prediction by an explainable ensemble on the fly. We propose an Interpretable
Dynamic Ensemble Architecture (IDEA), in which interpretable base learners give
predictions independently with sparse communication as a group. The model is
composed of several sequentially stacked groups connected by group backcast
residuals and recurrent input competition. Ensemble driven by end-to-end
training both horizontally and vertically brings state-of-the-art (SOTA)
performances. Forecast accuracy improves by 2.6% over the best statistical
benchmark on the TOURISM dataset and 2% over the best deep learning benchmark
on the M4 dataset. The architecture enjoys several advantages, being applicable
to time series from various domains, explainable to users with specialized
modular structure and robust to changes in task distribution.",http://arxiv.org/pdf/2201.05336v1,cs.LG
2022-01-14 08:11:09+00:00,Time Series Generation with Masked Autoencoder,"['Mengyue Zha', 'SiuTim Wong', 'Mengqi Liu', 'Tong Zhang', 'Kani Chen']","This paper shows that masked autoencoder with extrapolator (ExtraMAE) is a
scalable self-supervised model for time series generation. ExtraMAE randomly
masks some patches of the original time series and learns temporal dynamics by
recovering the masked patches. Our approach has two core designs. First,
ExtraMAE is self-supervised. Supervision allows ExtraMAE to effectively and
efficiently capture the temporal dynamics of the original time series. Second,
ExtraMAE proposes an extrapolator to disentangle two jobs of the decoder:
recovering latent representations and mapping them back into the feature space.
These unique designs enable ExtraMAE to consistently and significantly
outperform state-of-the-art (SoTA) benchmarks in time series generation. The
lightweight architecture also makes ExtraMAE fast and scalable. ExtraMAE shows
outstanding behavior in various downstream tasks such as time series
classification, prediction, and imputation. As a self-supervised generative
model, ExtraMAE allows explicit management of the synthetic data. We hope this
paper will usher in a new era of time series generation with self-supervised
models.",http://arxiv.org/pdf/2201.07006v3,cs.LG
2022-01-12 14:38:11+00:00,Generative time series models using Neural ODE in Variational Autoencoders,"['M. L. Garsdal', 'V. Søgaard', 'S. M. Sørensen']","In this paper, we implement Neural Ordinary Differential Equations in a
Variational Autoencoder setting for generative time series modeling. An
object-oriented approach to the code was taken to allow for easier development
and research and all code used in the paper can be found here:
https://github.com/simonmoesorensen/neural-ode-project
  The results were initially recreated and the reconstructions compared to a
baseline Long-Short Term Memory AutoEncoder. The model was then extended with a
LSTM encoder and challenged by more complex data consisting of time series in
the form of spring oscillations. The model showed promise, and was able to
reconstruct true trajectories for all complexities of data with a smaller RMSE
than the baseline model. However, it was able to capture the dynamic behavior
of the time series for known data in the decoder but was not able to produce
extrapolations following the true trajectory very well for any of the
complexities of spring data. A final experiment was carried out where the model
was also presented with 68 days of solar power production data, and was able to
reconstruct just as well as the baseline, even when very little data is
available.
  Finally, the models training time was compared to the baseline. It was found
that for small amounts of data the NODE method was significantly slower at
training than the baseline, while for larger amounts of data the NODE method
would be equal or faster at training.
  The paper is ended with a future work section which describes the many
natural extensions to the work presented in this paper, with examples being
investigating further the importance of input data, including extrapolation in
the baseline model or testing more specific model setups.",http://arxiv.org/pdf/2201.04630v1,cs.LG
2022-01-10 22:00:28+00:00,Positive Time Series Regression Models,"['Taiane Schaedler Prass', 'Jonas Hendler Carlos', 'Cleiton Guolo Taufemback', 'Guilherme Pumi']","In this paper we discuss dynamic ARMA-type regression models for time series
taking values in $(0,\infty)$. In the proposed model, the conditional mean is
modeled by a dynamic structure containing autoregressive and moving average
terms, time-varying regressors, unknown parameters and link functions. We
introduce the new class of models and discuss partial maximum likelihood
estimation, hypothesis testing inference, diagnostic analysis and forecasting.",http://arxiv.org/pdf/2201.03667v1,stat.ME
2022-01-08 02:26:56+00:00,Bayesian Changepoint Estimation for Spatially Indexed Functional Time Series,"['Mengchen Wang', 'Trevor Harris', 'Bo Li']","We propose a Bayesian hierarchical model to simultaneously estimate mean
based changepoints in spatially correlated functional time series. Unlike
previous methods that assume a shared changepoint at all spatial locations or
ignore spatial correlation, our method treats changepoints as a spatial
process. This allows our model to respect spatial heterogeneity and exploit
spatial correlations to improve estimation. Our method is derived from the
ubiquitous cumulative sum (CUSUM) statistic that dominates changepoint
detection in functional time series. However, instead of directly searching for
the maximum of the CUSUM based processes, we build spatially correlated
two-piece linear models with appropriate variance structure to locate all
changepoints at once. The proposed linear model approach increases the
robustness of our method to variability in the CUSUM process, which, combined
with our spatial correlation model, improves changepoint estimation near the
edges. We demonstrate through extensive simulation studies that our method
outperforms existing functional changepoint estimators in terms of both
estimation accuracy and uncertainty quantification, under either weak and
strong spatial correlation, and weak and strong change signals. Finally, we
demonstrate our method using a temperature data set and a coronavirus disease
2019 (COVID-19) study.",http://arxiv.org/pdf/2201.02742v1,stat.ME
2022-01-07 04:44:25+00:00,Bayesian Online Change Point Detection for Baseline Shifts,['Ginga Yoshizawa'],"In time series data analysis, detecting change points on a real-time basis
(online) is of great interest in many areas, such as finance, environmental
monitoring, and medicine. One promising means to achieve this is the Bayesian
online change point detection (BOCPD) algorithm, which has been successfully
adopted in particular cases in which the time series of interest has a fixed
baseline. However, we have found that the algorithm struggles when the baseline
irreversibly shifts from its initial state. This is because with the original
BOCPD algorithm, the sensitivity with which a change point can be detected is
degraded if the data points are fluctuating at locations relatively far from
the original baseline. In this paper, we not only extend the original BOCPD
algorithm to be applicable to a time series whose baseline is constantly
shifting toward unknown values but also visualize why the proposed extension
works. To demonstrate the efficacy of the proposed algorithm compared to the
original one, we examine these algorithms on two real-world data sets and six
synthetic data sets.",http://arxiv.org/pdf/2201.02325v1,stat.ML
2022-01-06 13:48:40+00:00,Sales Time Series Analytics Using Deep Q-Learning,['Bohdan M. Pavlyshenko'],"The article describes the use of deep Q-learning models in the problems of
sales time series analytics. In contrast to supervised machine learning which
is a kind of passive learning using historical data, Q-learning is a kind of
active learning with goal to maximize a reward by optimal sequence of actions.
Model free Q-learning approach for optimal pricing strategies and supply-demand
problems was considered in the work. The main idea of the study is to show that
using deep Q-learning approach in time series analytics, the sequence of
actions can be optimized by maximizing the reward function when the environment
for learning agent interaction can be modeled using the parametric model and in
the case of using the model which is based on the historical data. In the
pricing optimizing case study environment was modeled using sales dependence on
extras price and randomly simulated demand. In the pricing optimizing case
study, the environment was modeled using sales dependence on extra price and
randomly simulated demand. In the supply-demand case study, it was proposed to
use historical demand time series for environment modeling, agent states were
represented by promo actions, previous demand values and weekly seasonality
features. Obtained results show that using deep Q-learning, we can optimize the
decision making process for price optimization and supply-demand problems.
Environment modeling using parametric models and historical data can be used
for the cold start of learning agent. On the next steps, after the cold start,
the trained agent can be used in real business environment.",http://arxiv.org/pdf/2201.02058v1,cs.LG
2022-01-05 02:14:57+00:00,Towards Similarity-Aware Time-Series Classification,"['Daochen Zha', 'Kwei-Herng Lai', 'Kaixiong Zhou', 'Xia Hu']","We study time-series classification (TSC), a fundamental task of time-series
data mining. Prior work has approached TSC from two major directions: (1)
similarity-based methods that classify time-series based on the nearest
neighbors, and (2) deep learning models that directly learn the representations
for classification in a data-driven manner. Motivated by the different working
mechanisms within these two research lines, we aim to connect them in such a
way as to jointly model time-series similarities and learn the representations.
This is a challenging task because it is unclear how we should efficiently
leverage similarity information. To tackle the challenge, we propose
Similarity-Aware Time-Series Classification (SimTSC), a conceptually simple and
general framework that models similarity information with graph neural networks
(GNNs). Specifically, we formulate TSC as a node classification problem in
graphs, where the nodes correspond to time-series, and the links correspond to
pair-wise similarities. We further design a graph construction strategy and a
batch training algorithm with negative sampling to improve training efficiency.
We instantiate SimTSC with ResNet as the backbone and Dynamic Time Warping
(DTW) as the similarity measure. Extensive experiments on the full UCR datasets
and several multivariate datasets demonstrate the effectiveness of
incorporating similarity information into deep learning models in both
supervised and semi-supervised settings. Our code is available at
https://github.com/daochenzha/SimTSC",http://arxiv.org/pdf/2201.01413v2,cs.LG
2022-01-04 09:23:06+00:00,Elastic Product Quantization for Time Series,"['Pieter Robberechts', 'Wannes Meert', 'Jesse Davis']","Analyzing numerous or long time series is difficult in practice due to the
high storage costs and computational requirements. Therefore, techniques have
been proposed to generate compact similarity-preserving representations of time
series, enabling real-time similarity search on large in-memory data
collections. However, the existing techniques are not ideally suited for
assessing similarity when sequences are locally out of phase. In this paper, we
propose the use of product quantization for efficient similarity-based
comparison of time series under time warping. The idea is to first compress the
data by partitioning the time series into equal length sub-sequences which are
represented by a short code. The distance between two time series can then be
efficiently approximated by pre-computed elastic distances between their codes.
The partitioning into sub-sequences forces unwanted alignments, which we
address with a pre-alignment step using the maximal overlap discrete wavelet
transform (MODWT). To demonstrate the efficiency and accuracy of our method, we
perform an extensive experimental evaluation on benchmark datasets in nearest
neighbors classification and clustering applications. Overall, the proposed
solution emerges as a highly efficient (both in terms of memory usage and
computation time) replacement for elastic measures in time series applications.",http://arxiv.org/pdf/2201.01856v2,cs.LG
2022-01-04 07:52:06+00:00,Clustering and Forecasting Multiple Functional Time Series,"['Chen Tang', 'Han Lin Shang', 'Yanrong Yang']","Modelling and forecasting homogeneous age-specific mortality rates of
multiple countries could lead to improvements in long-term forecasting. Data
fed into joint models are often grouped according to nominal attributes, such
as geographic regions, ethnic groups, and socioeconomic status, which may still
contain heterogeneity and deteriorate the forecast results. Our paper proposes
a novel clustering technique to pursue homogeneity among multiple functional
time series based on functional panel data modelling to address this issue.
Using a functional panel data model with fixed effects, we can extract common
functional time series features. These common features could be decomposed into
two components: the functional time trend and the mode of variations of
functions (functional pattern). The functional time trend reflects the dynamics
across time, while the functional pattern captures the fluctuations within
curves. The proposed clustering method searches for homogeneous age-specific
mortality rates of multiple countries by accounting for both the modes of
variations and the temporal dynamics among curves. We demonstrate that the
proposed clustering technique outperforms other existing methods through a
Monte Carlo simulation and could handle complicated cases with slow decaying
eigenvalues. In empirical data analysis, we find that the clustering results of
age-specific mortality rates can be explained by the combination of geographic
region, ethnic groups, and socioeconomic status. We further show that our model
produces more accurate forecasts than several benchmark methods in forecasting
age-specific mortality rates.",http://arxiv.org/pdf/2201.01024v1,stat.ME
2022-01-03 16:11:46+00:00,Graph Neural Networks for Multivariate Time Series Regression with Application to Seismic Data,"['Stefan Bloemheuvel', 'Jurgen van den Hoogen', 'Dario Jozinović', 'Alberto Michelini', 'Martin Atzmueller']","Machine learning, with its advances in deep learning has shown great
potential in analyzing time series. In many scenarios, however, additional
information that can potentially improve the predictions is available. This is
crucial for data that arise from e.g., sensor networks that contain information
about sensor locations. Then, such spatial information can be exploited by
modeling it via graph structures, along with the sequential (time series)
information. Recent advances in adapting deep learning to graphs have shown
potential in various tasks. However, these methods have not been adapted for
time series tasks to a great extent. Most attempts have essentially
consolidated around time series forecasting with small sequence lengths.
Generally, these architectures are not well suited for regression or
classification tasks where the value to be predicted is not strictly depending
on the most recent values, but rather on the whole length of the time series.
We propose TISER-GCN, a novel graph neural network architecture for processing,
in particular, these long time series in a multivariate regression task. Our
proposed model is tested on two seismic datasets containing earthquake
waveforms, where the goal is to predict maximum intensity measurements of
ground shaking at each seismic station. Our findings demonstrate promising
results of our approach -- with an average MSE reduction of 16.3% - compared to
the best performing baselines. In addition, our approach matches the baseline
scores by needing only half the input size. The results are discussed in depth
with an additional ablation study.",http://arxiv.org/pdf/2201.00818v3,cs.LG
2021-12-31 13:02:06+00:00,Modelling matrix time series via a tensor CP-decomposition,"['Jinyuan Chang', 'Jing He', 'Lin Yang', 'Qiwei Yao']","We consider to model matrix time series based on a tensor CP-decomposition.
Instead of using an iterative algorithm which is the standard practice for
estimating CP-decompositions, we propose a new and one-pass estimation
procedure based on a generalized eigenanalysis constructed from the serial
dependence structure of the underlying process. To overcome the intricacy of
solving a rank-reduced generalized eigenequation, we propose a further refined
approach which projects it into a lower-dimensional full-ranked eigenequation.
This refined method improves significantly the finite-sample performance of the
estimation. The asymptotic theory has been established under a general setting
without the stationarity. It shows, for example, that all the component
coefficient vectors in the CP-decomposition are estimated consistently with
certain convergence rates. The proposed model and the estimation method are
also illustrated with both simulated and real data; showing effective
dimension-reduction in modelling and forecasting matrix time series.",http://arxiv.org/pdf/2112.15423v2,stat.ME
2021-12-31 06:05:06+00:00,Bayesian Testing Of Granger Causality In Functional Time Series,"['Rituparna Sen', 'Anandamayee Majumdar', 'Shubhangi Sikaria']","We develop a multivariate functional autoregressive model (MFAR), which
captures the cross-correlation among multiple functional time series and thus
improves forecast accuracy. We estimate the parameters under the Bayesian
dynamic linear models (DLM) framework. In order to capture Granger causality
from one FAR series to another we employ Bayes Factor. Motivated by the broad
application of functional data in finance, we investigate the causality between
the yield curves of two countries. Furthermore, we illustrate a climatology
example, examining whether the weather conditions Granger cause pollutant daily
levels in a city.",http://arxiv.org/pdf/2112.15315v1,stat.ME
2021-12-30 10:29:04+00:00,Optimal Difference-based Variance Estimators in Time Series: A General Framework,['Kin Wai Chan'],"Variance estimation is important for statistical inference. It becomes
non-trivial when observations are masked by serial dependence structures and
time-varying mean structures. Existing methods either ignore or sub-optimally
handle these nuisance structures. This paper develops a general framework for
the estimation of the long-run variance for time series with non-constant
means. The building blocks are difference statistics. The proposed class of
estimators is general enough to cover many existing estimators. Necessary and
sufficient conditions for consistency are investigated. The first
asymptotically optimal estimator is derived. Our proposed estimator is
theoretically proven to be invariant to arbitrary mean structures, which may
include trends and a possibly divergent number of discontinuities.",http://arxiv.org/pdf/2112.15003v1,stat.ME
2021-12-29 19:42:48+00:00,AutoFITS: Automatic Feature Engineering for Irregular Time Series,"['Pedro Costa', 'Vitor Cerqueira', 'João Vinagre']","A time series represents a set of observations collected over time.
Typically, these observations are captured with a uniform sampling frequency
(e.g. daily). When data points are observed in uneven time intervals the time
series is referred to as irregular or intermittent. In such scenarios, the most
common solution is to reconstruct the time series to make it regular, thus
removing its intermittency. We hypothesise that, in irregular time series, the
time at which each observation is collected may be helpful to summarise the
dynamics of the data and improve forecasting performance. We study this idea by
developing a novel automatic feature engineering framework, which focuses on
extracting information from this point of view, i.e., when each instance is
collected. We study how valuable this information is by integrating it in a
time series forecasting workflow and investigate how it compares to or
complements state-of-the-art methods for regular time series forecasting. In
the end, we contribute by providing a novel framework that tackles feature
engineering for time series from an angle previously vastly ignored. We show
that our approach has the potential to further extract more information about
time series that significantly improves forecasting performance.",http://arxiv.org/pdf/2112.14806v1,cs.LG
2021-12-29 07:52:36+00:00,Monte Carlo EM for Deep Time Series Anomaly Detection,"['François-Xavier Aubet', 'Daniel Zügner', 'Jan Gasthaus']","Time series data are often corrupted by outliers or other kinds of anomalies.
Identifying the anomalous points can be a goal on its own (anomaly detection),
or a means to improving performance of other time series tasks (e.g.
forecasting). Recent deep-learning-based approaches to anomaly detection and
forecasting commonly assume that the proportion of anomalies in the training
data is small enough to ignore, and treat the unlabeled data as coming from the
nominal data distribution. We present a simple yet effective technique for
augmenting existing time series models so that they explicitly account for
anomalies in the training data. By augmenting the training data with a latent
anomaly indicator variable whose distribution is inferred while training the
underlying model using Monte Carlo EM, our method simultaneously infers
anomalous points while improving model performance on nominal data. We
demonstrate the effectiveness of the approach by combining it with a simple
feed-forward forecasting model. We investigate how anomalies in the train set
affect the training of forecasting models, which are commonly used for time
series anomaly detection, and show that our method improves the training of the
model.",http://arxiv.org/pdf/2112.14436v1,cs.LG
2021-12-27 16:09:43+00:00,Self-supervision of wearable sensors time-series data for influenza detection,"['Arinbjörn Kolbeinsson', 'Piyusha Gade', 'Raghu Kainkaryam', 'Filip Jankovic', 'Luca Foschini']","Self-supervision may boost model performance in downstream tasks. However,
there is no principled way of selecting the self-supervised objectives that
yield the most adaptable models. Here, we study this problem on daily
time-series data generated from wearable sensors used to detect onset of
influenza-like illness (ILI). We first show that using self-supervised learning
to predict next-day time-series values allows us to learn rich representations
which can be adapted to perform accurate ILI prediction. Second, we perform an
empirical analysis of three different self-supervised objectives to assess
their adaptability to ILI prediction. Our results show that predicting the next
day's resting heart rate or time-in-bed during sleep provides better
representations for ILI prediction. These findings add to previous work
demonstrating the practical application of self-supervised learning from
activity data to improve health predictions.",http://arxiv.org/pdf/2112.13755v1,cs.LG
2021-12-26 11:13:52+00:00,Time Series Data Mining Algorithms Towards Scalable and Real-Time Behavior Monitoring,['Alireza Abdoli'],"In recent years, there have been unprecedented technological advances in
sensor technology, and sensors have become more affordable than ever. Thus,
sensor-driven data collection is increasingly becoming an attractive and
practical option for researchers around the globe. Such data is typically
extracted in the form of time series data, which can be investigated with data
mining techniques to summarize behaviors of a range of subjects including
humans and animals. While enabling cheap and mass collection of data,
continuous sensor data recording results in datasets which are big in size and
volume, which are challenging to process and analyze with traditional
techniques in a timely manner. Such collected sensor data is typically
extracted in the form of time series data. There are two main approaches in the
literature, namely, shape-based classification and feature-based
classification. Shape-based classification determines the best class according
to a distance measure. Feature-based classification, on the other hand,
measures properties of the time series and finds the best class according to
the set of features defined for the time series. In this dissertation, we
demonstrate that neither of the two techniques will dominate for some problems,
but that some combination of both might be the best. In other words, on a
single problem, it might be possible that one of the techniques is better for
one subset of the behaviors, and the other technique is better for another
subset of behaviors. We introduce a hybrid algorithm to classify behaviors,
using both shape and feature measures, in weakly labeled time series data
collected from sensors to quantify specific behaviors performed by the subject.
We demonstrate that our algorithm can robustly classify real, noisy, and
complex datasets, based on a combination of shape and features, and tested our
proposed algorithm on real-world datasets.",http://arxiv.org/pdf/2112.14630v1,cs.LG
2021-12-24 08:32:09+00:00,"Toeplitz Least Squares Problems, Fast Algorithms and Big Data","['Ali Eshragh', 'Oliver Di Pietro', 'Michael A. Saunders']","In time series analysis, when fitting an autoregressive model, one must solve
a Toeplitz ordinary least squares problem numerous times to find an appropriate
model, which can severely affect computational times with large data sets. Two
recent algorithms (LSAR and Repeated Halving) have applied randomized numerical
linear algebra (RandNLA) techniques to fitting an autoregressive model to big
time-series data. We investigate and compare the quality of these two
approximation algorithms on large-scale synthetic and real-world data. While
both algorithms display comparable results for synthetic datasets, the LSAR
algorithm appears to be more robust when applied to real-world time series
data. We conclude that RandNLA is effective in the context of big-data time
series.",http://arxiv.org/pdf/2112.12994v1,stat.ML
2021-12-24 02:34:50+00:00,TSAX is Trending,['Muhammad Marwan Muhammad Fuad'],"Time series mining is an important branch of data mining, as time series data
is ubiquitous and has many applications in several domains. The main task in
time series mining is classification. Time series representation methods play
an important role in time series classification and other time series mining
tasks. One of the most popular representation methods of time series data is
the Symbolic Aggregate approXimation (SAX). The secret behind its popularity is
its simplicity and efficiency. SAX has however one major drawback, which is its
inability to represent trend information. Several methods have been proposed to
enable SAX to capture trend information, but this comes at the expense of
complex processing, preprocessing, or post-processing procedures. In this paper
we present a new modification of SAX that we call Trending SAX (TSAX), which
only adds minimal complexity to SAX, but substantially improves its performance
in time series classification. This is validated experimentally on 50 datasets.
The results show the superior performance of our method, as it gives a smaller
classification error on 39 datasets compared with SAX.",http://arxiv.org/pdf/2112.12912v1,cs.LG
2021-12-22 05:05:30+00:00,Dynamic Combination of Heterogeneous Models for Hierarchical Time Series,"['Xing Han', 'Jing Hu', 'Joydeep Ghosh']","We introduce a framework to dynamically combine heterogeneous models called
\texttt{DYCHEM}, which forecasts a set of time series that are related through
an aggregation hierarchy. Different types of forecasting models can be employed
as individual ``experts'' so that each model is tailored to the nature of the
corresponding time series. \texttt{DYCHEM} learns hierarchical structures
during the training stage to help generalize better across all the time series
being modeled and also mitigates coherency issues that arise due to constraints
imposed by the hierarchy. To improve the reliability of forecasts, we construct
quantile estimations based on the point forecasts obtained from combined
heterogeneous models. The resulting quantile forecasts are coherent and
independent of the choice of forecasting models. We conduct a comprehensive
evaluation of both point and quantile forecasts for hierarchical time series
(HTS), including public data and user records from a large financial software
company. In general, our method is robust, adaptive to datasets with different
properties, and highly configurable and efficient for large-scale forecasting
pipelines.",http://arxiv.org/pdf/2112.11669v2,cs.LG
2021-12-21 13:11:00+00:00,AutoCTS: Automated Correlated Time Series Forecasting -- Extended Version,"['Xinle Wu', 'Dalin Zhang', 'Chenjuan Guo', 'Chaoyang He', 'Bin Yang', 'Christian S. Jensen']","Correlated time series (CTS) forecasting plays an essential role in many
cyber-physical systems, where multiple sensors emit time series that capture
interconnected processes. Solutions based on deep learning that deliver
state-of-the-art CTS forecasting performance employ a variety of
spatio-temporal (ST) blocks that are able to model temporal dependencies and
spatial correlations among time series. However, two challenges remain. First,
ST-blocks are designed manually, which is time consuming and costly. Second,
existing forecasting models simply stack the same ST-blocks multiple times,
which limits the model potential. To address these challenges, we propose
AutoCTS that is able to automatically identify highly competitive ST-blocks as
well as forecasting models with heterogeneous ST-blocks connected using diverse
topologies, as opposed to the same ST-blocks connected using simple stacking.
Specifically, we design both a micro and a macro search space to model possible
architectures of ST-blocks and the connections among heterogeneous ST-blocks,
and we provide a search strategy that is able to jointly explore the search
spaces to identify optimal forecasting models. Extensive experiments on eight
commonly used CTS forecasting benchmark datasets justify our design choices and
demonstrate that AutoCTS is capable of automatically discovering forecasting
models that outperform state-of-the-art human-designed models. This is an
extended version of ``AutoCTS: Automated Correlated Time Series Forecasting'',
to appear in PVLDB 2022.",http://arxiv.org/pdf/2112.11174v1,cs.LG
2021-12-20 21:01:30+00:00,Causality in extremes of time series,"['Juraj Bodik', 'Zbyněk Pawlas', 'Milan Paluš']","Consider two stationary time series with heavy-tailed marginal distributions.
We aim to detect whether they have a causal relation, that is, if a change in
one causes a change in the other. Usual methods for causal discovery are not
well suited if the causal mechanisms only appear during extreme events. We
propose a framework to detect a causal structure from the extremes of time
series, providing a new tool to extract causal information from extreme events.
We introduce the causal tail coefficient for time series, which can identify
asymmetrical causal relations between extreme events under certain assumptions.
This method can handle nonlinear relations and latent variables. Moreover, we
mention how our method can help estimate a typical time difference between
extreme events. Our methodology is especially well suited for large sample
sizes, and we show the performance on the simulations. Finally, we apply our
method to real-world space-weather and hydro-meteorological datasets.",http://arxiv.org/pdf/2112.10858v3,math.ST
2021-12-19 20:35:16+00:00,SSDNet: State Space Decomposition Neural Network for Time Series Forecasting,"['Yang Lin', 'Irena Koprinska', 'Mashud Rana']","In this paper, we present SSDNet, a novel deep learning approach for time
series forecasting. SSDNet combines the Transformer architecture with state
space models to provide probabilistic and interpretable forecasts, including
trend and seasonality components and previous time steps important for the
prediction. The Transformer architecture is used to learn the temporal patterns
and estimate the parameters of the state space model directly and efficiently,
without the need for Kalman filters. We comprehensively evaluate the
performance of SSDNet on five data sets, showing that SSDNet is an effective
method in terms of accuracy and speed, outperforming state-of-the-art deep
learning and statistical methods, and able to provide meaningful trend and
seasonality components.",http://arxiv.org/pdf/2112.10251v1,cs.LG
2021-12-18 06:01:07+00:00,High-Dimensional Knockoffs Inference for Time Series Data,"['Chien-Ming Chi', 'Yingying Fan', 'Ching-Kang Ing', 'Jinchi Lv']","The model-X knockoffs framework provides a flexible tool for achieving
finite-sample false discovery rate (FDR) control in variable selection in
arbitrary dimensions without assuming any dependence structure of the response
on covariates. It also completely bypasses the use of conventional p-values,
making it especially appealing in high-dimensional nonlinear models. Existing
works have focused on the setting of independent and identically distributed
observations. Yet time series data is prevalent in practical applications in
various fields such as economics and social sciences. This motivates the study
of model-X knockoffs inference for time series data. In this paper, we make
some initial attempt to establish the theoretical and methodological foundation
for the model-X knockoffs inference for time series data. We suggest the method
of time series knockoffs inference (TSKI) by exploiting the ideas of
subsampling and e-values to address the difficulty caused by the serial
dependence. We also generalize the robust knockoffs inference to the time
series setting and relax the assumption of known covariate distribution
required by model-X knockoffs, because such an assumption is overly stringent
for time series data. We establish sufficient conditions under which TSKI
achieves the asymptotic FDR control. Our technical analysis reveals the effects
of serial dependence and unknown covariate distribution on the FDR control. We
conduct power analysis of TSKI using the Lasso coefficient difference knockoff
statistic under linear time series models. The finite-sample performance of
TSKI is illustrated with several simulation examples and an economic inflation
study.",http://arxiv.org/pdf/2112.09851v2,stat.ME
2021-12-17 02:46:55+00:00,A Comparative Study of Detecting Anomalies in Time Series Data Using LSTM and TCN Models,"['Saroj Gopali', 'Faranak Abri', 'Sima Siami-Namini', 'Akbar Siami Namin']","There exist several data-driven approaches that enable us model time series
data including traditional regression-based modeling approaches (i.e., ARIMA).
Recently, deep learning techniques have been introduced and explored in the
context of time series analysis and prediction. A major research question to
ask is the performance of these many variations of deep learning techniques in
predicting time series data. This paper compares two prominent deep learning
modeling techniques. The Recurrent Neural Network (RNN)-based Long Short-Term
Memory (LSTM) and the convolutional Neural Network (CNN)-based Temporal
Convolutional Networks (TCN) are compared and their performance and training
time are reported. According to our experimental results, both modeling
techniques perform comparably having TCN-based models outperform LSTM slightly.
Moreover, the CNN-based TCN model builds a stable model faster than the
RNN-based LSTM models.",http://arxiv.org/pdf/2112.09293v1,cs.LG
2021-12-16 07:16:12+00:00,Model-free Bootstrap Prediction Regions for Multivariate Time Series,"['Yiren Wang', 'Dimitris N. Politis']","In Das and Politis(2020), a model-free bootstrap(MFB) paradigm was proposed
for generating prediction intervals of univariate, (locally) stationary time
series. Theoretical guarantees for this algorithm was resolved in Wang and
Politis(2019) under stationarity and weak dependence condition. Following this
line of work, here we extend MFB for predictive inference under a multivariate
time series setup. We describe two algorithms, the first one works for a
particular class of time series under any fixed dimension d; the second one
works for a more generalized class of time series under low-dimensional
setting. We justify our procedure through theoretical validity and simulation
performance.",http://arxiv.org/pdf/2112.08671v1,stat.ME
2021-12-16 01:02:39+00:00,Simultaneous Sieve Inference for Time-Inhomogeneous Nonlinear Time Series Regression,"['Xiucai Ding', 'Zhou Zhou']","In this paper, we consider the time-inhomogeneous nonlinear time series
regression for a general class of locally stationary time series. On one hand,
we propose sieve nonparametric estimators for the time-varying regression
functions which can achieve the min-max optimal rate. On the other hand, we
develop a unified simultaneous inferential theory which can be used to conduct
both structural and exact form testings on the functions. Our proposed
statistics are powerful even under locally weak alternatives. We also propose a
multiplier bootstrapping procedure for practical implementation. Our
methodology and theory do not require any structural assumptions on the
regression functions and we also allow the functions to be supported in an
unbounded domain. We also establish sieve approximation theory for 2-D
functions in unbounded domain and a Gaussian approximation result for affine
and quadratic forms for high dimensional locally stationary time series, which
can be of independent interest. Numerical simulations and a real financial data
analysis are provided to support our results.",http://arxiv.org/pdf/2112.08545v1,math.ST
2021-12-15 19:04:46+00:00,Characterization of causal ancestral graphs for time series with latent confounders,['Andreas Gerhardus'],"In this paper, we introduce a novel class of graphical models for
representing time lag specific causal relationships and independencies of
multivariate time series with unobserved confounders. We completely
characterize these graphs and show that they constitute proper subsets of the
currently employed model classes. As we show, from the novel graphs one can
thus draw stronger causal inferences -- without additional assumptions. We
further introduce a graphical representation of Markov equivalence classes of
the novel graphs. This graphical representation contains more causal knowledge
than what current state-of-the-art causal discovery algorithms learn.",http://arxiv.org/pdf/2112.08417v2,stat.ME
2021-12-15 11:55:11+00:00,Leveraging Image-based Generative Adversarial Networks for Time Series Generation,"['Justin Hellermann', 'Stefan Lessmann']","Generative models for images have gained significant attention in computer
vision and natural language processing due to their ability to generate
realistic samples from complex data distributions. To leverage the advances of
image-based generative models for the time series domain, we propose a
two-dimensional image representation for time series, the Extended
Intertemporal Return Plot (XIRP). Our approach captures the intertemporal time
series dynamics in a scale-invariant and invertible way, reducing training time
and improving sample quality. We benchmark synthetic XIRPs obtained by an
off-the-shelf Wasserstein GAN with gradient penalty (WGAN-GP) to other image
representations and models regarding similarity and predictive ability metrics.
Our novel, validated image representation for time series consistently and
significantly outperforms a state-of-the-art RNN-based generative model
regarding predictive ability. Further, we introduce an improved stochastic
inversion to substantially improve simulation quality regardless of the
representation and provide the prospect of transfer potentials in other
domains.",http://arxiv.org/pdf/2112.08060v2,cs.LG
2021-12-15 11:39:21+00:00,Optimal Latent Space Forecasting for Large Collections of Short Time Series Using Temporal Matrix Factorization,"['Himanshi Charotia', 'Abhishek Garg', 'Gaurav Dhama', 'Naman Maheshwari']","In the context of time series forecasting, it is a common practice to
evaluate multiple methods and choose one of these methods or an ensemble for
producing the best forecasts. However, choosing among different ensembles over
multiple methods remains a challenging task that undergoes a combinatorial
explosion as the number of methods increases. In the context of demand
forecasting or revenue forecasting, this challenge is further exacerbated by a
large number of time series as well as limited historical data points available
due to changing business context. Although deep learning forecasting methods
aim to simultaneously forecast large collections of time series, they become
challenging to apply in such scenarios due to the limited history available and
might not yield desirable results. We propose a framework for forecasting short
high-dimensional time series data by combining low-rank temporal matrix
factorization and optimal model selection on latent time series using
cross-validation. We demonstrate that forecasting the latent factors leads to
significant performance gains as compared to directly applying different
uni-variate models on time series. Performance has been validated on a
truncated version of the M4 monthly dataset which contains time series data
from multiple domains showing the general applicability of the method.
Moreover, it is amenable to incorporating the analyst view of the future owing
to the low number of latent factors which is usually impractical when applying
forecasting methods directly to high dimensional datasets.",http://arxiv.org/pdf/2112.08052v1,cs.LG
2021-12-14 15:14:03+00:00,Scale-Aware Neural Architecture Search for Multivariate Time Series Forecasting,"['Donghui Chen', 'Ling Chen', 'Zongjiang Shang', 'Youdong Zhang', 'Bo Wen', 'Chenghu Yang']","Multivariate time series (MTS) forecasting has attracted much attention in
many intelligent applications. It is not a trivial task, as we need to consider
both intra-variable dependencies and inter-variable dependencies. However,
existing works are designed for specific scenarios, and require much domain
knowledge and expert efforts, which is difficult to transfer between different
scenarios. In this paper, we propose a scale-aware neural architecture search
framework for MTS forecasting (SNAS4MTF). A multi-scale decomposition module
transforms raw time series into multi-scale sub-series, which can preserve
multi-scale temporal patterns. An adaptive graph learning module infers the
different inter-variable dependencies under different time scales without any
prior knowledge. For MTS forecasting, a search space is designed to capture
both intra-variable dependencies and inter-variable dependencies at each time
scale. The multi-scale decomposition, adaptive graph learning, and neural
architecture search modules are jointly learned in an end-to-end framework.
Extensive experiments on two real-world datasets demonstrate that SNAS4MTF
achieves a promising performance compared with the state-of-the-art methods.",http://arxiv.org/pdf/2112.07459v1,cs.LG
2021-12-12 14:28:06+00:00,DeepFIB: Self-Imputation for Time Series Anomaly Detection,"['Minhao Liu', 'Zhijian Xu', 'Qiang Xu']","Time series (TS) anomaly detection (AD) plays an essential role in various
applications, e.g., fraud detection in finance and healthcare monitoring. Due
to the inherently unpredictable and highly varied nature of anomalies and the
lack of anomaly labels in historical data, the AD problem is typically
formulated as an unsupervised learning problem. The performance of existing
solutions is often not satisfactory, especially in data-scarce scenarios. To
tackle this problem, we propose a novel self-supervised learning technique for
AD in time series, namely \emph{DeepFIB}. We model the problem as a \emph{Fill
In the Blank} game by masking some elements in the TS and imputing them with
the rest. Considering the two common anomaly shapes (point- or
sequence-outliers) in TS data, we implement two masking strategies with many
self-generated training samples. The corresponding self-imputation networks can
extract more robust temporal relations than existing AD solutions and
effectively facilitate identifying the two types of anomalies. For continuous
outliers, we also propose an anomaly localization algorithm that dramatically
reduces AD errors. Experiments on various real-world TS datasets demonstrate
that DeepFIB outperforms state-of-the-art methods by a large margin, achieving
up to $65.2\%$ relative improvement in F1-score.",http://arxiv.org/pdf/2112.06247v1,cs.LG
2021-12-12 13:08:14+00:00,Approximation algorithms for confidence bands for time series,['Nikolaj Tatti'],"Confidence intervals are a standard technique for analyzing data. When
applied to time series, confidence intervals are computed for each time point
separately. Alternatively, we can compute confidence bands, where we are
required to find the smallest area enveloping $k$ time series, where $k$ is a
user parameter. Confidence bands can be then used to detect abnormal time
series, not just individual observations within the time series. We will show
that despite being an NP-hard problem it is possible to find optimal confidence
band for some $k$. We do this by considering a different problem: discovering
regularized bands, where we minimize the envelope area minus the number of
included time series weighted by a parameter $\alpha$. Unlike normal confidence
bands we can solve the problem exactly by using a minimum cut. By varying
$\alpha$ we can obtain solutions for various $k$. If we have a constraint $k$
for which we cannot find appropriate $\alpha$, we demonstrate a simple
algorithm that yields $O(\sqrt{n})$ approximation guarantee by connecting the
problem to a minimum $k$-union problem. This connection also implies that we
cannot approximate the problem better than $O(n^{1/4})$ under some (mild)
assumptions. Finally, we consider a variant where instead of minimizing the
area we minimize the maximum width. Here, we demonstrate a simple
2-approximation algorithm and show that we cannot achieve better approximation
guarantee.",http://arxiv.org/pdf/2112.06225v1,cs.LG
2021-12-09 11:22:15+00:00,Sampling rate-corrected analysis of irregularly sampled time series,"['Tobias Braun', 'Cinthya N. Fernandez', 'Deniz Eroglu', 'Adam Hartland', 'Sebastian F. M. Breitenbach', 'Norbert Marwan']","The analysis of irregularly sampled time series remains a challenging task
requiring methods that account for continuous and abrupt changes of sampling
resolution without introducing additional biases. The edit-distance is an
effective metric to quantitatively compare time series segments of unequal
length by computing the cost of transforming one segment into the other. We
show that transformation costs generally exhibit a non-trivial relationship
with local sampling rate. If the sampling resolution undergoes strong
variations, this effect impedes unbiased comparison between different time
episodes. We study the impact of this effect on recurrence quantification
analysis, a framework that is well-suited for identifying regime shifts in
nonlinear time series. A constrained randomization approach is put forward to
correct for the biased recurrence quantification measures. This strategy
involves the generation of a novel type of time series and time axis surrogates
which we call sampling rate constrained (SRC) surrogates. We demonstrate the
effectiveness of the proposed approach with a synthetic example and an
irregularly sampled speleothem proxy record from Niue island in the central
tropical Pacific. Application of the proposed correction scheme identifies a
spurious transition that is solely imposed by an abrupt shift in sampling rate
and uncovers periods of reduced seasonal rainfall predictability associated
with enhanced ENSO and tropical cyclone activity.",http://arxiv.org/pdf/2112.04843v1,stat.ME
2021-12-09 05:07:49+00:00,Ymir: A Supervised Ensemble Framework for Multivariate Time Series Anomaly Detection,['Zhanxiang Zhao'],"We proposed a multivariate time series anomaly detection frame-work Ymir,
which leverages ensemble learning and supervisedlearning technology to
efficiently learn and adapt to anomaliesin real-world system applications. Ymir
integrates several currentlywidely used unsupervised anomaly detection models
through anensemble learning method, and thus can provide robust frontalanomaly
detection results in unsupervised scenarios. In a super-vised setting, domain
experts and system users discuss and providelabels (anomalous or not) for the
training data, which reflects theiranomaly detection criteria for the specific
system. Ymir leveragesthe aforementioned unsupervised methods to extract rich
and usefulfeature representations from the raw multivariate time series
data,then combines the features and labels with a supervised classifier todo
anomaly detection. We evaluated Ymir on internal multivariatetime series
datasets from large monitoring systems and achievedgood anomaly detection
performance.",http://arxiv.org/pdf/2112.04704v1,cs.LG
2021-12-06 21:13:18+00:00,Cadence: A Practical Time-series Partitioning Algorithm for Unlabeled IoT Sensor Streams,"['Tahiya Chowdhury', 'Murtadha Aldeer', 'Shantanu Laghate', 'Jorge Ortiz']","Timeseries partitioning is an essential step in most machine-learning driven,
sensor-based IoT applications. This paper introduces a sample-efficient,
robust, time-series segmentation model and algorithm. We show that by learning
a representation specifically with the segmentation objective based on maximum
mean discrepancy (MMD), our algorithm can robustly detect time-series events
across different applications. Our loss function allows us to infer whether
consecutive sequences of samples are drawn from the same distribution (null
hypothesis) and determines the change-point between pairs that reject the null
hypothesis (i.e., come from different distributions). We demonstrate its
applicability in a real-world IoT deployment for ambient-sensing based activity
recognition. Moreover, while many works on change-point detection exist in the
literature, our model is significantly simpler and can be fully trained in 9-93
seconds on average with little variation in hyperparameters for data across
different applications. We empirically evaluate Cadence on four popular change
point detection (CPD) datasets where Cadence matches or outperforms existing
CPD techniques.",http://arxiv.org/pdf/2112.03360v2,cs.LG
2021-12-06 17:55:01+00:00,Online false discovery rate control for anomaly detection in time series,"['Quentin Rebjock', 'Barış Kurt', 'Tim Januschowski', 'Laurent Callot']","This article proposes novel rules for false discovery rate control (FDRC)
geared towards online anomaly detection in time series. Online FDRC rules allow
to control the properties of a sequence of statistical tests. In the context of
anomaly detection, the null hypothesis is that an observation is normal and the
alternative is that it is anomalous. FDRC rules allow users to target a lower
bound on precision in unsupervised settings. The methods proposed in this
article overcome short-comings of previous FDRC rules in the context of anomaly
detection, in particular ensuring that power remains high even when the
alternative is exceedingly rare (typical in anomaly detection) and the test
statistics are serially dependent (typical in time series). We show the
soundness of these rules in both theory and experiments.",http://arxiv.org/pdf/2112.03196v1,stat.ML
2021-12-06 15:48:07+00:00,Strong mixing properties of discrete-valued time series with exogenous covariates,['Lionel Truquet'],"We derive strong mixing conditions for many existing discrete-valued time
series models that include exogenous covariates in the dynamic. Our main
contribution is to study how a mixing condition on the covariate process
transfers to a mixing condition for the response. Using a coupling method, we
first derive mixing conditions for some Markov chains in random environments,
which gives a first result for some autoregressive categorical processes with
strictly exogenous regressors. Our result is then extended to some infinite
memory categorical processes. In the second part of the paper, we study
autoregressive models for which the covariates are sequentially exogenous.
Using a general random mapping approach on finite sets, we get explicit mixing
conditions that can be checked for many categorical time series found in the
literature, including multinomial autoregressive processes, ordinal time series
and dynamic multiple choice models. We also study some autoregressive count
time series using a somewhat different contraction argument. Our contribution
fill an important gap for such models, presented here under a more general
form, since such a strong mixing condition is often assumed in some recent
works but no general approach is available to check it.",http://arxiv.org/pdf/2112.03121v1,math.ST
2021-12-06 08:19:15+00:00,Dynamic Graph Learning-Neural Network for Multivariate Time Series Modeling,"['Zhuoling Li', 'Gaowei Zhang', 'Lingyu Xu', 'Jie Yu']","Multivariate time series forecasting is a challenging task because the data
involves a mixture of long- and short-term patterns, with dynamic
spatio-temporal dependencies among variables. Existing graph neural networks
(GNN) typically model multivariate relationships with a pre-defined spatial
graph or learned fixed adjacency graph. It limits the application of GNN and
fails to handle the above challenges. In this paper, we propose a novel
framework, namely static- and dynamic-graph learning-neural network (SDGL). The
model acquires static and dynamic graph matrices from data to model long- and
short-term patterns respectively. Static matric is developed to capture the
fixed long-term association pattern via node embeddings, and we leverage graph
regularity for controlling the quality of the learned static graph. To capture
dynamic dependencies among variables, we propose dynamic graphs learning method
to generate time-varying matrices based on changing node features and static
node embeddings. And in the method, we integrate the learned static graph
information as inductive bias to construct dynamic graphs and local
spatio-temporal patterns better. Extensive experiments are conducted on two
traffic datasets with extra structural information and four time series
datasets, which show that our approach achieves state-of-the-art performance on
almost all datasets. If the paper is accepted, I will open the source code on
github.",http://arxiv.org/pdf/2112.03273v1,cs.LG
2021-12-05 03:41:59+00:00,Anomaly Detection of Wind Turbine Time Series using Variational Recurrent Autoencoders,"['Alan Preciado-Grijalva', 'Victor Rodrigo Iza-Teran']","Ice accumulation in the blades of wind turbines can cause them to describe
anomalous rotations or no rotations at all, thus affecting the generation of
electricity and power output. In this work, we investigate the problem of ice
accumulation in wind turbines by framing it as anomaly detection of
multi-variate time series. Our approach focuses on two main parts: first,
learning low-dimensional representations of time series using a Variational
Recurrent Autoencoder (VRAE), and second, using unsupervised clustering
algorithms to classify the learned representations as normal (no ice
accumulated) or abnormal (ice accumulated). We have evaluated our approach on a
custom wind turbine time series dataset, for the two-classes problem (one
normal versus one abnormal class), we obtained a classification accuracy of up
to 96$\%$ on test data. For the multiple-class problem (one normal versus
multiple abnormal classes), we present a qualitative analysis of the
low-dimensional learned latent space, providing insights into the capacities of
our approach to tackle such problem. The code to reproduce this work can be
found here https://github.com/agrija9/Wind-Turbines-VRAE-Paper.",http://arxiv.org/pdf/2112.02468v1,cs.LG
2021-12-03 19:50:09+00:00,Combining Embeddings and Fuzzy Time Series for High-Dimensional Time Series Forecasting in Internet of Energy Applications,"['Hugo Vinicius Bitencourt', 'Luiz Augusto Facury de Souza', 'Matheus Cascalho dos Santos', 'Petrônio Cândido de Lima e Silva', 'Frederico Gadelha Guimarães']","The prediction of residential power usage is essential in assisting a smart
grid to manage and preserve energy to ensure efficient use. An accurate energy
forecasting at the customer level will reflect directly into efficiency
improvements across the power grid system, however forecasting building energy
use is a complex task due to many influencing factors, such as meteorological
and occupancy patterns. In addiction, high-dimensional time series increasingly
arise in the Internet of Energy (IoE), given the emergence of multi-sensor
environments and the two way communication between energy consumers and the
smart grid. Therefore, methods that are capable of computing high-dimensional
time series are of great value in smart building and IoE applications. Fuzzy
Time Series (FTS) models stand out as data-driven non-parametric models of easy
implementation and high accuracy. Unfortunately, the existing FTS models can be
unfeasible if all features were used to train the model. We present a new
methodology for handling high-dimensional time series, by projecting the
original high-dimensional data into a low dimensional embedding space and using
multivariate FTS approach in this low dimensional representation. Combining
these techniques enables a better representation of the complex content of
multivariate time series and more accurate forecasts.",http://arxiv.org/pdf/2112.02140v1,cs.LG
2021-12-03 18:58:07+00:00,Causal-based Time Series Domain Generalization for Vehicle Intention Prediction,"['Yeping Hu', 'Xiaogang Jia', 'Masayoshi Tomizuka', 'Wei Zhan']","Accurately predicting possible behaviors of traffic participants is an
essential capability for autonomous vehicles. Since autonomous vehicles need to
navigate in dynamically changing environments, they are expected to make
accurate predictions regardless of where they are and what driving
circumstances they encountered. Therefore, generalization capability to unseen
domains is crucial for prediction models when autonomous vehicles are deployed
in the real world. In this paper, we aim to address the domain generalization
problem for vehicle intention prediction tasks and a causal-based time series
domain generalization (CTSDG) model is proposed. We construct a structural
causal model for vehicle intention prediction tasks to learn an invariant
representation of input driving data for domain generalization. We further
integrate a recurrent latent variable model into our structural causal model to
better capture temporal latent dependencies from time-series input data. The
effectiveness of our approach is evaluated via real-world driving data. We
demonstrate that our proposed method has consistent improvement on prediction
accuracy compared to other state-of-the-art domain generalization and behavior
prediction methods.",http://arxiv.org/pdf/2112.02093v1,cs.LG
2021-12-03 08:24:59+00:00,A Novel Deep Parallel Time-series Relation Network for Fault Diagnosis,['Chun Yang'],"Considering the models that apply the contextual information of time-series
data could improve the fault diagnosis performance, some neural network
structures such as RNN, LSTM, and GRU were proposed to model the fault
diagnosis effectively. However, these models are restricted by their serial
computation and hence cannot achieve high diagnostic efficiency. Also the
parallel CNN is difficult to implement fault diagnosis in an efficient way
because it requires larger convolution kernels or deep structure to achieve
long-term feature extraction capabilities. Besides, BERT model applies absolute
position embedding to introduce contextual information to the model, which
would bring noise to the raw data and therefore cannot be applied to fault
diagnosis directly. In order to address the above problems, a fault diagnosis
model named deep parallel time-series relation network(DPTRN) has been proposed
in this paper. There are mainly three advantages for DPTRN: (1) Our proposed
time relationship unit is based on full multilayer perceptron(MLP) structure,
therefore, DPTRN performs fault diagnosis in a parallel way and improves
computing efficiency significantly. (2) By improving the absolute position
embedding, our novel decoupling position embedding unit could be applied on the
fault diagnosis directly and learn contextual information. (3) Our proposed
DPTRN has obvious advantage in feature interpretability. We confirm the effect
of the proposed method on four datasets, and the results show the
effectiveness, efficiency and interpretability of the proposed DPTRN model.",http://arxiv.org/pdf/2112.03405v3,cs.LG
2021-12-03 01:38:38+00:00,Deep Efficient Continuous Manifold Learning for Time Series Modeling,"['Seungwoo Jeong', 'Wonjun Ko', 'Ahmad Wisnu Mulyadi', 'Heung-Il Suk']","Modeling non-Euclidean data is drawing extensive attention along with the
unprecedented successes of deep neural networks in diverse fields.
Particularly, a symmetric positive definite matrix is being actively studied in
computer vision, signal processing, and medical image analysis, due to its
ability to learn beneficial statistical representations. However, owing to its
rigid constraints, it remains challenging to optimization problems and
inefficient computational costs, especially, when incorporating it with a deep
learning framework. In this paper, we propose a framework to exploit a
diffeomorphism mapping between Riemannian manifolds and a Cholesky space, by
which it becomes feasible not only to efficiently solve optimization problems
but also to greatly reduce computation costs. Further, for dynamic modeling of
time-series data, we devise a continuous manifold learning method by
systematically integrating a manifold ordinary differential equation and a
gated recurrent neural network. It is worth noting that due to the nice
parameterization of matrices in a Cholesky space, training our proposed network
equipped with Riemannian geometric metrics is straightforward. We demonstrate
through experiments over regular and irregular time-series datasets that our
proposed model can be efficiently and reliably trained and outperforms existing
manifold methods and state-of-the-art methods in various time-series tasks.",http://arxiv.org/pdf/2112.03379v2,cs.LG
2021-12-01 18:15:38+00:00,"Auto-Regressive Approximations to Non-stationary Time Series, with Inference and Applications","['Xiucai Ding', 'Zhou Zhou']","Understanding the time-varying structure of complex temporal systems is one
of the main challenges of modern time series analysis. In this paper, we show
that every uniformly-positive-definite-in-covariance and sufficiently
short-range dependent non-stationary and nonlinear time series can be well
approximated globally by a white-noise-driven auto-regressive (AR) process of
slowly diverging order. To our best knowledge, it is the first time such a
structural approximation result is established for general classes of
non-stationary time series. A high dimensional $\mathcal{L}^2$ test and an
associated multiplier bootstrap procedure are proposed for the inference of the
AR approximation coefficients. In particular, an adaptive stability test is
proposed to check whether the AR approximation coefficients are time-varying, a
frequently-encountered question for practitioners and researchers of time
series. As an application, globally optimal short-term forecasting theory and
methodology for a wide class of locally stationary time series are established
via the method of sieves.",http://arxiv.org/pdf/2112.00693v2,math.ST
2021-12-01 10:59:38+00:00,AR-sieve Bootstrap for High-dimensional Time Series,"['Daning Bi', 'Han Lin Shang', 'Yanrong Yang', 'Huanjun Zhu']","This paper proposes a new AR-sieve bootstrap approach on high-dimensional
time series. The major challenge of classical bootstrap methods on
high-dimensional time series is two-fold: the curse dimensionality and temporal
dependence. To tackle such difficulty, we utilise factor modelling to reduce
dimension and capture temporal dependence simultaneously. A factor-based
bootstrap procedure is constructed, which conducts AR-sieve bootstrap on the
extracted low-dimensional common factor time series and then recovers the
bootstrap samples for original data from the factor model. Asymptotic
properties for bootstrap mean statistics and extreme eigenvalues are
established. Various simulations further demonstrate the advantages of the new
AR-sieve bootstrap under high-dimensional scenarios. Finally, an empirical
application on particulate matter (PM) concentration data is studied, where
bootstrap confidence intervals for mean vectors and autocovariance matrices are
provided.",http://arxiv.org/pdf/2112.00414v1,stat.ME
2021-11-29 12:28:22+00:00,Evaluating Privacy-Preserving Machine Learning in Critical Infrastructures: A Case Study on Time-Series Classification,"['Dominique Mercier', 'Adriano Lucieri', 'Mohsin Munir', 'Andreas Dengel', 'Sheraz Ahmed']","With the advent of machine learning in applications of critical
infrastructure such as healthcare and energy, privacy is a growing concern in
the minds of stakeholders. It is pivotal to ensure that neither the model nor
the data can be used to extract sensitive information used by attackers against
individuals or to harm whole societies through the exploitation of critical
infrastructure. The applicability of machine learning in these domains is
mostly limited due to a lack of trust regarding the transparency and the
privacy constraints. Various safety-critical use cases (mostly relying on
time-series data) are currently underrepresented in privacy-related
considerations. By evaluating several privacy-preserving methods regarding
their applicability on time-series data, we validated the inefficacy of
encryption for deep learning, the strong dataset dependence of differential
privacy, and the broad applicability of federated methods.",http://arxiv.org/pdf/2111.14838v1,cs.LG
2021-11-29 08:17:23+00:00,Self-supervised Autoregressive Domain Adaptation for Time Series Data,"['Mohamed Ragab', 'Emadeldeen Eldele', 'Zhenghua Chen', 'Min Wu', 'Chee-Keong Kwoh', 'Xiaoli Li']","Unsupervised domain adaptation (UDA) has successfully addressed the domain
shift problem for visual applications. Yet, these approaches may have limited
performance for time series data due to the following reasons. First, they
mainly rely on large-scale dataset (i.e., ImageNet) for the source pretraining,
which is not applicable for time-series data. Second, they ignore the temporal
dimension on the feature space of the source and target domains during the
domain alignment step. Last, most of prior UDA methods can only align the
global features without considering the fine-grained class distribution of the
target domain. To address these limitations, we propose a Self-supervised
Autoregressive Domain Adaptation (SLARDA) framework. In particular, we first
design a self-supervised learning module that utilizes forecasting as an
auxiliary task to improve the transferability of the source features. Second,
we propose a novel autoregressive domain adaptation technique that incorporates
temporal dependency of both source and target features during domain alignment.
Finally, we develop an ensemble teacher model to align the class-wise
distribution in the target domain via a confident pseudo labeling approach.
Extensive experiments have been conducted on three real-world time series
applications with 30 cross-domain scenarios. Results demonstrate that our
proposed SLARDA method significantly outperforms the state-of-the-art
approaches for time series domain adaptation.",http://arxiv.org/pdf/2111.14834v2,cs.LG
2021-11-27 22:44:54+00:00,Factor-augmented tree ensembles,['Filippo Pellegrino'],"This manuscript proposes to extend the information set of time-series
regression trees with latent stationary factors extracted via state-space
methods. In doing so, this approach generalises time-series regression trees on
two dimensions. First, it allows to handle predictors that exhibit measurement
error, non-stationary trends, seasonality and/or irregularities such as missing
observations. Second, it gives a transparent way for using domain-specific
theory to inform time-series regression trees. Empirically, ensembles of these
factor-augmented trees provide a reliable approach for macro-finance problems.
This article highlights it focussing on the lead-lag effect between equity
volatility and the business cycle in the United States.",http://arxiv.org/pdf/2111.14000v6,stat.ML
2021-11-26 17:39:33+00:00,Correlation Based Feature Subset Selection for Multivariate Time-Series Data,"['Bahavathy Kathirgamanathan', 'Padraig Cunningham']","Correlations in streams of multivariate time series data means that
typically, only a small subset of the features are required for a given data
mining task. In this paper, we propose a technique which we call Merit Score
for Time-Series data (MSTS) that does feature subset selection based on the
correlation patterns of single feature classifier outputs. We assign a Merit
Score to the feature subsets which is used as the basis for selecting 'good'
feature subsets. The proposed technique is evaluated on datasets from the UEA
multivariate time series archive and is compared against a Wrapper approach for
feature subset selection. MSTS is shown to be effective for feature subset
selection and is in particular effective as a data reduction technique. MSTS is
shown here to be computationally more efficient than the Wrapper strategy in
selecting a suitable feature subset, being more than 100 times faster for some
larger datasets while also maintaining a good classification accuracy.",http://arxiv.org/pdf/2112.03705v1,cs.LG
2021-11-26 05:11:04+00:00,"Amercing: An Intuitive, Elegant and Effective Constraint for Dynamic Time Warping","['Matthieu Herrmann', 'Geoffrey I. Webb']","Dynamic Time Warping (DTW), and its constrained (CDTW) and weighted (WDTW)
variants, are time series distances with a wide range of applications. They
minimize the cost of non-linear alignments between series. CDTW and WDTW have
been introduced because DTW is too permissive in its alignments. However, CDTW
uses a crude step function, allowing unconstrained flexibility within the
window, and none beyond it. WDTW's multiplicative weight is relative to the
distances between aligned points along a warped path, rather than being a
direct function of the amount of warping that is introduced. In this paper, we
introduce Amerced Dynamic Time Warping (ADTW), a new, intuitive, DTW variant
that penalizes the act of warping by a fixed additive cost. Like CDTW and WDTW,
ADTW constrains the amount of warping. However, it avoids both abrupt
discontinuities in the amount of warping allowed and the limitations of a
multiplicative penalty. We formally introduce ADTW, prove some of its
properties, and discuss its parameterization. We show on a simple example how
it can be parameterized to achieve an intuitive outcome, and demonstrate its
usefulness on a standard time series classification benchmark. We provide a
demonstration application in C++.",http://arxiv.org/pdf/2111.13314v1,cs.LG
2021-11-25 16:49:01+00:00,Neural network stochastic differential equation models with applications to financial data forecasting,"['Luxuan Yang', 'Ting Gao', 'Yubin Lu', 'Jinqiao Duan', 'Tao Liu']","In this article, we employ a collection of stochastic differential equations
with drift and diffusion coefficients approximated by neural networks to
predict the trend of chaotic time series which has big jump properties. Our
contributions are, first, we propose a model called L\'evy induced stochastic
differential equation network, which explores compounded stochastic
differential equations with $\alpha$-stable L\'evy motion to model complex time
series data and solve the problem through neural network approximation. Second,
we theoretically prove that the numerical solution through our algorithm
converges in probability to the solution of corresponding stochastic
differential equation, without curse of dimensionality. Finally, we illustrate
our method by applying it to real financial time series data and find the
accuracy increases through the use of non-Gaussian L\'evy processes. We also
present detailed comparisons in terms of data patterns, various models,
different shapes of L\'evy motion and the prediction lengths.",http://arxiv.org/pdf/2111.13164v6,cs.LG
2021-11-25 11:45:40+00:00,"Learning dynamical systems from data: A simple cross-validation perspective, part III: Irregularly-Sampled Time Series","['Jonghyeon Lee', 'Edward De Brouwer', 'Boumediene Hamzi', 'Houman Owhadi']","A simple and interpretable way to learn a dynamical system from data is to
interpolate its vector-field with a kernel. In particular, this strategy is
highly efficient (both in terms of accuracy and complexity) when the kernel is
data-adapted using Kernel Flows (KF)~\cite{Owhadi19} (which uses gradient-based
optimization to learn a kernel based on the premise that a kernel is good if
there is no significant loss in accuracy if half of the data is used for
interpolation). Despite its previous successes, this strategy (based on
interpolating the vector field driving the dynamical system) breaks down when
the observed time series is not regularly sampled in time. In this work, we
propose to address this problem by directly approximating the vector field of
the dynamical system by incorporating time differences between observations in
the (KF) data-adapted kernels. We compare our approach with the classical one
over different benchmark dynamical systems and show that it significantly
improves the forecasting accuracy while remaining simple, fast, and robust.",http://arxiv.org/pdf/2111.13037v1,stat.ML
2021-11-24 11:18:03+00:00,tsflex: flexible time series processing & feature extraction,"['Jonas Van Der Donckt', 'Jeroen Van Der Donckt', 'Emiel Deprost', 'Sofie Van Hoecke']","Time series processing and feature extraction are crucial and time-intensive
steps in conventional machine learning pipelines. Existing packages are limited
in their applicability, as they cannot cope with irregularly-sampled or
asynchronous data and make strong assumptions about the data format. Moreover,
these packages do not focus on execution speed and memory efficiency, resulting
in considerable overhead. We present $\texttt{tsflex}$, a Python toolkit for
time series processing and feature extraction, that focuses on performance and
flexibility, enabling broad applicability. This toolkit leverages window-stride
arguments of the same data type as the sequence-index, and maintains the
sequence-index through all operations. $\texttt{tsflex}$ is flexible as it
supports (1) multivariate time series, (2) multiple window-stride
configurations, and (3) integrates with processing and feature functions from
other packages, while (4) making no assumptions about the data sampling
regularity, series alignment, and data type. Other functionalities include
multiprocessing, detailed execution logging, chunking sequences, and
serialization. Benchmarks show that $\texttt{tsflex}$ is faster and more
memory-efficient compared to similar packages, while being more permissive and
flexible in its utilization.",http://arxiv.org/pdf/2111.12429v2,cs.LG
2021-11-22 17:43:00+00:00,Spatial Correlation in Weather Forecast Accuracy: A Functional Time Series Approach,"['Phillip A. Jang', 'David S. Matteson']","A functional time series approach is proposed for investigating spatial
correlation in daily maximum temperature forecast errors for 111 cities spread
across the U.S. The modelling of spatial correlation is most fruitful for
longer forecast horizons, and becomes less relevant as the forecast horizon
shrinks towards zero. For 6-day-ahead forecasts, the functional approach
uncovers interpretable regional spatial effects, and captures the higher
variance observed in inland cities versus coastal cities, as well as the higher
variance observed in mountain and midwest states. The functional approach also
naturally handles missing data through modelling a continuum, and can be
implemented efficiently by exploiting the sparsity induced by a B-spline basis.
  The temporal dependence in the data is modeled through temporal dependence in
functional basis coefficients. Independent first order autoregressions with
generalized autoregressive conditional heteroskedasticity [AR(1)+GARCH(1,1)]
and Student-t innovations work well to capture the persistence of basis
coefficients over time and the seasonal heteroskedasticity reflecting higher
variance in winter. Through exploiting autocorrelation in the basis
coefficients, the functional time series approach also yields a method for
improving weather forecasts and uncertainty quantification. The resulting
method corrects for bias in the weather forecasts, while reducing the error
variance.",http://arxiv.org/pdf/2111.11381v1,stat.ME
2021-11-22 12:49:37+00:00,Time Series Prediction about Air Quality using LSTM-Based Models: A Systematic Mapping,"['Lucas L. S. Sachetti', 'Vinicius F. S. Mota']","This systematic mapping study investigates the use of Long short-term memory
networks to predict time series data about air quality, trying to understand
the reasons, characteristics and methods available in the scientific
literature, identify gaps in the researched area and potential approaches that
can be exploited on later studies.",http://arxiv.org/pdf/2111.11848v1,cs.LG
2021-11-22 10:58:53+00:00,Unsupervised Time Series Outlier Detection with Diversity-Driven Convolutional Ensembles -- Extended Version,"['David Campos', 'Tung Kieu', 'Chenjuan Guo', 'Feiteng Huang', 'Kai Zheng', 'Bin Yang', 'Christian S. Jensen']","With the sweeping digitalization of societal, medical, industrial, and
scientific processes, sensing technologies are being deployed that produce
increasing volumes of time series data, thus fueling a plethora of new or
improved applications. In this setting, outlier detection is frequently
important, and while solutions based on neural networks exist, they leave room
for improvement in terms of both accuracy and efficiency. With the objective of
achieving such improvements, we propose a diversity-driven, convolutional
ensemble. To improve accuracy, the ensemble employs multiple basic outlier
detection models built on convolutional sequence-to-sequence autoencoders that
can capture temporal dependencies in time series. Further, a novel
diversity-driven training method maintains diversity among the basic models,
with the aim of improving the ensemble's accuracy. To improve efficiency, the
approach enables a high degree of parallelism during training. In addition, it
is able to transfer some model parameters from one basic model to another,
which reduces training time. We report on extensive experiments using
real-world multivariate time series that offer insight into the design choices
underlying the new approach and offer evidence that it is capable of improved
accuracy and efficiency. This is an extended version of ""Unsupervised Time
Series Outlier Detection with Diversity-Driven Convolutional Ensembles"", to
appear in PVLDB 2022.",http://arxiv.org/pdf/2111.11108v1,cs.LG
2021-11-21 07:25:47+00:00,Seasonal Count Time Series,"['Jiajie Kong', 'Robert Lund']","Count time series are widely encountered in practice. As with continuous
valued data, many count series have seasonal properties. This paper uses a
recent advance in stationary count time series to develop a general seasonal
count time series modeling paradigm. The model permits any marginal
distribution for the series and the most flexible autocorrelations possible,
including those with negative dependence. Likelihood methods of inference can
be conducted and covariates can be easily accommodated. The paper first
develops the modeling methods, which entail a discrete transformation of a
Gaussian process having seasonal dynamics. Properties of this model class are
then established and particle filtering likelihood methods of parameter
estimation are developed. A simulation study demonstrating the efficacy of the
methods is presented and an application to the number of rainy days in
successive weeks in Seattle, Washington is given.",http://arxiv.org/pdf/2111.10757v1,stat.ME
2021-11-20 10:52:37+00:00,Learning Non-Stationary Time-Series with Dynamic Pattern Extractions,"['Xipei Wang', 'Haoyu Zhang', 'Yuanbo Zhang', 'Meng Wang', 'Jiarui Song', 'Tin Lai', 'Matloob Khushi']","The era of information explosion had prompted the accumulation of a
tremendous amount of time-series data, including stationary and non-stationary
time-series data. State-of-the-art algorithms have achieved a decent
performance in dealing with stationary temporal data. However, traditional
algorithms that tackle stationary time-series do not apply to non-stationary
series like Forex trading. This paper investigates applicable models that can
improve the accuracy of forecasting future trends of non-stationary time-series
sequences. In particular, we focus on identifying potential models and
investigate the effects of recognizing patterns from historical data. We
propose a combination of \rebuttal{the} seq2seq model based on RNN, along with
an attention mechanism and an enriched set features extracted via dynamic time
warping and zigzag peak valley indicators. Customized loss functions and
evaluating metrics have been designed to focus more on the predicting
sequence's peaks and valley points. Our results show that our model can predict
4-hour future trends with high accuracy in the Forex dataset, which is crucial
in realistic scenarios to assist foreign exchange trading decision making. We
further provide evaluations of the effects of various loss functions,
evaluation metrics, model variants, and components on model performance.",http://arxiv.org/pdf/2111.10559v1,cs.LG
2021-11-19 16:44:33+00:00,Unsupervised Visual Time-Series Representation Learning and Clustering,"['Gaurangi Anand', 'Richi Nayak']","Time-series data is generated ubiquitously from Internet-of-Things (IoT)
infrastructure, connected and wearable devices, remote sensing, autonomous
driving research and, audio-video communications, in enormous volumes. This
paper investigates the potential of unsupervised representation learning for
these time-series. In this paper, we use a novel data transformation along with
novel unsupervised learning regime to transfer the learning from other domains
to time-series where the former have extensive models heavily trained on very
large labelled datasets. We conduct extensive experiments to demonstrate the
potential of the proposed approach through time-series clustering.",http://arxiv.org/pdf/2111.10309v1,cs.LG
2021-11-17 16:04:01+00:00,GAETS: A Graph Autoencoder Time Series Approach Towards Battery Parameter Estimation,"['Edward Elson Kosasih', 'Rucha Bhalchandra Joshi', 'Janamejaya Channegowda']","Lithium-ion batteries are powering the ongoing transportation electrification
revolution. Lithium-ion batteries possess higher energy density and favourable
electrochemical properties which make it a preferable energy source for
electric vehicles. Precise estimation of battery parameters (Charge capacity,
voltage etc) is vital to estimate the available range in an electric vehicle.
Graph-based estimation techniques enable us to understand the variable
dependencies underpinning them to improve estimates. In this paper we employ
Graph Neural Networks for battery parameter estimation, we introduce a unique
graph autoencoder time series estimation approach. Variables in battery
measurements are known to have an underlying relationship with each other in a
certain correlation within variables of interest. We use graph autoencoder
based on a non-linear version of NOTEARS as this allowed us to perform
gradient-descent in learning the structure (instead of treating it as a
combinatorial optimisation problem). The proposed architecture outperforms the
state-of-the-art Graph Time Series (GTS) architecture for battery parameter
estimation. We call our method GAETS (Graph AutoEncoder Time Series).",http://arxiv.org/pdf/2111.09314v2,cs.LG
2021-11-16 11:31:37+00:00,Towards Generating Real-World Time Series Data,"['Hengzhi Pei', 'Kan Ren', 'Yuqing Yang', 'Chang Liu', 'Tao Qin', 'Dongsheng Li']","Time series data generation has drawn increasing attention in recent years.
Several generative adversarial network (GAN) based methods have been proposed
to tackle the problem usually with the assumption that the targeted time series
data are well-formatted and complete. However, real-world time series (RTS)
data are far away from this utopia, e.g., long sequences with variable lengths
and informative missing data raise intractable challenges for designing
powerful generation algorithms. In this paper, we propose a novel generative
framework for RTS data - RTSGAN to tackle the aforementioned challenges. RTSGAN
first learns an encoder-decoder module which provides a mapping between a time
series instance and a fixed-dimension latent vector and then learns a
generation module to generate vectors in the same latent space. By combining
the generator and the decoder, RTSGAN is able to generate RTS which respect the
original feature distributions and the temporal dynamics. To generate time
series with missing values, we further equip RTSGAN with an observation
embedding layer and a decide-and-generate decoder to better utilize the
informative missing patterns. Experiments on the four RTS datasets show that
the proposed framework outperforms the previous generation methods in terms of
synthetic data utility for downstream classification and prediction tasks.",http://arxiv.org/pdf/2111.08386v1,cs.LG
2021-11-15 21:42:14+00:00,TimeVAE: A Variational Auto-Encoder for Multivariate Time Series Generation,"['Abhyuday Desai', 'Cynthia Freeman', 'Zuhui Wang', 'Ian Beaver']","Recent work in synthetic data generation in the time-series domain has
focused on the use of Generative Adversarial Networks. We propose a novel
architecture for synthetically generating time-series data with the use of
Variational Auto-Encoders (VAEs). The proposed architecture has several
distinct properties: interpretability, ability to encode domain knowledge, and
reduced training times. We evaluate data generation quality by similarity and
predictability against four multivariate datasets. We experiment with varying
sizes of training data to measure the impact of data availability on generation
quality for our VAE method as well as several state-of-the-art data generation
methods. Our results on similarity tests show that the VAE approach is able to
accurately represent the temporal attributes of the original data. On next-step
prediction tasks using generated data, the proposed VAE architecture
consistently meets or exceeds performance of state-of-the-art data generation
methods. While noise reduction may cause the generated data to deviate from
original data, we demonstrate the resulting de-noised data can significantly
improve performance for next-step prediction using generated data. Finally, the
proposed architecture can incorporate domain-specific time-patterns such as
polynomial trends and seasonalities to provide interpretable outputs. Such
interpretability can be highly advantageous in applications requiring
transparency of model outputs or where users desire to inject prior knowledge
of time-series patterns into the generative model.",http://arxiv.org/pdf/2111.08095v3,cs.LG
2021-11-13 12:52:56+00:00,Nyström Regularization for Time Series Forecasting,"['Zirui Sun', 'Mingwei Dai', 'Yao Wang', 'Shao-Bo Lin']","This paper focuses on learning rate analysis of Nystr\""{o}m regularization
with sequential sub-sampling for $\tau$-mixing time series. Using a recently
developed Banach-valued Bernstein inequality for $\tau$-mixing sequences and an
integral operator approach based on second-order decomposition, we succeed in
deriving almost optimal learning rates of Nystr\""{o}m regularization with
sequential sub-sampling for $\tau$-mixing time series. A series of numerical
experiments are carried out to verify our theoretical results, showing the
excellent learning performance of Nystr\""{o}m regularization with sequential
sub-sampling in learning massive time series data. All these results extend the
applicable range of Nystr\""{o}m regularization from i.i.d. samples to
non-i.i.d. sequences.",http://arxiv.org/pdf/2111.07109v1,cs.LG
2021-11-13 00:17:52+00:00,LoMEF: A Framework to Produce Local Explanations for Global Model Time Series Forecasts,"['Dilini Rajapaksha', 'Christoph Bergmeir', 'Rob J Hyndman']","Global Forecasting Models (GFM) that are trained across a set of multiple
time series have shown superior results in many forecasting competitions and
real-world applications compared with univariate forecasting approaches. One
aspect of the popularity of statistical forecasting models such as ETS and
ARIMA is their relative simplicity and interpretability (in terms of relevant
lags, trend, seasonality, and others), while GFMs typically lack
interpretability, especially towards particular time series. This reduces the
trust and confidence of the stakeholders when making decisions based on the
forecasts without being able to understand the predictions. To mitigate this
problem, in this work, we propose a novel local model-agnostic interpretability
approach to explain the forecasts from GFMs. We train simpler univariate
surrogate models that are considered interpretable (e.g., ETS) on the
predictions of the GFM on samples within a neighbourhood that we obtain through
bootstrapping or straightforwardly as the one-step-ahead global black-box model
forecasts of the time series which needs to be explained. After, we evaluate
the explanations for the forecasts of the global models in both qualitative and
quantitative aspects such as accuracy, fidelity, stability and
comprehensibility, and are able to show the benefits of our approach.",http://arxiv.org/pdf/2111.07001v1,cs.LG
2021-11-12 23:26:18+00:00,GraSSNet: Graph Soft Sensing Neural Networks,"['Yu Huang', 'Chao Zhang', 'Jaswanth Yella', 'Sergei Petrov', 'Xiaoye Qian', 'Yufei Tang', 'Xingquan Zhu', 'Sthitie Bom']","In the era of big data, data-driven based classification has become an
essential method in smart manufacturing to guide production and optimize
inspection. The industrial data obtained in practice is usually time-series
data collected by soft sensors, which are highly nonlinear, nonstationary,
imbalanced, and noisy. Most existing soft-sensing machine learning models focus
on capturing either intra-series temporal dependencies or pre-defined
inter-series correlations, while ignoring the correlation between labels as
each instance is associated with multiple labels simultaneously. In this paper,
we propose a novel graph based soft-sensing neural network (GraSSNet) for
multivariate time-series classification of noisy and highly-imbalanced
soft-sensing data. The proposed GraSSNet is able to 1) capture the inter-series
and intra-series dependencies jointly in the spectral domain; 2) exploit the
label correlations by superimposing label graph that built from statistical
co-occurrence information; 3) learn features with attention mechanism from both
textual and numerical domain; and 4) leverage unlabeled data and mitigate data
imbalance by semi-supervised learning. Comparative studies with other commonly
used classifiers are carried out on Seagate soft sensing data, and the
experimental results validate the competitive performance of our proposed
method.",http://arxiv.org/pdf/2111.06980v1,cs.LG
2021-11-11 02:54:36+00:00,Benefit-aware Early Prediction of Health Outcomes on Multivariate EEG Time Series,"['Shubhranshu Shekhar', 'Dhivya Eswaran', 'Bryan Hooi', 'Jonathan Elmer', 'Christos Faloutsos', 'Leman Akoglu']","Given a cardiac-arrest patient being monitored in the ICU (intensive care
unit) for brain activity, how can we predict their health outcomes as early as
possible? Early decision-making is critical in many applications, e.g.
monitoring patients may assist in early intervention and improved care. On the
other hand, early prediction on EEG data poses several challenges: (i)
earliness-accuracy trade-off; observing more data often increases accuracy but
sacrifices earliness, (ii) large-scale (for training) and streaming (online
decision-making) data processing, and (iii) multi-variate (due to multiple
electrodes) and multi-length (due to varying length of stay of patients) time
series. Motivated by this real-world application, we present BeneFitter that
infuses the incurred savings from an early prediction as well as the cost from
misclassification into a unified domain-specific target called benefit.
Unifying these two quantities allows us to directly estimate a single target
(i.e. benefit), and importantly, dictates exactly when to output a prediction:
when benefit estimate becomes positive. BeneFitter (a) is efficient and fast,
with training time linear in the number of input sequences, and can operate in
real-time for decision-making, (b) can handle multi-variate and variable-length
time-series, suitable for patient data, and (c) is effective, providing up to
2x time-savings with equal or better accuracy as compared to competitors.",http://arxiv.org/pdf/2111.06032v1,cs.LG
2021-11-09 15:18:03+00:00,Deep diffusion-based forecasting of COVID-19 by incorporating network-level mobility information,"['Padmaksha Roy', 'Shailik Sarkar', 'Subhodip Biswas', 'Fanglan Chen', 'Zhiqian Chen', 'Naren Ramakrishnan', 'Chang-Tien Lu']","Modeling the spatiotemporal nature of the spread of infectious diseases can
provide useful intuition in understanding the time-varying aspect of the
disease spread and the underlying complex spatial dependency observed in
people's mobility patterns. Besides, the county level multiple related time
series information can be leveraged to make a forecast on an individual time
series. Adding to this challenge is the fact that real-time data often deviates
from the unimodal Gaussian distribution assumption and may show some complex
mixed patterns. Motivated by this, we develop a deep learning-based time-series
model for probabilistic forecasting called Auto-regressive Mixed Density
Dynamic Diffusion Network(ARM3Dnet), which considers both people's mobility and
disease spread as a diffusion process on a dynamic directed graph. The Gaussian
Mixture Model layer is implemented to consider the multimodal nature of the
real-time data while learning from multiple related time series. We show that
our model, when trained with the best combination of dynamic covariate features
and mixture components, can outperform both traditional statistical and deep
learning models in forecasting the number of Covid-19 deaths and cases at the
county level in the United States.",http://arxiv.org/pdf/2111.05199v1,cs.LG
2021-11-09 03:52:24+00:00,Learning from Multiple Time Series: A Deep Disentangled Approach to Diversified Time Series Forecasting,"['Ling Chen', 'Weiqi Chen', 'Binqing Wu', 'Youdong Zhang', 'Bo Wen', 'Chenghu Yang']","Time series forecasting is a significant problem in many applications, e.g.,
financial predictions and business optimization. Modern datasets can have
multiple correlated time series, which are often generated with global (shared)
regularities and local (specific) dynamics. In this paper, we seek to tackle
such forecasting problems with DeepDGL, a deep forecasting model that
disentangles dynamics into global and local temporal patterns. DeepDGL employs
an encoder-decoder architecture, consisting of two encoders to learn global and
local temporal patterns, respectively, and a decoder to make multi-step
forecasting. Specifically, to model complicated global patterns, the vector
quantization (VQ) module is introduced, allowing the global feature encoder to
learn a shared codebook among all time series. To model diversified and
heterogenous local patterns, an adaptive parameter generation module enhanced
by the contrastive multi-horizon coding (CMC) is proposed to generate the
parameters of the local feature encoder for each individual time series, which
maximizes the mutual information between the series-specific context variable
and the long/short-term representations of the corresponding time series. Our
experiments on several real-world datasets show that DeepDGL outperforms
existing state-of-the-art models.",http://arxiv.org/pdf/2111.04942v1,cs.LG
2021-11-08 11:20:19+00:00,Is the group structure important in grouped functional time series?,"['Yang Yang', 'Han Lin Shang']","We study the importance of group structure in grouped functional time series.
Due to the non-uniqueness of group structure, we investigate different
disaggregation structures in grouped functional time series. We address a
practical question on whether or not the group structure can affect forecast
accuracy. Using a dynamic multivariate functional time series method, we
consider joint modeling and forecasting multiple series. Illustrated by
Japanese sub-national age-specific mortality rates from 1975 to 2016, we
investigate one- to 15-step-ahead point and interval forecast accuracies for
the two group structures.",http://arxiv.org/pdf/2111.04390v1,stat.ME
2021-11-08 04:47:31+00:00,Mimic: An adaptive algorithm for multivariate time series classification,"['Yuhui Wang', 'Diane J. Cook']","Time series data are valuable but are often inscrutable. Gaining trust in
time series classifiers for finance, healthcare, and other critical
applications may rely on creating interpretable models. Researchers have
previously been forced to decide between interpretable methods that lack
predictive power and deep learning methods that lack transparency. In this
paper, we propose a novel Mimic algorithm that retains the predictive accuracy
of the strongest classifiers while introducing interpretability. Mimic mirrors
the learning method of an existing multivariate time series classifier while
simultaneously producing a visual representation that enhances user
understanding of the learned model. Experiments on 26 time series datasets
support Mimic's ability to imitate a variety of time series classifiers
visually and accurately.",http://arxiv.org/pdf/2111.04273v1,cs.LG
2021-11-07 12:54:11+00:00,DVS: Deep Visibility Series and its Application in Construction Cost Index Forecasting,"['Tianxiang Zhan', 'Yuanpeng He', 'Hanwen Li', 'Fuyuan Xiao']","Time series forecasting is a hot spot in recent years. Visibility Graph (VG)
algorithm is used for time series forecasting in previous research, but the
forecasting effect is not as good as deep learning prediction methods such as
methods based on Artificial Neural Network (ANN), Convolutional Neural Network
(CNN) and Long Short-Term Memory Network (LSTM). The visibility graph generated
from specific time series contains abundant network information, but the
previous forecasting method did not effectively use the network information to
forecast, resulting in relatively large prediction errors. To optimize the
forecasting method based on VG, this article proposes the Deep Visibility
Series (DVS) module through the bionic design of VG and the expansion of the
past research. By applying the bionic design of biological vision to VG, DVS
has obtained superior forecasting accuracy. At the same time, this paper
applies the DVS forecasting method to the construction cost index forecast,
which has practical significance.",http://arxiv.org/pdf/2111.04071v4,cs.LG
2021-11-05 11:50:07+00:00,Transferable Time-Series Forecasting under Causal Conditional Shift,"['Zijian Li', 'Ruichu Cai', 'Tom Z. J Fu', 'Zhifeng Hao', 'Kun Zhang']","This paper focuses on the problem of semi-supervised domain adaptation for
time-series forecasting, which is underexplored in literatures, despite being
often encountered in practice. Existing methods on time-series domain
adaptation mainly follow the paradigm designed for the static data, which
cannot handle domain-specific complex conditional dependencies raised by data
offset, time lags, and variant data distributions. In order to address these
challenges, we analyze variational conditional dependencies in time-series data
and find that the causal structures are usually stable among domains, and
further raise the causal conditional shift assumption. Enlightened by this
assumption, we consider the causal generation process for time-series data and
propose an end-to-end model for the semi-supervised domain adaptation problem
on time-series forecasting. Our method can not only discover the Granger-Causal
structures among cross-domain data but also address the cross-domain
time-series forecasting problem with accurate and interpretable predicted
results. We further theoretically analyze the superiority of the proposed
method, where the generalization error on the target domain is bounded by the
empirical risks and by the discrepancy between the causal structures from
different domains. Experimental results on both synthetic and real data
demonstrate the effectiveness of our method for the semi-supervised domain
adaptation method on time-series forecasting.",http://arxiv.org/pdf/2111.03422v3,cs.LG
2021-11-05 11:45:02+00:00,Meta-Forecasting by combining Global Deep Representations with Local Adaptation,"['Riccardo Grazzi', 'Valentin Flunkert', 'David Salinas', 'Tim Januschowski', 'Matthias Seeger', 'Cedric Archambeau']","While classical time series forecasting considers individual time series in
isolation, recent advances based on deep learning showed that jointly learning
from a large pool of related time series can boost the forecasting accuracy.
However, the accuracy of these methods suffers greatly when modeling
out-of-sample time series, significantly limiting their applicability compared
to classical forecasting methods. To bridge this gap, we adopt a meta-learning
view of the time series forecasting problem. We introduce a novel forecasting
method, called Meta Global-Local Auto-Regression (Meta-GLAR), that adapts to
each time series by learning in closed-form the mapping from the
representations produced by a recurrent neural network (RNN) to one-step-ahead
forecasts. Crucially, the parameters ofthe RNN are learned across multiple time
series by backpropagating through the closed-form adaptation mechanism. In our
extensive empirical evaluation we show that our method is competitive with the
state-of-the-art in out-of-sample forecasting accuracy reported in earlier
work.",http://arxiv.org/pdf/2111.03418v2,cs.LG
2021-11-05 04:24:51+00:00,Dynamic Data Augmentation with Gating Networks for Time Series Recognition,"['Daisuke Oba', 'Shinnosuke Matsuo', 'Brian Kenji Iwana']","Data augmentation is a technique to improve the generalization ability of
machine learning methods by increasing the size of the dataset. However, since
every augmentation method is not equally effective for every dataset, you need
to select an appropriate method carefully. We propose a neural network that
dynamically selects the best combination of data augmentation methods using a
mutually beneficial gating network and a feature consistency loss. The gating
network is able to control how much of each data augmentation is used for the
representation within the network. The feature consistency loss gives a
constraint that augmented features from the same input should be in similar. In
experiments, we demonstrate the effectiveness of the proposed method on the 12
largest time-series datasets from 2018 UCR Time Series Archive and reveal the
relationships between the data augmentation methods through analysis of the
proposed method.",http://arxiv.org/pdf/2111.03253v3,cs.LG
2021-11-04 14:59:28+00:00,Reconstructing Nonlinear Dynamical Systems from Multi-Modal Time Series,"['Daniel Kramer', 'Philine Lou Bommer', 'Carlo Tombolini', 'Georgia Koppe', 'Daniel Durstewitz']","Empirically observed time series in physics, biology, or medicine, are
commonly generated by some underlying dynamical system (DS) which is the target
of scientific interest. There is an increasing interest to harvest machine
learning methods to reconstruct this latent DS in a data-driven, unsupervised
way. In many areas of science it is common to sample time series observations
from many data modalities simultaneously, e.g. electrophysiological and
behavioral time series in a typical neuroscience experiment. However, current
machine learning tools for reconstructing DSs usually focus on just one data
modality. Here we propose a general framework for multi-modal data integration
for the purpose of nonlinear DS reconstruction and the analysis of cross-modal
relations. This framework is based on dynamically interpretable recurrent
neural networks as general approximators of nonlinear DSs, coupled to sets of
modality-specific decoder models from the class of generalized linear models.
Both an expectation-maximization and a variational inference algorithm for
model training are advanced and compared. We show on nonlinear DS benchmarks
that our algorithms can efficiently compensate for too noisy or missing
information in one data channel by exploiting other channels, and demonstrate
on experimental neuroscience data how the algorithm learns to link different
data domains to the underlying dynamics.",http://arxiv.org/pdf/2111.02922v3,cs.LG
2021-11-01 21:50:35+00:00,Brain dynamics via Cumulative Auto-Regressive Self-Attention,"['Usman Mahmood', 'Zening Fu', 'Vince Calhoun', 'Sergey Plis']","Multivariate dynamical processes can often be intuitively described by a
weighted connectivity graph between components representing each individual
time-series. Even a simple representation of this graph as a Pearson
correlation matrix may be informative and predictive as demonstrated in the
brain imaging literature. However, there is a consensus expectation that
powerful graph neural networks (GNNs) should perform better in similar
settings. In this work, we present a model that is considerably shallow than
deep GNNs, yet outperforms them in predictive accuracy in a brain imaging
application. Our model learns the autoregressive structure of individual time
series and estimates directed connectivity graphs between the learned
representations via a self-attention mechanism in an end-to-end fashion. The
supervised training of the model as a classifier between patients and controls
results in a model that generates directed connectivity graphs and highlights
the components of the time-series that are predictive for each subject. We
demonstrate our results on a functional neuroimaging dataset classifying
schizophrenia patients and controls.",http://arxiv.org/pdf/2111.01271v2,cs.LG
2021-11-01 19:01:16+00:00,Sig-Wasserstein GANs for Time Series Generation,"['Hao Ni', 'Lukasz Szpruch', 'Marc Sabate-Vidales', 'Baoren Xiao', 'Magnus Wiese', 'Shujian Liao']","Synthetic data is an emerging technology that can significantly accelerate
the development and deployment of AI machine learning pipelines. In this work,
we develop high-fidelity time-series generators, the SigWGAN, by combining
continuous-time stochastic models with the newly proposed signature $W_1$
metric. The former are the Logsig-RNN models based on the stochastic
differential equations, whereas the latter originates from the universal and
principled mathematical features to characterize the measure induced by time
series. SigWGAN allows turning computationally challenging GAN min-max problem
into supervised learning while generating high fidelity samples. We validate
the proposed model on both synthetic data generated by popular quantitative
risk models and empirical financial data. Codes are available at
https://github.com/SigCGANs/Sig-Wasserstein-GANs.git.",http://arxiv.org/pdf/2111.01207v1,cs.LG
2021-10-30 19:17:20+00:00,ECG synthesis with Neural ODE and GAN models,"['Mansura Habiba', 'Eoin Brophy', 'Barak A. Pearlmutter', 'Tomas Ward']","Continuous medical time series data such as ECG is one of the most complex
time series due to its dynamic and high dimensional characteristics. In
addition, due to its sensitive nature, privacy concerns and legal restrictions,
it is often even complex to use actual data for different medical research. As
a result, generating continuous medical time series is a very critical research
area. Several research works already showed that the ability of generative
adversarial networks (GANs) in the case of continuous medical time series
generation is promising. Most medical data generation works, such as ECG
synthesis, are mainly driven by the GAN model and its variation. On the other
hand, Some recent work on Neural Ordinary Differential Equation (Neural ODE)
demonstrates its strength against informative missingness, high dimension as
well as dynamic nature of continuous time series. Instead of considering
continuous-time series as a discrete-time sequence, Neural ODE can train
continuous time series in real-time continuously. In this work, we used Neural
ODE based model to generate synthetic sine waves and synthetic ECG. We
introduced a new technique to design the generative adversarial network with
Neural ODE based Generator and Discriminator. We developed three new models to
synthesise continuous medical data. Different evaluation metrics are then used
to quantitatively assess the quality of generated synthetic data for real-world
applications and data analysis. Another goal of this work is to combine the
strength of GAN and Neural ODE to generate synthetic continuous medical time
series data such as ECG. We also evaluated both the GAN model and the Neural
ODE model to understand the comparative efficiency of models from the GAN and
Neural ODE family in medical data synthesis.",http://arxiv.org/pdf/2111.00314v2,cs.LG
2021-10-29 07:53:11+00:00,Cause-effect inference through spectral independence in linear dynamical systems: theoretical foundations,"['Michel Besserve', 'Naji Shajarisales', 'Dominik Janzing', 'Bernhard Schölkopf']","Distinguishing between cause and effect using time series observational data
is a major challenge in many scientific fields. A new perspective has been
provided based on the principle of Independence of Causal Mechanisms (ICM),
leading to the Spectral Independence Criterion (SIC), postulating that the
power spectral density (PSD) of the cause time series is uncorrelated with the
squared modulus of the frequency response of the filter generating the effect.
Since SIC rests on methods and assumptions in stark contrast with most causal
discovery methods for time series, it raises questions regarding what
theoretical grounds justify its use. In this paper, we provide answers covering
several key aspects. After providing an information theoretic interpretation of
SIC, we present an identifiability result that sheds light on the context for
which this approach is expected to perform well. We further demonstrate the
robustness of SIC to downsampling - an obstacle that can spoil Granger-based
inference. Finally, an invariance perspective allows to explore the limitations
of the spectral independence assumption and how to generalize it. Overall,
these results support the postulate of Spectral Independence is a well grounded
leading principle for causal inference based on empirical time series.",http://arxiv.org/pdf/2110.15595v1,stat.ME
2021-10-29 03:18:53+00:00,CP Factor Model for Dynamic Tensors,"['Yuefeng Han', 'Cun-Hui Zhang', 'Rong Chen']","Observations in various applications are frequently represented as a time
series of multidimensional arrays, called tensor time series, preserving the
inherent multidimensional structure. In this paper, we present a factor model
approach, in a form similar to tensor CP decomposition, to the analysis of
high-dimensional dynamic tensor time series. As the loading vectors are
uniquely defined but not necessarily orthogonal, it is significantly different
from the existing tensor factor models based on Tucker-type tensor
decomposition. The model structure allows for a set of uncorrelated
one-dimensional latent dynamic factor processes, making it much more convenient
to study the underlying dynamics of the time series. A new high order
projection estimator is proposed for such a factor model, utilizing the special
structure and the idea of the higher order orthogonal iteration procedures
commonly used in Tucker-type tensor factor model and general tensor CP
decomposition procedures. Theoretical investigation provides statistical error
bounds for the proposed methods, which shows the significant advantage of
utilizing the special model structure. Simulation study is conducted to further
demonstrate the finite sample properties of the estimators. Real data
application is used to illustrate the model and its interpretations.",http://arxiv.org/pdf/2110.15517v1,stat.ME
2021-10-28 16:21:13+00:00,Coresets for Time Series Clustering,"['Lingxiao Huang', 'K. Sudhir', 'Nisheeth K. Vishnoi']","We study the problem of constructing coresets for clustering problems with
time series data. This problem has gained importance across many fields
including biology, medicine, and economics due to the proliferation of sensors
facilitating real-time measurement and rapid drop in storage costs. In
particular, we consider the setting where the time series data on $N$ entities
is generated from a Gaussian mixture model with autocorrelations over $k$
clusters in $\mathbb{R}^d$. Our main contribution is an algorithm to construct
coresets for the maximum likelihood objective for this mixture model. Our
algorithm is efficient, and under a mild boundedness assumption on the
covariance matrices of the underlying Gaussians, the size of the coreset is
independent of the number of entities $N$ and the number of observations for
each entity, and depends only polynomially on $k$, $d$ and $1/\varepsilon$,
where $\varepsilon$ is the error parameter. We empirically assess the
performance of our coreset with synthetic data.",http://arxiv.org/pdf/2110.15263v1,cs.LG
2021-10-28 10:07:29+00:00,Using Time-Series Privileged Information for Provably Efficient Learning of Prediction Models,"['Rickard K. A. Karlsson', 'Martin Willbo', 'Zeshan Hussain', 'Rahul G. Krishnan', 'David Sontag', 'Fredrik D. Johansson']","We study prediction of future outcomes with supervised models that use
privileged information during learning. The privileged information comprises
samples of time series observed between the baseline time of prediction and the
future outcome; this information is only available at training time which
differs from the traditional supervised learning. Our question is when using
this privileged data leads to more sample-efficient learning of models that use
only baseline data for predictions at test time. We give an algorithm for this
setting and prove that when the time series are drawn from a non-stationary
Gaussian-linear dynamical system of fixed horizon, learning with privileged
information is more efficient than learning without it. On synthetic data, we
test the limits of our algorithm and theory, both when our assumptions hold and
when they are violated. On three diverse real-world datasets, we show that our
approach is generally preferable to classical learning, particularly when data
is scarce. Finally, we relate our estimator to a distillation approach both
theoretically and empirically.",http://arxiv.org/pdf/2110.14993v2,cs.LG
2021-10-27 21:44:00+00:00,Warped Dynamic Linear Models for Time Series of Counts,"['Brian King', 'Daniel R. Kowal']","Dynamic Linear Models (DLMs) are commonly employed for time series analysis
due to their versatile structure, simple recursive updating, ability to handle
missing data, and probabilistic forecasting. However, the options for count
time series are limited: Gaussian DLMs require continuous data, while
Poisson-based alternatives often lack sufficient modeling flexibility. We
introduce a novel semiparametric methodology for count time series by warping a
Gaussian DLM. The warping function has two components: a (nonparametric)
transformation operator that provides distributional flexibility and a rounding
operator that ensures the correct support for the discrete data-generating
process. We develop conjugate inference for the warped DLM, which enables
analytic and recursive updates for the state space filtering and smoothing
distributions. We leverage these results to produce customized and efficient
algorithms for inference and forecasting, including Monte Carlo simulation for
offline analysis and an optimal particle filter for online inference. This
framework unifies and extends a variety of discrete time series models and is
valid for natural counts, rounded values, and multivariate observations.
Simulation studies illustrate the excellent forecasting capabilities of the
warped DLM. The proposed approach is applied to a multivariate time series of
daily overdose counts and demonstrates both modeling and computational
successes.",http://arxiv.org/pdf/2110.14790v4,stat.ME
2021-10-27 14:14:25+00:00,Validation Methods for Energy Time Series Scenarios from Deep Generative Models,"['Eike Cramer', 'Leonardo Rydin Gorjão', 'Alexander Mitsos', 'Benjamin Schäfer', 'Dirk Witthaut', 'Manuel Dahmen']","The design and operation of modern energy systems are heavily influenced by
time-dependent and uncertain parameters, e.g., renewable electricity
generation, load-demand, and electricity prices. These are typically
represented by a set of discrete realizations known as scenarios. A popular
scenario generation approach uses deep generative models (DGM) that allow
scenario generation without prior assumptions about the data distribution.
However, the validation of generated scenarios is difficult, and a
comprehensive discussion about appropriate validation methods is currently
lacking. To start this discussion, we provide a critical assessment of the
currently used validation methods in the energy scenario generation literature.
In particular, we assess validation methods based on probability density,
auto-correlation, and power spectral density. Furthermore, we propose using the
multifractal detrended fluctuation analysis (MFDFA) as an additional validation
method for non-trivial features like peaks, bursts, and plateaus. As
representative examples, we train generative adversarial networks (GANs),
Wasserstein GANs (WGANs), and variational autoencoders (VAEs) on two renewable
power generation time series (photovoltaic and wind from Germany in 2013 to
2015) and an intra-day electricity price time series form the European Energy
Exchange in 2017 to 2019. We apply the four validation methods to both the
historical and the generated data and discuss the interpretation of validation
results as well as common mistakes, pitfalls, and limitations of the validation
methods. Our assessment shows that no single method sufficiently characterizes
a scenario but ideally validation should include multiple methods and be
interpreted carefully in the context of scenarios over short time periods.",http://arxiv.org/pdf/2110.14451v2,cs.LG
2021-10-27 11:14:49+00:00,MixSeq: Connecting Macroscopic Time Series Forecasting with Microscopic Time Series Data,"['Zhibo Zhu', 'Ziqi Liu', 'Ge Jin', 'Zhiqiang Zhang', 'Lei Chen', 'Jun Zhou', 'Jianyong Zhou']","Time series forecasting is widely used in business intelligence, e.g.,
forecast stock market price, sales, and help the analysis of data trend. Most
time series of interest are macroscopic time series that are aggregated from
microscopic data. However, instead of directly modeling the macroscopic time
series, rare literature studied the forecasting of macroscopic time series by
leveraging data on the microscopic level. In this paper, we assume that the
microscopic time series follow some unknown mixture probabilistic
distributions. We theoretically show that as we identify the ground truth
latent mixture components, the estimation of time series from each component
could be improved because of lower variance, thus benefitting the estimation of
macroscopic time series as well. Inspired by the power of Seq2seq and its
variants on the modeling of time series data, we propose Mixture of Seq2seq
(MixSeq), an end2end mixture model to cluster microscopic time series, where
all the components come from a family of Seq2seq models parameterized by
different parameters. Extensive experiments on both synthetic and real-world
data show the superiority of our approach.",http://arxiv.org/pdf/2110.14354v1,cs.LG
2021-10-27 10:21:13+00:00,GACAN: Graph Attention-Convolution-Attention Networks for Traffic Forecasting Based on Multi-granularity Time Series,"['Sikai Zhang', 'Hong Zheng', 'Hongyi Su', 'Bo Yan', 'Jiamou Liu', 'Song Yang']","Traffic forecasting is an integral part of intelligent transportation systems
(ITS). Achieving a high prediction accuracy is a challenging task due to a high
level of dynamics and complex spatial-temporal dependency of road networks. For
this task, we propose Graph Attention-Convolution-Attention Networks (GACAN).
The model uses a novel Att-Conv-Att (ACA) block which contains two graph
attention layers and one spectral-based GCN layer sandwiched in between. The
graph attention layers are meant to capture temporal features while the
spectral-based GCN layer is meant to capture spatial features. The main novelty
of the model is the integration of time series of four different time
granularities: the original time series, together with hourly, daily, and
weekly time series. Unlike previous work that used multi-granularity time
series by handling every time series separately, GACAN combines the outcome of
processing all time series after each graph attention layer. Thus, the effects
of different time granularities are integrated throughout the model. We perform
a series of experiments on three real-world datasets. The experimental results
verify the advantage of using multi-granularity time series and that the
proposed GACAN model outperforms the state-of-the-art baselines.",http://arxiv.org/pdf/2110.14331v1,cs.LG
2021-10-26 22:50:25+00:00,Simultaneous Statistical Inference for Second Order Parameters of Time Series under Weak Conditions,"['Yunyi Zhang', 'Efstathios Paparoditis', 'Dimitris N. Politis']","Strict stationarity is a common assumption used in the time series literature
in order to derive asymptotic distributional results for second-order
statistics, like sample autocovariances and sample autocorrelations. Focusing
on weak stationarity, this paper derives the asymptotic distribution of the
maximum of sample autocovariances and sample autocorrelations under weak
conditions by using Gaussian approximation techniques. The asymptotic theory
for parameter estimation obtained by fitting a (linear) autoregressive model to
a general weakly stationary time series is revisited and a Gaussian
approximation theorem for the maximum of the estimators of the autoregressive
coefficients is derived. To perform statistical inference for the second order
parameters considered, a bootstrap algorithm, the so-called second-order wild
bootstrap, is applied. Consistency of this bootstrap procedure is proven. In
contrast to existing bootstrap alternatives, validity of the second-order wild
bootstrap does not require the imposition of strict stationary conditions or
structural process assumptions, like linearity. The good finite sample
performance of the second-order wild bootstrap is demonstrated by means of
simulations.",http://arxiv.org/pdf/2110.14067v2,math.ST
2021-10-26 20:41:19+00:00,Cluster-and-Conquer: A Framework For Time-Series Forecasting,"['Reese Pathak', 'Rajat Sen', 'Nikhil Rao', 'N. Benjamin Erichson', 'Michael I. Jordan', 'Inderjit S. Dhillon']","We propose a three-stage framework for forecasting high-dimensional
time-series data. Our method first estimates parameters for each univariate
time series. Next, we use these parameters to cluster the time series. These
clusters can be viewed as multivariate time series, for which we then compute
parameters. The forecasted values of a single time series can depend on the
history of other time series in the same cluster, accounting for intra-cluster
similarity while minimizing potential noise in predictions by ignoring
inter-cluster effects. Our framework -- which we refer to as
""cluster-and-conquer"" -- is highly general, allowing for any time-series
forecasting and clustering method to be used in each step. It is
computationally efficient and embarrassingly parallel. We motivate our
framework with a theoretical analysis in an idealized mixed linear regression
setting, where we provide guarantees on the quality of the estimates. We
accompany these guarantees with experimental results that demonstrate the
advantages of our framework: when instantiated with simple linear
autoregressive models, we are able to achieve state-of-the-art results on
several benchmark datasets, sometimes outperforming deep-learning-based
approaches.",http://arxiv.org/pdf/2110.14011v1,cs.LG
2021-10-26 17:35:21+00:00,Deep Explicit Duration Switching Models for Time Series,"['Abdul Fatir Ansari', 'Konstantinos Benidis', 'Richard Kurle', 'Ali Caner Turkmen', 'Harold Soh', 'Alexander J. Smola', 'Yuyang Wang', 'Tim Januschowski']","Many complex time series can be effectively subdivided into distinct regimes
that exhibit persistent dynamics. Discovering the switching behavior and the
statistical patterns in these regimes is important for understanding the
underlying dynamical system. We propose the Recurrent Explicit Duration
Switching Dynamical System (RED-SDS), a flexible model that is capable of
identifying both state- and time-dependent switching dynamics. State-dependent
switching is enabled by a recurrent state-to-switch connection and an explicit
duration count variable is used to improve the time-dependent switching
behavior. We demonstrate how to perform efficient inference using a hybrid
algorithm that approximates the posterior of the continuous states via an
inference network and performs exact inference for the discrete switches and
counts. The model is trained by maximizing a Monte Carlo lower bound of the
marginal log-likelihood that can be computed efficiently as a byproduct of the
inference routine. Empirical results on multiple datasets demonstrate that
RED-SDS achieves considerable improvement in time series segmentation and
competitive forecasting performance against the state of the art.",http://arxiv.org/pdf/2110.13878v1,cs.LG
2021-10-26 15:26:38+00:00,Data-Driven Time Series Reconstruction for Modern Power Systems Research,"['Minas Chatzos', 'Mathieu Tanneau', 'Pascal Van Hentenryck']","A critical aspect of power systems research is the availability of suitable
data, access to which is limited by privacy concerns and the sensitive nature
of energy infrastructure. This lack of data, in turn, hinders the development
of modern research avenues such as machine learning approaches or stochastic
formulations. To overcome this challenge, this paper proposes a systematic,
data-driven framework for reconstructing high-fidelity time series, using
publicly-available grid snapshots and historical data published by transmission
system operators. The proposed approach, from geo-spatial data and generation
capacity reconstruction, to time series disaggregation, is applied to the
French transmission grid. Thereby, synthetic but highly realistic time series
data, spanning multiple years with a 5-minute granularity, is generated at the
individual component level.",http://arxiv.org/pdf/2110.13772v1,cs.LG
2021-10-25 18:02:03+00:00,Probabilistic Hierarchical Forecasting with Deep Poisson Mixtures,"['Kin G. Olivares', 'O. Nganba Meetei', 'Ruijun Ma', 'Rohan Reddy', 'Mengfei Cao', 'Lee Dicker']","Hierarchical forecasting problems arise when time series have a natural group
structure, and predictions at multiple levels of aggregation and disaggregation
across the groups are needed. In such problems, it is often desired to satisfy
the aggregation constraints in a given hierarchy, referred to as hierarchical
coherence in the literature. Maintaining coherence while producing accurate
forecasts can be a challenging problem, especially in the case of probabilistic
forecasting. We present a novel method capable of accurate and coherent
probabilistic forecasts for time series when reliable hierarchical information
is present. We call it Deep Poisson Mixture Network (DPMN). It relies on the
combination of neural networks and a statistical model for the joint
distribution of the hierarchical multivariate time series structure. By
construction, the model guarantees hierarchical coherence and provides simple
rules for aggregation and disaggregation of the predictive distributions. We
perform an extensive empirical evaluation comparing the DPMN to other
state-of-the-art methods which produce hierarchically coherent probabilistic
forecasts on multiple public datasets. Comparing to existing coherent
probabilistic models, we obtain a relative improvement in the overall
Continuous Ranked Probability Score (CRPS) of 11.8% on Australian domestic
tourism data, and 8.1% on the Favorita grocery sales dataset, where time series
are grouped with geographical hierarchies or travel intent hierarchies. For San
Francisco Bay Area highway traffic, where the series' hierarchical structure is
randomly assigned, and their correlations are less informative, our method does
not show significant performance differences over statistical baselines.",http://arxiv.org/pdf/2110.13179v8,cs.LG
2021-10-25 15:11:32+00:00,Applying Regression Conformal Prediction with Nearest Neighbors to time series data,"['Samya Tajmouati', 'Bouazza El Wahbi', 'Mohammed Dakkoun']","In this paper, we apply conformal prediction to time series data. Conformal
prediction isa method that produces predictive regions given a confidence
level. The regions outputs arealways valid under the exchangeability
assumption. However, this assumption does not holdfor the time series data
because there is a link among past, current, and future
observations.Consequently, the challenge of applying conformal predictors to
the problem of time seriesdata lies in the fact that observations of a time
series are dependent and therefore do notmeet the exchangeability assumption.
This paper aims to present a way of constructingreliable prediction intervals
by using conformal predictors in the context of time series. Weuse the nearest
neighbors method based on the fast parameters tuning technique in theweighted
nearest neighbors (FPTO-WNN) approach as the underlying algorithm. Dataanalysis
demonstrates the effectiveness of the proposed approach.",http://arxiv.org/pdf/2110.13031v1,stat.ME
2021-10-23 19:57:22+00:00,Path Signature Area-Based Causal Discovery in Coupled Time Series,"['Will Glad', 'Thomas Woolf']","Coupled dynamical systems are frequently observed in nature, but often not
well understood in terms of their causal structure without additional domain
knowledge about the system. Especially when analyzing observational time series
data of dynamical systems where it is not possible to conduct controlled
experiments, for example time series of climate variables, it can be
challenging to determine how features causally influence each other. There are
many techniques available to recover causal relationships from data, such as
Granger causality, convergent cross mapping, and causal graph structure
learning approaches such as PCMCI. Path signatures and their associated signed
areas provide a new way to approach the analysis of causally linked dynamical
systems, particularly in informing a model-free, data-driven approach to
algorithmic causal discovery. With this paper, we explore the use of path
signatures in causal discovery and propose the application of confidence
sequences to analyze the significance of the magnitude of the signed area
between two variables. These confidence sequence regions converge with greater
sampling length, and in conjunction with analyzing pairwise signed areas across
time-shifted versions of the time series, can help identify the presence of
lag/lead causal relationships. This approach provides a new way to define the
confidence of a causal link existing between two time series, and ultimately
may provide a framework for hypothesis testing to define whether one time
series causes another",http://arxiv.org/pdf/2110.12288v1,stat.ML
2021-10-21 06:06:46+00:00,An Empirical Evaluation of Time-Series Feature Sets,"['Trent Henderson', 'Ben D. Fulcher']","Solving time-series problems with features has been rising in popularity due
to the availability of software for feature extraction. Feature-based
time-series analysis can now be performed using many different feature sets,
including hctsa (7730 features: Matlab), feasts (42 features: R), tsfeatures
(63 features: R), Kats (40 features: Python), tsfresh (up to 1558 features:
Python), TSFEL (390 features: Python), and the C-coded catch22 (22 features:
Matlab, R, Python, and Julia). There is substantial overlap in the types of
methods included in these sets (e.g., properties of the autocorrelation
function and Fourier power spectrum), but they are yet to be systematically
compared. Here we compare these seven sets on computational speed, assess the
redundancy of features contained in each, and evaluate the overlap and
redundancy between them. We take an empirical approach to feature similarity
based on outputs across a diverse set of real-world and simulated time series.
We find that feature sets vary across three orders of magnitude in their
computation time per feature on a laptop for a 1000-sample series, from the
fastest sets catch22 and TSFEL (~0.1ms per feature) to tsfeatures (~3s per
feature). Using PCA to evaluate feature redundancy within each set, we find the
highest within-set redundancy for TSFEL and tsfresh. For example, in TSFEL, 90%
of the variance across 390 features can be captured with just four PCs.
Finally, we introduce a metric for quantifying overlap between pairs of feature
sets, which indicates substantial overlap. We found that the largest feature
set, hctsa, is the most comprehensive, and that tsfresh is the most
distinctive, due to its incorporation of many low-level Fourier coefficients.
Our results provide empirical understanding of the differences between existing
feature sets, information that can be used to better tailor feature sets to
their applications.",http://arxiv.org/pdf/2110.10914v1,cs.LG
2021-10-20 23:24:45+00:00,"The R package sentometrics to compute, aggregate and predict with textual sentiment","['David Ardia', 'Keven Bluteau', 'Samuel Borms', 'Kris Boudt']","We provide a hands-on introduction to optimized textual sentiment indexation
using the R package sentometrics. Textual sentiment analysis is increasingly
used to unlock the potential information value of textual data. The
sentometrics package implements an intuitive framework to efficiently compute
sentiment scores of numerous texts, to aggregate the scores into multiple time
series, and to use these time series to predict other variables. The workflow
of the package is illustrated with a built-in corpus of news articles from two
major U.S. journals to forecast the CBOE Volatility Index.",http://arxiv.org/pdf/2110.10817v1,stat.ML
2021-10-17 09:13:45+00:00,Towards Better Long-range Time Series Forecasting using Generative Adversarial Networks,"['Shiyu Liu', 'Rohan Ghosh', 'Mehul Motani']","Long-range time series forecasting is usually based on one of two existing
forecasting strategies: Direct Forecasting and Iterative Forecasting, where the
former provides low bias, high variance forecasts and the later leads to low
variance, high bias forecasts. In this paper, we propose a new forecasting
strategy called Generative Forecasting (GenF), which generates synthetic data
for the next few time steps and then makes long-range forecasts based on
generated and observed data. We theoretically prove that GenF is able to better
balance the forecasting variance and bias, leading to a much smaller
forecasting error. We implement GenF via three components: (i) a novel
conditional Wasserstein Generative Adversarial Network (GAN) based generator
for synthetic time series data generation, called CWGAN-TS. (ii) a transformer
based predictor, which makes long-range predictions using both generated and
observed data. (iii) an information theoretic clustering algorithm to improve
the training of both the CWGAN-TS and the transformer based predictor. The
experimental results on five public datasets demonstrate that GenF
significantly outperforms a diverse range of state-of-the-art benchmarks and
classical approaches. Specifically, we find a 5% - 11% improvement in
predictive performance (mean absolute error) while having a 15% - 50% reduction
in parameters compared to the benchmarks. Lastly, we conduct an ablation study
to demonstrate the effectiveness of the components comprising GenF.",http://arxiv.org/pdf/2110.08770v2,cs.LG
2021-10-15 18:29:05+00:00,Memory-augmented Adversarial Autoencoders for Multivariate Time-series Anomaly Detection with Deep Reconstruction and Prediction,"['Qinfeng Xiao', 'Shikuan Shao', 'Jing Wang']","Detecting anomalies for multivariate time-series without manual supervision
continues a challenging problem due to the increased scale of dimensions and
complexity of today's IT monitoring systems. Recent progress of unsupervised
time-series anomaly detection mainly use deep autoencoders to solve this
problem, i.e. training on normal samples and producing significant
reconstruction error on abnormal inputs. However, in practice, autoencoders can
reconstruct anomalies so well, due to powerful capabilites of neural networks.
Besides, these approaches can be ineffective for identifying non-point
anomalies, e.g. contextual anomalies and collective anomalies, since they
solely utilze a point-wise reconstruction objective. To tackle the above
issues, we propose MemAAE (\textit{Memory-augmented Adversarial Autoencoders
with Deep Reconstruction and Prediction}), a novel unsupervised anomaly
detection method for time-series. By jointly training two complementary proxy
tasks, reconstruction and prediction, with a shared network architecture, we
show that detecting anomalies via multiple tasks obtains superior performance
rather than single-task training. Additionally, a compressive memory module is
introduced to preserve normal patterns, avoiding unexpected generalization on
abnormal inputs. Through extensive experiments, MemAAE achieves an overall F1
score of 0.90 on four public datasets, significantly outperforming the best
baseline by 0.02.",http://arxiv.org/pdf/2110.08306v1,cs.LG
2021-10-15 14:29:30+00:00,Quickest Inference of Network Cascades with Noisy Information,"['Anirudh Sridhar', 'H. Vincent Poor']","We study the problem of estimating the source of a network cascade given a
time series of noisy information about the spread. Initially, there is a single
vertex affected by the cascade (the source) and the cascade spreads in discrete
time steps across the network. The cascade evolution is hidden, but one can
observe a time series of noisy signals from each vertex. The time series of a
vertex is assumed to be a sequence of i.i.d. samples from a pre-change
distribution $Q_0$ before the cascade affects the vertex, and the time series
is a sequence of i.i.d. samples from a post-change distribution $Q_1$ once the
cascade has affected the vertex. Given the time series of noisy signals, which
can be viewed as a noisy measurement of the cascade evolution, we aim to devise
a procedure to reliably estimate the cascade source as fast as possible.
  We investigate Bayesian and minimax formulations of the source estimation
problem, and derive near-optimal estimators for simple cascade dynamics and
network topologies. In the Bayesian setting, an estimator which observes
samples until the error of the Bayes-optimal estimator falls below a threshold
achieves optimal performance. In the minimax setting, optimal performance is
achieved by designing a novel multi-hypothesis sequential probability ratio
test (MSPRT). We find that these optimal estimators require $\log \log n / \log
(k - 1)$ observations of the noisy time series when the network topology is a
$k$-regular tree, and $(\log n)^{\frac{1}{\ell + 1}}$ observations are required
for $\ell$-dimensional lattices. Finally, we discuss how our methods may be
extended to cascades on arbitrary graphs.",http://arxiv.org/pdf/2110.08115v2,math.ST
2021-10-14 18:33:57+00:00,A Semi-Supervised Approach for Abnormal Event Prediction on Large Operational Network Time-Series Data,"['Yijun Lin', 'Yao-Yi Chiang']","Large network logs, recording multivariate time series generated from
heterogeneous devices and sensors in a network, can often reveal important
information about abnormal activities, such as network intrusions and device
malfunctions. Existing machine learning methods for anomaly detection on
multivariate time series typically assume that 1) normal sequences would have
consistent behavior for training unsupervised models, or 2) require a large set
of labeled normal and abnormal sequences for supervised models. However, in
practice, normal network activities can demonstrate significantly varying
sequence patterns (e.g., before and after rerouting partial network traffic).
Also, the recorded abnormal events can be sparse. This paper presents a novel
semi-supervised method that efficiently captures dependencies between network
time series and across time points to generate meaningful representations of
network activities for predicting abnormal events. The method can use the
limited labeled data to explicitly learn separable embedding space for normal
and abnormal samples and effectively leverage unlabeled data to handle training
data scarcity. The experiments demonstrate that our approach significantly
outperformed state-of-the-art approaches for event detection on a large
real-world network log.",http://arxiv.org/pdf/2110.07660v1,cs.LG
2021-10-14 17:19:35+00:00,Time Series Clustering for Human Behavior Pattern Mining,"['Rohan Kabra', 'Divya Saxena', 'Dhaval Patel', 'Jiannong Cao']","Human behavior modeling deals with learning and understanding behavior
patterns inherent in humans' daily routines. Existing pattern mining techniques
either assume human dynamics is strictly periodic, or require the number of
modes as input, or do not consider uncertainty in the sensor data. To handle
these issues, in this paper, we propose a novel clustering approach for
modeling human behavior (named, MTpattern) from time-series data. For mining
frequent human behavior patterns effectively, we utilize a three-stage
pipeline: (1) represent time series data into a sequence of regularly sampled
equal-sized unit time intervals for better analysis, (2) a new distance measure
scheme is proposed to cluster similar sequences which can handle temporal
variation and uncertainty in the data, and (3) exploit an exemplar-based
clustering mechanism and fine-tune its parameters to output minimum number of
clusters with given permissible distance constraints and without knowing the
number of modes present in the data. Then, the average of all sequences in a
cluster is considered as a human behavior pattern. Empirical studies on two
real-world datasets and a simulated dataset demonstrate the effectiveness of
MTpattern with respect to internal and external measures of clustering.",http://arxiv.org/pdf/2110.07549v2,cs.LG
2021-10-12 22:09:29+00:00,Real-time Drift Detection on Time-series Data,"['Nandini Ramanan', 'Rasool Tahmasbi', 'Marjorie Sayer', 'Deokwoo Jung', 'Shalini Hemachandran', 'Claudionor Nunes Coelho Jr']","Practical machine learning applications involving time series data, such as
firewall log analysis to proactively detect anomalous behavior, are concerned
with real time analysis of streaming data. Consequently, we need to update the
ML models as the statistical characteristics of such data may shift frequently
with time. One alternative explored in the literature is to retrain models with
updated data whenever the models accuracy is observed to degrade. However,
these methods rely on near real time availability of ground truth, which is
rarely fulfilled. Further, in applications with seasonal data, temporal concept
drift is confounded by seasonal variation. In this work, we propose an approach
called Unsupervised Temporal Drift Detector or UTDD to flexibly account for
seasonal variation, efficiently detect temporal concept drift in time series
data in the absence of ground truth, and subsequently adapt our ML models to
concept drift for better generalization.",http://arxiv.org/pdf/2110.06383v1,cs.LG
2021-10-12 18:12:57+00:00,Causal discovery from conditionally stationary time-series,"['Carles Balsells Rodas', 'Ruibo Tu', 'Hedvig Kjellstrom']","Causal discovery, i.e., inferring underlying cause-effect relationships from
observations of a scene or system, is an inherent mechanism in human cognition,
but has been shown to be highly challenging to automate. The majority of
approaches in the literature aiming for this task consider constrained
scenarios with fully observed variables or data from stationary time-series. In
this work we aim for causal discovery in a more general class of scenarios,
scenes with non-stationary behavior over time. For our purposes we here regard
a scene as a composition objects interacting with each other over time.
Non-stationarity is modeled as stationarity conditioned on an underlying
variable, a state, which can be of varying dimension, more or less hidden given
observations of the scene, and also depend more or less directly on these
observations. We propose a probabilistic deep learning approach called
State-Dependent Causal Inference (SDCI) for causal discovery in such
conditionally stationary time-series data. Results in two different synthetic
scenarios show that this method is able to recover the underlying causal
dependencies with high accuracy even in cases with hidden states.",http://arxiv.org/pdf/2110.06257v1,cs.LG
2021-10-11 15:37:58+00:00,Graph-Guided Network for Irregularly Sampled Multivariate Time Series,"['Xiang Zhang', 'Marko Zeman', 'Theodoros Tsiligkaridis', 'Marinka Zitnik']","In many domains, including healthcare, biology, and climate science, time
series are irregularly sampled with varying time intervals between successive
readouts and different subsets of variables (sensors) observed at different
time points. Here, we introduce RAINDROP, a graph neural network that embeds
irregularly sampled and multivariate time series while also learning the
dynamics of sensors purely from observational data. RAINDROP represents every
sample as a separate sensor graph and models time-varying dependencies between
sensors with a novel message passing operator. It estimates the latent sensor
graph structure and leverages the structure together with nearby observations
to predict misaligned readouts. This model can be interpreted as a graph neural
network that sends messages over graphs that are optimized for capturing
time-varying dependencies among sensors. We use RAINDROP to classify time
series and interpret temporal dynamics on three healthcare and human activity
datasets. RAINDROP outperforms state-of-the-art methods by up to 11.4%
(absolute F1-score points), including techniques that deal with irregular
sampling using fixed discretization and set functions. RAINDROP shows
superiority in diverse setups, including challenging leave-sensor-out settings.",http://arxiv.org/pdf/2110.05357v2,cs.LG
2021-10-11 04:11:01+00:00,Graphical Assistant Grouped Network Autoregression Model: a Bayesian Nonparametric Recourse,"['Yimeng Ren', 'Xuening Zhu', 'Guanyu Hu']","Vector autoregression model is ubiquitous in classical time series data
analysis. With the rapid advance of social network sites, time series data over
latent graph is becoming increasingly popular. In this paper, we develop a
novel Bayesian grouped network autoregression model to simultaneously estimate
group information (number of groups and group configurations) and group-wise
parameters. Specifically, a graphically assisted Chinese restaurant process is
incorporated under framework of the network autoregression model to improve the
statistical inference performance. An efficient Markov chain Monte Carlo
sampling algorithm is used to sample from the posterior distribution. Extensive
studies are conducted to evaluate the finite sample performance of our proposed
methodology. Additionally, we analyze two real datasets as illustrations of the
effectiveness of our approach.",http://arxiv.org/pdf/2110.04991v1,stat.ME
2021-10-10 10:02:14+00:00,Time Series Classification Using Convolutional Neural Network On Imbalanced Datasets,['Syed Rawshon Jamil'],"Time Series Classification (TSC) has drawn a lot of attention in literature
because of its broad range of applications for different domains, such as
medical data mining, weather forecasting. Although TSC algorithms are designed
for balanced datasets, most real-life time series datasets are imbalanced. The
Skewed distribution is a problem for time series classification both in
distance-based and feature-based algorithms under the condition of poor class
separability. To address the imbalance problem, both sampling-based and
algorithmic approaches are used in this paper. Different methods significantly
improve time series classification's performance on imbalanced datasets.
Despite having a high imbalance ratio, the result showed that F score could be
as high as 97.6% for the simulated TwoPatterns Dataset.",http://arxiv.org/pdf/2110.04748v1,cs.LG
2021-10-08 19:35:39+00:00,Hankel-structured Tensor Robust PCA for Multivariate Traffic Time Series Anomaly Detection,"['Xudong Wang', 'Luis Miranda-Moreno', 'Lijun Sun']","Spatiotemporal traffic data (e.g., link speed/flow) collected from sensor
networks can be organized as multivariate time series with additional spatial
attributes. A crucial task in analyzing such data is to identify and detect
anomalous observations and events from the data with complex spatial and
temporal dependencies. Robust Principal Component Analysis (RPCA) is a widely
used tool for anomaly detection. However, the traditional RPCA purely relies on
the global low-rank assumption while ignoring the local temporal correlations.
In light of this, this study proposes a Hankel-structured tensor version of
RPCA for anomaly detection in spatiotemporal data. We treat the raw data with
anomalies as a multivariate time series matrix (location $\times$ time) and
assume the denoised matrix has a low-rank structure. Then we transform the
low-rank matrix to a third-order tensor by applying temporal Hankelization. In
the end, we decompose the corrupted matrix into a low-rank Hankel tensor and a
sparse matrix. With the Hankelization operation, the model can simultaneously
capture the global and local spatiotemporal correlations and exhibit more
robust performance. We formulate the problem as an optimization problem and use
tensor nuclear norm (TNN) to approximate the tensor rank and $l_1$ norm to
approximate the sparsity. We develop an efficient solution algorithm based on
the Alternating Direction Method of Multipliers (ADMM). Despite having three
hyper-parameters, the model is easy to set in practice. We evaluate the
proposed method by synthetic data and metro passenger flow time series and the
results demonstrate the accuracy of anomaly detection.",http://arxiv.org/pdf/2110.04352v1,cs.LG
2021-10-08 11:36:08+00:00,Subspace Change-Point Detection via Low-Rank Matrix Factorisation,"['Euan Thomas McGonigle', 'Hankui Peng']","Multivariate time series can often have a large number of dimensions, whether
it is due to the vast amount of collected features or due to how the data
sources are processed. Frequently, the main structure of the high-dimensional
time series can be well represented by a lower dimensional subspace. As vast
quantities of data are being collected over long periods of time, it is
reasonable to assume that the underlying subspace structure would change over
time. In this work, we propose a change-point detection method based on
low-rank matrix factorisation that can detect multiple changes in the
underlying subspace of a multivariate time series. Experimental results on both
synthetic and real data sets demonstrate the effectiveness of our approach and
its advantages against various state-of-the-art methods.",http://arxiv.org/pdf/2110.04044v1,stat.ME
2021-10-07 07:18:57+00:00,Darts: User-Friendly Modern Machine Learning for Time Series,"['Julien Herzen', 'Francesco Lässig', 'Samuele Giuliano Piazzetta', 'Thomas Neuer', 'Léo Tafti', 'Guillaume Raille', 'Tomas Van Pottelbergh', 'Marek Pasieka', 'Andrzej Skrodzki', 'Nicolas Huguenin', 'Maxime Dumonal', 'Jan Kościsz', 'Dennis Bader', 'Frédérick Gusset', 'Mounir Benheddi', 'Camila Williamson', 'Michal Kosinski', 'Matej Petrik', 'Gaël Grosch']","We present Darts, a Python machine learning library for time series, with a
focus on forecasting. Darts offers a variety of models, from classics such as
ARIMA to state-of-the-art deep neural networks. The emphasis of the library is
on offering modern machine learning functionalities, such as supporting
multidimensional series, meta-learning on multiple series, training on large
datasets, incorporating external data, ensembling models, and providing a rich
support for probabilistic forecasting. At the same time, great care goes into
the API design to make it user-friendly and easy to use. For instance, all
models can be used using fit()/predict(), similar to scikit-learn.",http://arxiv.org/pdf/2110.03224v3,cs.LG
2021-10-06 10:33:55+00:00,Anomaly Transformer: Time Series Anomaly Detection with Association Discrepancy,"['Jiehui Xu', 'Haixu Wu', 'Jianmin Wang', 'Mingsheng Long']","Unsupervised detection of anomaly points in time series is a challenging
problem, which requires the model to derive a distinguishable criterion.
Previous methods tackle the problem mainly through learning pointwise
representation or pairwise association, however, neither is sufficient to
reason about the intricate dynamics. Recently, Transformers have shown great
power in unified modeling of pointwise representation and pairwise association,
and we find that the self-attention weight distribution of each time point can
embody rich association with the whole series. Our key observation is that due
to the rarity of anomalies, it is extremely difficult to build nontrivial
associations from abnormal points to the whole series, thereby, the anomalies'
associations shall mainly concentrate on their adjacent time points. This
adjacent-concentration bias implies an association-based criterion inherently
distinguishable between normal and abnormal points, which we highlight through
the \emph{Association Discrepancy}. Technically, we propose the \emph{Anomaly
Transformer} with a new \emph{Anomaly-Attention} mechanism to compute the
association discrepancy. A minimax strategy is devised to amplify the
normal-abnormal distinguishability of the association discrepancy. The Anomaly
Transformer achieves state-of-the-art results on six unsupervised time series
anomaly detection benchmarks of three applications: service monitoring, space &
earth exploration, and water treatment.",http://arxiv.org/pdf/2110.02642v5,cs.LG
2021-10-05 18:20:42+00:00,Networked Time Series Prediction with Incomplete Data,"['Yichen Zhu', 'Bo Jiang', 'Haiming Jin', 'Mengtian Zhang', 'Feng Gao', 'Jianqiang Huang', 'Tao Lin', 'Xinbing Wang']","A networked time series (NETS) is a family of time series on a given graph,
one for each node. It has a wide range of applications from intelligent
transportation, environment monitoring to smart grid management. An important
task in such applications is to predict the future values of a NETS based on
its historical values and the underlying graph. Most existing methods require
complete data for training. However, in real-world scenarios, it is not
uncommon to have missing data due to sensor malfunction, incomplete sensing
coverage, etc. In this paper, we study the problem of NETS prediction with
incomplete data. We propose NETS-ImpGAN, a novel deep learning framework that
can be trained on incomplete data with missing values in both history and
future. Furthermore, we propose Graph Temporal Attention Networks, which
incorporate the attention mechanism to capture both inter-time series and
temporal correlations. We conduct extensive experiments on four real-world
datasets under different missing patterns and missing rates. The experimental
results show that NETS-ImpGAN outperforms existing methods, reducing the MAE by
up to 25%.",http://arxiv.org/pdf/2110.02271v2,cs.LG
2021-10-05 05:20:46+00:00,Attention Augmented Convolutional Transformer for Tabular Time-series,"['Sharath M Shankaranarayana', 'Davor Runje']","Time-series classification is one of the most frequently performed tasks in
industrial data science, and one of the most widely used data representation in
the industrial setting is tabular representation. In this work, we propose a
novel scalable architecture for learning representations from tabular
time-series data and subsequently performing downstream tasks such as
time-series classification. The representation learning framework is
end-to-end, akin to bidirectional encoder representations from transformers
(BERT) in language modeling, however, we introduce novel masking technique
suitable for pretraining of time-series data. Additionally, we also use
one-dimensional convolutions augmented with transformers and explore their
effectiveness, since the time-series datasets lend themselves naturally for
one-dimensional convolutions. We also propose a novel timestamp embedding
technique, which helps in handling both periodic cycles at different time
granularity levels, and aperiodic trends present in the time-series data. Our
proposed model is end-to-end and can handle both categorical and continuous
valued inputs, and does not require any quantization or encoding of continuous
features.",http://arxiv.org/pdf/2110.01825v1,cs.LG
2021-10-04 18:49:51+00:00,Cross-Modal Virtual Sensing for Combustion Instability Monitoring,"['Tryambak Gangopadhyay', 'Vikram Ramanan', 'Satyanarayanan R Chakravarthy', 'Soumik Sarkar']","In many cyber-physical systems, imaging can be an important but expensive or
'difficult to deploy' sensing modality. One such example is detecting
combustion instability using flame images, where deep learning frameworks have
demonstrated state-of-the-art performance. The proposed frameworks are also
shown to be quite trustworthy such that domain experts can have sufficient
confidence to use these models in real systems to prevent unwanted incidents.
However, flame imaging is not a common sensing modality in engine combustors
today. Therefore, the current roadblock exists on the hardware side regarding
the acquisition and processing of high-volume flame images. On the other hand,
the acoustic pressure time series is a more feasible modality for data
collection in real combustors. To utilize acoustic time series as a sensing
modality, we propose a novel cross-modal encoder-decoder architecture that can
reconstruct cross-modal visual features from acoustic pressure time series in
combustion systems. With the ""distillation"" of cross-modal features, the
results demonstrate that the detection accuracy can be enhanced using the
virtual visual sensing modality. By providing the benefit of cross-modal
reconstruction, our framework can prove to be useful in different domains well
beyond the power generation and transportation industries.",http://arxiv.org/pdf/2110.01659v2,cs.LG
2021-09-30 20:01:19+00:00,PIETS: Parallelised Irregularity Encoders for Forecasting with Heterogeneous Time-Series,"['Futoon M. Abushaqra', 'Hao Xue', 'Yongli Ren', 'Flora D. Salim']","Heterogeneity and irregularity of multi-source data sets present a
significant challenge to time-series analysis. In the literature, the fusion of
multi-source time-series has been achieved either by using ensemble learning
models which ignore temporal patterns and correlation within features or by
defining a fixed-size window to select specific parts of the data sets. On the
other hand, many studies have shown major improvement to handle the
irregularity of time-series, yet none of these studies has been applied to
multi-source data. In this work, we design a novel architecture, PIETS, to
model heterogeneous time-series. PIETS has the following characteristics: (1)
irregularity encoders for multi-source samples that can leverage all available
information and accelerate the convergence of the model; (2) parallelised
neural networks to enable flexibility and avoid information overwhelming; and
(3) attention mechanism that highlights different information and gives high
importance to the most related data. Through extensive experiments on
real-world data sets related to COVID-19, we show that the proposed
architecture is able to effectively model heterogeneous temporal data and
outperforms other state-of-the-art approaches in the prediction task.",http://arxiv.org/pdf/2110.00071v2,cs.LG
2021-09-30 00:58:27+00:00,CALDA: Improving Multi-Source Time Series Domain Adaptation with Contrastive Adversarial Learning,"['Garrett Wilson', 'Janardhan Rao Doppa', 'Diane J. Cook']","Unsupervised domain adaptation (UDA) provides a strategy for improving
machine learning performance in data-rich (target) domains where ground truth
labels are inaccessible but can be found in related (source) domains. In cases
where meta-domain information such as label distributions is available, weak
supervision can further boost performance. We propose a novel framework, CALDA,
to tackle these two problems. CALDA synergistically combines the principles of
contrastive learning and adversarial learning to robustly support multi-source
UDA (MS-UDA) for time series data. Similar to prior methods, CALDA utilizes
adversarial learning to align source and target feature representations. Unlike
prior approaches, CALDA additionally leverages cross-source label information
across domains. CALDA pulls examples with the same label close to each other,
while pushing apart examples with different labels, reshaping the space through
contrastive learning. Unlike prior contrastive adaptation methods, CALDA
requires neither data augmentation nor pseudo labeling, which may be more
challenging for time series. We empirically validate our proposed approach.
Based on results from human activity recognition, electromyography, and
synthetic datasets, we find utilizing cross-source information improves
performance over prior time series and contrastive methods. Weak supervision
further improves performance, even in the presence of noise, allowing CALDA to
offer generalizable strategies for MS-UDA. Code is available at:
https://github.com/floft/calda",http://arxiv.org/pdf/2109.14778v2,cs.LG
2021-09-29 22:54:17+00:00,"Kernel distance measures for time series, random fields and other structured data","['Srinjoy Das', 'Hrushikesh Mhaskar', 'Alexander Cloninger']","This paper introduces kdiff, a novel kernel-based measure for estimating
distances between instances of time series, random fields and other forms of
structured data. This measure is based on the idea of matching distributions
that only overlap over a portion of their region of support. Our proposed
measure is inspired by MPdist which has been previously proposed for such
datasets and is constructed using Euclidean metrics, whereas kdiff is
constructed using non-linear kernel distances. Also, kdiff accounts for both
self and cross similarities across the instances and is defined using a lower
quantile of the distance distribution. Comparing the cross similarity to self
similarity allows for measures of similarity that are more robust to noise and
partial occlusions of the relevant signals. Our proposed measure kdiff is a
more general form of the well known kernel-based Maximum Mean Discrepancy (MMD)
distance estimated over the embeddings. Some theoretical results are provided
for separability conditions using kdiff as a distance measure for clustering
and classification problems where the embedding distributions can be modeled as
two component mixtures. Applications are demonstrated for clustering of
synthetic and real-life time series and image data, and the performance of
kdiff is compared to competing distance measures for clustering.",http://arxiv.org/pdf/2109.14752v1,stat.ML
2021-09-28 13:12:09+00:00,Improving Time Series Classification Algorithms Using Octave-Convolutional Layers,"['Samuel Harford', 'Fazle Karim', 'Houshang Darabi']","Deep learning models utilizing convolution layers have achieved
state-of-the-art performance on univariate time series classification tasks. In
this work, we propose improving CNN based time series classifiers by utilizing
Octave Convolutions (OctConv) to outperform themselves. These network
architectures include Fully Convolutional Networks (FCN), Residual Neural
Networks (ResNets), LSTM-Fully Convolutional Networks (LSTM-FCN), and Attention
LSTM-Fully Convolutional Networks (ALSTM-FCN). The proposed layers
significantly improve each of these models with minimally increased network
parameters. In this paper, we experimentally show that by substituting
convolutions with OctConv, we significantly improve accuracy for time series
classification tasks for most of the benchmark datasets. In addition, the
updated ALSTM-OctFCN performs statistically the same as the top two time series
classifers, TS-CHIEF and HIVE-COTE (both ensemble models). To further explore
the impact of the OctConv layers, we perform ablation tests of the augmented
model compared to their base model.",http://arxiv.org/pdf/2109.13696v1,cs.LG
2021-09-27 10:44:07+00:00,Time Series Model Attribution Visualizations as Explanations,"['Udo Schlegel', 'Daniel A. Keim']","Attributions are a common local explanation technique for deep learning
models on single samples as they are easily extractable and demonstrate the
relevance of input values. In many cases, heatmaps visualize such attributions
for samples, for instance, on images. However, heatmaps are not always the
ideal visualization to explain certain model decisions for other data types. In
this review, we focus on attribution visualizations for time series. We collect
attribution heatmap visualizations and some alternatives, discuss the
advantages as well as disadvantages and give a short position towards future
opportunities for attributions and explanations for time series.",http://arxiv.org/pdf/2109.12935v1,cs.LG
2021-09-23 21:02:40+00:00,Deep Learning with Kernel Flow Regularization for Time Series Forecasting,"['Mahdy Shirdel', 'Reza Asadi', 'Duc Do', 'Micheal Hintlian']","Long Short-Term Memory (LSTM) neural networks have been widely used for time
series forecasting problems. However, LSTMs are prone to overfitting and
performance reduction during test phases. Several different regularization
techniques have been shown in literature to prevent overfitting problems in
neural networks. In this paper, first, we introduce application of kernel flow
methods for time series forecasting in general. Afterward, we examine the
effectiveness of applying kernel flow regularization on LSTM layers to avoid
overfitting problems. We describe a regularization method by applying kernel
flow loss function on LSTM layers. In experimental results, we show that kernel
flow outperforms baseline models on time series forecasting benchmarks. We also
compare the effect of dropout and kernel flow regularization techniques on
LSTMs. The experimental results illustrate that kernel flow achieves similar
regularization effect to dropout. It also shows that the best results is
obtained using both kernel flow and dropout regularizations with early stopping
on LSTM layers on some time series datasets (e.g. power-load demand forecasts).",http://arxiv.org/pdf/2109.11649v1,cs.LG
2021-09-23 15:14:24+00:00,An Evaluation of Anomaly Detection and Diagnosis in Multivariate Time Series,"['Astha Garg', 'Wenyu Zhang', 'Jules Samaran', 'Savitha Ramasamy', 'Chuan-Sheng Foo']","Several techniques for multivariate time series anomaly detection have been
proposed recently, but a systematic comparison on a common set of datasets and
metrics is lacking. This paper presents a systematic and comprehensive
evaluation of unsupervised and semi-supervised deep-learning based methods for
anomaly detection and diagnosis on multivariate time series data from
cyberphysical systems. Unlike previous works, we vary the model and
post-processing of model errors, i.e. the scoring functions independently of
each other, through a grid of 10 models and 4 scoring functions, comparing
these variants to state of the art methods. In time-series anomaly detection,
detecting anomalous events is more important than detecting individual
anomalous time-points. Through experiments, we find that the existing
evaluation metrics either do not take events into account, or cannot
distinguish between a good detector and trivial detectors, such as a random or
an all-positive detector. We propose a new metric to overcome these drawbacks,
namely, the composite F-score ($Fc_1$), for evaluating time-series anomaly
detection.
  Our study highlights that dynamic scoring functions work much better than
static ones for multivariate time series anomaly detection, and the choice of
scoring functions often matters more than the choice of the underlying model.
We also find that a simple, channel-wise model - the Univariate Fully-Connected
Auto-Encoder, with the dynamic Gaussian scoring function emerges as a winning
candidate for both anomaly detection and diagnosis, beating state of the art
algorithms.",http://arxiv.org/pdf/2109.11428v1,cs.LG
2021-09-23 13:36:44+00:00,Multi-fidelity surrogate modeling for time-series outputs,['Baptiste Kerleguer'],"This paper considers the surrogate modeling of a complex numerical code in a
multifidelity framework when the code output is a time series. Using an
experimental design of the low-and high-fidelity code levels, an original
Gaussian process regression method is proposed. The code output is expanded on
a basis built from the experimental design. The first coefficients of the
expansion of the code output are processed by a co-kriging approach. The last
coefficients are collectively processed by a kriging approach with covariance
tensorization. The resulting surrogate model taking into account the
uncertainty in the basis construction is shown to have better performance in
terms of prediction errors and uncertainty quantification than standard
dimension reduction techniques.",http://arxiv.org/pdf/2109.11374v2,math.ST
2021-09-22 20:26:12+00:00,Quantile-based fuzzy C-means clustering of multivariate time series: Robust techniques,"['Ángel López-Oriona', ""Pierpaolo D'Urso"", 'José Antonio Vilar', 'Borja Lafuente-Rego']","Three robust methods for clustering multivariate time series from the point
of view of generating processes are proposed. The procedures are robust
versions of a fuzzy C-means model based on: (i) estimates of the quantile
cross-spectral density and (ii) the classical principal component analysis.
Robustness to the presence of outliers is achieved by using the so-called
metric, noise and trimmed approaches. The metric approach incorporates in the
objective function a distance measure aimed at neutralizing the effect of the
outliers, the noise approach builds an artificial cluster expected to contain
the outlying series and the trimmed approach eliminates the most atypical
series in the dataset. All the proposed techniques inherit the nice properties
of the quantile cross-spectral density, as being able to uncover general types
of dependence. Results from a broad simulation study including multivariate
linear, nonlinear and GARCH processes indicate that the algorithms are
substantially effective in coping with the presence of outlying series (i.e.,
series exhibiting a dependence structure different from that of the majority),
clearly poutperforming alternative procedures. The usefulness of the suggested
methods is highlighted by means of two specific applications regarding
financial and environmental series.",http://arxiv.org/pdf/2109.11027v1,stat.ME
2021-09-22 16:07:27+00:00,Causal Inference in Non-linear Time-series using Deep Networks and Knockoff Counterfactuals,"['Wasim Ahmad', 'Maha Shadaydeh', 'Joachim Denzler']","Estimating causal relations is vital in understanding the complex
interactions in multivariate time series. Non-linear coupling of variables is
one of the major challenges inaccurate estimation of cause-effect relations. In
this paper, we propose to use deep autoregressive networks (DeepAR) in tandem
with counterfactual analysis to infer nonlinear causal relations in
multivariate time series. We extend the concept of Granger causality using
probabilistic forecasting with DeepAR. Since deep networks can neither handle
missing input nor out-of-distribution intervention, we propose to use the
Knockoffs framework (Barberand Cand`es, 2015) for generating intervention
variables and consequently counterfactual probabilistic forecasting. Knockoff
samples are independent of their output given the observed variables and
exchangeable with their counterpart variables without changing the underlying
distribution of the data. We test our method on synthetic as well as real-world
time series datasets. Overall our method outperforms the widely used vector
autoregressive Granger causality and PCMCI in detecting nonlinear causal
dependency in multivariate time series.",http://arxiv.org/pdf/2109.10817v3,cs.LG
2021-09-21 22:52:58+00:00,Personalized Online Machine Learning,"['Ivana Malenica', 'Rachael V. Phillips', 'Romain Pirracchio', 'Antoine Chambaz', 'Alan Hubbard', 'Mark J. van der Laan']","In this work, we introduce the Personalized Online Super Learner (POSL) -- an
online ensembling algorithm for streaming data whose optimization procedure
accommodates varying degrees of personalization. Namely, POSL optimizes
predictions with respect to baseline covariates, so personalization can vary
from completely individualized (i.e., optimization with respect to baseline
covariate subject ID) to many individuals (i.e., optimization with respect to
common baseline covariates). As an online algorithm, POSL learns in real-time.
POSL can leverage a diversity of candidate algorithms, including online
algorithms with different training and update times, fixed algorithms that are
never updated during the procedure, pooled algorithms that learn from many
individuals' time-series, and individualized algorithms that learn from within
a single time-series. POSL's ensembling of this hybrid of base learning
strategies depends on the amount of data collected, the stationarity of the
time-series, and the mutual characteristics of a group of time-series. In
essence, POSL decides whether to learn across samples, through time, or both,
based on the underlying (unknown) structure in the data. For a wide range of
simulations that reflect realistic forecasting scenarios, and in a medical data
application, we examine the performance of POSL relative to other current
ensembling and online learning methods. We show that POSL is able to provide
reliable predictions for time-series data and adjust to changing
data-generating environments. We further cultivate POSL's practicality by
extending it to settings where time-series enter/exit dynamically over
chronological time.",http://arxiv.org/pdf/2109.10452v1,stat.ML
2021-09-21 08:23:27+00:00,Online Multi-horizon Transaction Metric Estimation with Multi-modal Learning in Payment Networks,"['Chin-Chia Michael Yeh', 'Zhongfang Zhuang', 'Junpeng Wang', 'Yan Zheng', 'Javid Ebrahimi', 'Ryan Mercer', 'Liang Wang', 'Wei Zhang']","Predicting metrics associated with entities' transnational behavior within
payment processing networks is essential for system monitoring. Multivariate
time series, aggregated from the past transaction history, can provide valuable
insights for such prediction. The general multivariate time series prediction
problem has been well studied and applied across several domains, including
manufacturing, medical, and entomology. However, new domain-related challenges
associated with the data such as concept drift and multi-modality have surfaced
in addition to the real-time requirements of handling the payment transaction
data at scale. In this work, we study the problem of multivariate time series
prediction for estimating transaction metrics associated with entities in the
payment transaction database. We propose a model with five unique components to
estimate the transaction metrics from multi-modality data. Four of these
components capture interaction, temporal, scale, and shape perspectives, and
the fifth component fuses these perspectives together. We also propose a hybrid
offline/online training scheme to address concept drift in the data and fulfill
the real-time requirements. Combining the estimation model with a graphical
user interface, the prototype transaction metric estimation system has
demonstrated its potential benefit as a tool for improving a payment processing
company's system monitoring capability.",http://arxiv.org/pdf/2109.10020v2,cs.LG
2021-09-21 08:07:47+00:00,A Bernstein-type Inequality for High Dimensional Linear Processes with Applications to Robust Estimation of Time Series Regressions,"['Linbo Liu', 'Danna Zhang']","Time series regression models are commonly used in time series analysis.
However, in modern real-world applications, serially correlated data with an
ultra-high dimension and fat tails are prevalent. This presents a challenge in
developing new statistical tools for time series analysis. In this paper, we
propose a novel Bernstein-type inequality for high-dimensional linear processes
and apply it to investigate two high-dimensional robust estimation problems:
(1) time series regression with fat-tailed and correlated covariates and
errors, and (2) fat-tailed vector autoregression. Our proposed approach allows
for exponential increases in dimension with sample size under mild moment and
dependence conditions, while ensuring consistency in the estimation process.",http://arxiv.org/pdf/2109.10354v3,math.ST
2021-09-20 17:02:29+00:00,Modeling Regime Shifts in Multiple Time Series,"['Etienne Gael Tajeuna', 'Mohamed Bouguessa', 'Shengrui Wang']","We investigate the problem of discovering and modeling regime shifts in an
ecosystem comprising multiple time series known as co-evolving time series.
Regime shifts refer to the changing behaviors exhibited by series at different
time intervals. Learning these changing behaviors is a key step toward time
series forecasting. While advances have been made, existing methods suffer from
one or more of the following shortcomings: (1) failure to take relationships
between time series into consideration for discovering regimes in multiple time
series; (2) lack of an effective approach that models time-dependent behaviors
exhibited by series; (3) difficulties in handling data discontinuities which
may be informative. Most of the existing methods are unable to handle all of
these three issues in a unified framework. This, therefore, motivates our
effort to devise a principled approach for modeling interactions and
time-dependency in co-evolving time series. Specifically, we model an ecosystem
of multiple time series by summarizing the heavy ensemble of time series into a
lighter and more meaningful structure called a \textit{mapping grid}. By using
the mapping grid, our model first learns time series behavioral dependencies
through a dynamic network representation, then learns the regime transition
mechanism via a full time-dependent Cox regression model. The originality of
our approach lies in modeling interactions between time series in regime
identification and in modeling time-dependent regime transition probabilities,
usually assumed to be static in existing work.",http://arxiv.org/pdf/2109.09692v4,cs.LG
2021-09-20 02:03:43+00:00,Merlion: A Machine Learning Library for Time Series,"['Aadyot Bhatnagar', 'Paul Kassianik', 'Chenghao Liu', 'Tian Lan', 'Wenzhuo Yang', 'Rowan Cassius', 'Doyen Sahoo', 'Devansh Arpit', 'Sri Subramanian', 'Gerald Woo', 'Amrita Saha', 'Arun Kumar Jagota', 'Gokulakrishnan Gopalakrishnan', 'Manpreet Singh', 'K C Krithika', 'Sukumar Maddineni', 'Daeki Cho', 'Bo Zong', 'Yingbo Zhou', 'Caiming Xiong', 'Silvio Savarese', 'Steven Hoi', 'Huan Wang']","We introduce Merlion, an open-source machine learning library for time
series. It features a unified interface for many commonly used models and
datasets for anomaly detection and forecasting on both univariate and
multivariate time series, along with standard pre/post-processing layers. It
has several modules to improve ease-of-use, including visualization, anomaly
score calibration to improve interpetability, AutoML for hyperparameter tuning
and model selection, and model ensembling. Merlion also provides a unique
evaluation framework that simulates the live deployment and re-training of a
model in production. This library aims to provide engineers and researchers a
one-stop solution to rapidly develop models for their specific time series
needs and benchmark them across multiple time series datasets. In this
technical report, we highlight Merlion's architecture and major
functionalities, and we report benchmark numbers across different baseline
models and ensembles.",http://arxiv.org/pdf/2109.09265v1,cs.LG
2021-09-17 18:20:58+00:00,Graphical models for nonstationary time series,"['Sumanta Basu', 'Suhasini Subba Rao']","We propose NonStGM, a general nonparametric graphical modeling framework for
studying dynamic associations among the components of a nonstationary
multivariate time series. It builds on the framework of Gaussian Graphical
Models (GGM) and stationary time series Gaussian Graphical model (StGM), and
complements existing works on parametric graphical models based on change point
vector autoregressions (VAR). Analogous to StGM, the proposed framework
captures conditional noncorrelations (both intertemporal and contemporaneous)
in the form of an undirected graph. In addition, to describe the more nuanced
nonstationary relationships among the components of the time series, we
introduce the new notion of conditional nonstationarity/stationarity and
incorporate it within the graph architecture. This allows one to distinguish
between direct and indirect nonstationary relationships among system
components, and can be used to search for small subnetworks that serve as the
""source"" of nonstationarity in a large system. Together, the two concepts of
conditional noncorrelation and nonstationarity/stationarity provide a
parsimonious description of the dependence structure of the time series.",http://arxiv.org/pdf/2109.08709v4,math.ST
2021-09-17 10:00:16+00:00,TS-MULE: Local Interpretable Model-Agnostic Explanations for Time Series Forecast Models,"['Udo Schlegel', 'Duy Vo Lam', 'Daniel A. Keim', 'Daniel Seebacher']","Time series forecasting is a demanding task ranging from weather to failure
forecasting with black-box models achieving state-of-the-art performances.
However, understanding and debugging are not guaranteed. We propose TS-MULE, a
local surrogate model explanation method specialized for time series extending
the LIME approach. Our extended LIME works with various ways to segment and
perturb the time series data. In our extension, we present six sampling
segmentation approaches for time series to improve the quality of surrogate
attributions and demonstrate their performances on three deep learning model
architectures and three common multivariate time series datasets.",http://arxiv.org/pdf/2109.08438v1,cs.LG
2021-09-17 07:35:26+00:00,From Known to Unknown: Knowledge-guided Transformer for Time-Series Sales Forecasting in Alibaba,"['Xinyuan Qi', 'Kai Hou', 'Tong Liu', 'Zhongzhong Yu', 'Sihao Hu', 'Wenwu Ou']","Time series forecasting (TSF) is fundamentally required in many real-world
applications, such as electricity consumption planning and sales forecasting.
In e-commerce, accurate time-series sales forecasting (TSSF) can significantly
increase economic benefits. TSSF in e-commerce aims to predict future sales of
millions of products. The trend and seasonality of products vary a lot, and the
promotion activity heavily influences sales. Besides the above difficulties, we
can know some future knowledge in advance except for the historical statistics.
Such future knowledge may reflect the influence of the future promotion
activity on current sales and help achieve better accuracy. However, most
existing TSF methods only predict the future based on historical information.
In this work, we make up for the omissions of future knowledge. Except for
introducing future knowledge for prediction, we propose Aliformer based on the
bidirectional Transformer, which can utilize the historical information,
current factor, and future knowledge to predict future sales. Specifically, we
design a knowledge-guided self-attention layer that uses known knowledge's
consistency to guide the transmission of timing information. And the
future-emphasized training strategy is proposed to make the model focus more on
the utilization of future knowledge. Extensive experiments on four public
benchmark datasets and one proposed large-scale industrial dataset from Tmall
demonstrate that Aliformer can perform much better than state-of-the-art TSF
methods. Aliformer has been deployed for goods selection on Tmall Industry
Tablework, and the dataset will be released upon approval.",http://arxiv.org/pdf/2109.08381v2,cs.LG
2021-09-15 22:50:25+00:00,Direct estimation of differential Granger causality between two high-dimensional time series,"['Yue Wang', 'Jing Ma', 'Ali Shojaie']","Differential Granger causality, that is understanding how Granger causal
relations differ between two related time series, is of interest in many
scientific applications. Modeling each time series by a vector autoregressive
(VAR) model, we propose a new method to directly learn the difference between
the corresponding transition matrices in high dimensions. Key to the new method
is an estimating equation constructed based on the Yule-Walker equation that
links the difference in transition matrices to the difference in the
corresponding precision matrices. In contrast to separately estimating each
transition matrix and then calculating the difference, the proposed direct
estimation method only requires sparsity of the difference of the two VAR
models, and hence allows hub nodes in each high-dimensional time series. The
direct estimator is shown to be consistent in estimation and support recovery
under mild assumptions. These results also lead to novel consistency results
with potentially faster convergence rates for estimating differences between
precision matrices of i.i.d observations under weaker assumptions than existing
results. We evaluate the finite sample performance of the proposed method using
simulation studies and an application to electroencephalogram (EEG) data.",http://arxiv.org/pdf/2109.07609v2,stat.ME
2021-09-15 22:30:19+00:00,Interpretable Additive Recurrent Neural Networks For Multivariate Clinical Time Series,"['Asif Rahman', 'Yale Chang', 'Jonathan Rubin']","Time series models with recurrent neural networks (RNNs) can have high
accuracy but are unfortunately difficult to interpret as a result of
feature-interactions, temporal-interactions, and non-linear transformations.
Interpretability is important in domains like healthcare where constructing
models that provide insight into the relationships they have learned are
required to validate and trust model predictions. We want accurate time series
models where users can understand the contribution of individual input
features. We present the Interpretable-RNN (I-RNN) that balances model
complexity and accuracy by forcing the relationship between variables in the
model to be additive. Interactions are restricted between hidden states of the
RNN and additively combined at the final step. I-RNN specifically captures the
unique characteristics of clinical time series, which are unevenly sampled in
time, asynchronously acquired, and have missing data. Importantly, the hidden
state activations represent feature coefficients that correlate with the
prediction target and can be visualized as risk curves that capture the global
relationship between individual input features and the outcome. We evaluate the
I-RNN model on the Physionet 2012 Challenge dataset to predict in-hospital
mortality, and on a real-world clinical decision support task: predicting
hemodynamic interventions in the intensive care unit. I-RNN provides
explanations in the form of global and local feature importances comparable to
highly intelligible models like decision trees trained on hand-engineered
features while significantly outperforming them. I-RNN remains intelligible
while providing accuracy comparable to state-of-the-art decay-based and
interpolation-based recurrent time series models. The experimental results on
real-world clinical datasets refute the myth that there is a tradeoff between
accuracy and interpretability.",http://arxiv.org/pdf/2109.07602v1,cs.LG
2021-09-14 15:56:37+00:00,Multiple shooting for training neural differential equations on time series,"['Evren Mert Turan', 'Johannes Jäschke']","Neural differential equations have recently emerged as a flexible
data-driven/hybrid approach to model time-series data. This work experimentally
demonstrates that if the data contains oscillations, then standard fitting of a
neural differential equation may result in a flattened out trajectory that
fails to describe the data. We then introduce the multiple shooting method and
present successful demonstrations of this method for the fitting of a neural
differential equation to two datasets (synthetic and experimental) that the
standard approach fails to fit. Constraints introduced by multiple shooting can
be satisfied using a penalty or augmented Lagrangian method.",http://arxiv.org/pdf/2109.06786v2,cs.LG
2021-09-14 10:15:52+00:00,Anomaly Attribution of Multivariate Time Series using Counterfactual Reasoning,"['Violeta Teodora Trifunov', 'Maha Shadaydeh', 'Björn Barz', 'Joachim Denzler']","There are numerous methods for detecting anomalies in time series, but that
is only the first step to understanding them. We strive to exceed this by
explaining those anomalies. Thus we develop a novel attribution scheme for
multivariate time series relying on counterfactual reasoning. We aim to answer
the counterfactual question of would the anomalous event have occurred if the
subset of the involved variables had been more similarly distributed to the
data outside of the anomalous interval. Specifically, we detect anomalous
intervals using the Maximally Divergent Interval (MDI) algorithm, replace a
subset of variables with their in-distribution values within the detected
interval and observe if the interval has become less anomalous, by re-scoring
it with MDI. We evaluate our method on multivariate temporal and
spatio-temporal data and confirm the accuracy of our anomaly attribution of
multiple well-understood extreme climate events such as heatwaves and
hurricanes.",http://arxiv.org/pdf/2109.06562v1,cs.LG
2021-09-14 07:38:35+00:00,Instance-wise Graph-based Framework for Multivariate Time Series Forecasting,"['Wentao Xu', 'Weiqing Liu', 'Jiang Bian', 'Jian Yin', 'Tie-Yan Liu']","The multivariate time series forecasting has attracted more and more
attention because of its vital role in different fields in the real world, such
as finance, traffic, and weather. In recent years, many research efforts have
been proposed for forecasting multivariate time series. Although some previous
work considers the interdependencies among different variables in the same
timestamp, existing work overlooks the inter-connections between different
variables at different time stamps. In this paper, we propose a simple yet
efficient instance-wise graph-based framework to utilize the inter-dependencies
of different variables at different time stamps for multivariate time series
forecasting. The key idea of our framework is aggregating information from the
historical time series of different variables to the current time series that
we need to forecast. We conduct experiments on the Traffic, Electricity, and
Exchange-Rate multivariate time series datasets. The results show that our
proposed model outperforms the state-of-the-art baseline methods.",http://arxiv.org/pdf/2109.06489v1,cs.LG
2021-09-13 18:42:37+00:00,Predicting the outcome of team movements -- Player time series analysis using fuzzy and deep methods for representation learning,"['Omid Shokrollahi', 'Bahman Rohani', 'Amin Nobakhti']","We extract and use player position time-series data, tagged along with the
action types, to build a competent model for representing team tactics
behavioral patterns and use this representation to predict the outcome of
arbitrary movements. We provide a framework for the useful encoding of short
tactics and space occupations in a more extended sequence of movements or
tactical plans. We investigate game segments during a match in which the team
in possession of the ball regularly attempts to reach a position where they can
take a shot at goal for a single game. A carefully designed and efficient
kernel is employed using a triangular fuzzy membership function to create
multiple time series for players' potential of presence at different court
regions. Unsupervised learning is then used for time series using triplet loss
and deep neural networks with exponentially dilated causal convolutions for the
derived multivariate time series. This works key contribution lies in its
approach to model how short scenes contribute to other longer ones and how
players occupies and creates new spaces in-game court. We discuss the
effectiveness of the proposed approach for prediction and recognition tasks on
the professional basketball SportVU dataset for the 2015-16 half-season. The
proposed system demonstrates descent functionality even with relatively small
data.",http://arxiv.org/pdf/2109.07570v1,cs.LG
2021-09-10 16:34:35+00:00,A Study of Joint Graph Inference and Forecasting,"['Daniel Zügner', 'François-Xavier Aubet', 'Victor Garcia Satorras', 'Tim Januschowski', 'Stephan Günnemann', 'Jan Gasthaus']","We study a recent class of models which uses graph neural networks (GNNs) to
improve forecasting in multivariate time series.
  The core assumption behind these models is that there is a latent graph
between the time series (nodes) that governs the evolution of the multivariate
time series.
  By parameterizing a graph in a differentiable way, the models aim to improve
forecasting quality.
  We compare four recent models of this class on the forecasting task. Further,
we perform ablations to study their behavior under changing conditions, e.g.,
when disabling the graph-learning modules and providing the ground-truth
relations instead. Based on our findings, we propose novel ways of combining
the existing architectures.",http://arxiv.org/pdf/2109.04979v1,cs.LG
2021-09-10 07:53:59+00:00,Implicit Copulas: An Overview,['Michael Stanley Smith'],"Implicit copulas are the most common copula choice for modeling dependence in
high dimensions. This broad class of copulas is introduced and surveyed,
including elliptical copulas, skew $t$ copulas, factor copulas, time series
copulas and regression copulas. The common auxiliary representation of implicit
copulas is outlined, and how this makes them both scalable and tractable for
statistical modeling. Issues such as parameter identification, extended
likelihoods for discrete or mixed data, parsimony in high dimensions, and
simulation from the copula model are considered. Bayesian approaches to
estimate the copula parameters, and predict from an implicit copula model, are
outlined. Particular attention is given to implicit copula processes
constructed from time series and regression models, which is at the forefront
of current research. Two econometric applications -- one from macroeconomic
time series and the other from financial asset pricing -- illustrate the
advantages of implicit copula models.",http://arxiv.org/pdf/2109.04718v1,stat.ME
2021-09-09 10:11:43+00:00,Multi-population mortality forecasting using high-dimensional functional factor models,"['Chen Tang', 'Han Lin Shang', 'Yanrong Yang']","This paper proposes a two-fold factor model for high-dimensional functional
time series (HDFTS), which enables the modeling and forecasting of
multi-population mortality under the functional data framework. The proposed
model first decomposes the HDFTS into functional time series with lower
dimensions (common feature) and a system of basis functions specific to
different cross-sections (heterogeneity). Then the lower-dimensional common
functional time series are further reduced into low-dimensional scalar factor
matrices. The dimensionally reduced factor matrices can reasonably convey
useful information in the original HDFTS. All the temporal dynamics contained
in the original HDFTS are extracted to facilitate forecasting. The proposed
model can be regarded as a general case of several existing functional factor
models. Through a Monte Carlo simulation, we demonstrate the performance of the
proposed method in model fitting. In an empirical study of the Japanese
subnational age-specific mortality rates, we show that the proposed model
produces more accurate point and interval forecasts in modeling
multi-population mortality than those existing functional factor models. The
financial impact of the improvements in forecasts is demonstrated through
comparisons in life annuity pricing practices.",http://arxiv.org/pdf/2109.04146v1,stat.ME
2021-09-08 15:38:33+00:00,Quantile-based fuzzy clustering of multivariate time series in the frequency domain,"['Ángel López-Oriona', 'José A. Vilar', ""Pierpaolo-D'Urso""]","A novel procedure to perform fuzzy clustering of multivariate time series
generated from different dependence models is proposed. Different amounts of
dissimilarity between the generating models or changes on the dynamic
behaviours over time are some arguments justifying a fuzzy approach, where each
series is associated to all the clusters with specific membership levels. Our
procedure considers quantile-based cross-spectral features and consists of
three stages: (i) each element is characterized by a vector of proper estimates
of the quantile cross-spectral densities, (ii) principal component analysis is
carried out to capture the main differences reducing the effects of the noise,
and (iii) the squared Euclidean distance between the first retained principal
components is used to perform clustering through the standard fuzzy C-means and
fuzzy C-medoids algorithms. The performance of the proposed approach is
evaluated in a broad simulation study where several types of generating
processes are considered, including linear, nonlinear and dynamic conditional
correlation models. Assessment is done in two different ways: by directly
measuring the quality of the resulting fuzzy partition and by taking into
account the ability of the technique to determine the overlapping nature of
series located equidistant from well-defined clusters. The procedure is
compared with the few alternatives suggested in the literature, substantially
outperforming all of them whatever the underlying process and the evaluation
scheme. Two specific applications involving air quality and financial databases
illustrate the usefulness of our approach.",http://arxiv.org/pdf/2109.03728v1,stat.ME
2021-09-08 13:32:34+00:00,Confidence surfaces for the mean of locally stationary functional time series,"['Holger Dette', 'Weichi Wu']","The problem of constructing a simultaneous confidence band for the mean
function of a locally stationary functional time series $ \{ X_{i,n} (t) \}_{i
= 1, \ldots, n}$ is challenging as these bands can not be built on classical
limit theory. On the one hand, for a fixed argument $t$ of the functions $
X_{i,n}$, the maximum absolute deviation between an estimate and the time
dependent regression function exhibits (after appropriate standardization) an
extreme value behaviour with a Gumbel distribution in the limit. On the other
hand, for stationary functional data, simultaneous confidence bands can be
built on classical central theorems for Banach space valued random variables
and the limit distribution of the maximum absolute deviation is given by the
sup-norm of a Gaussian process. As both limit theorems have different rates of
convergence, they are not compatible, and a weak convergence result, which
could be used for the construction of a confidence surface in the locally
stationary case, does not exist.
  In this paper we propose new bootstrap methodology to construct a
simultaneous confidence band for the mean function of a locally stationary
functional time series, which is motivated by a Gaussian approximation for the
maximum absolute deviation. We prove the validity of our approach by asymptotic
theory, demonstrate good finite sample properties by means of a simulation
study and illustrate its applicability analyzing a data example.",http://arxiv.org/pdf/2109.03641v2,math.ST
2021-09-06 01:42:08+00:00,On the extreme eigenvalues of the precision matrix of the nonstationary autoregressive process and its applications to outlier estimation of panel time series,['Junho Yang'],"This paper investigates the structural change of the coefficients in the
autoregressive process of order one by considering eigenvalues of an inverse
Toeplitz matrix. More precisely, under mild assumptions, extreme eigenvalues
are observed when the structural change has occurred. A consistent estimator of
extreme eigenvalues is provided under the panel time series framework. The
proposed estimation method is demonstrated with simulations.",http://arxiv.org/pdf/2109.02204v2,stat.ME
2021-09-05 20:30:32+00:00,Estimation of cluster functionals for regularly varying time series: runs estimators,"['Youssouph Cissokho', 'Rafal Kulik']","Cluster indices describe extremal behaviour of stationary time series. We
consider runs estimators of cluster indices. Using a modern theory of
multivariate, regularly varying time series, we obtain central limit theorems
under conditions that can be easily verified for a large class of models. In
particular, we show that blocks and runs estimators have the same limiting
variance.",http://arxiv.org/pdf/2109.02164v1,math.ST
2021-09-05 14:21:24+00:00,"Nonparametric Extrema Analysis in Time Series for Envelope Extraction, Peak Detection and Clustering","['Kaan Gokcesu', 'Hakan Gokcesu']","In this paper, we propose a nonparametric approach that can be used in
envelope extraction, peak-burst detection and clustering in time series. Our
problem formalization results in a naturally defined splitting/forking of the
time series. With a possibly hierarchical implementation, it can be used for
various applications in machine learning, signal processing and mathematical
finance. From an incoming input signal, our iterative procedure sequentially
creates two signals (one upper bounding and one lower bounding signal) by
minimizing the cumulative $L_1$ drift. We show that a solution can be
efficiently calculated by use of a Viterbi-like path tracking algorithm
together with an optimal elimination rule. We consider many interesting
settings, where our algorithm has near-linear time complexities.",http://arxiv.org/pdf/2109.02082v1,cs.LG
2021-09-04 14:17:01+00:00,Attentive Neural Controlled Differential Equations for Time-series Classification and Forecasting,"['Sheo Yon Jhin', 'Heejoo Shin', 'Seoyoung Hong', 'Solhee Park', 'Noseong Park']","Neural networks inspired by differential equations have proliferated for the
past several years. Neural ordinary differential equations (NODEs) and neural
controlled differential equations (NCDEs) are two representative examples of
them. In theory, NCDEs provide better representation learning capability for
time-series data than NODEs. In particular, it is known that NCDEs are suitable
for processing irregular time-series data. Whereas NODEs have been successfully
extended after adopting attention, however, it had not been studied yet how to
integrate attention into NCDEs. To this end, we present the method of Attentive
Neural Controlled Differential Equations (ANCDEs) for time-series
classification and forecasting, where dual NCDEs are used: one for generating
attention values, and the other for evolving hidden vectors for a downstream
machine learning task. We conduct experiments with three real-world time-series
datasets and 10 baselines. After dropping some values, we also conduct
irregular time-series experiments. Our method consistently shows the best
accuracy in all cases by non-trivial margins. Our visualizations also show that
the presented attention mechanism works as intended by focusing on crucial
information.",http://arxiv.org/pdf/2109.01876v3,cs.LG
2021-09-02 15:54:46+00:00,MrSQM: Fast Time Series Classification with Symbolic Representations,"['Thach Le Nguyen', 'Georgiana Ifrim']","Symbolic representations of time series have proven to be effective for time
series classification, with many recent approaches including SAX-VSM, BOSS,
WEASEL, and MrSEQL. The key idea is to transform numerical time series to
symbolic representations in the time or frequency domain, i.e., sequences of
symbols, and then extract features from these sequences. While achieving high
accuracy, existing symbolic classifiers are computationally expensive. In this
paper we present MrSQM, a new time series classifier which uses multiple
symbolic representations and efficient sequence mining, to extract important
time series features. We study four feature selection approaches on symbolic
sequences, ranging from fully supervised, to unsupervised and hybrids. We
propose a new approach for optimal supervised symbolic feature selection in
all-subsequence space, by adapting a Chi-squared bound developed for
discriminative pattern mining, to time series. Our extensive experiments on 112
datasets of the UEA/UCR benchmark demonstrate that MrSQM can quickly extract
useful features and learn accurate classifiers with the classic logistic
regression algorithm. Interestingly, we find that a very simple and fast
feature selection strategy can be highly effective as compared with more
sophisticated and expensive methods. MrSQM advances the state-of-the-art for
symbolic time series classifiers and it is an effective method to achieve high
accuracy, with fast runtime.",http://arxiv.org/pdf/2109.01036v2,cs.LG
2021-09-02 13:53:22+00:00,Fault detection and diagnosis of batch process using dynamic ARMA-based control charts,"['Batista Nunes de Oliveira', 'Marcio Valk', 'Danilo Marcondes Filho']","A wide range of approaches for batch processes monitoring can be found in the
literature. This kind of process generates a very peculiar data structure, in
which successive measurements of many process variables in each batch run are
available. Traditional approaches do not take into account the time series
nature of the data. The main reason is that the time series inference theory is
not based on replications of time series, as it is in batch process data. It is
based on the variability in a time domain. This fact demands some adaptations
of this theory in order to accommodate the model coefficient estimates,
considering jointly the batch to batch samples variability (batch domain) and
the serial correlation in each batch (time domain). In order to address this
issue, this paper proposes a new approach grounded in a group of control charts
based on the classical ARMA model for monitoring and diagnostic of batch
processes dynamics. The model coefficients are estimated (through the ordinary
least square method) for each historical time series sample batch and modified
Hotelling and t-Student distributions are derived and used to accommodate those
estimates. A group of control charts based on that distributions are proposed
for monitoring the new batches. Additionally, those groups of charts help to
fault diagnosis, identifying the source of disturbances. Through simulated and
real data we show that this approach seems to work well for both purposes.",http://arxiv.org/pdf/2109.00952v1,stat.ME
2021-09-02 08:45:53+00:00,Computer Vision Self-supervised Learning Methods on Time Series,"['Daesoo Lee', 'Erlend Aune']","Self-supervised learning (SSL) has had great success in both computer vision
and natural language processing. These approaches often rely on cleverly
crafted loss functions and training setups to avoid feature collapse. In this
study, the effectiveness of mainstream SSL frameworks from computer vision and
some SSL frameworks for time series are evaluated on the UCR, UEA and PTB-XL
datasets, and we show that computer vision SSL frameworks can be effective for
time series. In addition, we propose a new method that improves on the recently
proposed VICReg method. Our method improves on a \textit{covariance} term
proposed in VICReg, and in addition we augment the head of the architecture by
an IterNorm layer that accelerates the convergence of the model.",http://arxiv.org/pdf/2109.00783v3,cs.LG
2021-09-01 10:40:27+00:00,Sparse principal component analysis for high-dimensional stationary time series,"['Kou Fujimori', 'Yuichi Goto', 'Yan Liu', 'Masanobu Taniguchi']","We consider the sparse principal component analysis for high-dimensional
stationary processes. The standard principal component analysis performs poorly
when the dimension of the process is large. We establish the oracle
inequalities for penalized principal component estimators for the processes
including heavy-tailed time series. The rate of convergence of the estimators
is established. We also elucidate the theoretical rate for choosing the tuning
parameter in penalized estimators. The performance of the sparse principal
component analysis is demonstrated by numerical simulations. The utility of the
sparse principal component analysis for time series data is exemplified by the
application to average temperature data.",http://arxiv.org/pdf/2109.00299v3,math.ST
2021-08-30 18:14:27+00:00,Time Series Prediction using Deep Learning Methods in Healthcare,"['Mohammad Amin Morid', 'Olivia R. Liu Sheng', 'Joseph Dunbar']","Traditional machine learning methods face two main challenges in dealing with
healthcare predictive analytics tasks. First, the high-dimensional nature of
healthcare data needs labor-intensive and time-consuming processes to select an
appropriate set of features for each new task. Second, these methods depend on
feature engineering to capture the sequential nature of patient data, which may
not adequately leverage the temporal patterns of the medical events and their
dependencies. Recent deep learning methods have shown promising performance for
various healthcare prediction tasks by addressing the high-dimensional and
temporal challenges of medical data. These methods can learn useful
representations of key factors (e.g., medical concepts or patients) and their
interactions from high-dimensional raw or minimally-processed healthcare data.
In this paper we systematically reviewed studies focused on advancing and using
deep neural networks to leverage patients structured time series data for
healthcare prediction tasks. To identify relevant studies, MEDLINE, IEEE,
Scopus and ACM digital library were searched for studies published up to
February 7th 2021. We found that researchers have contributed to deep time
series prediction literature in ten research streams: deep learning models,
missing value handling, irregularity handling, patient representation, static
data inclusion, attention mechanisms, interpretation, incorporating medical
ontologies, learning strategies, and scalability. This study summarizes
research insights from these literature streams, identifies several critical
research gaps, and suggests future research opportunities for deep learning in
patient time series data.",http://arxiv.org/pdf/2108.13461v3,cs.LG
2021-08-29 08:49:31+00:00,TCCT: Tightly-Coupled Convolutional Transformer on Time Series Forecasting,"['Li Shen', 'Yangzhu Wang']","Time series forecasting is essential for a wide range of real-world
applications. Recent studies have shown the superiority of Transformer in
dealing with such problems, especially long sequence time series input(LSTI)
and long sequence time series forecasting(LSTF) problems. To improve the
efficiency and enhance the locality of Transformer, these studies combine
Transformer with CNN in varying degrees. However, their combinations are
loosely-coupled and do not make full use of CNN. To address this issue, we
propose the concept of tightly-coupled convolutional Transformer(TCCT) and
three TCCT architectures which apply transformed CNN architectures into
Transformer: (1) CSPAttention: through fusing CSPNet with self-attention
mechanism, the computation cost of self-attention mechanism is reduced by 30%
and the memory usage is reduced by 50% while achieving equivalent or beyond
prediction accuracy. (2) Dilated causal convolution: this method is to modify
the distilling operation proposed by Informer through replacing canonical
convolutional layers with dilated causal convolutional layers to gain
exponentially receptive field growth. (3) Passthrough mechanism: the
application of passthrough mechanism to stack of self-attention blocks helps
Transformer-like models get more fine-grained information with negligible extra
computation costs. Our experiments on real-world datasets show that our TCCT
architectures could greatly improve the performance of existing state-of-art
Transformer models on time series forecasting with much lower computation and
memory costs, including canonical Transformer, LogTrans and Informer.",http://arxiv.org/pdf/2108.12784v2,cs.LG
2021-08-27 02:40:37+00:00,Anomaly Detection on IT Operation Series via Online Matrix Profile,"['Shi-Ying Lan', 'Run-Qing Chen', 'Wan-Lei Zhao']","Anomaly detection on time series is a fundamental task in monitoring the Key
Performance Indicators (KPIs) of IT systems. Many of the existing approaches in
the literature show good performance while requiring a lot of training
resources. In this paper, the online matrix profile, which requires no
training, is proposed to address this issue. The anomalies are detected by
referring to the past subsequence that is the closest to the current one. The
distance significance is introduced based on the online matrix profile, which
demonstrates a prominent pattern when an anomaly occurs. Another training-free
approach spectral residual is integrated into our approach to further enhance
the detection accuracy. Moreover, the proposed approach is sped up by at least
four times for long time series by the introduced cache strategy. In comparison
to the existing approaches, the online matrix profile makes a good trade-off
between accuracy and efficiency. More importantly, it is generic to various
types of time series in the sense that it works without the constraint from any
trained model.",http://arxiv.org/pdf/2108.12093v2,cs.LG
2021-08-26 00:18:25+00:00,SOMTimeS: Self Organizing Maps for Time Series Clustering and its Application to Serious Illness Conversations,"['Ali Javed', 'Donna M. Rizzo', 'Byung Suk Lee', 'Robert Gramling']","There is an increasing demand for scalable algorithms capable of clustering
and analyzing large time series datasets. The Kohonen self-organizing map (SOM)
is a type of unsupervised artificial neural network for visualizing and
clustering complex data, reducing the dimensionality of data, and selecting
influential features. Like all clustering methods, the SOM requires a measure
of similarity between input data (in this work time series). Dynamic time
warping (DTW) is one such measure, and a top performer given that it
accommodates the distortions when aligning time series. Despite its use in
clustering, DTW is limited in practice because it is quadratic in runtime
complexity with the length of the time series data. To address this, we present
a new DTW-based clustering method, called SOMTimeS (a Self-Organizing Map for
TIME Series), that scales better and runs faster than other DTW-based
clustering algorithms, and has similar performance accuracy. The computational
performance of SOMTimeS stems from its ability to prune unnecessary DTW
computations during the SOM's training phase. We also implemented a similar
pruning strategy for K-means for comparison with one of the top performing
clustering algorithms. We evaluated the pruning effectiveness, accuracy,
execution time and scalability on 112 benchmark time series datasets from the
University of California, Riverside classification archive. We showed that for
similar accuracy, the speed-up achieved for SOMTimeS and K-means was 1.8x on
average; however, rates varied between 1x and 18x depending on the dataset.
SOMTimeS and K-means pruned 43% and 50% of the total DTW computations,
respectively. We applied SOMtimeS to natural language conversation data
collected as part of a large healthcare cohort study of patient-clinician
serious illness conversations to demonstrate the algorithm's utility with
complex, temporally sequenced phenomena.",http://arxiv.org/pdf/2108.11523v1,cs.LG
2021-08-23 01:46:24+00:00,DTWSSE: Data Augmentation with a Siamese Encoder for Time Series,"['Xinyu Yang', 'Xinlan Zhang', 'Zhenguo Zhang', 'Yahui Zhao', 'Rongyi Cui']","Access to labeled time series data is often limited in the real world, which
constrains the performance of deep learning models in the field of time series
analysis. Data augmentation is an effective way to solve the problem of small
sample size and imbalance in time series datasets. The two key factors of data
augmentation are the distance metric and the choice of interpolation method.
SMOTE does not perform well on time series data because it uses a Euclidean
distance metric and interpolates directly on the object. Therefore, we propose
a DTW-based synthetic minority oversampling technique using siamese encoder for
interpolation named DTWSSE. In order to reasonably measure the distance of the
time series, DTW, which has been verified to be an effective method forts, is
employed as the distance metric. To adapt the DTW metric, we use an autoencoder
trained in an unsupervised self-training manner for interpolation. The encoder
is a Siamese Neural Network for mapping the time series data from the DTW
hidden space to the Euclidean deep feature space, and the decoder is used to
map the deep feature space back to the DTW hidden space. We validate the
proposed methods on a number of different balanced or unbalanced time series
datasets. Experimental results show that the proposed method can lead to better
performance of the downstream deep learning model.",http://arxiv.org/pdf/2108.09885v1,cs.LG
2021-08-20 03:13:34+00:00,ASAT: Adaptively Scaled Adversarial Training in Time Series,"['Zhiyuan Zhang', 'Wei Li', 'Ruihan Bao', 'Keiko Harimoto', 'Yunfang Wu', 'Xu Sun']","Adversarial training is a method for enhancing neural networks to improve the
robustness against adversarial examples. Besides the security concerns of
potential adversarial examples, adversarial training can also improve the
generalization ability of neural networks, train robust neural networks, and
provide interpretability for neural networks. In this work, we introduce
adversarial training in time series analysis to enhance the neural networks for
better generalization ability by taking the finance field as an example.
Rethinking existing research on adversarial training, we propose the adaptively
scaled adversarial training (ASAT) in time series analysis, by rescaling data
at different time slots with adaptive scales. Experimental results show that
the proposed ASAT can improve both the generalization ability and the
adversarial robustness of neural networks compared to the baselines. Compared
to the traditional adversarial training algorithm, ASAT can achieve better
generalization ability and similar adversarial robustness.",http://arxiv.org/pdf/2108.08976v2,cs.LG
2021-08-18 22:23:15+00:00,Federated Variational Learning for Anomaly Detection in Multivariate Time Series,"['Kai Zhang', 'Yushan Jiang', 'Lee Seversky', 'Chengtao Xu', 'Dahai Liu', 'Houbing Song']","Anomaly detection has been a challenging task given high-dimensional
multivariate time series data generated by networked sensors and actuators in
Cyber-Physical Systems (CPS). Besides the highly nonlinear, complex, and
dynamic natures of such time series, the lack of labeled data impedes data
exploitation in a supervised manner and thus prevents an accurate detection of
abnormal phenomenons. On the other hand, the collected data at the edge of the
network is often privacy sensitive and large in quantity, which may hinder the
centralized training at the main server. To tackle these issues, we propose an
unsupervised time series anomaly detection framework in a federated fashion to
continuously monitor the behaviors of interconnected devices within a network
and alerts for abnormal incidents so that countermeasures can be taken before
undesired consequences occur. To be specific, we leave the training data
distributed at the edge to learn a shared Variational Autoencoder (VAE) based
on Convolutional Gated Recurrent Unit (ConvGRU) model, which jointly captures
feature and temporal dependencies in the multivariate time series data for
representation learning and downstream anomaly detection tasks. Experiments on
three real-world networked sensor datasets illustrate the advantage of our
approach over other state-of-the-art models. We also conduct extensive
experiments to demonstrate the effectiveness of our detection framework under
non-federated and federated settings in terms of overall performance and
detection latency.",http://arxiv.org/pdf/2108.08404v2,cs.LG
2021-08-18 16:17:29+00:00,Transformers predicting the future. Applying attention in next-frame and time series forecasting,"['Radostin Cholakov', 'Todor Kolev']","Recurrent Neural Networks were, until recently, one of the best ways to
capture the timely dependencies in sequences. However, with the introduction of
the Transformer, it has been proven that an architecture with only
attention-mechanisms without any RNN can improve on the results in various
sequence processing tasks (e.g. NLP). Multiple studies since then have shown
that similar approaches can be applied for images, point clouds, video, audio
or time series forecasting. Furthermore, solutions such as the Perceiver or the
Informer have been introduced to expand on the applicability of the
Transformer. Our main objective is testing and evaluating the effectiveness of
applying Transformer-like models on time series data, tackling susceptibility
to anomalies, context awareness and space complexity by fine-tuning the
hyperparameters, preprocessing the data, applying dimensionality reduction or
convolutional encodings, etc. We are also looking at the problem of next-frame
prediction and exploring ways to modify existing solutions in order to achieve
higher performance and learn generalized knowledge.",http://arxiv.org/pdf/2108.08224v1,cs.LG
2021-08-18 07:26:19+00:00,XAI Methods for Neural Time Series Classification: A Brief Review,"['Ilija Šimić', 'Vedran Sabol', 'Eduardo Veas']","Deep learning models have recently demonstrated remarkable results in a
variety of tasks, which is why they are being increasingly applied in
high-stake domains, such as industry, medicine, and finance. Considering that
automatic predictions in these domains might have a substantial impact on the
well-being of a person, as well as considerable financial and legal
consequences to an individual or a company, all actions and decisions that
result from applying these models have to be accountable. Given that a
substantial amount of data that is collected in high-stake domains are in the
form of time series, in this paper we examine the current state of eXplainable
AI (XAI) methods with a focus on approaches for opening up deep learning black
boxes for the task of time series classification. Finally, our contribution
also aims at deriving promising directions for future work, to advance XAI for
deep learning on time series data.",http://arxiv.org/pdf/2108.08009v1,cs.LG
2021-08-17 10:36:44+00:00,Modelling Time-Varying First and Second-Order Structure of Time Series via Wavelets and Differencing,"['Euan T. McGonigle', 'Rebecca Killick', 'Matthew A. Nunes']","Most time series observed in practice exhibit time-varying trend
(first-order) and autocovariance (second-order) behaviour. Differencing is a
commonly-used technique to remove the trend in such series, in order to
estimate the time-varying second-order structure (of the differenced series).
However, often we require inference on the second-order behaviour of the
original series, for example, when performing trend estimation. In this
article, we propose a method, using differencing, to jointly estimate the
time-varying trend and second-order structure of a nonstationary time series,
within the locally stationary wavelet modelling framework. We develop a
wavelet-based estimator of the second-order structure of the original time
series based on the differenced estimate, and show how this can be incorporated
into the estimation of the trend of the time series. We perform a simulation
study to investigate the performance of the methodology, and demonstrate the
utility of the method by analysing data examples from environmental and
biomedical science.",http://arxiv.org/pdf/2108.07550v2,stat.ME
2021-08-15 17:50:37+00:00,Event2Graph: Event-driven Bipartite Graph for Multivariate Time-series Anomaly Detection,"['Yuhang Wu', 'Mengting Gu', 'Lan Wang', 'Yusan Lin', 'Fei Wang', 'Hao Yang']","Modeling inter-dependencies between time-series is the key to achieve high
performance in anomaly detection for multivariate time-series data. The
de-facto solution to model the dependencies is to feed the data into a
recurrent neural network (RNN). However, the fully connected network structure
underneath the RNN (either GRU or LSTM) assumes a static and complete
dependency graph between time-series, which may not hold in many real-world
applications. To alleviate this assumption, we propose a dynamic bipartite
graph structure to encode the inter-dependencies between time-series. More
concretely, we model time series as one type of nodes, and the time series
segments (regarded as event) as another type of nodes, where the edge between
two types of nodes describe a temporal pattern occurred on a specific time
series at a certain time. Based on this design, relations between time series
can be explicitly modelled via dynamic connections to event nodes, and the
multivariate time-series anomaly detection problem can be formulated as a
self-supervised, edge stream prediction problem in dynamic graphs. We conducted
extensive experiments to demonstrate the effectiveness of the design.",http://arxiv.org/pdf/2108.06783v1,cs.LG
2021-08-11 12:35:24+00:00,Empirical Risk Minimization for Time Series: Nonparametric Performance Bounds for Prediction,"['Christian Brownlees', 'Jordi Llorens-Terrazas']","Empirical risk minimization is a standard principle for choosing algorithms
in learning theory. In this paper we study the properties of empirical risk
minimization for time series. The analysis is carried out in a general
framework that covers different types of forecasting applications encountered
in the literature. We are concerned with 1-step-ahead prediction of a
univariate time series generated by a parameter-driven process. A class of
recursive algorithms is available to forecast the time series. The algorithms
are recursive in the sense that the forecast produced in a given period is a
function of the lagged values of the forecast and of the time series. The
relationship between the generating mechanism of the time series and the class
of algorithms is unspecified. Our main result establishes that the algorithm
chosen by empirical risk minimization achieves asymptotically the optimal
predictive performance that is attainable within the class of algorithms.",http://arxiv.org/pdf/2108.05184v1,stat.ML
2021-08-10 04:32:04+00:00,AdaRNN: Adaptive Learning and Forecasting of Time Series,"['Yuntao Du', 'Jindong Wang', 'Wenjie Feng', 'Sinno Pan', 'Tao Qin', 'Renjun Xu', 'Chongjun Wang']","Time series has wide applications in the real world and is known to be
difficult to forecast. Since its statistical properties change over time, its
distribution also changes temporally, which will cause severe distribution
shift problem to existing methods. However, it remains unexplored to model the
time series in the distribution perspective. In this paper, we term this as
Temporal Covariate Shift (TCS). This paper proposes Adaptive RNNs (AdaRNN) to
tackle the TCS problem by building an adaptive model that generalizes well on
the unseen test data. AdaRNN is sequentially composed of two novel algorithms.
First, we propose Temporal Distribution Characterization to better characterize
the distribution information in the TS. Second, we propose Temporal
Distribution Matching to reduce the distribution mismatch in TS to learn the
adaptive TS model. AdaRNN is a general framework with flexible distribution
distances integrated. Experiments on human activity recognition, air quality
prediction, and financial analysis show that AdaRNN outperforms the latest
methods by a classification accuracy of 2.6% and significantly reduces the RMSE
by 9.0%. We also show that the temporal distribution matching algorithm can be
extended in Transformer structure to boost its performance.",http://arxiv.org/pdf/2108.04443v2,cs.LG
2021-08-05 20:50:18+00:00,Multimodal Meta-Learning for Time Series Regression,"['Sebastian Pineda Arango', 'Felix Heinrich', 'Kiran Madhusudhanan', 'Lars Schmidt-Thieme']","Recent work has shown the efficiency of deep learning models such as Fully
Convolutional Networks (FCN) or Recurrent Neural Networks (RNN) to deal with
Time Series Regression (TSR) problems. These models sometimes need a lot of
data to be able to generalize, yet the time series are sometimes not long
enough to be able to learn patterns. Therefore, it is important to make use of
information across time series to improve learning. In this paper, we will
explore the idea of using meta-learning for quickly adapting model parameters
to new short-history time series by modifying the original idea of Model
Agnostic Meta-Learning (MAML) \cite{finn2017model}. Moreover, based on prior
work on multimodal MAML \cite{vuorio2019multimodal}, we propose a method for
conditioning parameters of the model through an auxiliary network that encodes
global information of the time series to extract meta-features. Finally, we
apply the data to time series of different domains, such as pollution
measurements, heart-rate sensors, and electrical battery data. We show
empirically that our proposed meta-learning method learns TSR with few data
fast and outperforms the baselines in 9 of 12 experiments.",http://arxiv.org/pdf/2108.02842v2,cs.LG
2021-08-05 17:19:51+00:00,Local Exceptionality Detection in Time Series Using Subgroup Discovery,"['Dan Hudson', 'Travis J. Wiltshire', 'Martin Atzmueller']","In this paper, we present a novel approach for local exceptionality detection
on time series data. This method provides the ability to discover interpretable
patterns in the data, which can be used to understand and predict the
progression of a time series. This being an exploratory approach, the results
can be used to generate hypotheses about the relationships between the
variables describing a specific process and its dynamics. We detail our
approach in a concrete instantiation and exemplary implementation, specifically
in the field of teamwork research. Using a real-world dataset of team
interactions we include results from an example data analytics application of
our proposed approach, showcase novel analysis options, and discuss possible
implications of the results from the perspective of teamwork research.",http://arxiv.org/pdf/2108.11751v1,cs.LG
2021-08-04 21:21:17+00:00,High dimensional Bayesian Optimization Algorithm for Complex System in Time Series,"['Yuyang Chen', 'Kaiming Bi', 'Chih-Hang J. Wu', 'David Ben-Arieh', 'Ashesh Sinha']","At present, high-dimensional global optimization problems with time-series
models have received much attention from engineering fields. Since it was
proposed, Bayesian optimization has quickly become a popular and promising
approach for solving global optimization problems. However, the standard
Bayesian optimization algorithm is insufficient to solving the global optimal
solution when the model is high-dimensional. Hence, this paper presents a novel
high dimensional Bayesian optimization algorithm by considering dimension
reduction and different dimension fill-in strategies. Most existing literature
about Bayesian optimization algorithms did not discuss the sampling strategies
to optimize the acquisition function. This study proposed a new sampling method
based on both the multi-armed bandit and random search methods while optimizing
the acquisition function. Besides, based on the time-dependent or
dimension-dependent characteristics of the model, the proposed algorithm can
reduce the dimension evenly. Then, five different dimension fill-in strategies
were discussed and compared in this study. Finally, to increase the final
accuracy of the optimal solution, the proposed algorithm adds a local search
based on a series of Adam-based steps at the final stage. Our computational
experiments demonstrated that the proposed Bayesian optimization algorithm
could achieve reasonable solutions with excellent performances for high
dimensional global optimization problems with a time-series optimal control
model.",http://arxiv.org/pdf/2108.02289v1,cs.LG
2021-08-04 06:10:58+00:00,Reconstructing a dynamical system and forecasting time series by self-consistent deep learning,"['Zhe Wang', 'Claude Guet']","We introduce a self-consistent deep-learning framework which, for a noisy
deterministic time series, provides unsupervised filtering, state-space
reconstruction, identification of the underlying differential equations and
forecasting. Without a priori information on the signal, we embed the time
series in a state space, where deterministic structures, i.e. attractors, are
revealed. Under the assumption that the evolution of solution trajectories is
described by an unknown dynamical system, we filter out stochastic outliers.
The embedding function, the solution trajectories and the dynamical systems are
constructed using deep neural networks, respectively. By exploiting the
differentiability of the neural solution trajectory, the neural dynamical
system is defined locally at each time, mitigating the need for propagating
gradients through numerical solvers. On a chaotic time series masked by
additive Gaussian noise, we demonstrate the filtering ability and the
predictive power of the proposed framework.",http://arxiv.org/pdf/2108.01862v1,cs.LG
2021-08-02 15:30:15+00:00,PSA-GAN: Progressive Self Attention GANs for Synthetic Time Series,"['Jeha Paul', 'Bohlke-Schneider Michael', 'Mercado Pedro', 'Kapoor Shubham', 'Singh Nirwan Rajbir', 'Flunkert Valentin', 'Gasthaus Jan', 'Januschowski Tim']","Realistic synthetic time series data of sufficient length enables practical
applications in time series modeling tasks, such as forecasting, but remains a
challenge. In this paper we present PSA-GAN, a generative adversarial network
(GAN) that generates long time series samples of high quality using progressive
growing of GANs and self-attention. We show that PSA-GAN can be used to reduce
the error in two downstream forecasting tasks over baselines that only use real
data. We also introduce a Frechet-Inception Distance-like score, Context-FID,
assessing the quality of synthetic time series samples. In our downstream
tasks, we find that the lowest scoring models correspond to the best-performing
ones. Therefore, Context-FID could be a useful tool to develop time series GAN
models.",http://arxiv.org/pdf/2108.00981v3,cs.LG
2021-08-02 06:53:37+00:00,Learning who is in the market from time series: market participant discovery through adversarial calibration of multi-agent simulators,"['Victor Storchan', 'Svitlana Vyetrenko', 'Tucker Balch']","In electronic trading markets often only the price or volume time series,
that result from interaction of multiple market participants, are directly
observable. In order to test trading strategies before deploying them to
real-time trading, multi-agent market environments calibrated so that the time
series that result from interaction of simulated agents resemble historical are
often used. To ensure adequate testing, one must test trading strategies in a
variety of market scenarios -- which includes both scenarios that represent
ordinary market days as well as stressed markets (most recently observed due to
the beginning of COVID pandemic). In this paper, we address the problem of
multi-agent simulator parameter calibration to allow simulator capture
characteristics of different market regimes. We propose a novel two-step method
to train a discriminator that is able to distinguish between ""real"" and ""fake""
price and volume time series as a part of GAN with self-attention, and then
utilize it within an optimization framework to tune parameters of a simulator
model with known agent archetypes to represent a market scenario. We conclude
with experimental results that demonstrate effectiveness of our method.",http://arxiv.org/pdf/2108.00664v1,cs.LG
2021-07-31 17:47:10+00:00,Filling the G_ap_s: Multivariate Time Series Imputation by Graph Neural Networks,"['Andrea Cini', 'Ivan Marisca', 'Cesare Alippi']","Dealing with missing values and incomplete time series is a labor-intensive,
tedious, inevitable task when handling data coming from real-world
applications. Effective spatio-temporal representations would allow imputation
methods to reconstruct missing temporal data by exploiting information coming
from sensors at different locations. However, standard methods fall short in
capturing the nonlinear time and space dependencies existing within networks of
interconnected sensors and do not take full advantage of the available - and
often strong - relational information. Notably, most state-of-the-art
imputation methods based on deep learning do not explicitly model relational
aspects and, in any case, do not exploit processing frameworks able to
adequately represent structured spatio-temporal data. Conversely, graph neural
networks have recently surged in popularity as both expressive and scalable
tools for processing sequential data with relational inductive biases. In this
work, we present the first assessment of graph neural networks in the context
of multivariate time series imputation. In particular, we introduce a novel
graph neural network architecture, named GRIN, which aims at reconstructing
missing data in the different channels of a multivariate time series by
learning spatio-temporal representations through message passing. Empirical
results show that our model outperforms state-of-the-art methods in the
imputation task on relevant real-world benchmarks with mean absolute error
improvements often higher than 20%.",http://arxiv.org/pdf/2108.00298v3,cs.LG
2021-07-30 16:54:49+00:00,A Survey of Estimation Methods for Sparse High-dimensional Time Series Models,"['Sumanta Basu', 'David S. Matteson']","High-dimensional time series datasets are becoming increasingly common in
many areas of biological and social sciences. Some important applications
include gene regulatory network reconstruction using time course gene
expression data, brain connectivity analysis from neuroimaging data, structural
analysis of a large panel of macroeconomic indicators, and studying linkages
among financial firms for more robust financial regulation. These applications
have led to renewed interest in developing principled statistical methods and
theory for estimating large time series models given only a relatively small
number of temporally dependent samples. Sparse modeling approaches have gained
popularity over the last two decades in statistics and machine learning for
their interpretability and predictive accuracy. Although there is a rich
literature on several sparsity inducing methods when samples are independent,
research on the statistical properties of these methods for estimating time
series models is still in progress.
  We survey some recent advances in this area, focusing on empirically
successful lasso based estimation methods for two canonical multivariate time
series models - stochastic regression and vector autoregression. We discuss key
technical challenges arising in high-dimensional time series analysis and
outline several interesting research directions.",http://arxiv.org/pdf/2107.14754v1,stat.ME
2021-07-29 23:32:15+00:00,Otimizacao de pesos e funcoes de ativacao de redes neurais aplicadas na previsao de series temporais,"['Gecynalda Gomes', 'Teresa Ludermir']","Neural Networks have been applied for time series prediction with good
experimental results that indicate the high capacity to approximate functions
with good precision. Most neural models used in these applications use
activation functions with fixed parameters. However, it is known that the
choice of activation function strongly influences the complexity and
performance of the neural network and that a limited number of activation
functions have been used. In this work, we propose the use of a family of free
parameter asymmetric activation functions for neural networks and show that
this family of defined activation functions satisfies the requirements of the
universal approximation theorem. A methodology for the global optimization of
this family of activation functions with free parameter and the weights of the
connections between the processing units of the neural network is used. The
central idea of the proposed methodology is to simultaneously optimize the
weights and the activation function used in a multilayer perceptron network
(MLP), through an approach that combines the advantages of simulated annealing,
tabu search and a local learning algorithm, with the purpose of improving
performance in the adjustment and forecasting of time series. We chose two
learning algorithms: backpropagation with the term momentum (BPM) and
LevenbergMarquardt (LM).",http://arxiv.org/pdf/2107.14370v1,cs.LG
2021-07-29 20:31:03+00:00,Temporal Dependencies in Feature Importance for Time Series Predictions,"['Kin Kwan Leung', 'Clayton Rooke', 'Jonathan Smith', 'Saba Zuberi', 'Maksims Volkovs']","Time series data introduces two key challenges for explainability methods:
firstly, observations of the same feature over subsequent time steps are not
independent, and secondly, the same feature can have varying importance to
model predictions over time. In this paper, we propose Windowed Feature
Importance in Time (WinIT), a feature removal based explainability approach to
address these issues. Unlike existing feature removal explanation methods,
WinIT explicitly accounts for the temporal dependence between different
observations of the same feature in the construction of its importance score.
Furthermore, WinIT captures the varying importance of a feature over time, by
summarizing its importance over a window of past time steps. We conduct an
extensive empirical study on synthetic and real-world data, compare against a
wide range of leading explainability methods, and explore the impact of various
evaluation strategies. Our results show that WinIT achieves significant gains
over existing methods, with more consistent performance across different
evaluation metrics. The code for our work is publicly available at
\url{https://github.com/layer6ai-labs/WinIT}.",http://arxiv.org/pdf/2107.14317v2,cs.LG
2021-07-29 19:39:39+00:00,Self-Supervised Transformer for Sparse and Irregularly Sampled Multivariate Clinical Time-Series,"['Sindhu Tipirneni', 'Chandan K. Reddy']","Multivariate time-series data are frequently observed in critical care
settings and are typically characterized by sparsity (missing information) and
irregular time intervals. Existing approaches for learning representations in
this domain handle these challenges by either aggregation or imputation of
values, which in-turn suppresses the fine-grained information and adds
undesirable noise/overhead into the machine learning model. To tackle this
problem, we propose a Self-supervised Transformer for Time-Series (STraTS)
model which overcomes these pitfalls by treating time-series as a set of
observation triplets instead of using the standard dense matrix representation.
It employs a novel Continuous Value Embedding technique to encode continuous
time and variable values without the need for discretization. It is composed of
a Transformer component with multi-head attention layers which enable it to
learn contextual triplet embeddings while avoiding the problems of recurrence
and vanishing gradients that occur in recurrent architectures. In addition, to
tackle the problem of limited availability of labeled data (which is typically
observed in many healthcare applications), STraTS utilizes self-supervision by
leveraging unlabeled data to learn better representations by using time-series
forecasting as an auxiliary proxy task. Experiments on real-world multivariate
clinical time-series benchmark datasets demonstrate that STraTS has better
prediction performance than state-of-the-art methods for mortality prediction,
especially when labeled data is limited. Finally, we also present an
interpretable version of STraTS which can identify important measurements in
the time-series data. Our data preprocessing and model implementation codes are
available at https://github.com/sindhura97/STraTS.",http://arxiv.org/pdf/2107.14293v2,cs.LG
2021-07-28 06:30:46+00:00,AutoML Meets Time Series Regression Design and Analysis of the AutoSeries Challenge,"['Zhen Xu', 'Wei-Wei Tu', 'Isabelle Guyon']","Analyzing better time series with limited human effort is of interest to
academia and industry. Driven by business scenarios, we organized the first
Automated Time Series Regression challenge (AutoSeries) for the WSDM Cup 2020.
We present its design, analysis, and post-hoc experiments. The code submission
requirement precluded participants from any manual intervention, testing
automated machine learning capabilities of solutions, across many datasets,
under hardware and time limitations. We prepared 10 datasets from diverse
application domains (sales, power consumption, air quality, traffic, and
parking), featuring missing data, mixed continuous and categorical variables,
and various sampling rates. Each dataset was split into a training and a test
sequence (which was streamed, allowing models to continuously adapt). The
setting of time series regression, differs from classical forecasting in that
covariates at the present time are known. Great strides were made by
participants to tackle this AutoSeries problem, as demonstrated by the jump in
performance from the sample submission, and post-hoc comparisons with
AutoGluon. Simple yet effective methods were used, based on feature
engineering, LightGBM, and random search hyper-parameter tuning, addressing all
aspects of the challenge. Our post-hoc analyses revealed that providing
additional time did not yield significant improvements. The winners' code was
open-sourced https://github.com/NehzUx/AutoSeries.",http://arxiv.org/pdf/2107.13186v2,cs.LG
2021-07-23 16:59:21+00:00,Heteroscedastic Temporal Variational Autoencoder For Irregularly Sampled Time Series,"['Satya Narayan Shukla', 'Benjamin M. Marlin']","Irregularly sampled time series commonly occur in several domains where they
present a significant challenge to standard deep learning models. In this
paper, we propose a new deep learning framework for probabilistic interpolation
of irregularly sampled time series that we call the Heteroscedastic Temporal
Variational Autoencoder (HeTVAE). HeTVAE includes a novel input layer to encode
information about input observation sparsity, a temporal VAE architecture to
propagate uncertainty due to input sparsity, and a heteroscedastic output layer
to enable variable uncertainty in output interpolations. Our results show that
the proposed architecture is better able to reflect variable uncertainty
through time due to sparse and irregular sampling than a range of baseline and
traditional models, as well as recently proposed deep latent variable models
that use homoscedastic output layers.",http://arxiv.org/pdf/2107.11350v1,cs.LG
2021-07-23 09:38:51+00:00,Generative adversarial networks in time series: A survey and taxonomy,"['Eoin Brophy', 'Zhengwei Wang', 'Qi She', 'Tomas Ward']","Generative adversarial networks (GANs) studies have grown exponentially in
the past few years. Their impact has been seen mainly in the computer vision
field with realistic image and video manipulation, especially generation,
making significant advancements. While these computer vision advances have
garnered much attention, GAN applications have diversified across disciplines
such as time series and sequence generation. As a relatively new niche for
GANs, fieldwork is ongoing to develop high quality, diverse and private time
series data. In this paper, we review GAN variants designed for time series
related applications. We propose a taxonomy of discrete-variant GANs and
continuous-variant GANs, in which GANs deal with discrete time series and
continuous time series data. Here we showcase the latest and most popular
literature in this field; their architectures, results, and applications. We
also provide a list of the most popular evaluation metrics and their
suitability across applications. Also presented is a discussion of privacy
measures for these GANs and further protections and directions for dealing with
sensitive data. We aim to frame clearly and concisely the latest and
state-of-the-art research in this area and their applications to real-world
technologies.",http://arxiv.org/pdf/2107.11098v1,cs.LG
2021-07-22 14:32:30+00:00,A Framework for Imbalanced Time-series Forecasting,"['Luis P. Silvestrin', 'Leonardos Pantiskas', 'Mark Hoogendoorn']","Time-series forecasting plays an important role in many domains. Boosted by
the advances in Deep Learning algorithms, it has for instance been used to
predict wind power for eolic energy production, stock market fluctuations, or
motor overheating. In some of these tasks, we are interested in predicting
accurately some particular moments which often are underrepresented in the
dataset, resulting in a problem known as imbalanced regression. In the
literature, while recognized as a challenging problem, limited attention has
been devoted on how to handle the problem in a practical setting. In this
paper, we put forward a general approach to analyze time-series forecasting
problems focusing on those underrepresented moments to reduce imbalances. Our
approach has been developed based on a case study in a large industrial
company, which we use to exemplify the approach.",http://arxiv.org/pdf/2107.10709v1,cs.LG
2021-07-22 07:02:03+00:00,Neural Ordinary Differential Equation Model for Evolutionary Subspace Clustering and Its Applications,"['Mingyuan Bai', 'S. T. Boris Choy', 'Junping Zhang', 'Junbin Gao']","The neural ordinary differential equation (neural ODE) model has attracted
increasing attention in time series analysis for its capability to process
irregular time steps, i.e., data are not observed over equally-spaced time
intervals. In multi-dimensional time series analysis, a task is to conduct
evolutionary subspace clustering, aiming at clustering temporal data according
to their evolving low-dimensional subspace structures. Many existing methods
can only process time series with regular time steps while time series are
unevenly sampled in many situations such as missing data. In this paper, we
propose a neural ODE model for evolutionary subspace clustering to overcome
this limitation and a new objective function with subspace self-expressiveness
constraint is introduced. We demonstrate that this method can not only
interpolate data at any time step for the evolutionary subspace clustering
task, but also achieve higher accuracy than other state-of-the-art evolutionary
subspace clustering methods. Both synthetic and real-world data are used to
illustrate the efficacy of our proposed method.",http://arxiv.org/pdf/2107.10484v1,cs.LG
2021-07-20 22:00:43+00:00,High-dimensional Multivariate Time Series Forecasting in IoT Applications using Embedding Non-stationary Fuzzy Time Series,"['Hugo Vinicius Bitencourt', 'Frederico Gadelha Guimarães']","In Internet of things (IoT), data is continuously recorded from different
data sources and devices can suffer faults in their embedded electronics, thus
leading to a high-dimensional data sets and concept drift events. Therefore,
methods that are capable of high-dimensional non-stationary time series are of
great value in IoT applications. Fuzzy Time Series (FTS) models stand out as
data-driven non-parametric models of easy implementation and high accuracy.
Unfortunately, FTS encounters difficulties when dealing with data sets of many
variables and scenarios with concept drift. We present a new approach to handle
high-dimensional non-stationary time series, by projecting the original
high-dimensional data into a low dimensional embedding space and using FTS
approach. Combining these techniques enables a better representation of the
complex content of non-stationary multivariate time series and accurate
forecasts. Our model is able to explain 98% of the variance and reach 11.52% of
RMSE, 2.68% of MAE and 2.91% of MAPE.",http://arxiv.org/pdf/2107.09785v1,cs.LG
2021-07-20 10:38:39+00:00,Diagnosis of model-structural errors with a sliding time-window Bayesian analysis,"['Han-Fang Hsueh', 'Anneli Guthke', 'Thomas Wöhling', 'Wolfgang Nowak']","Deterministic hydrological models with uncertain, but
inferred-to-be-time-invariant parameters typically show time-dependent model
structural errors. Such errors can occur if a hydrological process is active in
certain time periods in nature, but is not resolved by the model. Such missing
processes could become visible during calibration as time-dependent best-fit
values of model parameters. We propose a formal time-windowed Bayesian analysis
to diagnose this type of model error, formalizing the question \In which period
of the calibration time-series does the model statistically disqualify itself
as quasi-true?"" Using Bayesian model evidence (BME) as model performance
metric, we determine how much the data in time windows of the calibration
time-series support or refute the model. Then, we track BME over sliding time
windows to obtain a dynamic, time-windowed BME (tBME) and search for sudden
decreases that indicate an onset of model error. tBME also allows us to perform
a formal, sliding likelihood-ratio test of the model against the data. Our
proposed approach is designed to detect error occurrence on various temporal
scales, which is especially useful in hydrological modelling. We illustrate
this by applying our proposed method to soil moisture modeling. We test tBME as
model error indicator on several synthetic and real-world test cases that we
designed to vary in error sources and error time scales. Results prove the
usefulness of the framework for detecting structural errors in dynamic models.
Moreover, the time sequence of posterior parameter distributions helps to
investigate the reasons for model error and provide guidance for model
improvement.",http://arxiv.org/pdf/2107.09399v1,stat.ME
2021-07-20 09:19:26+00:00,Approximation Theory of Convolutional Architectures for Time Series Modelling,"['Haotian Jiang', 'Zhong Li', 'Qianxiao Li']","We study the approximation properties of convolutional architectures applied
to time series modelling, which can be formulated mathematically as a
functional approximation problem. In the recurrent setting, recent results
reveal an intricate connection between approximation efficiency and memory
structures in the data generation process. In this paper, we derive parallel
results for convolutional architectures, with WaveNet being a prime example.
Our results reveal that in this new setting, approximation efficiency is not
only characterised by memory, but also additional fine structures in the target
relationship. This leads to a novel definition of spectrum-based regularity
that measures the complexity of temporal relationships under the convolutional
approximation scheme. These analyses provide a foundation to understand the
differences between architectural choices for time series modelling and can
give theoretically grounded guidance for practical applications.",http://arxiv.org/pdf/2107.09355v1,cs.LG
2021-07-19 19:03:27+00:00,OnlineSTL: Scaling Time Series Decomposition by 100x,"['Abhinav Mishra', 'Ram Sriharsha', 'Sichen Zhong']","Decomposing a complex time series into trend, seasonality, and remainder
components is an important primitive that facilitates time series anomaly
detection, change point detection, and forecasting. Although numerous batch
algorithms are known for time series decomposition, none operate well in an
online scalable setting where high throughput and real-time response are
paramount. In this paper, we propose OnlineSTL, a novel online algorithm for
time series decomposition which is highly scalable and is deployed for
real-time metrics monitoring on high-resolution, high-ingest rate data.
Experiments on different synthetic and real world time series datasets
demonstrate that OnlineSTL achieves orders of magnitude speedups (100x) while
maintaining quality of decomposition.",http://arxiv.org/pdf/2107.09110v4,cs.LG
2021-07-19 17:24:05+00:00,Topological Attention for Time Series Forecasting,"['Sebastian Zeng', 'Florian Graf', 'Christoph Hofer', 'Roland Kwitt']","The problem of (point) forecasting $ \textit{univariate} $ time series is
considered. Most approaches, ranging from traditional statistical methods to
recent learning-based techniques with neural networks, directly operate on raw
time series observations. As an extension, we study whether $\textit{local
topological properties}$, as captured via persistent homology, can serve as a
reliable signal that provides complementary information for learning to
forecast. To this end, we propose $\textit{topological attention}$, which
allows attending to local topological features within a time horizon of
historical data. Our approach easily integrates into existing end-to-end
trainable forecasting models, such as $\texttt{N-BEATS}$, and in combination
with the latter exhibits state-of-the-art performance on the large-scale M4
benchmark dataset of 100,000 diverse time series from different domains.
Ablation experiments, as well as a comparison to a broad range of forecasting
methods in a setting where only a single time series is available for training,
corroborate the beneficial nature of including local topological information
through an attention mechanism.",http://arxiv.org/pdf/2107.09031v1,cs.LG
2021-07-19 08:46:22+00:00,Long-term series forecasting with Query Selector -- efficient model of sparse attention,"['Jacek Klimek', 'Jakub Klimek', 'Witold Kraskiewicz', 'Mateusz Topolewski']","Various modifications of TRANSFORMER were recently used to solve time-series
forecasting problem. We propose Query Selector - an efficient, deterministic
algorithm for sparse attention matrix. Experiments show it achieves
state-of-the art results on ETT, Helpdesk and BPI'12 datasets.",http://arxiv.org/pdf/2107.08687v2,cs.LG
2021-07-18 09:31:14+00:00,A Method for Estimating the Entropy of Time Series Using Artificial Neural Networks,"['Andrei Velichko', 'Hanif Heidari']","Measuring the predictability and complexity of time series using entropy is
essential tool de-signing and controlling a nonlinear system. However, the
existing methods have some drawbacks related to the strong dependence of
entropy on the parameters of the methods. To overcome these difficulties, this
study proposes a new method for estimating the entropy of a time series using
the LogNNet neural network model. The LogNNet reservoir matrix is filled with
time series elements according to our algorithm. The accuracy of the
classification of images from the MNIST-10 database is considered as the
entropy measure and denoted by NNetEn. The novelty of entropy calculation is
that the time series is involved in mixing the input information in the
res-ervoir. Greater complexity in the time series leads to a higher
classification accuracy and higher NNetEn values. We introduce a new time
series characteristic called time series learning inertia that determines the
learning rate of the neural network. The robustness and efficiency of the
method is verified on chaotic, periodic, random, binary, and constant time
series. The comparison of NNetEn with other methods of entropy estimation
demonstrates that our method is more robust and accurate and can be widely used
in practice.",http://arxiv.org/pdf/2107.08399v4,cs.LG
2021-07-17 16:25:46+00:00,STRODE: Stochastic Boundary Ordinary Differential Equation,"['Hengguan Huang', 'Hongfu Liu', 'Hao Wang', 'Chang Xiao', 'Ye Wang']","Perception of time from sequentially acquired sensory inputs is rooted in
everyday behaviors of individual organisms. Yet, most algorithms for
time-series modeling fail to learn dynamics of random event timings directly
from visual or audio inputs, requiring timing annotations during training that
are usually unavailable for real-world applications. For instance, neuroscience
perspectives on postdiction imply that there exist variable temporal ranges
within which the incoming sensory inputs can affect the earlier perception, but
such temporal ranges are mostly unannotated for real applications such as
automatic speech recognition (ASR). In this paper, we present a probabilistic
ordinary differential equation (ODE), called STochastic boundaRy ODE (STRODE),
that learns both the timings and the dynamics of time series data without
requiring any timing annotations during training. STRODE allows the usage of
differential equations to sample from the posterior point processes,
efficiently and analytically. We further provide theoretical guarantees on the
learning of STRODE. Our empirical results show that our approach successfully
infers event timings of time series data. Our method achieves competitive or
superior performances compared to existing state-of-the-art methods for both
synthetic and real-world datasets.",http://arxiv.org/pdf/2107.08273v1,cs.LG
2021-07-16 17:21:14+00:00,Online Graph Topology Learning from Matrix-valued Time Series,"['Yiye Jiang', 'Jérémie Bigot', 'Sofian Maabout']","This paper is concerned with the statistical analysis of matrix-valued time
series. These are data collected over a network of sensors (typically a set of
spatial locations) along time, where a vector of features is observed per time
instant per sensor. Thus each sensor is characterized by a vectorial time
series. We would like to identify the dependency structure among these sensors
and represent it by a graph. When there is only one feature per sensor, the
vector auto-regressive models have been widely adapted to infer the structure
of Granger causality. The resulting graph is referred to as causal graph. Our
first contribution is then extending VAR models to matrix-variate models to
serve the purpose of graph learning. Secondly, we propose two online procedures
respectively in low and high dimensions, which can update quickly the estimates
of coefficients when new samples arrive. In particular in high dimensional
regime, a novel Lasso-type is introduced and we develop its homotopy algorithms
for the online learning. We also provide an adaptive tuning procedure for the
regularization parameter. Lastly, we consider that, the application of AR
models onto data usually requires detrending the raw data, however, this step
is forbidden in online context. Therefore, we augment the proposed AR models by
incorporating trend as extra parameter, and then adapt the online algorithms to
the augmented data models, which allow us to simultaneously learn the graph and
trend from streaming samples. In this work, we consider primarily the periodic
trend. Numerical experiments using both synthetic and real data are performed,
whose results support the effectiveness of the proposed methods.",http://arxiv.org/pdf/2107.08020v2,stat.ML
2021-07-16 14:33:59+00:00,Time Series Anomaly Detection for Smart Grids: A Survey,"['Jiuqi Elise Zhang', 'Di Wu', 'Benoit Boulet']","With the rapid increase in the integration of renewable energy generation and
the wide adoption of various electric appliances, power grids are now faced
with more and more challenges. One prominent challenge is to implement
efficient anomaly detection for different types of anomalous behaviors within
power grids. These anomalous behaviors might be induced by unusual consumption
patterns of the users, faulty grid infrastructures, outages, external
cyberattacks, or energy fraud. Identifying such anomalies is of critical
importance for the reliable and efficient operation of modern power grids.
Various methods have been proposed for anomaly detection on power grid
time-series data. This paper presents a short survey of the recent advances in
anomaly detection for power grid time-series data. Specifically, we first
outline current research challenges in the power grid anomaly detection domain
and further review the major anomaly detection approaches. Finally, we conclude
the survey by identifying the potential directions for future research.",http://arxiv.org/pdf/2107.08835v1,cs.LG
2021-07-16 04:33:53+00:00,Neural Contextual Anomaly Detection for Time Series,"['Chris U. Carmona', 'François-Xavier Aubet', 'Valentin Flunkert', 'Jan Gasthaus']","We introduce Neural Contextual Anomaly Detection (NCAD), a framework for
anomaly detection on time series that scales seamlessly from the unsupervised
to supervised setting, and is applicable to both univariate and multivariate
time series. This is achieved by effectively combining recent developments in
representation learning for multivariate time series, with techniques for deep
anomaly detection originally developed for computer vision that we tailor to
the time series setting. Our window-based approach facilitates learning the
boundary between normal and anomalous classes by injecting generic synthetic
anomalies into the available data. Moreover, our method can effectively take
advantage of all the available information, be it as domain knowledge, or as
training labels in the semi-supervised setting. We demonstrate empirically on
standard benchmark datasets that our approach obtains a state-of-the-art
performance in these settings.",http://arxiv.org/pdf/2107.07702v1,cs.LG
2021-07-13 11:59:05+00:00,Wasserstein GAN: Deep Generation applied on Bitcoins financial time series,"['Rikli Samuel', 'Bigler Daniel Nico', 'Pfenninger Moritz', 'Osterrieder Joerg']","Modeling financial time series is challenging due to their high volatility
and unexpected happenings on the market. Most financial models and algorithms
trying to fill the lack of historical financial time series struggle to perform
and are highly vulnerable to overfitting. As an alternative, we introduce in
this paper a deep neural network called the WGAN-GP, a data-driven model that
focuses on sample generation. The WGAN-GP consists of a generator and
discriminator function which utilize an LSTM architecture. The WGAN-GP is
supposed to learn the underlying structure of the input data, which in our
case, is the Bitcoin. Bitcoin is unique in its behavior; the prices fluctuate
what makes guessing the price trend hardly impossible. Through adversarial
training, the WGAN-GP should learn the underlying structure of the bitcoin and
generate very similar samples of the bitcoin distribution. The generated
synthetic time series are visually indistinguishable from the real data. But
the numerical results show that the generated data were close to the real data
distribution but distinguishable. The model mainly shows a stable learning
behavior. However, the model has space for optimization, which could be
achieved by adjusting the hyperparameters.",http://arxiv.org/pdf/2107.06008v1,stat.ML
2021-07-13 11:08:47+00:00,Deep Autoregressive Models with Spectral Attention,"['Fernando Moreno-Pino', 'Pablo M. Olmos', 'Antonio Artés-Rodríguez']","Time series forecasting is an important problem across many domains, playing
a crucial role in multiple real-world applications. In this paper, we propose a
forecasting architecture that combines deep autoregressive models with a
Spectral Attention (SA) module, which merges global and local frequency domain
information in the model's embedded space. By characterizing in the spectral
domain the embedding of the time series as occurrences of a random process, our
method can identify global trends and seasonality patterns. Two spectral
attention models, global and local to the time series, integrate this
information within the forecast and perform spectral filtering to remove time
series's noise. The proposed architecture has a number of useful properties: it
can be effectively incorporated into well-know forecast architectures,
requiring a low number of parameters and producing interpretable results that
improve forecasting accuracy. We test the Spectral Attention Autoregressive
Model (SAAM) on several well-know forecast datasets, consistently demonstrating
that our model compares favorably to state-of-the-art approaches.",http://arxiv.org/pdf/2107.05984v2,stat.ML
2021-07-12 14:28:40+00:00,Automated Label Generation for Time Series Classification with Representation Learning: Reduction of Label Cost for Training,"['Soma Bandyopadhyay', 'Anish Datta', 'Arpan Pal']","Time-series generated by end-users, edge devices, and different wearables are
mostly unlabelled. We propose a method to auto-generate labels of un-labelled
time-series, exploiting very few representative labelled time-series. Our
method is based on representation learning using Auto Encoded Compact Sequence
(AECS) with a choice of best distance measure. It performs self-correction in
iterations, by learning latent structure, as well as synthetically boosting
representative time-series using Variational-Auto-Encoder (VAE) to improve the
quality of labels. We have experimented with UCR and UCI archives, public
real-world univariate, multivariate time-series taken from different
application domains. Experimental results demonstrate that the proposed method
is very close to the performance achieved by fully supervised classification.
The proposed method not only produces close to benchmark results but
outperforms the benchmark performance in some cases.",http://arxiv.org/pdf/2107.05458v1,cs.LG
2021-07-11 08:49:37+00:00,A prediction perspective on the Wiener-Hopf equations for time series,"['Suhasini Subba Rao', 'Junho Yang']","The Wiener-Hopf equations are a Toeplitz system of linear equations that
naturally arise in several applications in time series. These include the
update and prediction step of the stationary Kalman filter equations and the
prediction of bivariate time series. The celebrated Wiener-Hopf technique is
usually used for solving these equations and is based on a comparison of
coefficients in a Fourier series expansion. However, a statistical
interpretation of both the method and solution is opaque. The purpose of this
note is to revisit the (discrete) Wiener-Hopf equations and obtain an
alternative solution that is more aligned with classical techniques in time
series analysis. Specifically, we propose a solution to the Wiener-Hopf
equations that combines linear prediction with deconvolution.
  The Wiener-Hopf solution requires the spectral factorization of the
underlying spectral density function. For ease of evaluation it is often
assumed that the spectral density is rational. This allows one to obtain a
computationally tractable solution. However, this leads to an approximation
error when the underlying spectral density is not a rational function. We use
the proposed solution with Baxter's inequality to derive an error bound for the
rational spectral density approximation.",http://arxiv.org/pdf/2107.04994v2,math.ST
2021-07-09 18:11:50+00:00,A deep convolutional neural network that is invariant to time rescaling,"['Brandon G. Jacques', 'Zoran Tiganj', 'Aakash Sarkar', 'Marc W. Howard', 'Per B. Sederberg']","Human learners can readily understand speech, or a melody, when it is
presented slower or faster than usual. Although deep convolutional neural
networks (CNNs) are extremely powerful in extracting information from time
series, they require explicit training to generalize to different time scales.
This paper presents a deep CNN that incorporates a temporal representation
inspired by recent findings from neuroscience. In the mammalian brain, time is
represented by populations of neurons with temporal receptive fields.
Critically, the peaks of the receptive fields form a geometric series, such
that the population codes a set of temporal basis functions over log time.
Because memory for the recent past is a function of log time, rescaling the
input results in translation of the memory. The Scale-Invariant Temporal
History Convolution network (SITHCon) builds a convolutional layer over this
logarithmically-distributed temporal memory. A max-pool operation results in a
network that is invariant to rescalings of time modulo edge effects. We compare
performance of SITHCon to a Temporal Convolution Network (TCN). Although both
networks can learn classification and regression problems on both univariate
and multivariate time series f(t), only SITHCon generalizes to rescalings
f(at). This property, inspired by findings from contemporary neuroscience and
consistent with findings from cognitive psychology, may enable networks that
learn with fewer training examples, fewer weights and that generalize more
robustly to out of sample data.",http://arxiv.org/pdf/2107.04616v3,cs.LG
2021-07-08 20:13:50+00:00,Ensembles of Randomized NNs for Pattern-based Time Series Forecasting,"['Grzegorz Dudek', 'Paweł Pełka']","In this work, we propose an ensemble forecasting approach based on randomized
neural networks. Improved randomized learning streamlines the fitting abilities
of individual learners by generating network parameters in accordance with the
data and target function features. A pattern-based representation of time
series makes the proposed approach suitable for forecasting time series with
multiple seasonality. We propose six strategies for controlling the diversity
of ensemble members. Case studies conducted on four real-world forecasting
problems verified the effectiveness and superior performance of the proposed
ensemble forecasting approach. It outperformed statistical models as well as
state-of-the-art machine learning models in terms of forecasting accuracy. The
proposed approach has several advantages: fast and easy training, simple
architecture, ease of implementation, high accuracy and the ability to deal
with nonstationarity and multiple seasonality in time series.",http://arxiv.org/pdf/2107.04091v1,cs.LG
2021-07-08 10:37:24+00:00,Probabilistic Time Series Forecasting with Implicit Quantile Networks,"['Adèle Gouttes', 'Kashif Rasul', 'Mateusz Koren', 'Johannes Stephan', 'Tofigh Naghibi']","Here, we propose a general method for probabilistic time series forecasting.
We combine an autoregressive recurrent neural network to model temporal
dynamics with Implicit Quantile Networks to learn a large class of
distributions over a time-series target. When compared to other probabilistic
neural forecasting models on real- and simulated data, our approach is
favorable in terms of point-wise prediction accuracy as well as on estimating
the underlying temporal distribution.",http://arxiv.org/pdf/2107.03743v1,cs.LG
2021-07-07 22:20:24+00:00,CSDI: Conditional Score-based Diffusion Models for Probabilistic Time Series Imputation,"['Yusuke Tashiro', 'Jiaming Song', 'Yang Song', 'Stefano Ermon']","The imputation of missing values in time series has many applications in
healthcare and finance. While autoregressive models are natural candidates for
time series imputation, score-based diffusion models have recently outperformed
existing counterparts including autoregressive models in many tasks such as
image generation and audio synthesis, and would be promising for time series
imputation. In this paper, we propose Conditional Score-based Diffusion models
for Imputation (CSDI), a novel time series imputation method that utilizes
score-based diffusion models conditioned on observed data. Unlike existing
score-based approaches, the conditional diffusion model is explicitly trained
for imputation and can exploit correlations between observed values. On
healthcare and environmental data, CSDI improves by 40-65% over existing
probabilistic imputation methods on popular performance metrics. In addition,
deterministic imputation by CSDI reduces the error by 5-20% compared to the
state-of-the-art deterministic imputation methods. Furthermore, CSDI can also
be applied to time series interpolation and probabilistic forecasting, and is
competitive with existing baselines. The code is available at
https://github.com/ermongroup/CSDI.",http://arxiv.org/pdf/2107.03502v2,cs.LG
2021-07-07 14:44:55+00:00,On the Use of Time Series Kernel and Dimensionality Reduction to Identify the Acquisition of Antimicrobial Multidrug Resistance in the Intensive Care Unit,"['Óscar Escudero-Arnanz', 'Joaquín Rodríguez-Álvarez', 'Karl Øyvind Mikalsen', 'Robert Jenssen', 'Cristina Soguero-Ruiz']","The acquisition of Antimicrobial Multidrug Resistance (AMR) in patients
admitted to the Intensive Care Units (ICU) is a major global concern. This
study analyses data in the form of multivariate time series (MTS) from 3476
patients recorded at the ICU of University Hospital of Fuenlabrada (Madrid)
from 2004 to 2020. 18\% of the patients acquired AMR during their stay in the
ICU. The goal of this paper is an early prediction of the development of AMR.
Towards that end, we leverage the time-series cluster kernel (TCK) to learn
similarities between MTS. To evaluate the effectiveness of TCK as a kernel, we
applied several dimensionality reduction techniques for visualization and
classification tasks. The experimental results show that TCK allows identifying
a group of patients that acquire the AMR during the first 48 hours of their ICU
stay, and it also provides good classification capabilities.",http://arxiv.org/pdf/2107.10398v1,cs.LG
2021-07-05 10:15:23+00:00,Low-Rank Temporal Attention-Augmented Bilinear Network for financial time-series forecasting,"['Mostafa Shabani', 'Alexandros Iosifidis']","Financial market analysis, especially the prediction of movements of stock
prices, is a challenging problem. The nature of financial time-series data,
being non-stationary and nonlinear, is the main cause of these challenges. Deep
learning models have led to significant performance improvements in many
problems coming from different domains, including prediction problems of
financial time-series data. Although the prediction performance is the main
goal of such models, dealing with ultra high-frequency data sets restrictions
in terms of the number of model parameters and its inference speed. The
Temporal Attention-Augmented Bilinear network was recently proposed as an
efficient and high-performing model for Limit Order Book time-series
forecasting. In this paper, we propose a low-rank tensor approximation of the
model to further reduce the number of trainable parameters and increase its
speed.",http://arxiv.org/pdf/2107.06995v1,cs.LG
2021-07-05 06:35:15+00:00,Zero-modified Count Time Series with Markovian Intensities,"['N. Balakrishna', 'Muhammed Anvar', 'Bovas Abraham']","This paper proposes a method for analyzing count time series with inflation
or deflation of zeros. In particular, zero-modified Poisson and zero-modified
negative binomial series with intensities generated by non-negative Markov
sequences are studied in detail. Parameters of the model are estimated by the
method of estimating equations which is facilitated by expressing the model in
a generalized state space form. The latent intensities required for estimation
are extracted using generalized Kalman filter. The applications of proposed
model and its estimation methods are illustrated using simulated and real data
sets.",http://arxiv.org/pdf/2107.01813v1,stat.ME
2021-07-04 18:39:27+00:00,Randomized Neural Networks for Forecasting Time Series with Multiple Seasonality,['Grzegorz Dudek'],"This work contributes to the development of neural forecasting models with
novel randomization-based learning methods. These methods improve the fitting
abilities of the neural model, in comparison to the standard method, by
generating network parameters in accordance with the data and target function
features. A pattern-based representation of time series makes the proposed
approach useful for forecasting time series with multiple seasonality. In the
simulation study, we evaluate the performance of the proposed models and find
that they can compete in terms of forecasting accuracy with fully-trained
networks. Extremely fast and easy training, simple architecture, ease of
implementation, high accuracy as well as dealing with nonstationarity and
multiple seasonality in time series make the proposed model very attractive for
a wide range of complex time series forecasting problems.",http://arxiv.org/pdf/2107.01705v1,cs.LG
2021-07-03 00:19:17+00:00,Clustering of Time Series Data with Prior Geographical Information,"['Reza Asadi', 'Amelia Regan']","Time Series data are broadly studied in various domains of transportation
systems. Traffic data area challenging example of spatio-temporal data, as it
is multi-variate time series with high correlations in spatial and temporal
neighborhoods. Spatio-temporal clustering of traffic flow data find similar
patterns in both spatial and temporal domain, where it provides better
capability for analyzing a transportation network, and improving related
machine learning models, such as traffic flow prediction and anomaly detection.
In this paper, we propose a spatio-temporal clustering model, where it clusters
time series data based on spatial and temporal contexts. We propose a variation
of a Deep Embedded Clustering(DEC) model for finding spatio-temporal clusters.
The proposed model Spatial-DEC (S-DEC) use prior geographical information in
building latent feature representations. We also define evaluation metrics for
spatio-temporal clusters. Not only do the obtained clusters have better
temporal similarity when evaluated using DTW distance, but also the clusters
better represents spatial connectivity and dis-connectivity. We use traffic
flow data obtained by PeMS in our analysis. The results show that the proposed
Spatial-DEC can find more desired spatio-temporal clusters.",http://arxiv.org/pdf/2107.01310v1,cs.LG
2021-07-01 13:13:24+00:00,Online learning of windmill time series using Long Short-term Cognitive Networks,"['Alejandro Morales-Hernández', 'Gonzalo Nápoles', 'Agnieszka Jastrzebska', 'Yamisleydi Salgueiro', 'Koen Vanhoof']","Forecasting windmill time series is often the basis of other processes such
as anomaly detection, health monitoring, or maintenance scheduling. The amount
of data generated on windmill farms makes online learning the most viable
strategy to follow. Such settings require retraining the model each time a new
batch of data is available. However, update the model with the new information
is often very expensive to perform using traditional Recurrent Neural Networks
(RNNs). In this paper, we use Long Short-term Cognitive Networks (LSTCNs) to
forecast windmill time series in online settings. These recently introduced
neural systems consist of chained Short-term Cognitive Network blocks, each
processing a temporal data chunk. The learning algorithm of these blocks is
based on a very fast, deterministic learning rule that makes LSTCNs suitable
for online learning tasks. The numerical simulations using a case study with
four windmills showed that our approach reported the lowest forecasting errors
with respect to a simple RNN, a Long Short-term Memory, a Gated Recurrent Unit,
and a Hidden Markov Model. What is perhaps more important is that the LSTCN
approach is significantly faster than these state-of-the-art models.",http://arxiv.org/pdf/2107.00425v2,cs.LG
2021-06-30 17:42:09+00:00,Long Short-term Cognitive Networks,"['Gonzalo Nápoles', 'Isel Grau', 'Agnieszka Jastrzebska', 'Yamisleydi Salgueiro']","In this paper, we present a recurrent neural system named Long Short-term
Cognitive Networks (LSTCNs) as a generalization of the Short-term Cognitive
Network (STCN) model. Such a generalization is motivated by the difficulty of
forecasting very long time series efficiently. The LSTCN model can be defined
as a collection of STCN blocks, each processing a specific time patch of the
(multivariate) time series being modeled. In this neural ensemble, each block
passes information to the subsequent one in the form of weight matrices
representing the prior knowledge. As a second contribution, we propose a
deterministic learning algorithm to compute the learnable weights while
preserving the prior knowledge resulting from previous learning processes. As a
third contribution, we introduce a feature influence score as a proxy to
explain the forecasting process in multivariate time series. The simulations
using three case studies show that our neural system reports small forecasting
errors while being significantly faster than state-of-the-art recurrent models.",http://arxiv.org/pdf/2106.16233v2,cs.LG
2021-06-29 17:16:04+00:00,Continuous Latent Process Flows,"['Ruizhi Deng', 'Marcus A. Brubaker', 'Greg Mori', 'Andreas M. Lehrmann']","Partial observations of continuous time-series dynamics at arbitrary time
stamps exist in many disciplines. Fitting this type of data using statistical
models with continuous dynamics is not only promising at an intuitive level but
also has practical benefits, including the ability to generate continuous
trajectories and to perform inference on previously unseen time stamps. Despite
exciting progress in this area, the existing models still face challenges in
terms of their representational power and the quality of their variational
approximations. We tackle these challenges with continuous latent process flows
(CLPF), a principled architecture decoding continuous latent processes into
continuous observable processes using a time-dependent normalizing flow driven
by a stochastic differential equation. To optimize our model using maximum
likelihood, we propose a novel piecewise construction of a variational
posterior process and derive the corresponding variational lower bound using
trajectory re-weighting. Our ablation studies demonstrate the effectiveness of
our contributions in various inference tasks on irregular time grids.
Comparisons to state-of-the-art baselines show our model's favourable
performance on both synthetic and real-world time-series data.",http://arxiv.org/pdf/2106.15580v2,cs.LG
2021-06-28 12:35:53+00:00,Local Whittle estimation with (quasi-)analytic wavelets,"['Sophie Achard', 'Irène Gannaz']","In the general setting of long-memory multivariate time series, the
long-memory characteristics are defined by two components. The long-memory
parameters describe the autocorrelation of each time series. And the long-run
covariance measures the coupling between time series, with general phase
parameters. It is of interest to estimate the long-memory, long-run covariance
and general phase parameters of time series generated by this wide class of
models although they are not necessarily Gaussian nor stationary. This
estimation is thus not directly possible using real wavelets decomposition or
Fourier analysis. Our purpose is to define an inference approach based on a
representation using quasi-analytic wavelets. We first show that the covariance
of the wavelet coefficients provides an adequate estimator of the covariance
structure including the phase term. Consistent estimators based on a local
Whittle approximation are then proposed. Simulations highlight a satisfactory
behavior of the estimation on finite samples on linear time series and on
multivariate fractional Brownian motions. An application on a real neuroscience
dataset is presented, where long-memory and brain connectivity are inferred.",http://arxiv.org/pdf/2106.14633v3,math.ST
2021-06-26 23:56:31+00:00,Time-Series Representation Learning via Temporal and Contextual Contrasting,"['Emadeldeen Eldele', 'Mohamed Ragab', 'Zhenghua Chen', 'Min Wu', 'Chee Keong Kwoh', 'Xiaoli Li', 'Cuntai Guan']","Learning decent representations from unlabeled time-series data with temporal
dynamics is a very challenging task. In this paper, we propose an unsupervised
Time-Series representation learning framework via Temporal and Contextual
Contrasting (TS-TCC), to learn time-series representation from unlabeled data.
First, the raw time-series data are transformed into two different yet
correlated views by using weak and strong augmentations. Second, we propose a
novel temporal contrasting module to learn robust temporal representations by
designing a tough cross-view prediction task. Last, to further learn
discriminative representations, we propose a contextual contrasting module
built upon the contexts from the temporal contrasting module. It attempts to
maximize the similarity among different contexts of the same sample while
minimizing similarity among contexts of different samples. Experiments have
been carried out on three real-world time-series datasets. The results manifest
that training a linear classifier on top of the features learned by our
proposed TS-TCC performs comparably with the supervised training. Additionally,
our proposed TS-TCC shows high efficiency in few-labeled data and transfer
learning scenarios. The code is publicly available at
https://github.com/emadeldeen24/TS-TCC.",http://arxiv.org/pdf/2106.14112v1,cs.LG
2021-06-26 20:14:31+00:00,Bayesian Time-Varying Tensor Vector Autoregressive Models for Dynamic Effective Connectivity,"['Wei Zhang', 'Ivor Cribben', 'sonia Petrone', 'Michele Guindani']","Recent developments in functional magnetic resonance imaging (fMRI)
investigate how some brain regions directly influence the activity of other
regions of the brain {\it dynamically} throughout the course of an experiment,
namely dynamic effective connectivity. Time-varying vector autoregressive
(TV-VAR) models have been employed to draw inferencesfor this purpose, but they
are very computationally intensive, since the number of parameters to be
estimated increases quadratically with the number of time series. In this
paper, we propose a computationally efficient Bayesian time-varying VAR
approach for modeling high-dimensional time series. The proposed framework
employs a tensor decomposition for the VAR coefficient matrices at different
lags. Dynamically varying connectivity patterns are captured by assuming that
at any given time only a subset of components in the tensor decomposition is
active. Latent binary time series select the active components at each time via
a convenient Ising prior specification. The proposed prior structure encourages
sparsity in the tensor structure and allows to ascertain model complexity
through the posterior distribution. More specifically, sparsity-inducing priors
are employed to allow for global-local shrinkage of the coefficients, to
determine automatically the rank of the tensor decomposition and to guide the
selection of the lags of the auto-regression. We show the performances of our
model formulation via simulation studies and data from a real fMRI study
involving a book reading experiment.",http://arxiv.org/pdf/2106.14083v1,stat.ME
2021-06-26 15:28:38+00:00,The mbsts package: Multivariate Bayesian Structural Time Series Models in R,"['Ning Ning', 'Jinwen Qiu']","The multivariate Bayesian structural time series (MBSTS) model is a general
machine learning model that deals with inference and prediction for multiple
correlated time series, where one also has the choice of using a different
candidate pool of contemporaneous predictors for each target series. The MBSTS
model has wide applications and is ideal for feature selection, time series
forecasting, nowcasting, inferring causal impact, and others. This paper
demonstrates how to use the R package mbsts for MBSTS modeling, establishing a
bridge between user-friendly and developer-friendly functions in the package
and the corresponding methodology. Object-oriented functions in the package are
explained in the way that enables users to flexibly add or deduct some
components, as well as to simplify or complicate some settings.",http://arxiv.org/pdf/2106.14045v3,stat.ME
2021-06-26 07:10:58+00:00,Functional Classwise Principal Component Analysis: A Novel Classification Framework,"['Avishek Chatterjee', 'Satyaki Mazumder', 'Koel Das']","In recent times, functional data analysis (FDA) has been successfully applied
in the field of high dimensional data classification. In this paper, we present
a novel classification framework using functional data and classwise Principal
Component Analysis (PCA). Our proposed method can be used in high dimensional
time series data which typically suffers from small sample size problem. Our
method extracts a piece wise linear functional feature space and is
particularly suitable for hard classification problems.The proposed framework
converts time series data into functional data and uses classwise functional
PCA for feature extraction followed by classification using a Bayesian linear
classifier. We demonstrate the efficacy of our proposed method by applying it
to both synthetic data sets and real time series data from diverse fields
including but not limited to neuroscience, food science, medical sciences and
chemometrics.",http://arxiv.org/pdf/2106.13959v1,stat.ML
2021-06-25 01:12:54+00:00,Bayesian Inference in High-Dimensional Time-Serieswith the Orthogonal Stochastic Linear Mixing Model,"['Rui Meng', 'Kristofer Bouchard']","Many modern time-series datasets contain large numbers of output response
variables sampled for prolonged periods of time. For example, in neuroscience,
the activities of 100s-1000's of neurons are recorded during behaviors and in
response to sensory stimuli. Multi-output Gaussian process models leverage the
nonparametric nature of Gaussian processes to capture structure across multiple
outputs. However, this class of models typically assumes that the correlations
between the output response variables are invariant in the input space.
Stochastic linear mixing models (SLMM) assume the mixture coefficients depend
on input, making them more flexible and effective to capture complex output
dependence. However, currently, the inference for SLMMs is intractable for
large datasets, making them inapplicable to several modern time-series
problems. In this paper, we propose a new regression framework, the orthogonal
stochastic linear mixing model (OSLMM) that introduces an orthogonal constraint
amongst the mixing coefficients. This constraint reduces the computational
burden of inference while retaining the capability to handle complex output
dependence. We provide Markov chain Monte Carlo inference procedures for both
SLMM and OSLMM and demonstrate superior model scalability and reduced
prediction error of OSLMM compared with state-of-the-art methods on several
real-world applications. In neurophysiology recordings, we use the inferred
latent functions for compact visualization of population responses to auditory
stimuli, and demonstrate superior results compared to a competing method
(GPFA). Together, these results demonstrate that OSLMM will be useful for the
analysis of diverse, large-scale time-series datasets.",http://arxiv.org/pdf/2106.13379v2,cs.LG
2021-06-24 13:43:43+00:00,Autoformer: Decomposition Transformers with Auto-Correlation for Long-Term Series Forecasting,"['Haixu Wu', 'Jiehui Xu', 'Jianmin Wang', 'Mingsheng Long']","Extending the forecasting time is a critical demand for real applications,
such as extreme weather early warning and long-term energy consumption
planning. This paper studies the long-term forecasting problem of time series.
Prior Transformer-based models adopt various self-attention mechanisms to
discover the long-range dependencies. However, intricate temporal patterns of
the long-term future prohibit the model from finding reliable dependencies.
Also, Transformers have to adopt the sparse versions of point-wise
self-attentions for long series efficiency, resulting in the information
utilization bottleneck. Going beyond Transformers, we design Autoformer as a
novel decomposition architecture with an Auto-Correlation mechanism. We break
with the pre-processing convention of series decomposition and renovate it as a
basic inner block of deep models. This design empowers Autoformer with
progressive decomposition capacities for complex time series. Further, inspired
by the stochastic process theory, we design the Auto-Correlation mechanism
based on the series periodicity, which conducts the dependencies discovery and
representation aggregation at the sub-series level. Auto-Correlation
outperforms self-attention in both efficiency and accuracy. In long-term
forecasting, Autoformer yields state-of-the-art accuracy, with a 38% relative
improvement on six benchmarks, covering five practical applications: energy,
traffic, economics, weather and disease. Code is available at this repository:
\url{https://github.com/thuml/Autoformer}.",http://arxiv.org/pdf/2106.13008v5,cs.LG
2021-06-24 08:07:49+00:00,On the asymptotic distribution of the maximum sample spectral coherence of Gaussian time series in the high dimensional regime,"['Alexis Rosuel', 'Philippe Loubaton', 'Pascal Vallet']","We investigate the asymptotic distribution of the maximum of a frequency
smoothed estimate of the spectral coherence of a M-variate complex Gaussian
time series with mutually independent components when the dimension M and the
number of samples N both converge to infinity. If B denotes the smoothing span
of the underlying smoothed periodogram estimator, a type I extreme value
limiting distribution is obtained under the rate assumptions M N $\rightarrow$
0 and M B $\rightarrow$ c $\in$ (0, +$\infty$). This result is then exploited
to build a statistic with controlled asymptotic level for testing independence
between the M components of the observed time series. Numerical simulations
support our results.",http://arxiv.org/pdf/2107.02891v1,math.ST
2021-06-23 17:25:43+00:00,Approximate Bayesian Computation with Path Signatures,"['Joel Dyer', 'Patrick Cannon', 'Sebastian M Schmon']","Simulation models often lack tractable likelihood functions, making
likelihood-free inference methods indispensable. Approximate Bayesian
computation generates likelihood-free posterior samples by comparing simulated
and observed data through some distance measure, but existing approaches are
often poorly suited to time series simulators, for example due to an
independent and identically distributed data assumption. In this paper, we
propose to use path signatures in approximate Bayesian computation to handle
the sequential nature of time series. We provide theoretical guarantees on the
resultant posteriors and demonstrate competitive Bayesian parameter inference
for simulators generating univariate, multivariate, irregularly spaced, and
even non-Euclidean sequences.",http://arxiv.org/pdf/2106.12555v2,stat.ME
2021-06-23 13:24:17+00:00,Innovations Autoencoder and its Application in One-class Anomalous Sequence Detection,"['Xinyi Wang', 'Lang Tong']","An innovations sequence of a time series is a sequence of independent and
identically distributed random variables with which the original time series
has a causal representation. The innovation at a time is statistically
independent of the history of the time series. As such, it represents the new
information contained at present but not in the past. Because of its simple
probability structure, an innovations sequence is the most efficient signature
of the original. Unlike the principle or independent component analysis
representations, an innovations sequence preserves not only the complete
statistical properties but also the temporal order of the original time series.
An long-standing open problem is to find a computationally tractable way to
extract an innovations sequence of non-Gaussian processes. This paper presents
a deep learning approach, referred to as Innovations Autoencoder (IAE), that
extracts innovations sequences using a causal convolutional neural network. An
application of IAE to the one-class anomalous sequence detection problem with
unknown anomaly and anomaly-free models is also presented.",http://arxiv.org/pdf/2106.12382v2,stat.ML
2021-06-21 09:48:03+00:00,Spliced Binned-Pareto Distribution for Robust Modeling of Heavy-tailed Time Series,"['Elena Ehrlich', 'Laurent Callot', 'François-Xavier Aubet']","This work proposes a novel method to robustly and accurately model time
series with heavy-tailed noise, in non-stationary scenarios. In many practical
application time series have heavy-tailed noise that significantly impacts the
performance of classical forecasting models; in particular, accurately modeling
a distribution over extreme events is crucial to performing accurate time
series anomaly detection. We propose a Spliced Binned-Pareto distribution which
is both robust to extreme observations and allows accurate modeling of the full
distribution. Our method allows the capture of time dependencies in the higher
order moments of the distribution such as the tail heaviness. We compare the
robustness and the accuracy of the tail estimation of our method to other state
of the art methods on Twitter mentions count time series.",http://arxiv.org/pdf/2106.10952v2,stat.ML
2021-06-19 11:50:39+00:00,Generalized Spatial and Spatiotemporal ARCH Models,"['Philipp Otto', 'Wolfgang Schmid']","In time-series analyses, particularly for finance, generalized autoregressive
conditional heteroscedasticity (GARCH) models are widely applied statistical
tools for modelling volatility clusters (i.e., periods of increased or
decreased risk). In contrast, it has not been considered to be of critical
importance until now to model spatial dependence in the conditional second
moments. Only a few models have been proposed for modelling local clusters of
increased risks. In this paper, we introduce a novel spatial GARCH process in a
unified spatial and spatiotemporal GARCH framework, which also covers all
previously proposed spatial ARCH models, exponential spatial GARCH, and
time-series GARCH models. In contrast to previous spatiotemporal and time
series models, this spatial GARCH allows for instantaneous spill-overs across
all spatial units. For this common modelling framework, estimators are derived
based on a non-linear least-squares approach. Eventually, the use of the model
is demonstrated by a Monte Carlo simulation study and by an empirical example
that focuses on real estate prices from 1995 to 2014 across the ZIP-Code areas
of Berlin. A spatial autoregressive model is applied to the data to illustrate
how locally varying model uncertainties (e.g., due to latent regressors) can be
captured by the spatial GARCH-type models.",http://arxiv.org/pdf/2106.10477v1,stat.ME
2021-06-19 10:24:13+00:00,TS2Vec: Towards Universal Representation of Time Series,"['Zhihan Yue', 'Yujing Wang', 'Juanyong Duan', 'Tianmeng Yang', 'Congrui Huang', 'Yunhai Tong', 'Bixiong Xu']","This paper presents TS2Vec, a universal framework for learning
representations of time series in an arbitrary semantic level. Unlike existing
methods, TS2Vec performs contrastive learning in a hierarchical way over
augmented context views, which enables a robust contextual representation for
each timestamp. Furthermore, to obtain the representation of an arbitrary
sub-sequence in the time series, we can apply a simple aggregation over the
representations of corresponding timestamps. We conduct extensive experiments
on time series classification tasks to evaluate the quality of time series
representations. As a result, TS2Vec achieves significant improvement over
existing SOTAs of unsupervised time series representation on 125 UCR datasets
and 29 UEA datasets. The learned timestamp-level representations also achieve
superior results in time series forecasting and anomaly detection tasks. A
linear regression trained on top of the learned representations outperforms
previous SOTAs of time series forecasting. Furthermore, we present a simple way
to apply the learned representations for unsupervised anomaly detection, which
establishes SOTA results in the literature. The source code is publicly
available at https://github.com/yuezhihan/ts2vec.",http://arxiv.org/pdf/2106.10466v4,cs.LG
2021-06-18 14:50:11+00:00,pyWATTS: Python Workflow Automation Tool for Time Series,"['Benedikt Heidrich', 'Andreas Bartschat', 'Marian Turowski', 'Oliver Neumann', 'Kaleb Phipps', 'Stefan Meisenbacher', 'Kai Schmieder', 'Nicole Ludwig', 'Ralf Mikut', 'Veit Hagenmeyer']","Time series data are fundamental for a variety of applications, ranging from
financial markets to energy systems. Due to their importance, the number and
complexity of tools and methods used for time series analysis is constantly
increasing. However, due to unclear APIs and a lack of documentation,
researchers struggle to integrate them into their research projects and
replicate results. Additionally, in time series analysis there exist many
repetitive tasks, which are often re-implemented for each project,
unnecessarily costing time. To solve these problems we present
\texttt{pyWATTS}, an open-source Python-based package that is a non-sequential
workflow automation tool for the analysis of time series data. pyWATTS includes
modules with clearly defined interfaces to enable seamless integration of new
or existing methods, subpipelining to easily reproduce repetitive tasks, load
and save functionality to simply replicate results, and native support for key
Python machine learning libraries such as scikit-learn, PyTorch, and Keras.",http://arxiv.org/pdf/2106.10157v1,cs.LG
2021-06-18 13:22:12+00:00,ScoreGrad: Multivariate Probabilistic Time Series Forecasting with Continuous Energy-based Generative Models,"['Tijin Yan', 'Hongwei Zhang', 'Tong Zhou', 'Yufeng Zhan', 'Yuanqing Xia']","Multivariate time series prediction has attracted a lot of attention because
of its wide applications such as intelligence transportation, AIOps. Generative
models have achieved impressive results in time series modeling because they
can model data distribution and take noise into consideration. However, many
existing works can not be widely used because of the constraints of functional
form of generative models or the sensitivity to hyperparameters. In this paper,
we propose ScoreGrad, a multivariate probabilistic time series forecasting
framework based on continuous energy-based generative models. ScoreGrad is
composed of time series feature extraction module and conditional stochastic
differential equation based score matching module. The prediction can be
achieved by iteratively solving reverse-time SDE. To the best of our knowledge,
ScoreGrad is the first continuous energy based generative model used for time
series forecasting. Furthermore, ScoreGrad achieves state-of-the-art results on
six real-world datasets. The impact of hyperparameters and sampler types on the
performance are also explored. Code is available at
https://github.com/yantijin/ScoreGradPred.",http://arxiv.org/pdf/2106.10121v1,cs.LG
2021-06-17 16:32:47+00:00,Multi-Modal Prototype Learning for Interpretable Multivariable Time Series Classification,"['Gaurav R. Ghosal', 'Reza Abbasi-Asl']","Multivariable time series classification problems are increasing in
prevalence and complexity in a variety of domains, such as biology and finance.
While deep learning methods are an effective tool for these problems, they
often lack interpretability. In this work, we propose a novel modular prototype
learning framework for multivariable time series classification. In the first
stage of our framework, encoders extract features from each variable
independently. Prototype layers identify single-variable prototypes in the
resulting feature spaces. The next stage of our framework represents the
multivariable time series sample points in terms of their similarity to these
single-variable prototypes. This results in an inherently interpretable
representation of multivariable patterns, on which prototype learning is
applied to extract representative examples i.e. multivariable prototypes. Our
framework is thus able to explicitly identify both informative patterns in the
individual variables, as well as the relationships between the variables. We
validate our framework on a simulated dataset with embedded patterns, as well
as a real human activity recognition problem. Our framework attains comparable
or superior classification performance to existing time series classification
methods on these tasks. On the simulated dataset, we find that our model
returns interpretations consistent with the embedded patterns. Moreover, the
interpretations learned on the activity recognition dataset align with domain
knowledge.",http://arxiv.org/pdf/2106.09636v1,cs.LG
2021-06-17 08:15:04+00:00,SCINet: Time Series Modeling and Forecasting with Sample Convolution and Interaction,"['Minhao Liu', 'Ailing Zeng', 'Muxi Chen', 'Zhijian Xu', 'Qiuxia Lai', 'Lingna Ma', 'Qiang Xu']","One unique property of time series is that the temporal relations are largely
preserved after downsampling into two sub-sequences. By taking advantage of
this property, we propose a novel neural network architecture that conducts
sample convolution and interaction for temporal modeling and forecasting, named
SCINet. Specifically, SCINet is a recursive downsample-convolve-interact
architecture. In each layer, we use multiple convolutional filters to extract
distinct yet valuable temporal features from the downsampled sub-sequences or
features. By combining these rich features aggregated from multiple
resolutions, SCINet effectively models time series with complex temporal
dynamics. Experimental results show that SCINet achieves significant
forecasting accuracy improvements over both existing convolutional models and
Transformer-based solutions across various real-world time series forecasting
datasets. Our codes and data are available at
https://github.com/cure-lab/SCINet.",http://arxiv.org/pdf/2106.09305v3,cs.LG
2021-06-17 07:59:15+00:00,Voice2Series: Reprogramming Acoustic Models for Time Series Classification,"['Chao-Han Huck Yang', 'Yun-Yun Tsai', 'Pin-Yu Chen']","Learning to classify time series with limited data is a practical yet
challenging problem. Current methods are primarily based on hand-designed
feature extraction rules or domain-specific data augmentation. Motivated by the
advances in deep speech processing models and the fact that voice data are
univariate temporal signals, in this paper, we propose Voice2Series (V2S), a
novel end-to-end approach that reprograms acoustic models for time series
classification, through input transformation learning and output label mapping.
Leveraging the representation learning power of a large-scale pre-trained
speech processing model, on 30 different time series tasks we show that V2S
performs competitive results on 19 time series classification tasks. We further
provide a theoretical justification of V2S by proving its population risk is
upper bounded by the source risk and a Wasserstein distance accounting for
feature alignment via reprogramming. Our results offer new and effective means
to time series classification.",http://arxiv.org/pdf/2106.09296v3,cs.LG
2021-06-16 06:00:49+00:00,Adaptive Visibility Graph Neural Network and its Application in Modulation Classification,"['Qi Xuan', 'Kunfeng Qiu', 'Jinchao Zhou', 'Zhuangzhi Chen', 'Dongwei Xu', 'Shilian Zheng', 'Xiaoniu Yang']","Our digital world is full of time series and graphs which capture the various
aspects of many complex systems. Traditionally, there are respective methods in
processing these two different types of data, e.g., Recurrent Neural Network
(RNN) and Graph Neural Network (GNN), while in recent years, time series could
be mapped to graphs by using the techniques such as Visibility Graph (VG), so
that researchers can use graph algorithms to mine the knowledge in time series.
Such mapping methods establish a bridge between time series and graphs, and
have high potential to facilitate the analysis of various real-world time
series. However, the VG method and its variants are just based on fixed rules
and thus lack of flexibility, largely limiting their application in reality. In
this paper, we propose an Adaptive Visibility Graph (AVG) algorithm that can
adaptively map time series into graphs, based on which we further establish an
end-to-end classification framework AVGNet, by utilizing GNN model DiffPool as
the classifier. We then adopt AVGNet for radio signal modulation classification
which is an important task in the field of wireless communication. The
simulations validate that AVGNet outperforms a series of advanced deep learning
methods, achieving the state-of-the-art performance in this task.",http://arxiv.org/pdf/2106.08564v1,cs.LG
2021-06-14 17:38:16+00:00,Hierarchically Regularized Deep Forecasting,"['Biswajit Paria', 'Rajat Sen', 'Amr Ahmed', 'Abhimanyu Das']","Hierarchical forecasting is a key problem in many practical multivariate
forecasting applications - the goal is to simultaneously predict a large number
of correlated time series that are arranged in a pre-specified aggregation
hierarchy. The main challenge is to exploit the hierarchical correlations to
simultaneously obtain good prediction accuracy for time series at different
levels of the hierarchy. In this paper, we propose a new approach for
hierarchical forecasting which consists of two components. First, decomposing
the time series along a global set of basis time series and modeling
hierarchical constraints using the coefficients of the basis decomposition. And
second, using a linear autoregressive model with coefficients that vary with
time. Unlike past methods, our approach is scalable (inference for a specific
time series only needs access to its own history) while also modeling the
hierarchical structure via (approximate) coherence constraints among the time
series forecasts. We experiment on several public datasets and demonstrate
significantly improved overall performance on forecasts at different levels of
the hierarchy, compared to existing state-of-the-art hierarchical models.",http://arxiv.org/pdf/2106.07630v2,cs.LG
2021-06-13 09:07:30+00:00,Graph Neural Network-Based Anomaly Detection in Multivariate Time Series,"['Ailin Deng', 'Bryan Hooi']","Given high-dimensional time series data (e.g., sensor data), how can we
detect anomalous events, such as system faults and attacks? More challengingly,
how can we do this in a way that captures complex inter-sensor relationships,
and detects and explains anomalies which deviate from these relationships?
Recently, deep learning approaches have enabled improvements in anomaly
detection in high-dimensional datasets; however, existing methods do not
explicitly learn the structure of existing relationships between variables, or
use them to predict the expected behavior of time series. Our approach combines
a structure learning approach with graph neural networks, additionally using
attention weights to provide explainability for the detected anomalies.
Experiments on two real-world sensor datasets with ground truth anomalies show
that our method detects anomalies more accurately than baseline approaches,
accurately captures correlations between sensors, and allows users to deduce
the root cause of a detected anomaly.",http://arxiv.org/pdf/2106.06947v1,cs.LG
2021-06-11 04:57:03+00:00,HIFI: Anomaly Detection for Multivariate Time Series with High-order Feature Interactions,"['Liwei Deng', 'Xuanhao Chen', 'Yan Zhao', 'Kai Zheng']","Monitoring complex systems results in massive multivariate time series data,
and anomaly detection of these data is very important to maintain the normal
operation of the systems. Despite the recent emergence of a large number of
anomaly detection algorithms for multivariate time series, most of them ignore
the correlation modeling among multivariate, which can often lead to poor
anomaly detection results. In this work, we propose a novel anomaly detection
model for multivariate time series with \underline{HI}gh-order
\underline{F}eature \underline{I}nteractions (HIFI). More specifically, HIFI
builds multivariate feature interaction graph automatically and uses the graph
convolutional neural network to achieve high-order feature interactions, in
which the long-term temporal dependencies are modeled by attention mechanisms
and a variational encoding technique is utilized to improve the model
performance and robustness. Extensive experiments on three publicly available
datasets demonstrate the superiority of our framework compared with
state-of-the-art approaches.",http://arxiv.org/pdf/2106.06167v1,cs.LG
2021-06-10 21:49:23+00:00,RNN with Particle Flow for Probabilistic Spatio-temporal Forecasting,"['Soumyasundar Pal', 'Liheng Ma', 'Yingxue Zhang', 'Mark Coates']","Spatio-temporal forecasting has numerous applications in analyzing wireless,
traffic, and financial networks. Many classical statistical models often fall
short in handling the complexity and high non-linearity present in time-series
data. Recent advances in deep learning allow for better modelling of spatial
and temporal dependencies. While most of these models focus on obtaining
accurate point forecasts, they do not characterize the prediction uncertainty.
In this work, we consider the time-series data as a random realization from a
nonlinear state-space model and target Bayesian inference of the hidden states
for probabilistic forecasting. We use particle flow as the tool for
approximating the posterior distribution of the states, as it is shown to be
highly effective in complex, high-dimensional settings. Thorough
experimentation on several real world time-series datasets demonstrates that
our approach provides better characterization of uncertainty while maintaining
comparable accuracy to the state-of-the art point forecasting methods.",http://arxiv.org/pdf/2106.06064v1,stat.ML
2021-06-10 20:22:41+00:00,Deep Probabilistic Koopman: Long-term time-series forecasting under periodic uncertainties,"['Alex Mallen', 'Henning Lange', 'J. Nathan Kutz']","Probabilistic forecasting of complex phenomena is paramount to various
scientific disciplines and applications. Despite the generality and importance
of the problem, general mathematical techniques that allow for stable long-term
forecasts with calibrated uncertainty measures are lacking. For most time
series models, the difficulty of obtaining accurate probabilistic future time
step predictions increases with the prediction horizon. In this paper, we
introduce a surprisingly simple approach that characterizes time-varying
distributions and enables reasonably accurate predictions thousands of
timesteps into the future. This technique, which we call Deep Probabilistic
Koopman (DPK), is based on recent advances in linear Koopman operator theory,
and does not require time stepping for future time predictions. Koopman models
also tend to have a small parameter footprint (often less than 10,000
parameters). We demonstrate the long-term forecasting performance of these
models on a diversity of domains, including electricity demand forecasting,
atmospheric chemistry, and neuroscience. For electricity demand modeling, our
domain-agnostic technique outperforms all of 177 domain-specific competitors in
the most recent Global Energy Forecasting Competition.",http://arxiv.org/pdf/2106.06033v1,cs.LG
2021-06-09 18:01:09+00:00,Explaining Time Series Predictions with Dynamic Masks,"['Jonathan Crabbé', 'Mihaela van der Schaar']","How can we explain the predictions of a machine learning model? When the data
is structured as a multivariate time series, this question induces additional
difficulties such as the necessity for the explanation to embody the time
dependency and the large number of inputs. To address these challenges, we
propose dynamic masks (Dynamask). This method produces instance-wise importance
scores for each feature at each time step by fitting a perturbation mask to the
input sequence. In order to incorporate the time dependency of the data,
Dynamask studies the effects of dynamic perturbation operators. In order to
tackle the large number of inputs, we propose a scheme to make the feature
selection parsimonious (to select no more feature than necessary) and legible
(a notion that we detail by making a parallel with information theory). With
synthetic and real-world data, we demonstrate that the dynamic underpinning of
Dynamask, together with its parsimony, offer a neat improvement in the
identification of feature importance over time. The modularity of Dynamask
makes it ideal as a plug-in to increase the transparency of a wide range of
machine learning models in areas such as medicine and finance, where time
series are abundant.",http://arxiv.org/pdf/2106.05303v1,cs.LG
2021-06-08 07:32:12+00:00,RECOWNs: Probabilistic Circuits for Trustworthy Time Series Forecasting,"['Nils Thoma', 'Zhongjie Yu', 'Fabrizio Ventola', 'Kristian Kersting']","Time series forecasting is a relevant task that is performed in several
real-world scenarios such as product sales analysis and prediction of energy
demand. Given their accuracy performance, currently, Recurrent Neural Networks
(RNNs) are the models of choice for this task. Despite their success in time
series forecasting, less attention has been paid to make the RNNs trustworthy.
For example, RNNs can not naturally provide an uncertainty measure to their
predictions. This could be extremely useful in practice in several cases e.g.
to detect when a prediction might be completely wrong due to an unusual pattern
in the time series. Whittle Sum-Product Networks (WSPNs), prominent deep
tractable probabilistic circuits (PCs) for time series, can assist an RNN with
providing meaningful probabilities as uncertainty measure. With this aim, we
propose RECOWN, a novel architecture that employs RNNs and a discriminant
variant of WSPNs called Conditional WSPNs (CWSPNs). We also formulate a
Log-Likelihood Ratio Score as better estimation of uncertainty that is tailored
to time series and Whittle likelihoods. In our experiments, we show that
RECOWNs are accurate and trustworthy time series predictors, able to ""know when
they do not know"".",http://arxiv.org/pdf/2106.04148v2,cs.LG
2021-06-07 11:46:29+00:00,Modeling Nonstationary Time Series using Locally Stationary Basis Processes,"['Shreyan Ganguly', 'Peter F. Craigmile']","Methods of estimation and forecasting for stationary models are well known in
classical time series analysis. However, stationarity is an idealization which,
in practice, can at best hold as an approximation, but for many time series may
be an unrealistic assumption. We define a class of locally stationary processes
which can lead to more accurate uncertainty quantification over making an
invalid assumption of stationarity. This class of processes assumes the model
parameters to be time-varying and parameterizes them in terms of a
transformation of basis functions that ensures that the processes are locally
stationary. We develop methods and theory for parameter estimation in this
class of models, and propose a test that allow us to examine certain departures
from stationarity. We assess our methods using simulation studies and apply
these techniques to the analysis of an electroencephalogram time series.",http://arxiv.org/pdf/2106.03533v1,stat.ME
2021-06-06 03:46:49+00:00,Context-tree weighting for real-valued time series: Bayesian inference with hierarchical mixture models,"['Ioannis Papageorgiou', 'Ioannis Kontoyiannis']","Real-valued time series are ubiquitous in the sciences and engineering. In
this work, a general, hierarchical Bayesian modelling framework is developed
for building mixture models for times series. This development is based, in
part, on the use of context trees, and it includes a collection of effective
algorithmic tools for learning and inference. A discrete context (or 'state')
is extracted for each sample, consisting of a discretised version of some of
the most recent observations preceding it. The set of all relevant contexts are
represented as a discrete context-tree. At the bottom level, a different
real-valued time series model is associated with each context-state, i.e., with
each leaf of the tree. This defines a very general framework that can be used
in conjunction with any existing model class to build flexible and
interpretable mixture models. Extending the idea of context-tree weighting
leads to algorithms that allow for efficient, exact Bayesian inference in this
setting. The utility of the general framework is illustrated in detail when
autoregressive (AR) models are used at the bottom level, resulting in a
nonlinear AR mixture model. The associated methods are found to outperform
several state-of-the-art techniques on simulated and real-world experiments.",http://arxiv.org/pdf/2106.03023v4,stat.ME
2021-06-03 23:41:11+00:00,Deep Probabilistic Time Series Forecasting using Augmented Recurrent Input for Dynamic Systems,"['Haitao Liu', 'Changjun Liu', 'Xiaomo Jiang', 'Xudong Chen', 'Shuhua Yang', 'Xiaofang Wang']","The demand of probabilistic time series forecasting has been recently raised
in various dynamic system scenarios, for example, system identification and
prognostic and health management of machines. To this end, we combine the
advances in both deep generative models and state space model (SSM) to come up
with a novel, data-driven deep probabilistic sequence model. Specifically, we
follow the popular encoder-decoder generative structure to build the recurrent
neural networks (RNN) assisted variational sequence model on an augmented
recurrent input space, which could induce rich stochastic sequence dependency.
Besides, in order to alleviate the inconsistency issue of the posterior between
training and predicting as well as improving the mining of dynamic patterns, we
(i) propose using a lagged hybrid output as input for the posterior at next
time step, which brings training and predicting into alignment; and (ii)
further devise a generalized auto-regressive strategy that encodes all the
historical dependencies for the posterior. Thereafter, we first investigate the
methodological characteristics of the proposed deep probabilistic sequence
model on toy cases, and then comprehensively demonstrate the superiority of our
model against existing deep probabilistic SSM models through extensive
numerical experiments on eight system identification benchmarks from various
dynamic systems. Finally, we apply our sequence model to a real-world
centrifugal compressor forecasting problem, and again verify its outstanding
performance by quantifying the time series predictive distribution.",http://arxiv.org/pdf/2106.05848v2,cs.LG
2021-06-03 17:56:24+00:00,Change-Point Analysis of Time Series with Evolutionary Spectra,"['Alessandro Casini', 'Pierre Perron']","This paper develops change-point methods for the spectrum of a locally
stationary time series. We focus on series with a bounded spectral density that
change smoothly under the null hypothesis but exhibits change-points or becomes
less smooth under the alternative. We address two local problems. The first is
the detection of discontinuities (or breaks) in the spectrum at unknown dates
and frequencies. The second involves abrupt yet continuous changes in the
spectrum over a short time period at an unknown frequency without signifying a
break. Both problems can be cast into changes in the degree of smoothness of
the spectral density over time. We consider estimation and minimax-optimal
testing. We determine the optimal rate for the minimax distinguishable
boundary, i.e., the minimum break magnitude such that we are able to uniformly
control type I and type II errors. We propose a novel procedure for the
estimation of the change-points based on a wild sequential top-down algorithm
and show its consistency under shrinking shifts and possibly growing number of
change-points. Our method can be used across many fields and a companion
program is made available in popular software packages.",http://arxiv.org/pdf/2106.02031v2,math.ST
2021-06-02 13:40:28+00:00,Feature Extraction for Functional Time Series: Theory and Application to NIR Spectroscopy Data,"['Yang Yang', 'Yanrong Yang', 'Han Lin Shang']","We propose a novel method to extract global and local features of functional
time series. The global features concerning the dominant modes of variation
over the entire function domain, and local features of function variations over
particular short intervals within function domain, are both important in
functional data analysis. Functional principal component analysis (FPCA),
though a key feature extraction tool, only focus on capturing the dominant
global features, neglecting highly localized features. We introduce a FPCA-BTW
method that initially extracts global features of functional data via FPCA, and
then extracts local features by block thresholding of wavelet (BTW)
coefficients. Using Monte Carlo simulations, along with an empirical
application on near-infrared spectroscopy data of wood panels, we illustrate
that the proposed method outperforms competing methods including FPCA and
sparse FPCA in the estimation functional processes. Moreover, extracted local
features inheriting serial dependence of the original functional time series
contribute to more accurate forecasts. Finally, we develop asymptotic
properties of FPCA-BTW estimators, discovering the interaction between
convergence rates of global and local features.",http://arxiv.org/pdf/2106.01150v1,stat.ME
2021-06-01 19:53:24+00:00,Unsupervised Representation Learning for Time Series with Temporal Neighborhood Coding,"['Sana Tonekaboni', 'Danny Eytan', 'Anna Goldenberg']","Time series are often complex and rich in information but sparsely labeled
and therefore challenging to model. In this paper, we propose a self-supervised
framework for learning generalizable representations for non-stationary time
series. Our approach, called Temporal Neighborhood Coding (TNC), takes
advantage of the local smoothness of a signal's generative process to define
neighborhoods in time with stationary properties. Using a debiased contrastive
objective, our framework learns time series representations by ensuring that in
the encoding space, the distribution of signals from within a neighborhood is
distinguishable from the distribution of non-neighboring signals. Our
motivation stems from the medical field, where the ability to model the dynamic
nature of time series data is especially valuable for identifying, tracking,
and predicting the underlying patients' latent states in settings where
labeling data is practically impossible. We compare our method to recently
developed unsupervised representation learning approaches and demonstrate
superior performance on clustering and classification tasks for multiple
datasets.",http://arxiv.org/pdf/2106.00750v1,cs.LG
2021-05-31 10:59:11+00:00,"Fast, Accurate and Interpretable Time Series Classification Through Randomization","['Nestor Cabello', 'Elham Naghizade', 'Jianzhong Qi', 'Lars Kulik']","Time series classification (TSC) aims to predict the class label of a given
time series, which is critical to a rich set of application areas such as
economics and medicine. State-of-the-art TSC methods have mostly focused on
classification accuracy and efficiency, without considering the
interpretability of their classifications, which is an important property
required by modern applications such as appliance modeling and legislation such
as the European General Data Protection Regulation. To address this gap, we
propose a novel TSC method - the Randomized-Supervised Time Series Forest
(r-STSF). r-STSF is highly efficient, achieves state-of-the-art classification
accuracy and enables interpretability. r-STSF takes an efficient interval-based
approach to classify time series according to aggregate values of
discriminatory sub-series (intervals). To achieve state-of-the-art accuracy,
r-STSF builds an ensemble of randomized trees using the discriminatory
sub-series. It uses four time series representations, nine aggregation
functions and a supervised binary-inspired search combined with a feature
ranking metric to identify highly discriminatory sub-series. The discriminatory
sub-series enable interpretable classifications. Experiments on extensive
datasets show that r-STSF achieves state-of-the-art accuracy while being orders
of magnitude faster than most existing TSC methods. It is the only classifier
from the state-of-the-art group that enables interpretability. Our findings
also highlight that r-STSF is the best TSC method when classifying complex time
series datasets.",http://arxiv.org/pdf/2105.14876v1,cs.LG
2021-05-28 13:50:33+00:00,Epidemic change-point detection in general causal time series,"['Mamadou Lamine Diop', 'William Kengne']","We consider an epidemic change-point detection in a large class of causal
time series models, including among other processes, AR($\infty$),
ARCH($\infty$), TARCH($\infty$), ARMA-GARCH. A test statistic based on the
Gaussian quasi-maximum likelihood estimator of the parameter is proposed. It is
shown that, under the null hypothesis of no change, the test statistic
converges to a distribution obtained from a difference of two Brownian bridge
and diverges to infinity under the epidemic alternative. Numerical results for
simulation and real data example are provided.",http://arxiv.org/pdf/2105.13836v1,math.ST
2021-05-28 07:05:22+00:00,Simultaneous predictive bands for functional time series using minimum entropy sets,"['Nicolás Hernández', 'Jairo Cugliari', 'Julien Jacques']","Functional Time Series are sequences of dependent random elements taking
values on some functional space. Most of the research on this domain is focused
on producing a predictor able to forecast the value of the next function having
observed a part of the sequence. For this, the Autoregresive Hilbertian process
is a suitable framework. We address here the problem of constructing
simultaneous predictive confidence bands for a stationary functional time
series. The method is based on an entropy measure for stochastic processes, in
particular functional time series. To construct predictive bands we use a
functional bootstrap procedure that allow us to estimate the prediction law
through the use of pseudo-predictions. Each pseudo-realisation is then
projected into a space of finite dimension, associated to a functional basis.
We use Reproducing Kernel Hilbert Spaces (RKHS) to represent the functions,
considering then the basis associated to the reproducing kernel. Using a simple
decision rule, we classify the points on the projected space among those
belonging to the minimum entropy set and those that do not. We push back the
minimum entropy set to the functional space and construct a band using the
regularity property of the RKHS. The proposed methodology is illustrated
through artificial and real-world data sets.",http://arxiv.org/pdf/2105.13627v3,stat.ME
2021-05-26 20:15:40+00:00,Anomaly Detection in Predictive Maintenance: A New Evaluation Framework for Temporal Unsupervised Anomaly Detection Algorithms,"['Jacinto Carrasco', 'Irina Markova', 'David López', 'Ignacio Aguilera', 'Diego García', 'Marta García-Barzana', 'Manuel Arias-Rodil', 'Julián Luengo', 'Francisco Herrera']","The research in anomaly detection lacks a unified definition of what
represents an anomalous instance. Discrepancies in the nature itself of an
anomaly lead to multiple paradigms of algorithms design and experimentation.
Predictive maintenance is a special case, where the anomaly represents a
failure that must be prevented. Related time-series research as outlier and
novelty detection or time-series classification does not apply to the concept
of an anomaly in this field, because they are not single points which have not
been seen previously and may not be precisely annotated. Moreover, due to the
lack of annotated anomalous data, many benchmarks are adapted from supervised
scenarios.
  To address these issues, we generalise the concept of positive and negative
instances to intervals to be able to evaluate unsupervised anomaly detection
algorithms. We also preserve the imbalance scheme for evaluation through the
proposal of the Preceding Window ROC, a generalisation for the calculation of
ROC curves for time-series scenarios. We also adapt the mechanism from a
established time-series anomaly detection benchmark to the proposed
generalisations to reward early detection. Therefore, the proposal represents a
flexible evaluation framework for the different scenarios. To show the
usefulness of this definition, we include a case study of Big Data algorithms
with a real-world time-series problem provided by the company ArcelorMittal,
and compare the proposal with an evaluation method.",http://arxiv.org/pdf/2105.12818v2,cs.LG
2021-05-25 12:18:41+00:00,On the estimation of locally stationary functional time series,['Daisuke Kurisu'],"This study develops an asymptotic theory for estimating the time-varying
characteristics of locally stationary functional time series (LSFTS). We
investigate a kernel-based method to estimate the time-varying covariance
operator and the time-varying mean function of an LSFTS. In particular, we
derive the convergence rate of the kernel estimator of the covariance operator
and associated eigenvalue and eigenfunctions and establish a central limit
theorem for the kernel-based locally weighted sample mean. As applications of
our results, we discuss methods for testing the equality of time-varying mean
functions in two functional samples.",http://arxiv.org/pdf/2105.11873v7,math.ST
2021-05-24 15:37:54+00:00,Change Point Detection in Nonstationary Sub-Hourly Wind Time Series,"['Sakitha Ariyarathne', 'Harsha Gangammanavar', 'Raanju R. Sundararajan']","In this paper, we present a change point detection method for detecting
change points in multivariate nonstationary wind speed time series. The change
point method identifies changes in the covariance structure and decomposes the
nonstationary multivariate time series into stationary segments. We also
present parametric and nonparametric simulation techniques to simulate new wind
time series within each stationary segment. The proposed simulation methods
retain statistical properties of the original time series and therefore, can be
employed for simulation-based analysis of power systems planning and operations
problems. We demonstrate the capabilities of the change point detection method
through computational experiments conducted on wind speed time series at
five-minute resolution. We also conduct experiments on the economic dispatch
problem to illustrate the impact of nonstationarity in wind generation on
conventional generation and location marginal prices.",http://arxiv.org/pdf/2105.11353v1,stat.ME
2021-05-20 14:56:30+00:00,Monte Carlo Filtering Objectives: A New Family of Variational Objectives to Learn Generative Model and Neural Adaptive Proposal for Time Series,"['Shuangshuang Chen', 'Sihao Ding', 'Yiannis Karayiannidis', 'Mårten Björkman']","Learning generative models and inferring latent trajectories have shown to be
challenging for time series due to the intractable marginal likelihoods of
flexible generative models. It can be addressed by surrogate objectives for
optimization. We propose Monte Carlo filtering objectives (MCFOs), a family of
variational objectives for jointly learning parametric generative models and
amortized adaptive importance proposals of time series. MCFOs extend the
choices of likelihood estimators beyond Sequential Monte Carlo in
state-of-the-art objectives, possess important properties revealing the factors
for the tightness of objectives, and allow for less biased and variant gradient
estimates. We demonstrate that the proposed MCFOs and gradient estimations lead
to efficient and stable model learning, and learned generative models well
explain data and importance proposals are more sample efficient on various
kinds of time series data.",http://arxiv.org/pdf/2105.09801v1,cs.LG
2021-05-18 09:50:00+00:00,StackVAE-G: An efficient and interpretable model for time series anomaly detection,"['Wenkai Li', 'Wenbo Hu', 'Ting Chen', 'Ning Chen', 'Cheng Feng']","Recent studies have shown that autoencoder-based models can achieve superior
performance on anomaly detection tasks due to their excellent ability to fit
complex data in an unsupervised manner. In this work, we propose a novel
autoencoder-based model, named StackVAE-G that can significantly bring the
efficiency and interpretability to multivariate time series anomaly detection.
Specifically, we utilize the similarities across the time series channels by
the stacking block-wise reconstruction with a weight-sharing scheme to reduce
the size of learned models and also relieve the overfitting to unknown noises
in the training data. We also leverage a graph learning module to learn a
sparse adjacency matrix to explicitly capture the stable interrelation
structure among multiple time series channels for the interpretable pattern
reconstruction of interrelated channels. Combining these two modules, we
introduce the stacking block-wise VAE (variational autoencoder) with GNN (graph
neural network) model for multivariate time series anomaly detection. We
conduct extensive experiments on three commonly used public datasets, showing
that our model achieves comparable (even better) performance with the
state-of-the-art modelsand meanwhile requires much less computation and memory
cost. Furthermore, we demonstrate that the adjacency matrix learned by our
model accurately captures the interrelation among multiple channels, and can
provide valuable information for failure diagnosis applications.",http://arxiv.org/pdf/2105.08397v2,cs.LG
2021-05-17 22:47:19+00:00,Distribution-free changepoint detection tests based on the breaking of records,['Jorge Castillo-Mateo'],"The analysis of record-breaking events is of interest in fields such as
climatology, hydrology or anthropology. In connection with the record
occurrence, we propose three distribution-free statistics for the changepoint
detection problem. They are CUSUM-type statistics based on the upper and/or
lower record indicators observed in a series. Using a version of the functional
central limit theorem, we show that the CUSUM-type statistics are
asymptotically Kolmogorov distributed. The main results under the null
hypothesis are based on series of independent and identically distributed
random variables, but a statistic to deal with series with seasonal component
and serial correlation is also proposed. A Monte Carlo study of size, power and
changepoint estimate has been performed. Finally, the methods are illustrated
by analyzing the time series of temperatures at Madrid, Spain.
  The R package $\texttt{RecordTest}$ publicly available on CRAN implements the
proposed methods.",http://arxiv.org/pdf/2105.08186v2,stat.ME
2021-05-17 22:02:24+00:00,Learning Disentangled Representations for Time Series,"['Yuening Li', 'Zhengzhang Chen', 'Daochen Zha', 'Mengnan Du', 'Denghui Zhang', 'Haifeng Chen', 'Xia Hu']","Time-series representation learning is a fundamental task for time-series
analysis. While significant progress has been made to achieve accurate
representations for downstream applications, the learned representations often
lack interpretability and do not expose semantic meanings. Different from
previous efforts on the entangled feature space, we aim to extract the
semantic-rich temporal correlations in the latent interpretable factorized
representation of the data. Motivated by the success of disentangled
representation learning in computer vision, we study the possibility of
learning semantic-rich time-series representations, which remains unexplored
due to three main challenges: 1) sequential data structure introduces complex
temporal correlations and makes the latent representations hard to interpret,
2) sequential models suffer from KL vanishing problem, and 3) interpretable
semantic concepts for time-series often rely on multiple factors instead of
individuals. To bridge the gap, we propose Disentangle Time Series (DTS), a
novel disentanglement enhancement framework for sequential data. Specifically,
to generate hierarchical semantic concepts as the interpretable and
disentangled representation of time-series, DTS introduces multi-level
disentanglement strategies by covering both individual latent factors and group
semantic segments. We further theoretically show how to alleviate the KL
vanishing problem: DTS introduces a mutual information maximization term, while
preserving a heavier penalty on the total correlation and the dimension-wise KL
to keep the disentanglement property. Experimental results on various
real-world benchmark datasets demonstrate that the representations learned by
DTS achieve superior performance in downstream applications, with high
interpretability of semantic concepts.",http://arxiv.org/pdf/2105.08179v2,cs.LG
2021-05-17 05:13:53+00:00,Nonparametric regression for locally stationary functional time series,['Daisuke Kurisu'],"In this study, we develop an asymptotic theory of nonparametric regression
for a locally stationary functional time series. First, we introduce the notion
of a locally stationary functional time series (LSFTS) that takes values in a
semi-metric space. Then, we propose a nonparametric model for LSFTS with a
regression function that changes smoothly over time. We establish the uniform
convergence rates of a class of kernel estimators, the Nadaraya-Watson (NW)
estimator of the regression function, and a central limit theorem of the NW
estimator.",http://arxiv.org/pdf/2105.07613v8,math.ST
2021-05-16 22:23:23+00:00,Towards Synthetic Multivariate Time Series Generation for Flare Forecasting,"['Yang Chen', 'Dustin J. Kempton', 'Azim Ahmadzadeh', 'Rafal A. Angryk']","One of the limiting factors in training data-driven, rare-event prediction
algorithms is the scarcity of the events of interest resulting in an extreme
imbalance in the data. There have been many methods introduced in the
literature for overcoming this issue; simple data manipulation through
undersampling and oversampling, utilizing cost-sensitive learning algorithms,
or by generating synthetic data points following the distribution of the
existing data. While synthetic data generation has recently received a great
deal of attention, there are real challenges involved in doing so for
high-dimensional data such as multivariate time series. In this study, we
explore the usefulness of the conditional generative adversarial network (CGAN)
as a means to perform data-informed oversampling in order to balance a large
dataset of multivariate time series. We utilize a flare forecasting benchmark
dataset, named SWAN-SF, and design two verification methods to both
quantitatively and qualitatively evaluate the similarity between the generated
minority and the ground-truth samples. We further assess the quality of the
generated samples by training a classical, supervised machine learning
algorithm on synthetic data, and testing the trained model on the unseen, real
data. The results show that the classifier trained on the data augmented with
the synthetic multivariate time series achieves a significant improvement
compared with the case where no augmentation is used. The popular flare
forecasting evaluation metrics, TSS and HSS, report 20-fold and 5-fold
improvements, respectively, indicating the remarkable statistical similarities,
and the usefulness of CGAN-based data generation for complicated tasks such as
flare forecasting.",http://arxiv.org/pdf/2105.07532v1,cs.LG
2021-05-14 10:34:14+00:00,Long Short-term Memory RNN,"['Christian Bakke Vennerød', 'Adrian Kjærran', 'Erling Stray Bugge']","This paper is based on a machine learning project at the Norwegian University
of Science and Technology, fall 2020. The project was initiated with a
literature review on the latest developments within time-series forecasting
methods in the scientific community over the past five years. The paper
summarizes the essential aspects of this research. Furthermore, in this paper,
we introduce an LSTM cell's architecture, and explain how different components
go together to alter the cell's memory and predict the output. Also, the paper
provides the necessary formulas and foundations to calculate a forward
iteration through an LSTM. Then, the paper refers to some practical
applications and research that emphasize the strength and weaknesses of LSTMs,
shown within the time-series domain and the natural language processing (NLP)
domain. Finally, alternative statistical methods for time series predictions
are highlighted, where the paper outline ARIMA and exponential smoothing.
Nevertheless, as LSTMs can be viewed as a complex architecture, the paper
assumes that the reader has some knowledge of essential machine learning
aspects, such as the multi-layer perceptron, activation functions, overfitting,
backpropagation, bias, over- and underfitting, and more.",http://arxiv.org/pdf/2105.06756v1,cs.LG
2021-05-14 04:49:58+00:00,Monash Time Series Forecasting Archive,"['Rakshitha Godahewa', 'Christoph Bergmeir', 'Geoffrey I. Webb', 'Rob J. Hyndman', 'Pablo Montero-Manso']","Many businesses and industries nowadays rely on large quantities of time
series data making time series forecasting an important research area. Global
forecasting models that are trained across sets of time series have shown a
huge potential in providing accurate forecasts compared with the traditional
univariate forecasting models that work on isolated series. However, there are
currently no comprehensive time series archives for forecasting that contain
datasets of time series from similar sources available for the research
community to evaluate the performance of new global forecasting algorithms over
a wide variety of datasets. In this paper, we present such a comprehensive time
series forecasting archive containing 20 publicly available time series
datasets from varied domains, with different characteristics in terms of
frequency, series lengths, and inclusion of missing values. We also
characterise the datasets, and identify similarities and differences among
them, by conducting a feature analysis. Furthermore, we present the performance
of a set of standard baseline forecasting methods over all datasets across
eight error metrics, for the benefit of researchers using the archive to
benchmark their forecasting algorithms.",http://arxiv.org/pdf/2105.06643v1,cs.LG
2021-05-12 09:19:13+00:00,Generalized Autoregressive Moving Average Models with GARCH Errors,"['Tingguo Zheng', 'Han Xiao', 'Rong Chen']","One of the important and widely used classes of models for non-Gaussian time
series is the generalized autoregressive model average models (GARMA), which
specifies an ARMA structure for the conditional mean process of the underlying
time series. However, in many applications one often encounters conditional
heteroskedasticity. In this paper we propose a new class of models, referred to
as GARMA-GARCH models, that jointly specify both the conditional mean and
conditional variance processes of a general non-Gaussian time series. Under the
general modeling framework, we propose three specific models, as examples, for
proportional time series, nonnegative time series, and skewed and heavy-tailed
financial time series. Maximum likelihood estimator (MLE) and quasi Gaussian
MLE (GMLE) are used to estimate the parameters. Simulation studies and three
applications are used to demonstrate the properties of the models and the
estimation procedures.",http://arxiv.org/pdf/2105.05532v1,stat.ME
2021-05-12 05:40:27+00:00,Autoregressive Optimal Transport Models,"['Changbo Zhu', 'Hans-Georg Müller']","Series of univariate distributions indexed by equally spaced time points are
ubiquitous in applications and their analysis constitutes one of the challenges
of the emerging field of distributional data analysis. To quantify such
distributional time series, we propose a class of intrinsic autoregressive
models that operate in the space of optimal transport maps. The autoregressive
transport models that we introduce here are based on regressing optimal
transport maps on each other, where predictors can be transport maps from an
overall barycenter to a current distribution or transport maps between past
consecutive distributions of the distributional time series. Autoregressive
transport models and their associated distributional regression models specify
the link between predictor and response transport maps by moving along
geodesics in Wasserstein space. These models emerge as natural extensions of
the classical autoregressive models in Euclidean space. Unique stationary
solutions of autoregressive transport models are shown to exist under a
geometric moment contraction condition of Wu and Shao (2004), using properties
of iterated random functions. We also discuss an extension to a varying
coefficient model for first order autoregressive transport models. In addition
to simulations, the proposed models are illustrated with distributional time
series of house prices across U.S. counties and annual summer temperature
distributions.",http://arxiv.org/pdf/2105.05439v4,stat.ME
2021-05-11 21:00:13+00:00,An Encoding Approach for Stable Change Point Detection,"['Xiaodong Wang', 'Fushing Hsieh']","Without imposing prior distributional knowledge underlying multivariate time
series of interest, we propose a nonparametric change-point detection approach
to estimate the number of change points and their locations along the temporal
axis. We develop a structural subsampling procedure such that the observations
are encoded into multiple sequences of Bernoulli variables. A maximum
likelihood approach in conjunction with a newly developed searching algorithm
is implemented to detect change points on each Bernoulli process separately.
Then, aggregation statistics are proposed to collectively synthesize
change-point results from all individual univariate time series into consistent
and stable location estimations. We also study a weighting strategy to measure
the degree of relevance for different subsampled groups. Simulation studies are
conducted and shown that the proposed change-point methodology for multivariate
time series has favorable performance comparing with currently popular
nonparametric methods under various settings with different degrees of
complexity. Real data analyses are finally performed on categorical, ordinal,
and continuous time series taken from fields of genetics, climate, and finance.",http://arxiv.org/pdf/2105.05341v1,stat.ME
2021-05-10 14:24:38+00:00,On projection methods for functional time series forecasting,"['Antonio Elías', 'Raúl Jiménez', 'Hanlin Shang']","Two nonparametric methods are presented for forecasting functional time
series (FTS). The FTS we observe is a curve at a discrete-time point. We
address both one-step-ahead forecasting and dynamic updating. Dynamic updating
is a forward prediction of the unobserved segment of the most recent curve.
Among the two proposed methods, the first one is a straightforward adaptation
to FTS of the $k$-nearest neighbors methods for univariate time series
forecasting. The second one is based on a selection of curves, termed \emph{the
curve envelope}, that aims to be representative in shape and magnitude of the
most recent functional observation, either a whole curve or the observed part
of a partially observed curve. In a similar fashion to $k$-nearest neighbors
and other projection methods successfully used for time series forecasting, we
``project'' the $k$-nearest neighbors and the curves in the envelope for
forecasting. In doing so, we keep track of the next period evolution of the
curves. The methods are applied to simulated data, daily electricity demand,
and NOx emissions and provide competitive results with and often superior to
several benchmark predictions. The approach offers a model-free alternative to
statistical methods based on FTS modeling to study the cyclic or seasonal
behavior of many FTS.",http://arxiv.org/pdf/2105.04399v1,stat.ME
2021-05-10 04:01:04+00:00,Z-GCNETs: Time Zigzags at Graph Convolutional Networks for Time Series Forecasting,"['Yuzhou Chen', 'Ignacio Segovia-Dominguez', 'Yulia R. Gel']","There recently has been a surge of interest in developing a new class of deep
learning (DL) architectures that integrate an explicit time dimension as a
fundamental building block of learning and representation mechanisms. In turn,
many recent results show that topological descriptors of the observed data,
encoding information on the shape of the dataset in a topological space at
different scales, that is, persistent homology of the data, may contain
important complementary information, improving both performance and robustness
of DL. As convergence of these two emerging ideas, we propose to enhance DL
architectures with the most salient time-conditioned topological information of
the data and introduce the concept of zigzag persistence into time-aware graph
convolutional networks (GCNs). Zigzag persistence provides a systematic and
mathematically rigorous framework to track the most important topological
features of the observed data that tend to manifest themselves over time. To
integrate the extracted time-conditioned topological descriptors into DL, we
develop a new topological summary, zigzag persistence image, and derive its
theoretical stability guarantees. We validate the new GCNs with a time-aware
zigzag topological layer (Z-GCNETs), in application to traffic forecasting and
Ethereum blockchain price prediction. Our results indicate that Z-GCNET
outperforms 13 state-of-the-art methods on 4 time series datasets.",http://arxiv.org/pdf/2105.04100v1,cs.LG
2021-05-09 05:27:42+00:00,The Temporal Dictionary Ensemble (TDE) Classifier for Time Series Classification,"['Matthew Middlehurst', 'James Large', 'Gavin Cawley', 'Anthony Bagnall']","Using bag of words representations of time series is a popular approach to
time series classification. These algorithms involve approximating and
discretising windows over a series to form words, then forming a count of words
over a given dictionary. Classifiers are constructed on the resulting
histograms of word counts. A 2017 evaluation of a range of time series
classifiers found the bag of symbolic-fourier approximation symbols (BOSS)
ensemble the best of the dictionary based classifiers. It forms one of the
components of hierarchical vote collective of transformation-based ensembles
(HIVE-COTE), which represents the current state of the art. Since then, several
new dictionary based algorithms have been proposed that are more accurate or
more scalable (or both) than BOSS. We propose a further extension of these
dictionary based classifiers that combines the best elements of the others
combined with a novel approach to constructing ensemble members based on an
adaptive Gaussian process model of the parameter space. We demonstrate that the
temporal dictionary ensemble (TDE) is more accurate than other dictionary based
approaches. Furthermore, unlike the other classifiers, if we replace BOSS in
HIVE-COTE with TDE, HIVE-COTE is significantly more accurate. We also show this
new version of HIVE-COTE is significantly more accurate than the current best
deep learning approach, a recently proposed hybrid tree ensemble and a recently
introduced competitive classifier making use of highly randomised convolutional
kernels. This advance represents a new state of the art for time series
classification.",http://arxiv.org/pdf/2105.03841v1,cs.LG
2021-05-07 21:13:42+00:00,Cross-Population Amplitude Coupling in High-Dimensional Oscillatory Neural Time Series,"['Heejong Bong', 'Valérie Ventura', 'Eric A. Yttri', 'Matthew A. Smith', 'Robert E. Kass']","An important outstanding problem in analysis of neural data is to
characterize interactions across brain regions from high-dimensional
multiple-electrode recordings during a behavioral experiment. A leading theory,
based on a considerable body of research, is that oscillations represent
coordinated activity across populations of neurons. We sought to quantify
time-varying covariation of oscillatory amplitudes across two brain regions,
during a memory task, based on neural potentials recorded from 96 electrodes in
each region. We extended probabilistic Canonical Correlation Analysis (CCA) to
the time series setting, which provides a new interpretation of multiset CCA
based on cross-correlation of latent time series. Because the latent time
series covariance matrix is high-dimensional, we assumed sparsity of partial
correlations within a range of possible interesting time series lead-lag
effects to derive procedures for estimation and inference. We found the
resulting methodology to perform well in realistic settings, and we applied it
to data recorded from prefrontal cortex and visual area V4 to produce results
that are highly plausible based on existing literature.",http://arxiv.org/pdf/2105.03508v2,stat.ME
2021-05-07 15:33:49+00:00,Finite volume method network for acceleration of unsteady computational fluid dynamics: non-reacting and reacting flows,"['Joongoo Jeon', 'Juhyeong Lee', 'Sung Joong Kim']","Despite rapid improvements in the performance of central processing unit
(CPU), the calculation cost of simulating chemically reacting flow using CFD
remains infeasible in many cases. The application of the convolutional neural
networks (CNNs) specialized in image processing in flow field prediction has
been studied, but the need to develop a neural netweork design fitted for CFD
is recently emerged. In this study, a neural network model introducing the
finite volume method (FVM) with a unique network architecture and
physics-informed loss function was developed to accelerate CFD simulations. The
developed network model, considering the nature of the CFD flow field where the
identical governing equations are applied to all grids, can predict the future
fields with only two previous fields unlike the CNNs requiring many field
images (>10,000). The performance of this baseline model was evaluated using
CFD time series data from non-reacting flow and reacting flow simulation;
counterflow and hydrogen flame with 20 detailed chemistries. Consequently, we
demonstrated that (1) the FVM-based network architecture provided improved
accuracy of multistep time series prediction compared to the previous MLP model
(2) the physic-informed loss function prevented non-physical overfitting
problem and ultimately reduced the error in time series prediction (3)
observing the calculated residuals in an unsupervised manner could indirectly
estimate the network accuracy. Additionally, under the reacting flow dataset,
the computational speed of this network model was measured to be about 10 times
faster than that of the CFD solver.",http://arxiv.org/pdf/2105.03332v2,cs.LG
2021-05-05 17:37:18+00:00,Granger Causality: A Review and Recent Advances,"['Ali Shojaie', 'Emily B. Fox']","Introduced more than a half century ago, Granger causality has become a
popular tool for analyzing time series data in many application domains, from
economics and finance to genomics and neuroscience. Despite this popularity,
the validity of this notion for inferring causal relationships among time
series has remained the topic of continuous debate. Moreover, while the
original definition was general, limitations in computational tools have
primarily limited the applications of Granger causality to simple bivariate
vector auto-regressive processes or pairwise relationships among a set of
variables. Starting with a review of early developments and debates, this paper
discusses recent advances that address various shortcomings of the earlier
approaches, from models for high-dimensional time series to more recent
developments that account for nonlinear and non-Gaussian observations and allow
for sub-sampled and mixed frequency time series.",http://arxiv.org/pdf/2105.02675v2,stat.ME
2021-05-04 10:36:29+00:00,TimeGym: Debugging for Time Series Modeling in Python,['Diogo Seca'],"We introduce the TimeGym Forecasting Debugging Toolkit, a Python library for
testing and debugging time series forecasting pipelines. TimeGym simplifies the
testing forecasting pipeline by providing generic tests for forecasting
pipelines fresh out of the box. These tests are based on common modeling
challenges of time series. Our library enables forecasters to apply a
Test-Driven Development approach to forecast modeling, using specified oracles
to generate artificial data with noise.",http://arxiv.org/pdf/2105.01404v1,cs.LG
2021-05-03 22:40:05+00:00,All-Clear Flare Prediction Using Interval-based Time Series Classifiers,"['Anli Ji', 'Berkay Aydin', 'Manolis K. Georgoulis', 'Rafal Angryk']","An all-clear flare prediction is a type of solar flare forecasting that puts
more emphasis on predicting non-flaring instances (often relatively small
flares and flare quiet regions) with high precision while still maintaining
valuable predictive results. While many flare prediction studies do not address
this problem directly, all-clear predictions can be useful in operational
context. However, in all-clear predictions, finding the right balance between
avoiding false negatives (misses) and reducing the false positives (false
alarms) is often challenging. Our study focuses on training and testing a set
of interval-based time series classifiers named Time Series Forest (TSF). These
classifiers will be used towards building an all-clear flare prediction system
by utilizing multivariate time series data. Throughout this paper, we
demonstrate our data collection, predictive model building and evaluation
processes, and compare our time series classification models with baselines
using our benchmark datasets. Our results show that time series classifiers
provide better forecasting results in terms of skill scores, precision and
recall metrics, and they can be further improved for more precise all-clear
forecasts by tuning model hyperparameters.",http://arxiv.org/pdf/2105.01202v1,cs.LG
2021-05-03 10:13:42+00:00,Ordinal Pattern Dependence in the Context of Long-Range Dependence,"['Ines Nüßgen', 'Alexander Schnurr']","Ordinal pattern dependence is a multivariate dependence measure based on the
co-movement of two time series. In strong connection to ordinal time series
analysis, the ordinal information is taken into account to derive robust
results on the dependence between the two processes. This article deals with
ordinal pattern dependence for long-range dependent time series including mixed
cases of short- and long-range dependence. We investigate the limit
distributions for estimators of ordinal pattern dependence. In doing so we
point out the differences that arise for the underlying time series having
different dependence structures. Depending on these assumptions, central and
non-central limit theorems are proven. The limit distributions for the latter
ones can be included in the class of multivariate Rosenblatt processes.
Finally, a simulation study is provided to illustrate our theoretical findings.",http://arxiv.org/pdf/2105.00724v1,math.ST
2021-05-02 08:00:46+00:00,TE-ESN: Time Encoding Echo State Network for Prediction Based on Irregularly Sampled Time Series Data,"['Chenxi Sun', 'Shenda Hong', 'Moxian Song', 'Yanxiu Zhou', 'Yongyue Sun', 'Derun Cai', 'Hongyan Li']","Prediction based on Irregularly Sampled Time Series (ISTS) is of wide concern
in the real-world applications. For more accurate prediction, the methods had
better grasp more data characteristics. Different from ordinary time series,
ISTS is characterised with irregular time intervals of intra-series and
different sampling rates of inter-series. However, existing methods have
suboptimal predictions due to artificially introducing new dependencies in a
time series and biasedly learning relations among time series when modeling
these two characteristics. In this work, we propose a novel Time Encoding (TE)
mechanism. TE can embed the time information as time vectors in the complex
domain. It has the the properties of absolute distance and relative distance
under different sampling rates, which helps to represent both two
irregularities of ISTS. Meanwhile, we create a new model structure named Time
Encoding Echo State Network (TE-ESN). It is the first ESNs-based model that can
process ISTS data. Besides, TE-ESN can incorporate long short-term memories and
series fusion to grasp horizontal and vertical relations. Experiments on one
chaos system and three real-world datasets show that TE-ESN performs better
than all baselines and has better reservoir property.",http://arxiv.org/pdf/2105.00412v1,cs.LG
2021-04-30 13:00:44+00:00,PSEUDo: Interactive Pattern Search in Multivariate Time Series with Locality-Sensitive Hashing and Relevance Feedback,"['Yuncong Yu', 'Dylan Kruyff', 'Tim Becker', 'Michael Behrisch']","We present PSEUDo, an adaptive feature learning technique for exploring
visual patterns in multi-track sequential data. Our approach is designed with
the primary focus to overcome the uneconomic retraining requirements and
inflexible representation learning in current deep learning-based systems.
Multi-track time series data are generated on an unprecedented scale due to
increased sensors and data storage. These datasets hold valuable patterns, like
in neuromarketing, where researchers try to link patterns in multivariate
sequential data from physiological sensors to the purchase behavior of products
and services. But a lack of ground truth and high variance make automatic
pattern detection unreliable. Our advancements are based on a novel query-aware
locality-sensitive hashing technique to create a feature-based representation
of multivariate time series windows. Most importantly, our algorithm features
sub-linear training and inference time. We can even accomplish both the
modeling and comparison of 10,000 different 64-track time series, each with 100
time steps (a typical EEG dataset) under 0.8 seconds. This performance gain
allows for a rapid relevance feedback-driven adaption of the underlying pattern
similarity model and enables the user to modify the speed-vs-accuracy trade-off
gradually. We demonstrate superiority of PSEUDo in terms of efficiency,
accuracy, and steerability through a quantitative performance comparison and a
qualitative visual quality comparison to the state-of-the-art algorithms in the
field. Moreover, we showcase the usability of PSEUDo through a case study
demonstrating our visual pattern retrieval concepts in a large meteorological
dataset. We find that our adaptive models can accurately capture the user's
notion of similarity and allow for an understandable exploratory visual pattern
retrieval in large multivariate time series datasets.",http://arxiv.org/pdf/2104.14962v2,cs.LG
2021-04-28 14:23:29+00:00,A general procedure for change-point detection in multivariate time series,"['Mamadou Lamine Diop', 'William Kengne']","We consider the change-point detection in multivariate continuous and integer
valued time series. We propose a Wald-type statistic based on the estimator
performed by a general contrast function; which can be constructed from the
likelihood, a quasi-likelihood, a least squares method, etc.
  Sufficient conditions are provided to ensure that the statistic convergences
to a well-known distribution under the null hypothesis (of no change) and
diverges to infinity under the alternative; which establishes the consistency
of the procedure. Some examples are detailed to illustrate the scope of
application of the proposed procedure.
  Simulation experiments are conducted to illustrate the asymptotic results.",http://arxiv.org/pdf/2104.13789v1,math.ST
2021-04-28 05:44:02+00:00,Time series forecasting of new cases and new deaths rate for COVID-19 using deep learning methods,"['Nooshin Ayoobi', 'Danial Sharifrazi', 'Roohallah Alizadehsani', 'Afshin Shoeibi', 'Juan M. Gorriz', 'Hossein Moosaei', 'Abbas Khosravi', 'Saeid Nahavandi', 'Abdoulmohammad Gholamzadeh Chofreh', 'Feybi Ariani Goni', 'Jiri Jaromir Klemes', 'Amir Mosavi']","The first known case of Coronavirus disease 2019 (COVID-19) was identified in
December 2019. It has spread worldwide, leading to an ongoing pandemic, imposed
restrictions and costs to many countries. Predicting the number of new cases
and deaths during this period can be a useful step in predicting the costs and
facilities required in the future. The purpose of this study is to predict new
cases and deaths rate one, three and seven-day ahead during the next 100 days.
The motivation for predicting every n days (instead of just every day) is the
investigation of the possibility of computational cost reduction and still
achieving reasonable performance. Such a scenario may be encountered in
real-time forecasting of time series. Six different deep learning methods are
examined on the data adopted from the WHO website. Three methods are LSTM,
Convolutional LSTM, and GRU. The bidirectional extension is then considered for
each method to forecast the rate of new cases and new deaths in Australia and
Iran countries.
  This study is novel as it carries out a comprehensive evaluation of the
aforementioned three deep learning methods and their bidirectional extensions
to perform prediction on COVID-19 new cases and new death rate time series. To
the best of our knowledge, this is the first time that Bi-GRU and Bi-Conv-LSTM
models are used for prediction on COVID-19 new cases and new deaths time
series. The evaluation of the methods is presented in the form of graphs and
Friedman statistical test. The results show that the bidirectional models have
lower errors than other models. A several error evaluation metrics are
presented to compare all models, and finally, the superiority of bidirectional
methods is determined. This research could be useful for organisations working
against COVID-19 and determining their long-term plans.",http://arxiv.org/pdf/2104.15007v3,cs.LG
2021-04-28 01:27:52+00:00,Estimation of Poisson Autoregressive Model for Multiple Time Series,"['Paolo Victor T. Redondo', 'Joseph Ryan G. Lansangan', 'Erniel B. Barrios']","A Poisson autoregressive (PAR) model accounting for discreteness and
autocorrelation of count time series data is typically estimated in the
state-space modelling framework through extended Kalman filter. However,
because of the complex dependencies in count time series, estimation becomes
more challenging. PAR is viewed as an additive model and estimated using a
hybrid of cubic smoothing splines and maximum likelihood estimation (MLE) in
the backfitting framework. Simulation studies show that this estimation method
is comparable or better than PAR estimated in the state-space context,
especially with larger count values. However, as [2] formulated PAR for
stationary counts, both estimation procedures underestimate parameters in
nearly nonstationary models. The flexibility of the additive model has two
benefits though: robust estimation in the presence of temporary structural
change, and; viability to integrate PAR model into a more complex model
structure. We further generalized the PAR(p) model into multiple time series of
counts and illustrated with indicators in the financial markets.",http://arxiv.org/pdf/2104.13520v1,stat.ME
2021-04-27 15:16:21+00:00,Early Classification of Time Series is Meaningful,"['Youssef Achenchabe', 'Alexis Bondu', 'Antoine Cornuéjols', 'Vincent Lemaire']","Many approaches have been proposed for early classification of time series in
light of its significance in a wide range of applications including healthcare,
transportation and finance. However, recently a preprint saved on Arxiv claim
that all research done for almost 20 years now on the Early Classification of
Time Series is useless, or, at the very least, ill-oriented because severely
lacking a strong ground. In this paper, we answer in detail the main issues and
misunderstandings raised by the authors of the preprint, and propose directions
to further expand the fields of application of early classification of time
series.",http://arxiv.org/pdf/2104.13257v2,cs.LG
2021-04-26 15:35:11+00:00,tsrobprep - an R package for robust preprocessing of time series data,"['Michał Narajewski', 'Jens Kley-Holsteg', 'Florian Ziel']","Data cleaning is a crucial part of every data analysis exercise. Yet, the
currently available R packages do not provide fast and robust methods for
cleaning and preparation of time series data. The open source package tsrobprep
introduces efficient methods for handling missing values and outliers using
model based approaches. For data imputation a probabilistic replacement model
is proposed, which may consist of autoregressive components and external
inputs. For outlier detection a clustering algorithm based on finite mixture
modelling is introduced, which considers time series properties in terms of the
gradient and the underlying seasonality as features. The procedure allows to
return a probability for each observation being outlying data as well as a
specific cause for an outlier assignment in terms of the provided feature
space. The methods work robust and are fully tunable. Moreover, by providing
the auto_data_cleaning function the data preprocessing can be carried out in
one cast, without comprehensive tuning and providing suitable results. The
primary motivation of the package is the preprocessing of energy system data.
We present application for electricity load, wind and solar power data.",http://arxiv.org/pdf/2104.12657v2,stat.ML
2021-04-23 09:53:28+00:00,Time Series Forecasting via Learning Convolutionally Low-Rank Models,['Guangcan Liu'],"Recently, Liu and Zhang studied the rather challenging problem of time series
forecasting from the perspective of compressed sensing. They proposed a
no-learning method, named Convolution Nuclear Norm Minimization (CNNM), and
proved that CNNM can exactly recover the future part of a series from its
observed part, provided that the series is convolutionally low-rank. While
impressive, the convolutional low-rankness condition may not be satisfied
whenever the series is far from being seasonal, and is in fact brittle to the
presence of trends and dynamics. This paper tries to approach the issues by
integrating a learnable, orthonormal transformation into CNNM, with the purpose
for converting the series of involute structures into regular signals of
convolutionally low-rank. We prove that the resultant model, termed
Learning-Based CNNM (LbCNNM), strictly succeeds in identifying the future part
of a series, as long as the transform of the series is convolutionally
low-rank. To learn proper transformations that may meet the required success
conditions, we devise an interpretable method based on Principal Component
Pursuit (PCP). Equipped with this learning method and some elaborate data
argumentation skills, LbCNNM not only can handle well the major components of
time series (including trends, seasonality and dynamics), but also can make use
of the forecasts provided by some other forecasting methods; this means LbCNNM
can be used as a general tool for model combination. Extensive experiments on
100,452 real-world time series from Time Series Data Library (TSDL) and M4
Competition (M4) demonstrate the superior performance of LbCNNM.",http://arxiv.org/pdf/2104.11510v5,cs.LG
2021-04-23 00:37:17+00:00,Joint Mean-Vector and Var-Matrix estimation for Locally Stationary VAR(1) processes,['Giovanni Motta'],"During the last two decades, locally stationary processes have been widely
studied in the time series literature. In this paper we consider the
locally-stationary vector-auto-regression model of order one, or LS-VAR(1), and
estimate its parameters by weighted least squares. The LS-VAR(1) we consider
allows for a smoothly time-varying non-diagonal VAR matrix, as well as for a
smoothly time-varying non-zero mean. The weighting scheme is based on kernel
smoothers. The time-varying mean and the time-varying VAR matrix are estimated
jointly, and the definition of the local-linear weighting matrix is provided in
closed-from. The quality of the estimated curves is illustrated through
simulation results.",http://arxiv.org/pdf/2104.11358v1,stat.ME
2021-04-22 14:49:00+00:00,A Feature Selection Method for Multi-Dimension Time-Series Data,"['Bahavathy Kathirgamanathan', 'Padraig Cunningham']","Time-series data in application areas such as motion capture and activity
recognition is often multi-dimension. In these application areas data typically
comes from wearable sensors or is extracted from video. There is a lot of
redundancy in these data streams and good classification accuracy will often be
achievable with a small number of features (dimensions). In this paper we
present a method for feature subset selection on multidimensional time-series
data based on mutual information. This method calculates a merit score (MSTS)
based on correlation patterns of the outputs of classifiers trained on single
features and the `best' subset is selected accordingly. MSTS was found to be
significantly more efficient in terms of computational cost while also managing
to maintain a good overall accuracy when compared to Wrapper-based feature
selection, a feature selection strategy that is popular elsewhere in Machine
Learning. We describe the motivations behind this feature selection strategy
and evaluate its effectiveness on six time series datasets.",http://arxiv.org/pdf/2104.11110v1,cs.LG
2021-04-20 09:39:38+00:00,Forecasting The JSE Top 40 Using Long Short-Term Memory Networks,"['Adam Balusik', 'Jared de Magalhaes', 'Rendani Mbuvha']","As a result of the greater availability of big data, as well as the
decreasing costs and increasing power of modern computing, the use of
artificial neural networks for financial time series forecasting is once again
a major topic of discussion and research in the financial world. Despite this
academic focus, there are still contrasting opinions and bodies of literature
on which artificial neural networks perform the best and whether or not they
outperform the forecasting capabilities of conventional time series models.
This paper uses a long-short term memory network to perform financial time
series forecasting on the return data of the JSE Top 40 index. Furthermore, the
forecasting performance of the long-short term memory network is compared to
the forecasting performance of a seasonal autoregressive integrated moving
average model. This paper evaluates the varying approaches presented in the
existing literature and ultimately, compares the results to that existing
literature. The paper concludes that the long short-term memory network
outperforms the seasonal autoregressive integrated moving average model when
forecasting intraday directional movements as well as when forecasting the
index close price.",http://arxiv.org/pdf/2104.09855v1,stat.ML
2021-04-19 10:36:23+00:00,SALAD: Self-Adaptive Lightweight Anomaly Detection for Real-time Recurrent Time Series,"['Ming-Chang Lee', 'Jia-Chun Lin', 'Ernst Gunnar Gran']","Real-world time series data often present recurrent or repetitive patterns
and it is often generated in real time, such as transportation passenger
volume, network traffic, system resource consumption, energy usage, and human
gait. Detecting anomalous events based on machine learning approaches in such
time series data has been an active research topic in many different areas.
However, most machine learning approaches require labeled datasets, offline
training, and may suffer from high computation complexity, consequently
hindering their applicability. Providing a lightweight self-adaptive approach
that does not need offline training in advance and meanwhile is able to detect
anomalies in real time could be highly beneficial. Such an approach could be
immediately applied and deployed on any commodity machine to provide timely
anomaly alerts. To facilitate such an approach, this paper introduces SALAD,
which is a Self-Adaptive Lightweight Anomaly Detection approach based on a
special type of recurrent neural networks called Long Short-Term Memory (LSTM).
Instead of using offline training, SALAD converts a target time series into a
series of average absolute relative error (AARE) values on the fly and predicts
an AARE value for every upcoming data point based on short-term historical AARE
values. If the difference between a calculated AARE value and its corresponding
forecast AARE value is higher than a self-adaptive detection threshold, the
corresponding data point is considered anomalous. Otherwise, the data point is
considered normal. Experiments based on two real-world open-source time series
datasets demonstrate that SALAD outperforms five other state-of-the-art anomaly
detection approaches in terms of detection accuracy. In addition, the results
also show that SALAD is lightweight and can be deployed on a commodity machine.",http://arxiv.org/pdf/2104.09968v3,cs.LG
2021-04-17 14:43:33+00:00,Recursive input and state estimation: A general framework for learning from time series with missing data,"['Alberto García-Durán', 'Robert West']","Time series with missing data are signals encountered in important settings
for machine learning. Some of the most successful prior approaches for modeling
such time series are based on recurrent neural networks that transform the
input and previous state to account for the missing observations, and then
treat the transformed signal in a standard manner.
  In this paper, we introduce a single unifying framework, Recursive Input and
State Estimation (RISE), for this general approach and reformulate existing
models as specific instances of this framework. We then explore additional
novel variations within the RISE framework to improve the performance of any
instance. We exploit representation learning techniques to learn latent
representations of the signals used by RISE instances. We discuss and develop
various encoding techniques to learn latent signal representations. We
benchmark instances of the framework with various encoding functions on three
data imputation datasets, observing that RISE instances always benefit from
encoders that learn representations for numerical values from the digits into
which they can be decomposed.",http://arxiv.org/pdf/2104.08556v1,cs.LG
2021-04-16 14:57:41+00:00,An Empirical Study of Graph-Based Approaches for Semi-Supervised Time Series Classification,"['Dominik Alfke', 'Miriam Gondos', 'Lucile Peroche', 'Martin Stoll']","Time series data play an important role in many applications and their
analysis reveals crucial information for understanding the underlying
processes. Among the many time series learning tasks of great importance, we
here focus on semi-supervised learning based on a graph representation of the
data. Two main aspects are involved in this task. A suitable distance measure
to evaluate the similarities between time series, and a learning method to make
predictions based on these distances. However, the relationship between the two
aspects has never been studied systematically in the context of graph-based
learning. We describe four different distance measures, including (Soft) DTW
and MPDist, a distance measure based on the Matrix Profile, as well as four
successful semi-supervised learning methods, including the graph Allen--Cahn
method and a Graph Convolutional Neural Network. We then compare the
performance of the algorithms on binary classification data sets. In our
findings we compare the chosen graph-based methods using all distance measures
and observe that the results vary strongly with respect to the accuracy. As
predicted by the ``no free lunch'' theorem, no clear best combination to employ
in all cases is found. Our study provides a reproducible framework for future
work in the direction of semi-supervised learning for time series with a focus
on graph representations.",http://arxiv.org/pdf/2104.08153v2,cs.LG
2021-04-16 11:38:29+00:00,Data Generating Process to Evaluate Causal Discovery Techniques for Time Series Data,"['Andrew R. Lawrence', 'Marcus Kaiser', 'Rui Sampaio', 'Maksim Sipos']","Going beyond correlations, the understanding and identification of causal
relationships in observational time series, an important subfield of Causal
Discovery, poses a major challenge. The lack of access to a well-defined ground
truth for real-world data creates the need to rely on synthetic data for the
evaluation of these methods. Existing benchmarks are limited in their scope, as
they either are restricted to a ""static"" selection of data sets, or do not
allow for a granular assessment of the methods' performance when commonly made
assumptions are violated. We propose a flexible and simple to use framework for
generating time series data, which is aimed at developing, evaluating, and
benchmarking time series causal discovery methods. In particular, the framework
can be used to fine tune novel methods on vast amounts of data, without
""overfitting"" them to a benchmark, but rather so they perform well in
real-world use cases. Using our framework, we evaluate prominent time series
causal discovery methods and demonstrate a notable degradation in performance
when their assumptions are invalidated and their sensitivity to choice of
hyperparameters. Finally, we propose future research directions and how our
framework can support both researchers and practitioners.",http://arxiv.org/pdf/2104.08043v1,stat.ML
2021-04-15 16:06:09+00:00,HIVE-COTE 2.0: a new meta ensemble for time series classification,"['Matthew Middlehurst', 'James Large', 'Michael Flynn', 'Jason Lines', 'Aaron Bostrom', 'Anthony Bagnall']","The Hierarchical Vote Collective of Transformation-based Ensembles
(HIVE-COTE) is a heterogeneous meta ensemble for time series classification.
HIVE-COTE forms its ensemble from classifiers of multiple domains, including
phase-independent shapelets, bag-of-words based dictionaries and
phase-dependent intervals. Since it was first proposed in 2016, the algorithm
has remained state of the art for accuracy on the UCR time series
classification archive. Over time it has been incrementally updated,
culminating in its current state, HIVE-COTE 1.0. During this time a number of
algorithms have been proposed which match the accuracy of HIVE-COTE. We propose
comprehensive changes to the HIVE-COTE algorithm which significantly improve
its accuracy and usability, presenting this upgrade as HIVE-COTE 2.0. We
introduce two novel classifiers, the Temporal Dictionary Ensemble (TDE) and
Diverse Representation Canonical Interval Forest (DrCIF), which replace
existing ensemble members. Additionally, we introduce the Arsenal, an ensemble
of ROCKET classifiers as a new HIVE-COTE 2.0 constituent. We demonstrate that
HIVE-COTE 2.0 is significantly more accurate than the current state of the art
on 112 univariate UCR archive datasets and 26 multivariate UEA archive
datasets.",http://arxiv.org/pdf/2104.07551v1,cs.LG
2021-04-10 14:38:11+00:00,Boosted Embeddings for Time Series Forecasting,"['Sankeerth Rao Karingula', 'Nandini Ramanan', 'Rasool Tahmasbi', 'Mehrnaz Amjadi', 'Deokwoo Jung', 'Ricky Si', 'Charanraj Thimmisetty', 'Luisa Polania Cabrera', 'Marjorie Sayer', 'Claudionor Nunes Coelho Jr']","Time series forecasting is a fundamental task emerging from diverse
data-driven applications. Many advanced autoregressive methods such as ARIMA
were used to develop forecasting models. Recently, deep learning based methods
such as DeepAr, NeuralProphet, Seq2Seq have been explored for time series
forecasting problem. In this paper, we propose a novel time series forecast
model, DeepGB. We formulate and implement a variant of Gradient boosting
wherein the weak learners are DNNs whose weights are incrementally found in a
greedy manner over iterations. In particular, we develop a new embedding
architecture that improves the performance of many deep learning models on time
series using Gradient boosting variant. We demonstrate that our model
outperforms existing comparable state-of-the-art models using real-world sensor
data and public dataset.",http://arxiv.org/pdf/2104.04781v2,cs.LG
2021-04-09 23:58:14+00:00,DeepSITH: Efficient Learning via Decomposition of What and When Across Time Scales,"['Brandon Jacques', 'Zoran Tiganj', 'Marc W. Howard', 'Per B. Sederberg']","Extracting temporal relationships over a range of scales is a hallmark of
human perception and cognition -- and thus it is a critical feature of machine
learning applied to real-world problems. Neural networks are either plagued by
the exploding/vanishing gradient problem in recurrent neural networks (RNNs) or
must adjust their parameters to learn the relevant time scales (e.g., in
LSTMs). This paper introduces DeepSITH, a network comprising
biologically-inspired Scale-Invariant Temporal History (SITH) modules in series
with dense connections between layers. SITH modules respond to their inputs
with a geometrically-spaced set of time constants, enabling the DeepSITH
network to learn problems along a continuum of time-scales. We compare DeepSITH
to LSTMs and other recent RNNs on several time series prediction and decoding
tasks. DeepSITH achieves state-of-the-art performance on these problems.",http://arxiv.org/pdf/2104.04646v2,cs.LG
2021-04-09 21:24:33+00:00,Deep Time Series Forecasting with Shape and Temporal Criteria,"['Vincent Le Guen', 'Nicolas Thome']","This paper addresses the problem of multi-step time series forecasting for
non-stationary signals that can present sudden changes. Current
state-of-the-art deep learning forecasting methods, often trained with variants
of the MSE, lack the ability to provide sharp predictions in deterministic and
probabilistic contexts. To handle these challenges, we propose to incorporate
shape and temporal criteria in the training objective of deep models. We define
shape and temporal similarities and dissimilarities, based on a smooth
relaxation of Dynamic Time Warping (DTW) and Temporal Distortion Index (TDI),
that enable to build differentiable loss functions and positive semi-definite
(PSD) kernels. With these tools, we introduce DILATE (DIstortion Loss including
shApe and TimE), a new objective for deterministic forecasting, that explicitly
incorporates two terms supporting precise shape and temporal change detection.
For probabilistic forecasting, we introduce STRIPE++ (Shape and Time diverRsIty
in Probabilistic forEcasting), a framework for providing a set of sharp and
diverse forecasts, where the structured shape and time diversity is enforced
with a determinantal point process (DPP) diversity loss. Extensive experiments
and ablations studies on synthetic and real-world datasets confirm the benefits
of leveraging shape and time features in time series forecasting.",http://arxiv.org/pdf/2104.04610v2,stat.ML
2021-04-09 06:14:54+00:00,Granger Causality Based Hierarchical Time Series Clustering for State Estimation,"['Sin Yong Tan', 'Homagni Saha', 'Margarite Jacoby', 'Gregor P. Henze', 'Soumik Sarkar']","Clustering is an unsupervised learning technique that is useful when working
with a large volume of unlabeled data. Complex dynamical systems in real life
often entail data streaming from a large number of sources. Although it is
desirable to use all source variables to form accurate state estimates, it is
often impractical due to large computational power requirements, and
sufficiently robust algorithms to handle these cases are not common. We propose
a hierarchical time series clustering technique based on symbolic dynamic
filtering and Granger causality, which serves as a dimensionality reduction and
noise-rejection tool. Our process forms a hierarchy of variables in the
multivariate time series with clustering of relevant variables at each level,
thus separating out noise and less relevant variables. A new distance metric
based on Granger causality is proposed and used for the time series clustering,
as well as validated on empirical data sets. Experimental results from
occupancy detection and building temperature estimation tasks show fidelity to
the empirical data sets while maintaining state-prediction accuracy with
substantially reduced data dimensionality.",http://arxiv.org/pdf/2104.04206v1,cs.LG
2021-04-08 01:45:28+00:00,Learning Graph Structures with Transformer for Multivariate Time Series Anomaly Detection in IoT,"['Zekai Chen', 'Dingshuo Chen', 'Xiao Zhang', 'Zixuan Yuan', 'Xiuzhen Cheng']","Many real-world IoT systems, which include a variety of internet-connected
sensory devices, produce substantial amounts of multivariate time series data.
Meanwhile, vital IoT infrastructures like smart power grids and water
distribution networks are frequently targeted by cyber-attacks, making anomaly
detection an important study topic. Modeling such relatedness is, nevertheless,
unavoidable for any efficient and effective anomaly detection system, given the
intricate topological and nonlinear connections that are originally unknown
among sensors. Furthermore, detecting anomalies in multivariate time series is
difficult due to their temporal dependency and stochasticity. This paper
presented GTA, a new framework for multivariate time series anomaly detection
that involves automatically learning a graph structure, graph convolution, and
modeling temporal dependency using a Transformer-based architecture. The
connection learning policy, which is based on the Gumbel-softmax sampling
approach to learn bi-directed links among sensors directly, is at the heart of
learning graph structure. To describe the anomaly information flow between
network nodes, we introduced a new graph convolution called Influence
Propagation convolution. In addition, to tackle the quadratic complexity
barrier, we suggested a multi-branch attention mechanism to replace the
original multi-head self-attention method. Extensive experiments on four
publicly available anomaly detection benchmarks further demonstrate the
superiority of our approach over alternative state-of-the-arts. Codes are
available at https://github.com/ZEKAICHEN/GTA.",http://arxiv.org/pdf/2104.03466v3,cs.LG
2021-04-06 17:16:36+00:00,Towards a Rigorous Evaluation of Explainability for Multivariate Time Series,"['Rohit Saluja', 'Avleen Malhi', 'Samanta Knapič', 'Kary Främling', 'Cicek Cavdar']","Machine learning-based systems are rapidly gaining popularity and in-line
with that there has been a huge research surge in the field of explainability
to ensure that machine learning models are reliable, fair, and can be held
liable for their decision-making process. Explainable Artificial Intelligence
(XAI) methods are typically deployed to debug black-box machine learning models
but in comparison to tabular, text, and image data, explainability in time
series is still relatively unexplored. The aim of this study was to achieve and
evaluate model agnostic explainability in a time series forecasting problem.
This work focused on proving a solution for a digital consultancy company
aiming to find a data-driven approach in order to understand the effect of
their sales related activities on the sales deals closed. The solution involved
framing the problem as a time series forecasting problem to predict the sales
deals and the explainability was achieved using two novel model agnostic
explainability techniques, Local explainable model-agnostic explanations (LIME)
and Shapley additive explanations (SHAP) which were evaluated using human
evaluation of explainability. The results clearly indicate that the
explanations produced by LIME and SHAP greatly helped lay humans in
understanding the predictions made by the machine learning model. The presented
work can easily be extended to any time",http://arxiv.org/pdf/2104.04075v1,cs.LG
2021-04-05 20:20:59+00:00,Spectral Subsampling MCMC for Stationary Multivariate Time Series with Applications to Vector ARTFIMA Processes,"['Mattias Villani', 'Matias Quiroz', 'Robert Kohn', 'Robert Salomone']","Spectral subsampling MCMC was recently proposed to speed up Markov chain
Monte Carlo (MCMC) for long stationary univariate time series by subsampling
periodogram observations in the frequency domain. This article extends the
approach to multivariate time series using a multivariate generalisation of the
Whittle likelihood. To assess the computational gains from spectral subsampling
in challenging problems, a multivariate generalisation of the autoregressive
tempered fractionally integrated moving average model (ARTFIMA) is introduced
and some of its properties derived. Bayesian inference based on the Whittle
likelihood is demonstrated to be a fast and accurate alternative to the exact
time domain likelihood. Spectral subsampling is shown to provide up to two
orders of magnitude additional speed-up, while retaining MCMC sampling
efficiency and accuracy, compared to spectral methods using the full dataset.
  Keywords: Bayesian, Markov chain Monte Carlo, Semi-long memory, Spectral
analysis, Whittle likelihood.",http://arxiv.org/pdf/2104.02134v2,stat.ME
2021-04-05 09:55:35+00:00,Model Compression for Dynamic Forecast Combination,"['Vitor Cerqueira', 'Luis Torgo', 'Carlos Soares', 'Albert Bifet']","The predictive advantage of combining several different predictive models is
widely accepted. Particularly in time series forecasting problems, this
combination is often dynamic to cope with potential non-stationary sources of
variation present in the data. Despite their superior predictive performance,
ensemble methods entail two main limitations: high computational costs and lack
of transparency. These issues often preclude the deployment of such approaches,
in favour of simpler yet more efficient and reliable ones. In this paper, we
leverage the idea of model compression to address this problem in time series
forecasting tasks. Model compression approaches have been mostly unexplored for
forecasting. Their application in time series is challenging due to the
evolving nature of the data. Further, while the literature focuses on neural
networks, we apply model compression to distinct types of methods. In an
extensive set of experiments, we show that compressing dynamic forecasting
ensembles into an individual model leads to a comparable predictive performance
and a drastic reduction in computational costs. Further, the compressed
individual model with best average rank is a rule-based regression model. Thus,
model compression also leads to benefits in terms of model interpretability.
The experiments carried in this paper are fully reproducible.",http://arxiv.org/pdf/2104.01830v1,stat.ML
2021-04-02 14:33:41+00:00,Multivariate time series models for mixed data,"['Zinsou Max Debaly', 'Lionel Truquet']","We introduce a general approach for modeling the dynamic of multivariate time
series when the data are of mixed type (binary/count/continuous). Our method is
quite flexible and conditionally on past values, each coordinate at time $t$
can have a distribution compatible with a standard univariate time series model
such as GARCH, ARMA, INGARCH or logistic models whereas past values of the
other coordinates play the role of exogenous covariates in the dynamic. The
simultaneous dependence in the multivariate time series can be modeled with a
copula. Additional exogenous covariates are also allowed in the dynamic. We
first study usual stability properties of these models and then show that
autoregressive parameters can be consistently estimated equation-by-equation
using a pseudo-maximum likelihood method, leading to a fast implementation even
when the number of time series is large. Moreover, we prove consistency results
when a parametric copula model is fitted to the time series and in the case of
Gaussian copulas, we show that the likelihood estimator of the correlation
matrix is strongly consistent. We carefully check all our assumptions for two
prototypical examples: a GARCH/INGARCH model and logistic/log-linear INGARCH
model. Our results are illustrated with numerical experiments as well as two
real data sets.",http://arxiv.org/pdf/2104.01067v1,stat.ME
2021-04-02 09:14:00+00:00,Explainable Artificial Intelligence (XAI) on TimeSeries Data: A Survey,"['Thomas Rojat', 'Raphaël Puget', 'David Filliat', 'Javier Del Ser', 'Rodolphe Gelin', 'Natalia Díaz-Rodríguez']","Most of state of the art methods applied on time series consist of deep
learning methods that are too complex to be interpreted. This lack of
interpretability is a major drawback, as several applications in the real world
are critical tasks, such as the medical field or the autonomous driving field.
The explainability of models applied on time series has not gather much
attention compared to the computer vision or the natural language processing
fields. In this paper, we present an overview of existing explainable AI (XAI)
methods applied on time series and illustrate the type of explanations they
produce. We also provide a reflection on the impact of these explanation
methods to provide confidence and trust in the AI systems.",http://arxiv.org/pdf/2104.00950v1,cs.LG
2021-04-02 08:58:44+00:00,Learnable Dynamic Temporal Pooling for Time Series Classification,"['Dongha Lee', 'Seonghyeon Lee', 'Hwanjo Yu']","With the increase of available time series data, predicting their class
labels has been one of the most important challenges in a wide range of
disciplines. Recent studies on time series classification show that
convolutional neural networks (CNN) achieved the state-of-the-art performance
as a single classifier. In this work, pointing out that the global pooling
layer that is usually adopted by existing CNN classifiers discards the temporal
information of high-level features, we present a dynamic temporal pooling (DTP)
technique that reduces the temporal size of hidden representations by
aggregating the features at the segment-level. For the partition of a whole
series into multiple segments, we utilize dynamic time warping (DTW) to align
each time point in a temporal order with the prototypical features of the
segments, which can be optimized simultaneously with the network parameters of
CNN classifiers. The DTP layer combined with a fully-connected layer helps to
extract further discriminative features considering their temporal position
within an input time series. Extensive experiments on both univariate and
multivariate time series datasets show that our proposed pooling significantly
improves the classification performance.",http://arxiv.org/pdf/2104.02577v1,cs.LG
2021-04-01 16:08:25+00:00,Model Selection for Time Series Forecasting: Empirical Analysis of Different Estimators,"['Vitor Cerqueira', 'Luis Torgo', 'Carlos Soares']","Evaluating predictive models is a crucial task in predictive analytics. This
process is especially challenging with time series data where the observations
show temporal dependencies. Several studies have analysed how different
performance estimation methods compare with each other for approximating the
true loss incurred by a given forecasting model. However, these studies do not
address how the estimators behave for model selection: the ability to select
the best solution among a set of alternatives. We address this issue and
compare a set of estimation methods for model selection in time series
forecasting tasks. We attempt to answer two main questions: (i) how often is
the best possible model selected by the estimators; and (ii) what is the
performance loss when it does not. We empirically found that the accuracy of
the estimators for selecting the best solution is low, and the overall
forecasting performance loss associated with the model selection process ranges
from 1.2% to 2.3%. We also discovered that some factors, such as the sample
size, are important in the relative performance of the estimators.",http://arxiv.org/pdf/2104.00584v2,stat.ML
2021-04-01 06:11:24+00:00,Model-based fuzzy time series clustering of conditional higher moments,"['Roy Cerqueti', 'Massimiliano Giacalone', 'Raffaele Mattera']","This paper develops a new time series clustering procedure allowing for
heteroskedasticity, non-normality and model's non-linearity. At this aim, we
follow a fuzzy approach. Specifically, considering a Dynamic Conditional Score
(DCS) model, we propose to cluster time series according to their estimated
conditional moments via the Autocorrelation-based fuzzy C-means (A-FCM)
algorithm. The DCS parametric modelling is appealing because of its generality
and computational feasibility. The usefulness of the proposed procedure is
illustrated using an experiment with simulated data and several empirical
applications with financial time series assuming both linear and nonlinear
models' specification and under several assumptions about time series density
function.",http://arxiv.org/pdf/2104.00271v1,stat.ME
2021-03-31 23:48:46+00:00,Time Series Analysis and Modeling to Forecast: a Survey,"['Fatoumata Dama', 'Christine Sinoquet']","Time series modeling for predictive purpose has been an active research area
of machine learning for many years. However, no sufficiently comprehensive and
meanwhile substantive survey was offered so far. This survey strives to meet
this need. A unified presentation has been adopted for entire parts of this
compilation.
  A red thread guides the reader from time series preprocessing to forecasting.
Time series decomposition is a major preprocessing task, to separate
nonstationary effects (the deterministic components) from the remaining
stochastic constituent, assumed to be stationary. The deterministic components
are predictable and contribute to the prediction through estimations or
extrapolation. Fitting the most appropriate model to the remaining stochastic
component aims at capturing the relationship between past and future values, to
allow prediction.
  We cover a sufficiently broad spectrum of models while nonetheless offering
substantial methodological developments. We describe three major linear
parametric models, together with two nonlinear extensions, and present five
categories of nonlinear parametric models. Beyond conventional statistical
models, we highlight six categories of deep neural networks appropriate for
time series forecasting in nonlinear framework.
  Finally, we enlighten new avenues of research for time series modeling and
forecasting. We also report software made publicly available for the models
presented.",http://arxiv.org/pdf/2104.00164v2,cs.LG
2021-03-31 15:21:15+00:00,RLAD: Time Series Anomaly Detection through Reinforcement Learning and Active Learning,"['Tong Wu', 'Jorge Ortiz']","We introduce a new semi-supervised, time series anomaly detection algorithm
that uses deep reinforcement learning (DRL) and active learning to efficiently
learn and adapt to anomalies in real-world time series data. Our model - called
RLAD - makes no assumption about the underlying mechanism that produces the
observation sequence and continuously adapts the detection model based on
experience with anomalous patterns. In addition, it requires no manual tuning
of parameters and outperforms all state-of-art methods we compare with, both
unsupervised and semi-supervised, across several figures of merit. More
specifically, we outperform the best unsupervised approach by a factor of 1.58
on the F1 score, with only 1% of labels and up to around 4.4x on another
real-world dataset with only 0.1% of labels. We compare RLAD with seven
deep-learning based algorithms across two common anomaly detection datasets
with up to around 3M data points and between 0.28% to 2.65% anomalies.We
outperform all of them across several important performance metrics.",http://arxiv.org/pdf/2104.00543v1,cs.LG
2021-03-30 13:47:30+00:00,Historical Inertia: A Neglected but Powerful Baseline for Long Sequence Time-series Forecasting,"['Yue Cui', 'Jiandong Xie', 'Kai Zheng']","Long sequence time-series forecasting (LSTF) has become increasingly popular
for its wide range of applications. Though superior models have been proposed
to enhance the prediction effectiveness and efficiency, it is reckless to
neglect or underestimate one of the most natural and basic temporal properties
of time-series. In this paper, we introduce a new baseline for LSTF, the
historical inertia (HI), which refers to the most recent historical data-points
in the input time series. We experimentally evaluate the power of historical
inertia on four public real-word datasets. The results demonstrate that up to
82\% relative improvement over state-of-the-art works can be achieved even by
adopting HI directly as output.",http://arxiv.org/pdf/2103.16349v3,cs.LG
2021-03-26 12:43:32+00:00,Gated Transformer Networks for Multivariate Time Series Classification,"['Minghao Liu', 'Shengqi Ren', 'Siyuan Ma', 'Jiahui Jiao', 'Yizhou Chen', 'Zhiguang Wang', 'Wei Song']","Deep learning model (primarily convolutional networks and LSTM) for time
series classification has been studied broadly by the community with the wide
applications in different domains like healthcare, finance, industrial
engineering and IoT. Meanwhile, Transformer Networks recently achieved frontier
performance on various natural language processing and computer vision tasks.
In this work, we explored a simple extension of the current Transformer
Networks with gating, named Gated Transformer Networks (GTN) for the
multivariate time series classification problem. With the gating that merges
two towers of Transformer which model the channel-wise and step-wise
correlations respectively, we show how GTN is naturally and effectively
suitable for the multivariate time series classification task. We conduct
comprehensive experiments on thirteen dataset with full ablation study. Our
results show that GTN is able to achieve competing results with current
state-of-the-art deep learning models. We also explored the attention map for
the natural interpretability of GTN on time series modeling. Our preliminary
results provide a strong baseline for the Transformer Networks on multivariate
time series classification task and grounds the foundation for future research.",http://arxiv.org/pdf/2103.14438v1,cs.LG
2021-03-26 04:07:11+00:00,Evaluation of deep learning models for multi-step ahead time series prediction,"['Rohitash Chandra', 'Shaurya Goyal', 'Rishabh Gupta']","Time series prediction with neural networks has been the focus of much
research in the past few decades. Given the recent deep learning revolution,
there has been much attention in using deep learning models for time series
prediction, and hence it is important to evaluate their strengths and
weaknesses. In this paper, we present an evaluation study that compares the
performance of deep learning models for multi-step ahead time series
prediction. The deep learning methods comprise simple recurrent neural
networks, long short-term memory (LSTM) networks, bidirectional LSTM networks,
encoder-decoder LSTM networks, and convolutional neural networks. We provide a
further comparison with simple neural networks that use stochastic gradient
descent and adaptive moment estimation (Adam) for training. We focus on
univariate time series for multi-step-ahead prediction from benchmark
time-series datasets and provide a further comparison of the results with
related methods from the literature. The results show that the bidirectional
and encoder-decoder LSTM network provides the best performance in accuracy for
the given time series problems.",http://arxiv.org/pdf/2103.14250v2,cs.LG
2021-03-26 02:32:16+00:00,Multi-source Transfer Learning with Ensemble for Financial Time Series Forecasting,"['Qi-Qiao He', 'Patrick Cheong-Iao Pang', 'Yain-Whar Si']","Although transfer learning is proven to be effective in computer vision and
natural language processing applications, it is rarely investigated in
forecasting financial time series. Majority of existing works on transfer
learning are based on single-source transfer learning due to the availability
of open-access large-scale datasets. However, in financial domain, the lengths
of individual time series are relatively short and single-source transfer
learning models are less effective. Therefore, in this paper, we investigate
multi-source deep transfer learning for financial time series. We propose two
multi-source transfer learning methods namely Weighted Average Ensemble for
Transfer Learning (WAETL) and Tree-structured Parzen Estimator Ensemble
Selection (TPEES). The effectiveness of our approach is evaluated on financial
time series extracted from stock markets. Experiment results reveal that TPEES
outperforms other baseline methods on majority of multi-source transfer tasks.",http://arxiv.org/pdf/2103.15593v1,cs.LG
2021-03-26 01:24:00+00:00,Applying k-nearest neighbors to time series forecasting : two new approaches,"['Samya Tajmouati', 'Bouazza El Wahbi', 'Adel Bedoui', 'Abdallah Abarda', 'Mohamed Dakkoun']","K-nearest neighbors algorithm is one of the prominent techniques used in
classification and regression. Despite its simplicity, the k-nearest neighbors
has been successfully applied in time series forecasting. However, the
selection of the number of neighbors and feature selection is a daunting task.
In this paper, we introduce two methodologies to forecasting time series that
we refer to as Classical Parameters Tuning in Weighted Nearest Neighbors and
Fast Parameters Tuning in Weighted Nearest Neighbors. The first approach uses
classical parameters tuning that compares the most recent subsequence with
every possible subsequence from the past of the same length. The second
approach reduces the neighbors' search set, which leads to significantly
reduced grid size and hence a lower computational time. To tune the models'
parameters, both methods implement an approach inspired by cross-validation for
weighted nearest neighbors. We evaluate the forecasting performance and
accuracy of our models. Then, we compare them to some classical approaches,
especially, Seasonal Autoregressive Integrated Moving Average, Holt-Winters and
Exponential Smoothing State Space Model. Real data examples on retail and food
services sales in the USA and milk production in the UK are analyzed to
demonstrate the application and the efficiency of the proposed approaches.",http://arxiv.org/pdf/2103.14200v1,stat.ME
2021-03-23 09:32:06+00:00,Neural ODE Processes,"['Alexander Norcliffe', 'Cristian Bodnar', 'Ben Day', 'Jacob Moss', 'Pietro Liò']","Neural Ordinary Differential Equations (NODEs) use a neural network to model
the instantaneous rate of change in the state of a system. However, despite
their apparent suitability for dynamics-governed time-series, NODEs present a
few disadvantages. First, they are unable to adapt to incoming data points, a
fundamental requirement for real-time applications imposed by the natural
direction of time. Second, time series are often composed of a sparse set of
measurements that could be explained by many possible underlying dynamics.
NODEs do not capture this uncertainty. In contrast, Neural Processes (NPs) are
a family of models providing uncertainty estimation and fast data adaptation
but lack an explicit treatment of the flow of time. To address these problems,
we introduce Neural ODE Processes (NDPs), a new class of stochastic processes
determined by a distribution over Neural ODEs. By maintaining an adaptive
data-dependent distribution over the underlying ODE, we show that our model can
successfully capture the dynamics of low-dimensional systems from just a few
data points. At the same time, we demonstrate that NDPs scale up to challenging
high-dimensional time-series with unknown latent dynamics such as rotating
MNIST digits.",http://arxiv.org/pdf/2103.12413v2,cs.LG
2021-03-22 17:58:36+00:00,An Experimental Review on Deep Learning Architectures for Time Series Forecasting,"['Pedro Lara-Benítez', 'Manuel Carranza-García', 'José C. Riquelme']","In recent years, deep learning techniques have outperformed traditional
models in many machine learning tasks. Deep neural networks have successfully
been applied to address time series forecasting problems, which is a very
important topic in data mining. They have proved to be an effective solution
given their capacity to automatically learn the temporal dependencies present
in time series. However, selecting the most convenient type of deep neural
network and its parametrization is a complex task that requires considerable
expertise. Therefore, there is a need for deeper studies on the suitability of
all existing architectures for different forecasting tasks. In this work, we
face two main challenges: a comprehensive review of the latest works using deep
learning for time series forecasting; and an experimental study comparing the
performance of the most popular architectures. The comparison involves a
thorough analysis of seven types of deep learning models in terms of accuracy
and efficiency. We evaluate the rankings and distribution of results obtained
with the proposed models under many different architecture configurations and
training hyperparameters. The datasets used comprise more than 50000 time
series divided into 12 different forecasting problems. By training more than
38000 models on these data, we provide the most extensive deep learning study
for time series forecasting. Among all studied models, the results show that
long short-term memory (LSTM) and convolutional networks (CNN) are the best
alternatives, with LSTMs obtaining the most accurate forecasts. CNNs achieve
comparable performance with less variability of results under different
parameter configurations, while also being more efficient.",http://arxiv.org/pdf/2103.12057v2,cs.LG
2021-03-19 12:15:37+00:00,Graph Attention Recurrent Neural Networks for Correlated Time Series Forecasting -- Full version,"['Razvan-Gabriel Cirstea', 'Chenjuan Guo', 'Bin Yang']","We consider a setting where multiple entities inter-act with each other over
time and the time-varying statuses of the entities are represented as multiple
correlated time series. For example, speed sensors are deployed in different
locations in a road network, where the speed of a specific location across time
is captured by the corresponding sensor as a time series, resulting in multiple
speed time series from different locations, which are often correlated. To
enable accurate forecasting on correlated time series, we proposes graph
attention recurrent neural networks.First, we build a graph among different
entities by taking into account spatial proximity and employ a multi-head
attention mechanism to derive adaptive weight matrices for the graph to capture
the correlations among vertices (e.g., speeds at different locations) at
different timestamps. Second, we employ recurrent neural networks to take into
account temporal dependency while taking into account the adaptive weight
matrices learned from the first step to consider the correlations among time
series.Experiments on a large real-world speed time series data set suggest
that the proposed method is effective and outperforms the state-of-the-art in
most settings. This manuscript provides a full version of a workshop paper [1].",http://arxiv.org/pdf/2103.10760v2,cs.LG
2021-03-17 02:54:51+00:00,Simultaneous Decorrelation of Matrix Time Series,"['Yuefeng Han', 'Rong Chen', 'Cun-Hui Zhang', 'Qiwei Yao']","We propose a contemporaneous bilinear transformation for a $p\times q$ matrix
time series to alleviate the difficulties in modeling and forecasting matrix
time series when $p$ and/or $q$ are large. The resulting transformed matrix
assumes a block structure consisting of several small matrices, and those small
matrix series are uncorrelated across all times. Hence an overall parsimonious
model is achieved by modelling each of those small matrix series separately
without the loss of information on the linear dynamics. Such a parsimonious
model often has better forecasting performance, even when the underlying true
dynamics deviates from the assumed uncorrelated block structure after
transformation. The uniform convergence rates of the estimated transformation
are derived, which vindicate an important virtue of the proposed bilinear
transformation, i.e. it is technically equivalent to the decorrelation of a
vector time series of dimension max$(p,q)$ instead of $p\times q$. The proposed
method is illustrated numerically via both simulated and real data examples.",http://arxiv.org/pdf/2103.09411v2,stat.ME
2021-03-16 22:16:54+00:00,Deep Time Series Models for Scarce Data,"['Qiyao Wang', 'Ahmed Farahat', 'Chetan Gupta', 'Shuai Zheng']","Time series data have grown at an explosive rate in numerous domains and have
stimulated a surge of time series modeling research. A comprehensive comparison
of different time series models, for a considered data analytics task, provides
useful guidance on model selection for data analytics practitioners. Data
scarcity is a universal issue that occurs in a vast range of data analytics
problems, due to the high costs associated with collecting, generating, and
labeling data as well as some data quality issues such as missing data. In this
paper, we focus on the temporal classification/regression problem that attempts
to build a mathematical mapping from multivariate time series inputs to a
discrete class label or a real-valued response variable. For this specific
problem, we identify two types of scarce data: scarce data with small samples
and scarce data with sparsely and irregularly observed time series covariates.
Observing that all existing works are incapable of utilizing the sparse time
series inputs for proper modeling building, we propose a model called sparse
functional multilayer perceptron (SFMLP) for handling the sparsity in the time
series covariates. The effectiveness of the proposed SFMLP under each of the
two types of data scarcity, in comparison with the conventional deep sequential
learning models (e.g., Recurrent Neural Network, and Long Short-Term Memory),
is investigated through mathematical arguments and numerical experiments.",http://arxiv.org/pdf/2103.09348v1,cs.LG
2021-03-16 16:23:41+00:00,Rollage: Efficient Rolling Average Algorithm to Estimate ARMA Models for Big Time Series Data,"['Ali Eshragh', 'Glen Livingston', 'Thomas McCarthy McCann', 'Luke Yerbury']","We develop a new efficient algorithm for the analysis of large-scale time
series data. We firstly define rolling averages, derive their analytical
properties, and establish their asymptotic distribution. These theoretical
results are subsequently exploited to develop an efficient algorithm, called
Rollage, for fitting an appropriate AR model to big time series data. When used
in conjunction with the Durbin's algorithm, we show that the Rollage algorithm
can be used as a criterion to optimally fit ARMA models to big time series
data. Empirical experiments on large-scale synthetic time series data support
the theoretical results and reveal the efficacy of this new approach,
especially when compared to existing methodology.",http://arxiv.org/pdf/2103.09175v4,stat.ME
2021-03-15 16:36:25+00:00,Cluster based inference for extremes of time series,"['Holger Drees', 'Anja Janßen', 'Sebastian Neblung']","We introduce a new type of estimator for the spectral tail process of a
regularly varying time series. The approach is based on a characterizing
invariance property of the spectral tail process, which is incorporated into
the new estimator via a projection technique. We show uniform asymptotic
normality of this estimator, both in the case of known and of unknown index of
regular variation. In a simulation study the new procedure shows a more stable
performance than previously proposed estimators.",http://arxiv.org/pdf/2103.08512v1,math.ST
2021-03-15 10:00:23+00:00,Hierarchical forecasting with a top-down alignment of independent level forecasts,"['Matthias Anderer', 'Feng Li']","Hierarchical forecasting with intermittent time series is a challenge in both
research and empirical studies. Extensive research focuses on improving the
accuracy of each hierarchy, especially the intermittent time series at bottom
levels. Then hierarchical reconciliation could be used to improve the overall
performance further. In this paper, we present a
\emph{hierarchical-forecasting-with-alignment} approach that treats the bottom
level forecasts as mutable to ensure higher forecasting accuracy on the upper
levels of the hierarchy. We employ a pure deep learning forecasting approach
N-BEATS for continuous time series at the top levels and a widely used
tree-based algorithm LightGBM for the intermittent time series at the bottom
level. The \emph{hierarchical-forecasting-with-alignment} approach is a simple
yet effective variant of the bottom-up method, accounting for biases that are
difficult to observe at the bottom level. It allows suboptimal forecasts at the
lower level to retain a higher overall performance. The approach in this
empirical study was developed by the first author during the M5 Forecasting
Accuracy competition, ranking second place. The method is also business
orientated and could benefit for business strategic planning.",http://arxiv.org/pdf/2103.08250v4,stat.ML
2021-03-15 08:12:19+00:00,Interpretable Feature Construction for Time Series Extrinsic Regression,"['Dominique Gay', 'Alexis Bondu', 'Vincent Lemaire', 'Marc Boullé']","Supervised learning of time series data has been extensively studied for the
case of a categorical target variable. In some application domains, e.g.,
energy, environment and health monitoring, it occurs that the target variable
is numerical and the problem is known as time series extrinsic regression
(TSER). In the literature, some well-known time series classifiers have been
extended for TSER problems. As first benchmarking studies have focused on
predictive performance, very little attention has been given to
interpretability. To fill this gap, in this paper, we suggest an extension of a
Bayesian method for robust and interpretable feature construction and selection
in the context of TSER. Our approach exploits a relational way to tackle with
TSER: (i), we build various and simple representations of the time series which
are stored in a relational data scheme, then, (ii), a propositionalisation
technique (based on classical aggregation / selection functions from the
relational data field) is applied to build interpretable features from
secondary tables to ""flatten"" the data; and (iii), the constructed features are
filtered out through a Bayesian Maximum A Posteriori approach. The resulting
transformed data can be processed with various existing regressors.
Experimental validation on various benchmark data sets demonstrates the
benefits of the suggested approach.",http://arxiv.org/pdf/2103.10247v1,cs.LG
2021-03-14 20:40:52+00:00,Multivariate Count Time Series Modelling,['Konstantinos Fokianos'],"We review autoregressive models for the analysis of multivariate count time
series. In doing so, we discuss the choice of a suitable distribution for a
vectors of count random variables. This review focus on three main approaches
taken for multivariate count time series analysis: (a) integer autoregressive
processes, (b) parameter-driven models and (c) observation-driven models. The
aim of this work is to highlight some recent methodological developments and
propose some potentially useful research topics.",http://arxiv.org/pdf/2103.08028v2,stat.ME
2021-03-13 13:44:20+00:00,Spectral Temporal Graph Neural Network for Multivariate Time-series Forecasting,"['Defu Cao', 'Yujing Wang', 'Juanyong Duan', 'Ce Zhang', 'Xia Zhu', 'Conguri Huang', 'Yunhai Tong', 'Bixiong Xu', 'Jing Bai', 'Jie Tong', 'Qi Zhang']","Multivariate time-series forecasting plays a crucial role in many real-world
applications. It is a challenging problem as one needs to consider both
intra-series temporal correlations and inter-series correlations
simultaneously. Recently, there have been multiple works trying to capture both
correlations, but most, if not all of them only capture temporal correlations
in the time domain and resort to pre-defined priors as inter-series
relationships.
  In this paper, we propose Spectral Temporal Graph Neural Network (StemGNN) to
further improve the accuracy of multivariate time-series forecasting. StemGNN
captures inter-series correlations and temporal dependencies \textit{jointly}
in the \textit{spectral domain}. It combines Graph Fourier Transform (GFT)
which models inter-series correlations and Discrete Fourier Transform (DFT)
which models temporal dependencies in an end-to-end framework. After passing
through GFT and DFT, the spectral representations hold clear patterns and can
be predicted effectively by convolution and sequential learning modules.
Moreover, StemGNN learns inter-series correlations automatically from the data
without using pre-defined priors. We conduct extensive experiments on ten
real-world datasets to demonstrate the effectiveness of StemGNN. Code is
available at https://github.com/microsoft/StemGNN/",http://arxiv.org/pdf/2103.07719v1,cs.LG
2021-03-12 17:10:54+00:00,A resampling approach for causal inference on novel two-point time-series with application to identify risk factors for type-2 diabetes and cardiovascular disease,"['Xiaowu Dai', 'Saad Mouti', 'Marjorie Lima do Vale', 'Sumantra Ray', 'Jeffrey Bohn', 'Lisa Goldberg']","Two-point time-series data, characterized by baseline and follow-up
observations, are frequently encountered in health research. We study a novel
two-point time series structure without a control group, which is driven by an
observational routine clinical dataset collected to monitor key risk markers of
type-$2$ diabetes (T2D) and cardiovascular disease (CVD). We propose a
resampling approach called 'I-Rand' for independently sampling one of the two
time points for each individual and making inference on the estimated causal
effects based on matching methods. The proposed method is illustrated with data
from a service-based dietary intervention to promote a low-carbohydrate diet
(LCD), designed to impact risk of T2D and CVD. Baseline data contain a
pre-intervention health record of study participants, and health data after LCD
intervention are recorded at the follow-up visit, providing a two-point
time-series pattern without a parallel control group. Using this approach we
find that obesity is a significant risk factor of T2D and CVD, and an LCD
approach can significantly mitigate the risks of T2D and CVD. We provide code
that implements our method.",http://arxiv.org/pdf/2103.07410v2,stat.ME
2021-03-12 09:53:34+00:00,Visualising Deep Network's Time-Series Representations,"['Błażej Leporowski', 'Alexandros Iosifidis']","Despite the popularisation of machine learning models, more often than not,
they still operate as black boxes with no insight into what is happening inside
the model. There exist a few methods that allow to visualise and explain why a
model has made a certain prediction. Those methods, however, allow
visualisation of the link between the input and output of the model without
presenting how the model learns to represent the data used to train the model
as whole. In this paper, a method that addresses that issue is proposed, with a
focus on visualising multi-dimensional time-series data. Experiments on a
high-frequency stock market dataset show that the method provides fast and
discernible visualisations. Large datasets can be visualised quickly and on one
plot, which makes it easy for a user to compare the learned representations of
the data. The developed method successfully combines known techniques to
provide an insight into the inner workings of time-series classification
models.",http://arxiv.org/pdf/2103.07176v2,cs.LG
2021-03-10 15:57:21+00:00,Stationary subspace analysis based on second-order statistics,"['Lea Flumian', 'Markus Matilainen', 'Klaus Nordhausen', 'Sara Taskinen']","In stationary subspace analysis (SSA) one assumes that the observable
p-variate time series is a linear mixture of a k-variate nonstationary time
series and a (p-k)-variate stationary time series. The aim is then to estimate
the unmixing matrix which transforms the observed multivariate time series onto
stationary and nonstationary components. In the classical approach multivariate
data are projected onto stationary and nonstationary subspaces by minimizing a
Kullback-Leibler divergence between Gaussian distributions, and the method only
detects nonstationarities in the first two moments. In this paper we consider
SSA in a more general multivariate time series setting and propose SSA methods
which are able to detect nonstationarities in mean, variance and
autocorrelation, or in all of them. Simulation studies illustrate the
performances of proposed methods, and it is shown that especially the method
that detects all three types of nonstationarities performs well in various time
series settings. The paper is concluded with an illustrative example.",http://arxiv.org/pdf/2103.06148v1,stat.ME
2021-03-09 14:53:11+00:00,Generating Reliable Process Event Streams and Time Series Data based on Neural Networks,"['Tobias Herbert', 'Juergen Mangler', 'Stefanie Rinderle-Ma']","Domains such as manufacturing and medicine crave for continuous monitoring
and analysis of their processes, especially in combination with time series as
produced by sensors. Time series data can be exploited to, for example, explain
and predict concept drifts during runtime. Generally, a certain data volume is
required in order to produce meaningful analysis results. However, reliable
data sets are often missing, for example, if event streams and times series
data are collected separately, in case of a new process, or if it is too
expensive to obtain a sufficient data volume. Additional challenges arise with
preparing time series data from multiple event sources, variations in data
collection frequency, and concept drift. This paper proposes the GENLOG
approach to generate reliable event and time series data that follows the
distribution of the underlying input data set. GENLOG employs data resampling
and enables the user to select different parts of the log data to orchestrate
the training of a recurrent neural network for stream generation. The generated
data is sampled back to its original sample rate and is embedded into the
originating log data file. Overall, GENLOG can boost small data sets and
consequently the application of online process mining.",http://arxiv.org/pdf/2103.05462v3,cs.LG
2021-03-08 09:08:08+00:00,Discovering Multiple Phases of Dynamics by Dissecting Multivariate Time Series,"['Xiaodong Wang', 'Fushing Hsieh']","We proposed a data-driven approach to dissect multivariate time series in
order to discover multiple phases underlying dynamics of complex systems. This
computing approach is developed as a multiple-dimension version of Hierarchical
Factor Segmentation(HFS) technique. This expanded approach proposes a
systematic protocol of choosing various extreme events in multi-dimensional
space. Upon each chosen event, an empirical distribution of event-recurrence,
or waiting time between the excursions, is fitted by a geometric distribution
with time-varying parameters. Iterative fittings are performed across all
chosen events. We then collect and summarize the local recurrent patterns into
a global dynamic mechanism. Clustering is applied for partitioning the whole
time period into alternating segments, in which variables are identically
distributed. Feature weighting techniques are also considered to compensate for
some drawbacks of clustering. Our simulation results show that this expanded
approach can even detect systematic differences when the joint distribution
varies. In real data experiments, we analyze the relationship from returns,
trading volume, and transaction number of a single, as well as of multiple
stocks in S&P500. We can successfully not only map out volatile periods but
also provide potential associative links between stocks.",http://arxiv.org/pdf/2103.04615v1,stat.ME
2021-03-03 04:10:07+00:00,Dynamic Gaussian Mixture based Deep Generative Model For Robust Forecasting on Sparse Multivariate Time Series,"['Yinjun Wu', 'Jingchao Ni', 'Wei Cheng', 'Bo Zong', 'Dongjin Song', 'Zhengzhang Chen', 'Yanchi Liu', 'Xuchao Zhang', 'Haifeng Chen', 'Susan Davidson']","Forecasting on sparse multivariate time series (MTS) aims to model the
predictors of future values of time series given their incomplete past, which
is important for many emerging applications. However, most existing methods
process MTS's individually, and do not leverage the dynamic distributions
underlying the MTS's, leading to sub-optimal results when the sparsity is high.
To address this challenge, we propose a novel generative model, which tracks
the transition of latent clusters, instead of isolated feature representations,
to achieve robust modeling. It is characterized by a newly designed dynamic
Gaussian mixture distribution, which captures the dynamics of clustering
structures, and is used for emitting timeseries. The generative model is
parameterized by neural networks. A structured inference network is also
designed for enabling inductive analysis. A gating mechanism is further
introduced to dynamically tune the Gaussian mixture distributions. Extensive
experimental results on a variety of real-life datasets demonstrate the
effectiveness of our method.",http://arxiv.org/pdf/2103.02164v1,cs.LG
2021-03-03 02:53:39+00:00,Two-Stage Framework for Seasonal Time Series Forecasting,"['Qingyang Xu', 'Qingsong Wen', 'Liang Sun']","Seasonal time series Forecasting remains a challenging problem due to the
long-term dependency from seasonality. In this paper, we propose a two-stage
framework to forecast univariate seasonal time series. The first stage
explicitly learns the long-range time series structure in a time window beyond
the forecast horizon. By incorporating the learned long-range structure, the
second stage can enhance the prediction accuracy in the forecast horizon. In
both stages, we integrate the auto-regressive model with neural networks to
capture both linear and non-linear characteristics in time series. Our
framework achieves state-of-the-art performance on M4 Competition Hourly
datasets. In particular, we show that incorporating the intermediate results
generated in the first stage to existing forecast models can effectively
enhance their prediction performance.",http://arxiv.org/pdf/2103.02144v1,cs.LG
2021-03-02 22:23:27+00:00,Variance Reduced Training with Stratified Sampling for Forecasting Models,"['Yucheng Lu', 'Youngsuk Park', 'Lifan Chen', 'Yuyang Wang', 'Christopher De Sa', 'Dean Foster']","In large-scale time series forecasting, one often encounters the situation
where the temporal patterns of time series, while drifting over time, differ
from one another in the same dataset. In this paper, we provably show under
such heterogeneity, training a forecasting model with commonly used stochastic
optimizers (e.g. SGD) potentially suffers large variance on gradient
estimation, and thus incurs long-time training. We show that this issue can be
efficiently alleviated via stratification, which allows the optimizer to sample
from pre-grouped time series strata. For better trading-off gradient variance
and computation complexity, we further propose SCott (Stochastic Stratified
Control Variate Gradient Descent), a variance reduced SGD-style optimizer that
utilizes stratified sampling via control variate. In theory, we provide the
convergence guarantee of SCott on smooth non-convex objectives. Empirically, we
evaluate SCott and other baseline optimizers on both synthetic and real-world
time series forecasting problems, and demonstrate SCott converges faster with
respect to both iterations and wall clock time.",http://arxiv.org/pdf/2103.02062v2,cs.LG
2021-03-02 19:20:49+00:00,Improving Neural Networks for Time Series Forecasting using Data Augmentation and AutoML,"['Indrajeet Y. Javeri', 'Mohammadhossein Toutiaee', 'Ismailcem B. Arpinar', 'Tom W. Miller', 'John A. Miller']","Statistical methods such as the Box-Jenkins method for time-series
forecasting have been prominent since their development in 1970. Many
researchers rely on such models as they can be efficiently estimated and also
provide interpretability. However, advances in machine learning research
indicate that neural networks can be powerful data modeling techniques, as they
can give higher accuracy for a plethora of learning problems and datasets. In
the past, they have been tried on time-series forecasting as well, but their
overall results have not been significantly better than the statistical models
especially for intermediate length times series data. Their modeling capacities
are limited in cases where enough data may not be available to estimate the
large number of parameters that these non-linear models require. This paper
presents an easy to implement data augmentation method to significantly improve
the performance of such networks. Our method, Augmented-Neural-Network, which
involves using forecasts from statistical models, can help unlock the power of
neural networks on intermediate length time-series and produces competitive
results. It shows that data augmentation, when paired with Automated Machine
Learning techniques such as Neural Architecture Search, can help to find the
best neural architecture for a given time-series. Using the combination of
these, demonstrates significant enhancement in the forecasting accuracy of
three neural network-based models for a COVID-19 dataset, with a maximum
improvement in forecasting accuracy by 21.41%, 24.29%, and 16.42%,
respectively, over the neural networks that do not use augmented data.",http://arxiv.org/pdf/2103.01992v3,cs.LG
2021-03-02 18:05:43+00:00,A Spectral Enabled GAN for Time Series Data Generation,"['Kaleb E. Smith', 'Anthony O. Smith']","Time dependent data is a main source of information in today's data driven
world. Generating this type of data though has shown its challenges and made it
an interesting research area in the field of generative machine learning. One
such approach was that by Smith et al. who developed Time Series Generative
Adversarial Network (TSGAN) which showed promising performance in generating
time dependent data and the ability of few shot generation though being flawed
in certain aspects of training and learning. This paper looks to improve on the
results from TSGAN and address those flaws by unifying the training of the
independent networks in TSGAN and creating a dependency both in training and
learning. This improvement, called unified TSGAN (uTSGAN) was tested and
comapred both quantitatively and qualitatively to its predecessor on 70
benchmark time series data sets used in the community. uTSGAN showed to
outperform TSGAN in 80\% of the data sets by the same number of training epochs
and 60\% of the data sets in 3/4th the amount of training time or less while
maintaining the few shot generation ability with better FID scores across those
data sets.",http://arxiv.org/pdf/2103.01904v1,cs.LG
2021-03-02 09:55:05+00:00,Missing Value Imputation on Multidimensional Time Series,"['Parikshit Bansal', 'Prathamesh Deshpande', 'Sunita Sarawagi']","We present DeepMVI, a deep learning method for missing value imputation in
multidimensional time-series datasets. Missing values are commonplace in
decision support platforms that aggregate data over long time stretches from
disparate sources, and reliable data analytics calls for careful handling of
missing data. One strategy is imputing the missing values, and a wide variety
of algorithms exist spanning simple interpolation, matrix factorization methods
like SVD, statistical models like Kalman filters, and recent deep learning
methods. We show that often these provide worse results on aggregate analytics
compared to just excluding the missing data. DeepMVI uses a neural network to
combine fine-grained and coarse-grained patterns along a time series, and
trends from related series across categorical dimensions. After failing with
off-the-shelf neural architectures, we design our own network that includes a
temporal transformer with a novel convolutional window feature, and kernel
regression with learned embeddings. The parameters and their training are
designed carefully to generalize across different placements of missing blocks
and data characteristics. Experiments across nine real datasets, four different
missing scenarios, comparing seven existing methods show that DeepMVI is
significantly more accurate, reducing error by more than 50% in more than half
the cases, compared to the best existing method. Although slower than simpler
matrix factorization methods, we justify the increased time overheads by
showing that DeepMVI is the only option that provided overall more accurate
analytics than dropping missing values.",http://arxiv.org/pdf/2103.01600v3,cs.LG
2021-03-01 23:48:11+00:00,Posterior consistency for the spectral density of non-Gaussian stationary time series,"['Yifu Tang', 'Claudia Kirch', 'Jeong Eun Lee', 'Renate Meyer']","Various nonparametric approaches for Bayesian spectral density estimation of
stationary time series have been suggested in the literature, mostly based on
the Whittle likelihood approximation. A generalization of this approximation
has been proposed in Kirch et al. who prove posterior consistency for spectral
density estimation in combination with the Bernstein-Dirichlet process prior
for Gaussian time series. In this paper, we will extend the posterior
consistency result to non-Gaussian time series by employing a general
consistency theorem of Shalizi for dependent data and misspecified models. As a
special case, posterior consistency for the spectral density under the Whittle
likelihood as proposed by Choudhuri, Ghosal and Roy is also extended to
non-Gaussian time series. Small sample properties of this approach are
illustrated with several examples of non-Gaussian time series.",http://arxiv.org/pdf/2103.01357v3,math.ST
2021-03-01 16:46:13+00:00,Automated data-driven approach for gap filling in the time series using evolutionary learning,"['Mikhail Sarafanov', 'Nikolay O. Nikitin', 'Anna V. Kalyuzhnaya']","In the paper, we propose an adaptive data-driven model-based approach for
filling the gaps in time series. The approach is based on the automated
evolutionary identification of the optimal structure for a composite
data-driven model. It allows adapting the model for the effective gap-filling
in a specific dataset without the involvement of the data scientist. As a case
study, both synthetic and real datasets from different fields (environmental,
economic, etc) are used. The experiments confirm that the proposed approach
allows achieving the higher quality of the gap restoration and improve the
effectiveness of forecasting models.",http://arxiv.org/pdf/2103.01124v2,cs.LG
2021-03-01 16:40:47+00:00,DTW-Merge: A Novel Data Augmentation Technique for Time Series Classification,"['Mohammad Akyash', 'Hoda Mohammadzade', 'Hamid Behroozi']","In recent years, neural networks achieved much success in various
applications. The main challenge in training deep neural networks is the lack
of sufficient data to improve the model's generalization and avoid overfitting.
One of the solutions is to generate new training samples. This paper proposes a
novel data augmentation method for time series based on Dynamic Time Warping.
This method is inspired by the concept that warped parts of two time series
have similar temporal properties and therefore, exchanging them between the two
series generates a new training sample. The proposed method selects an element
of the optimal warping path randomly and then exchanges the segments that are
aligned together. Exploiting the proposed approach with recently introduced
ResNet reveals improved results on the 2018 UCR Time Series Classification
Archive. By employing Gradient-weighted Class Activation Mapping (Grad-CAM) and
Multidimensional Scaling (MDS), we manifest that our method extract more
discriminant features out of time series.",http://arxiv.org/pdf/2103.01119v2,cs.LG
2021-03-01 03:13:58+00:00,CLPVG: Circular limited penetrable visibility graph as a new network model for time series,"['Qi Xuan', 'Jinchao Zhou', 'Kunfeng Qiu', 'Dongwei Xu', 'Shilian Zheng', 'Xiaoniu Yang']","Visibility Graph (VG) transforms time series into graphs, facilitating signal
processing by advanced graph data mining algorithms. In this paper, based on
the classic Limited Penetrable Visibility Graph (LPVG) method, we propose a
novel nonlinear mapping method named Circular Limited Penetrable Visibility
Graph (CLPVG). The testing on degree distribution and clustering coefficient on
the generated graphs of typical time series validates that our CLPVG is able to
effectively capture the important features of time series and has better
anti-noise ability than traditional LPVG. The experiments on real-world
time-series datasets of radio signal and electroencephalogram (EEG) also
suggest that the structural features provided by CLPVG, rather than LPVG, are
more useful for time-series classification, leading to higher accuracy. And
this classification performance can be further enhanced through structural
feature expansion by adopting Subgraph Networks (SGN). All of these results
validate the effectiveness of our CLPVG model.",http://arxiv.org/pdf/2104.13772v1,cs.LG
2021-02-25 09:05:35+00:00,Time-Series Imputation with Wasserstein Interpolation for Optimal Look-Ahead-Bias and Variance Tradeoff,"['Jose Blanchet', 'Fernando Hernandez', 'Viet Anh Nguyen', 'Markus Pelger', 'Xuhui Zhang']","Missing time-series data is a prevalent practical problem. Imputation methods
in time-series data often are applied to the full panel data with the purpose
of training a model for a downstream out-of-sample task. For example, in
finance, imputation of missing returns may be applied prior to training a
portfolio optimization model. Unfortunately, this practice may result in a
look-ahead-bias in the future performance on the downstream task. There is an
inherent trade-off between the look-ahead-bias of using the full data set for
imputation and the larger variance in the imputation from using only the
training data. By connecting layers of information revealed in time, we propose
a Bayesian posterior consensus distribution which optimally controls the
variance and look-ahead-bias trade-off in the imputation. We demonstrate the
benefit of our methodology both in synthetic and real financial data.",http://arxiv.org/pdf/2102.12736v2,stat.ML
2021-02-25 00:59:01+00:00,Simultaneously Reconciled Quantile Forecasting of Hierarchically Related Time Series,"['Xing Han', 'Sambarta Dasgupta', 'Joydeep Ghosh']","Many real-life applications involve simultaneously forecasting multiple time
series that are hierarchically related via aggregation or disaggregation
operations. For instance, commercial organizations often want to forecast
inventories simultaneously at store, city, and state levels for resource
planning purposes. In such applications, it is important that the forecasts, in
addition to being reasonably accurate, are also consistent w.r.t one another.
Although forecasting such hierarchical time series has been pursued by
economists and data scientists, the current state-of-the-art models use strong
assumptions, e.g., all forecasts being unbiased estimates, noise distribution
being Gaussian. Besides, state-of-the-art models have not harnessed the power
of modern nonlinear models, especially ones based on deep learning. In this
paper, we propose using a flexible nonlinear model that optimizes quantile
regression loss coupled with suitable regularization terms to maintain the
consistency of forecasts across hierarchies. The theoretical framework
introduced herein can be applied to any forecasting model with an underlying
differentiable loss function. A proof of optimality of our proposed method is
also provided. Simulation studies over a range of datasets highlight the
efficacy of our approach.",http://arxiv.org/pdf/2102.12612v1,cs.LG
2021-02-24 22:12:05+00:00,Partially Hidden Markov Chain Linear Autoregressive model: inference and forecasting,"['Fatoumata Dama', 'Christine Sinoquet']","Time series subject to change in regime have attracted much interest in
domains such as econometry, finance or meteorology. For discrete-valued
regimes, some models such as the popular Hidden Markov Chain (HMC) describe
time series whose state process is unknown at all time-steps. Sometimes, time
series are firstly labelled thanks to some annotation function. Thus, another
category of models handles the case with regimes observed at all time-steps. We
present a novel model which addresses the intermediate case: (i) state
processes associated to such time series are modelled by Partially Hidden
Markov Chains (PHMCs); (ii) a linear autoregressive (LAR) model drives the
dynamics of the time series, within each regime. We describe a variant of the
expection maximization (EM) algorithm devoted to PHMC-LAR model learning. We
propose a hidden state inference procedure and a forecasting function that take
into account the observed states when existing. We assess inference and
prediction performances, and analyze EM convergence times for the new model,
using simulated data. We show the benefits of using partially observed states
to decrease EM convergence times. A fully labelled scheme with unreliable
labels also speeds up EM. This offers promising prospects to enhance PHMC-LAR
model selection. We also point out the robustness of PHMC-LAR to labelling
errors in inference task, when large training datasets and moderate labelling
error rates are considered. Finally, we highlight the remarkable robustness to
error labelling in the prediction task, over the whole range of error rates.",http://arxiv.org/pdf/2102.12584v1,cs.LG
2021-02-23 05:23:35+00:00,Model-Attentive Ensemble Learning for Sequence Modeling,"['Victor D. Bourgin', 'Ioana Bica', 'Mihaela van der Schaar']","Medical time-series datasets have unique characteristics that make prediction
tasks challenging. Most notably, patient trajectories often contain
longitudinal variations in their input-output relationships, generally referred
to as temporal conditional shift. Designing sequence models capable of adapting
to such time-varying distributions remains a prevailing problem. To address
this we present Model-Attentive Ensemble learning for Sequence modeling (MAES).
MAES is a mixture of time-series experts which leverages an attention-based
gating mechanism to specialize the experts on different sequence dynamics and
adaptively weight their predictions. We demonstrate that MAES significantly
out-performs popular sequence models on datasets subject to temporal shift.",http://arxiv.org/pdf/2102.11500v1,cs.LG
2021-02-23 04:42:05+00:00,When is Early Classification of Time Series Meaningful?,"['Renjie Wu', 'Audrey Der', 'Eamonn J. Keogh']","Since its introduction two decades ago, there has been increasing interest in
the problem of early classification of time series. This problem generalizes
classic time series classification to ask if we can classify a time series
subsequence with sufficient accuracy and confidence after seeing only some
prefix of a target pattern. The idea is that the earlier classification would
allow us to take immediate action, in a domain in which some practical
interventions are possible. For example, that intervention might be sounding an
alarm or applying the brakes in an automobile. In this work, we make a
surprising claim. In spite of the fact that there are dozens of papers on early
classification of time series, it is not clear that any of them could ever work
in a real-world setting. The problem is not with the algorithms per se but with
the vague and underspecified problem description. Essentially all algorithms
make implicit and unwarranted assumptions about the problem that will ensure
that they will be plagued by false positives and false negatives even if their
results suggested that they could obtain near-perfect results. We will explain
our findings with novel insights and experiments and offer recommendations to
the community.",http://arxiv.org/pdf/2102.11487v3,cs.LG
2021-02-21 19:52:36+00:00,Autocovariance Estimation in the Presence of Changepoints,"['Colin Gallagher', 'Rebecca Killick', 'Robert Lund', 'Xueheng Shi']","This article studies estimation of a stationary autocovariance structure in
the presence of an unknown number of mean shifts. Here, a Yule-Walker moment
estimator for the autoregressive parameters in a dependent time series
contaminated by mean shift changepoints is proposed and studied. The estimator
is based on first order differences of the series and is proven consistent and
asymptotically normal when the number of changepoints $m$ and the series length
$N$ satisfies $m/N \rightarrow 0$ as $N \rightarrow \infty$",http://arxiv.org/pdf/2102.10669v2,math.ST
2021-02-20 03:58:17+00:00,nTreeClus: a Tree-based Sequence Encoder for Clustering Categorical Series,"['Hadi Jahanshahi', 'Mustafa Gokce Baydogan']","The overwhelming presence of categorical/sequential data in diverse domains
emphasizes the importance of sequence mining. The challenging nature of
sequences proves the need for continuing research to find a more accurate and
faster approach providing a better understanding of their (dis)similarities.
This paper proposes a new Model-based approach for clustering sequence data,
namely nTreeClus. The proposed method deploys Tree-based Learners, k-mers, and
autoregressive models for categorical time series, culminating with a novel
numerical representation of the categorical sequences. Adopting this new
representation, we cluster sequences, considering the inherent patterns in
categorical time series. Accordingly, the model showed robustness to its
parameter. Under different simulated scenarios, nTreeClus improved the baseline
methods for various internal and external cluster validation metrics for up to
10.7% and 2.7%, respectively. The empirical evaluation using synthetic and real
datasets, protein sequences, and categorical time series showed that nTreeClus
is competitive or superior to most state-of-the-art algorithms.",http://arxiv.org/pdf/2102.10252v3,cs.LG
2021-02-20 02:24:33+00:00,Elastic Similarity and Distance Measures for Multivariate Time Series,"['Ahmed Shifaz', 'Charlotte Pelletier', 'Francois Petitjean', 'Geoffrey I. Webb']","This paper contributes multivariate versions of seven commonly used elastic
similarity and distance measures for time series data analytics. Elastic
similarity and distance measures are a class of similarity measures that can
compensate for misalignments in the time axis of time series data. We adapt two
existing strategies used in a multivariate version of the well-known Dynamic
Time Warping (DTW), namely, Independent and Dependent DTW, to these seven
measures.
  While these measures can be applied to various time series analysis tasks, we
demonstrate their utility on multivariate time series classification using the
nearest neighbor classifier. On 23 well-known datasets, we demonstrate that
each of the measures but one achieves the highest accuracy relative to others
on at least one dataset, supporting the value of developing a suite of
multivariate similarity and distance measures. We also demonstrate that there
are datasets for which either the dependent versions of all measures are more
accurate than their independent counterparts or vice versa. In addition, we
also construct a nearest neighbor-based ensemble of the measures and show that
it is competitive to other state-of-the-art single-strategy multivariate time
series classifiers.",http://arxiv.org/pdf/2102.10231v2,cs.LG
2021-02-18 07:47:43+00:00,Unsupervised Clustering of Time Series Signals using Neuromorphic Energy-Efficient Temporal Neural Networks,"['Shreyas Chaudhari', 'Harideep Nair', 'José M. F. Moura', 'John Paul Shen']","Unsupervised time series clustering is a challenging problem with diverse
industrial applications such as anomaly detection, bio-wearables, etc. These
applications typically involve small, low-power devices on the edge that
collect and process real-time sensory signals. State-of-the-art time-series
clustering methods perform some form of loss minimization that is extremely
computationally intensive from the perspective of edge devices. In this work,
we propose a neuromorphic approach to unsupervised time series clustering based
on Temporal Neural Networks that is capable of ultra low-power, continuous
online learning. We demonstrate its clustering performance on a subset of UCR
Time Series Archive datasets. Our results show that the proposed approach
either outperforms or performs similarly to most of the existing algorithms
while being far more amenable for efficient hardware implementation. Our
hardware assessment analysis shows that in 7 nm CMOS the proposed architecture,
on average, consumes only about 0.005 mm^2 die area and 22 uW power and can
process each signal with about 5 ns latency.",http://arxiv.org/pdf/2102.09200v1,cs.LG
2021-02-17 17:56:12+00:00,POLA: Online Time Series Prediction by Adaptive Learning Rates,['Wenyu Zhang'],"Online prediction for streaming time series data has practical use for many
real-world applications where downstream decisions depend on accurate forecasts
for the future. Deployment in dynamic environments requires models to adapt
quickly to changing data distributions without overfitting. We propose POLA
(Predicting Online by Learning rate Adaptation) to automatically regulate the
learning rate of recurrent neural network models to adapt to changing time
series patterns across time. POLA meta-learns the learning rate of the
stochastic gradient descent (SGD) algorithm by assimilating the prequential or
interleaved-test-then-train evaluation scheme for online prediction. We
evaluate POLA on two real-world datasets across three commonly-used recurrent
neural network models. POLA demonstrates overall comparable or better
predictive performance over other online prediction methods.",http://arxiv.org/pdf/2102.08907v1,cs.LG
2021-02-16 23:35:10+00:00,Pattern Sampling for Shapelet-based Time Series Classification,"['Atif Raza', 'Stefan Kramer']","Subsequence-based time series classification algorithms provide accurate and
interpretable models, but training these models is extremely computation
intensive. The asymptotic time complexity of subsequence-based algorithms
remains a higher-order polynomial, because these algorithms are based on
exhaustive search for highly discriminative subsequences. Pattern sampling has
been proposed as an effective alternative to mitigate the pattern explosion
phenomenon. Therefore, we employ pattern sampling to extract discriminative
features from discretized time series data. A weighted trie is created based on
the discretized time series data to sample highly discriminative patterns.
These sampled patterns are used to identify the shapelets which are used to
transform the time series classification problem into a feature-based
classification problem. Finally, a classification model can be trained using
any off-the-shelf algorithm. Creating a pattern sampler requires a small number
of patterns to be evaluated compared to an exhaustive search as employed by
previous approaches. Compared to previously proposed algorithms, our approach
requires considerably less computational and memory resources. Experiments
demonstrate how the proposed approach fares in terms of classification accuracy
and runtime performance.",http://arxiv.org/pdf/2102.08498v1,cs.LG
2021-02-16 17:50:51+00:00,Adaptive Weighting Scheme for Automatic Time-Series Data Augmentation,"['Elizabeth Fons', 'Paula Dawson', 'Xiao-jun Zeng', 'John Keane', 'Alexandros Iosifidis']","Data augmentation methods have been shown to be a fundamental technique to
improve generalization in tasks such as image, text and audio classification.
Recently, automated augmentation methods have led to further improvements on
image classification and object detection leading to state-of-the-art
performances. Nevertheless, little work has been done on time-series data, an
area that could greatly benefit from automated data augmentation given the
usually limited size of the datasets. We present two sample-adaptive automatic
weighting schemes for data augmentation: the first learns to weight the
contribution of the augmented samples to the loss, and the second method
selects a subset of transformations based on the ranking of the predicted
training loss. We validate our proposed methods on a large, noisy financial
dataset and on time-series datasets from the UCR archive. On the financial
dataset, we show that the methods in combination with a trading strategy lead
to improvements in annualized returns of over 50$\%$, and on the time-series
data we outperform state-of-the-art models on over half of the datasets, and
achieve similar performance in accuracy on the others.",http://arxiv.org/pdf/2102.08310v1,cs.LG
2021-02-16 16:05:38+00:00,Classification of multivariate weakly-labelled time-series with attention,"['Surayez Rahman', 'Chang Wei Tan']","This research identifies a gap in weakly-labelled multivariate time-series
classification (TSC), where state-of-the-art TSC models do not per-form well.
Weakly labelled time-series are time-series containing noise and significant
redundancies. In response to this gap, this paper proposes an approach of
exploiting context relevance of subsequences from previous subsequences to
improve classification accuracy. To achieve this, state-of-the-art Attention
algorithms are experimented in combination with the top CNN models for TSC (FCN
and ResNet), in an CNN-LSTM architecture. Attention is a popular strategy for
context extraction with exceptional performance in modern sequence-to-sequence
tasks. This paper shows how attention algorithms can be used for improved
weakly labelledTSC by evaluating models on a multivariate EEG time-series
dataset obtained using a commercial Emotiv headsets from participants
performing various activities while driving. These time-series are segmented
into sub-sequences and labelled to allow supervised TSC.",http://arxiv.org/pdf/2102.08245v3,cs.LG
2021-02-15 18:34:18+00:00,Network of Tensor Time Series,"['Baoyu Jing', 'Hanghang Tong', 'Yada Zhu']","Co-evolving time series appears in a multitude of applications such as
environmental monitoring, financial analysis, and smart transportation. This
paper aims to address the following challenges, including (C1) how to
incorporate explicit relationship networks of the time series; (C2) how to
model the implicit relationship of the temporal dynamics. We propose a novel
model called Network of Tensor Time Series, which is comprised of two modules,
including Tensor Graph Convolutional Network (TGCN) and Tensor Recurrent Neural
Network (TRNN). TGCN tackles the first challenge by generalizing Graph
Convolutional Network (GCN) for flat graphs to tensor graphs, which captures
the synergy between multiple graphs associated with the tensors. TRNN leverages
tensor decomposition to model the implicit relationships among co-evolving time
series. The experimental results on five real-world datasets demonstrate the
efficacy of the proposed method.",http://arxiv.org/pdf/2102.07736v3,cs.LG
2021-02-15 16:56:44+00:00,Geometric feature performance under downsampling for EEG classification tasks,"['Bryan Bischof', 'Eric Bunch']","We experimentally investigate a collection of feature engineering pipelines
for use with a CNN for classifying eyes-open or eyes-closed from
electroencephalogram (EEG) time-series from the Bonn dataset. Using the Takens'
embedding--a geometric representation of time-series--we construct simplicial
complexes from EEG data. We then compare $\epsilon$-series of Betti-numbers and
$\epsilon$-series of graph spectra (a novel construction)--two topological
invariants of the latent geometry from these complexes--to raw time series of
the EEG to fill in a gap in the literature for benchmarking. These methods,
inspired by Topological Data Analysis, are used for feature engineering to
capture local geometry of the time-series. Additionally, we test these feature
pipelines' robustness to downsampling and data reduction. This paper seeks to
establish clearer expectations for both time-series classification via
geometric features, and how CNNs for time-series respond to data of degraded
resolution.",http://arxiv.org/pdf/2102.07669v1,cs.LG
2021-02-15 12:49:14+00:00,Tight Risk Bound for High Dimensional Time Series Completion,"['Pierre Alquier', 'Nicolas Marie', 'Amélie Rosier']","Initially designed for independent datas, low-rank matrix completion was
successfully applied in many domains to the reconstruction of partially
observed high-dimensional time series. However, there is a lack of theory to
support the application of these methods to dependent datas. In this paper, we
propose a general model for multivariate, partially observed time series. We
show that the least-square method with a rank penalty leads to reconstruction
error of the same order as for independent datas. Moreover, when the time
series has some additional properties such as periodicity or smoothness, the
rate can actually be faster than in the independent case.",http://arxiv.org/pdf/2102.08178v3,math.ST
2021-02-13 21:22:40+00:00,Clustering Interval-Censored Time-Series for Disease Phenotyping,"['Irene Y. Chen', 'Rahul G. Krishnan', 'David Sontag']","Unsupervised learning is often used to uncover clusters in data. However,
different kinds of noise may impede the discovery of useful patterns from
real-world time-series data. In this work, we focus on mitigating the
interference of interval censoring in the task of clustering for disease
phenotyping. We develop a deep generative, continuous-time model of time-series
data that clusters time-series while correcting for censorship time. We provide
conditions under which clusters and the amount of delayed entry may be
identified from data under a noiseless model. On synthetic data, we demonstrate
accurate, stable, and interpretable results that outperform several benchmarks.
On real-world clinical datasets of heart failure and Parkinson's disease
patients, we study how interval censoring can adversely affect the task of
disease phenotyping. Our model corrects for this source of error and recovers
known clinical subtypes.",http://arxiv.org/pdf/2102.07005v4,stat.ML
2021-02-13 00:26:35+00:00,Domain Adaptation for Time Series Forecasting via Attention Sharing,"['Xiaoyong Jin', 'Youngsuk Park', 'Danielle C. Maddix', 'Hao Wang', 'Yuyang Wang']","Recently, deep neural networks have gained increasing popularity in the field
of time series forecasting. A primary reason for their success is their ability
to effectively capture complex temporal dynamics across multiple related time
series. The advantages of these deep forecasters only start to emerge in the
presence of a sufficient amount of data. This poses a challenge for typical
forecasting problems in practice, where there is a limited number of time
series or observations per time series, or both. To cope with this data
scarcity issue, we propose a novel domain adaptation framework, Domain
Adaptation Forecaster (DAF). DAF leverages statistical strengths from a
relevant domain with abundant data samples (source) to improve the performance
on the domain of interest with limited data (target). In particular, we use an
attention-based shared module with a domain discriminator across domains and
private modules for individual domains. We induce domain-invariant latent
features (queries and keys) and retrain domain-specific features (values)
simultaneously to enable joint training of forecasters on source and target
domains. A main insight is that our design of aligning keys allows the target
domain to leverage source time series even with different characteristics.
Extensive experiments on various domains demonstrate that our proposed method
outperforms state-of-the-art baselines on synthetic and real-world datasets,
and ablation studies verify the effectiveness of our design choices.",http://arxiv.org/pdf/2102.06828v9,cs.LG
2021-02-12 20:56:12+00:00,Statistical Power for Estimating Treatment Effects Using Difference-in-Differences and Comparative Interrupted Time Series Designs with Variation in Treatment Timing,['Peter Z. Schochet'],"This article develops new closed-form variance expressions for power analyses
for commonly used difference-in-differences (DID) and comparative interrupted
time series (CITS) panel data estimators. The main contribution is to
incorporate variation in treatment timing into the analysis. The power formulas
also account for other key design features that arise in practice:
autocorrelated errors, unequal measurement intervals, and clustering due to the
unit of treatment assignment. We consider power formulas for both
cross-sectional and longitudinal models and allow for covariates. An
illustrative power analysis provides guidance on appropriate sample sizes. The
key finding is that accounting for treatment timing increases required sample
sizes. Further, DID estimators have considerably more power than standard CITS
and ITS estimators. An available Shiny R dashboard performs the sample size
calculations for the considered estimators.",http://arxiv.org/pdf/2102.06770v2,stat.ME
2021-02-12 14:51:05+00:00,How Far Should We Look Back to Achieve Effective Real-Time Time-Series Anomaly Detection?,"['Ming-Chang Lee', 'Jia-Chun Lin', 'Ernst Gunnar Gran']","Anomaly detection is the process of identifying unexpected events or
ab-normalities in data, and it has been applied in many different areas such as
system monitoring, fraud detection, healthcare, intrusion detection, etc.
Providing real-time, lightweight, and proactive anomaly detection for time
series with neither human intervention nor domain knowledge could be highly
valuable since it reduces human effort and enables appropriate countermeasures
to be undertaken before a disastrous event occurs. To our knowledge, RePAD
(Real-time Proactive Anomaly Detection algorithm) is a generic approach with
all above-mentioned features. To achieve real-time and lightweight detection,
RePAD utilizes Long Short-Term Memory (LSTM) to detect whether or not each
upcoming data point is anomalous based on short-term historical data points.
However, it is unclear that how different amounts of historical data points
affect the performance of RePAD. Therefore, in this paper, we investigate the
impact of different amounts of historical data on RePAD by introducing a set of
performance metrics that cover novel detection accuracy measures, time
efficiency, readiness, and resource consumption, etc. Empirical experiments
based on real-world time series datasets are conducted to evaluate RePAD in
different scenarios, and the experimental results are presented and discussed.",http://arxiv.org/pdf/2102.06560v6,cs.LG
2021-02-11 14:33:39+00:00,Feature Selection for Multivariate Time Series via Network Pruning,"['Kang Gu', 'Soroush Vosoughi', 'Temiloluwa Prioleau']","In recent years, there has been an ever increasing amount of multivariate
time series (MTS) data in various domains, typically generated by a large
family of sensors such as wearable devices. This has led to the development of
novel learning methods on MTS data, with deep learning models dominating the
most recent advancements. Prior literature has primarily focused on designing
new network architectures for modeling temporal dependencies within MTS.
However, a less studied challenge is associated with high dimensionality of MTS
data. In this paper, we propose a novel neural component, namely Neural Feature
Selector (NFS), as an end-2-end solution for feature selection in MTS data.
Specifically, NFS is based on decomposed convolution design and includes two
modules: firstly each feature stream (a stream corresponds to an univariate
series of MTS) within MTS is processed by a temporal CNN independently; then an
aggregating CNN combines the processed streams to produce input for other
downstream networks. We evaluated the proposed NFS model on four real-world MTS
datasets and found that it achieves comparable results with state-of-the-art
methods while providing the benefit of feature selection. Our paper also
highlights the robustness and effectiveness of feature selection with NFS
compared to using recent autoencoder-based methods.",http://arxiv.org/pdf/2102.06024v3,cs.LG
2021-02-11 10:08:09+00:00,PatchX: Explaining Deep Models by Intelligible Pattern Patches for Time-series Classification,"['Dominique Mercier', 'Andreas Dengel', 'Sheraz Ahmed']","The classification of time-series data is pivotal for streaming data and
comes with many challenges. Although the amount of publicly available datasets
increases rapidly, deep neural models are only exploited in a few areas.
Traditional methods are still used very often compared to deep neural models.
These methods get preferred in safety-critical, financial, or medical fields
because of their interpretable results. However, their performance and
scale-ability are limited, and finding suitable explanations for time-series
classification tasks is challenging due to the concepts hidden in the numerical
time-series data. Visualizing complete time-series results in a cognitive
overload concerning our perception and leads to confusion. Therefore, we
believe that patch-wise processing of the data results in a more interpretable
representation. We propose a novel hybrid approach that utilizes deep neural
networks and traditional machine learning algorithms to introduce an
interpretable and scale-able time-series classification approach. Our method
first performs a fine-grained classification for the patches followed by sample
level classification.",http://arxiv.org/pdf/2102.05917v1,cs.LG
2021-02-11 03:26:11+00:00,"Causal Inference for Time series Analysis: Problems, Methods and Evaluation","['Raha Moraffah', 'Paras Sheth', 'Mansooreh Karami', 'Anchit Bhattacharya', 'Qianru Wang', 'Anique Tahir', 'Adrienne Raglin', 'Huan Liu']","Time series data is a collection of chronological observations which is
generated by several domains such as medical and financial fields. Over the
years, different tasks such as classification, forecasting, and clustering have
been proposed to analyze this type of data. Time series data has been also used
to study the effect of interventions over time. Moreover, in many fields of
science, learning the causal structure of dynamic systems and time series data
is considered an interesting task which plays an important role in scientific
discoveries. Estimating the effect of an intervention and identifying the
causal relations from the data can be performed via causal inference. Existing
surveys on time series discuss traditional tasks such as classification and
forecasting or explain the details of the approaches proposed to solve a
specific task. In this paper, we focus on two causal inference tasks, i.e.,
treatment effect estimation and causal discovery for time series data, and
provide a comprehensive review of the approaches in each task. Furthermore, we
curate a list of commonly used evaluation metrics and datasets for each task
and provide in-depth insight. These metrics and datasets can serve as
benchmarks for research in the field.",http://arxiv.org/pdf/2102.05829v1,cs.LG
2021-02-10 21:16:13+00:00,Self-supervised learning for fast and scalable time series hyper-parameter tuning,"['Peiyi Zhang', 'Xiaodong Jiang', 'Ginger M Holt', 'Nikolay Pavlovich Laptev', 'Caner Komurlu', 'Peng Gao', 'Yang Yu']","Hyper-parameters of time series models play an important role in time series
analysis. Slight differences in hyper-parameters might lead to very different
forecast results for a given model, and therefore, selecting good
hyper-parameter values is indispensable. Most of the existing generic
hyper-parameter tuning methods, such as Grid Search, Random Search, Bayesian
Optimal Search, are based on one key component - search, and thus they are
computationally expensive and cannot be applied to fast and scalable
time-series hyper-parameter tuning (HPT). We propose a self-supervised learning
framework for HPT (SSL-HPT), which uses time series features as inputs and
produces optimal hyper-parameters. SSL-HPT algorithm is 6-20x faster at getting
hyper-parameters compared to other search based algorithms while producing
comparable accurate forecasting results in various applications.",http://arxiv.org/pdf/2102.05740v1,cs.LG
2021-02-10 18:36:11+00:00,NAST: Non-Autoregressive Spatial-Temporal Transformer for Time Series Forecasting,"['Kai Chen', 'Guang Chen', 'Dan Xu', 'Lijun Zhang', 'Yuyao Huang', 'Alois Knoll']","Although Transformer has made breakthrough success in widespread domains
especially in Natural Language Processing (NLP), applying it to time series
forecasting is still a great challenge. In time series forecasting, the
autoregressive decoding of canonical Transformer models could introduce huge
accumulative errors inevitably. Besides, utilizing Transformer to deal with
spatial-temporal dependencies in the problem still faces tough difficulties.~To
tackle these limitations, this work is the first attempt to propose a
Non-Autoregressive Transformer architecture for time series forecasting, aiming
at overcoming the time delay and accumulative error issues in the canonical
Transformer. Moreover, we present a novel spatial-temporal attention mechanism,
building a bridge by a learned temporal influence map to fill the gaps between
the spatial and temporal attention, so that spatial and temporal dependencies
can be processed integrally. Empirically, we evaluate our model on diversified
ego-centric future localization datasets and demonstrate state-of-the-art
performance on both real-time and accuracy.",http://arxiv.org/pdf/2102.05624v2,cs.LG
2021-02-10 15:49:27+00:00,On Disentanglement in Gaussian Process Variational Autoencoders,"['Simon Bing', 'Vincent Fortuin', 'Gunnar Rätsch']","Complex multivariate time series arise in many fields, ranging from computer
vision to robotics or medicine. Often we are interested in the independent
underlying factors that give rise to the high-dimensional data we are
observing. While many models have been introduced to learn such disentangled
representations, only few attempt to explicitly exploit the structure of
sequential data. We investigate the disentanglement properties of Gaussian
process variational autoencoders, a class of models recently introduced that
have been successful in different tasks on time series data. Our model exploits
the temporal structure of the data by modeling each latent channel with a GP
prior and employing a structured variational distribution that can capture
dependencies in time. We demonstrate the competitiveness of our approach
against state-of-the-art unsupervised and weakly-supervised disentanglement
methods on a benchmark task. Moreover, we provide evidence that we can learn
meaningful disentangled representations on real-world medical time series data.",http://arxiv.org/pdf/2102.05507v1,stat.ML
2021-02-10 08:29:55+00:00,Forecasting Nonnegative Time Series via Sliding Mask Method (SMM) and Latent Clustered Forecast (LCF),"['Yohann de Castro', 'Luca Mencarelli']","We consider nonnegative time series forecasting framework. Based on recent
advances in Nonnegative Matrix Factorization (NMF) and Archetypal Analysis, we
introduce two procedures referred to as Sliding Mask Method (SMM) and Latent
Clustered Forecast (LCF). SMM is a simple and powerful method based on time
window prediction using Completion of Nonnegative Matrices. This new procedure
combines low nonnegative rank decomposition and matrix completion where the
hidden values are to be forecasted. LCF is two stage: it leverages archetypal
analysis for dimension reduction and clustering of time series, then it uses
any black-box supervised forecast solver on the clustered latent
representation. Theoretical guarantees on uniqueness and robustness of the
solution of NMF Completion-type problems are also provided for the first time.
Finally, numerical experiments on real-world and synthetic data-set confirms
forecasting accuracy for both the methodologies.",http://arxiv.org/pdf/2102.05314v1,cs.LG
2021-02-10 08:18:35+00:00,Conditional Loss and Deep Euler Scheme for Time Series Generation,"['Carl Remlinger', 'Joseph Mikael', 'Romuald Elie']","We introduce three new generative models for time series that are based on
Euler discretization of Stochastic Differential Equations (SDEs) and
Wasserstein metrics. Two of these methods rely on the adaptation of generative
adversarial networks (GANs) to time series. The third algorithm, called
Conditional Euler Generator (CEGEN), minimizes a dedicated distance between the
transition probability distributions over all time steps. In the context of Ito
processes, we provide theoretical guarantees that minimizing this criterion
implies accurate estimations of the drift and volatility parameters. We
demonstrate empirically that CEGEN outperforms state-of-the-art and GAN
generators on both marginal and temporal dynamics metrics. Besides, it
identifies accurate correlation structures in high dimension. When few data
points are available, we verify the effectiveness of CEGEN, when combined with
transfer learning methods on Monte Carlo simulations. Finally, we illustrate
the robustness of our method on various real-world datasets.",http://arxiv.org/pdf/2102.05313v5,stat.ML
2021-02-10 07:48:00+00:00,Inductive Granger Causal Modeling for Multivariate Time Series,"['Yunfei Chu', 'Xiaowei Wang', 'Jianxin Ma', 'Kunyang Jia', 'Jingren Zhou', 'Hongxia Yang']","Granger causal modeling is an emerging topic that can uncover Granger causal
relationship behind multivariate time series data. In many real-world systems,
it is common to encounter a large amount of multivariate time series data
collected from different individuals with sharing commonalities. However, there
are ongoing concerns regarding Granger causality's applicability in such large
scale complex scenarios, presenting both challenges and opportunities for
Granger causal structure reconstruction. Existing methods usually train a
distinct model for each individual, suffering from inefficiency and
over-fitting issues. To bridge this gap, we propose an Inductive GRanger cAusal
modeling (InGRA) framework for inductive Granger causality learning and common
causal structure detection on multivariate time series, which exploits the
shared commonalities underlying the different individuals. In particular, we
train one global model for individuals with different Granger causal structures
through a novel attention mechanism, called prototypical Granger causal
attention. The model can detect common causal structures for different
individuals and infer Granger causal structures for newly arrived individuals.
Extensive experiments, as well as an online A/B test on an E-commercial
advertising platform, demonstrate the superior performances of InGRA.",http://arxiv.org/pdf/2102.05298v1,cs.LG
2021-02-10 02:13:27+00:00,Early Abandoning and Pruning for Elastic Distances including Dynamic Time Warping,"['Matthieu Herrmann', 'Geoffrey I. Webb']","Nearest neighbor search under elastic distances is a key tool for time series
analysis, supporting many applications. However, straightforward
implementations of distances require $O(n^2)$ space and time complexities,
preventing these applications from scaling to long series. Much work has been
devoted to speeding up the NN search process, mostly with the development of
lower bounds, allowing to avoid costly distance computations when a given
threshold is exceeded. This threshold, provided by the similarity search
process, also allows to early abandon the computation of a distance itself.
Another approach, is to prune parts of the computation. All these techniques
are othogonal to each other. In this work, we develop a new generic strategy,
""EAPruned"", that tightly integrates pruning with early abandoning. We apply it
to six elastic distance measures: DTW, CDTW, WDTW, ERP, MSM and TWE, showing
substantial speedup in NN search applications. Pruning alone also shows
substantial speedup for some distances, benefiting applications beyond the
scope of NN search (e.g. requiring all pairwise distances), and hence where
early abandoning is not applicable. We~release our implementation as part of a
new C++ library for time series classification, along with easy to use
Python/Numpy bindings.",http://arxiv.org/pdf/2102.05221v2,cs.LG
2021-02-09 07:19:19+00:00,Meta-Learning for Koopman Spectral Analysis with Short Time-series,"['Tomoharu Iwata', 'Yoshinobu Kawahara']","Koopman spectral analysis has attracted attention for nonlinear dynamical
systems since we can analyze nonlinear dynamics with a linear regime by
embedding data into a Koopman space by a nonlinear function. For the analysis,
we need to find appropriate embedding functions. Although several neural
network-based methods have been proposed for learning embedding functions,
existing methods require long time-series for training neural networks. This
limitation prohibits performing Koopman spectral analysis in applications where
only short time-series are available. In this paper, we propose a meta-learning
method for estimating embedding functions from unseen short time-series by
exploiting knowledge learned from related but different time-series. With the
proposed method, a representation of a given short time-series is obtained by a
bidirectional LSTM for extracting its properties. The embedding function of the
short time-series is modeled by a neural network that depends on the
time-series representation. By sharing the LSTM and neural networks across
multiple time-series, we can learn common knowledge from different time-series
while modeling time-series-specific embedding functions with the time-series
representation. Our model is trained such that the expected test prediction
error is minimized with the episodic training framework. We experimentally
demonstrate that the proposed method achieves better performance in terms of
eigenvalue estimation and future prediction than existing methods.",http://arxiv.org/pdf/2102.04683v1,stat.ML
2021-02-08 10:31:48+00:00,Changepoint detection on a graph of time series,"['Karl L. Hallgren', 'Nicholas A. Heard', 'Melissa J. M. Turcotte']","When analysing multiple time series that may be subject to changepoints, it
is sometimes possible to specify a priori, by means of a graph, which pairs of
time series are likely to be impacted by simultaneous changepoints. This
article proposes an informative prior for changepoints which encodes the
information contained in the graph, inducing a changepoint model for multiple
time series that borrows strength across clusters of connected time series to
detect weak signals for synchronous changepoints. The graphical model for
changepoints is further extended to allow dependence between nearby but not
necessarily synchronous changepoints across neighbouring time series in the
graph. A novel reversible jump Markov chain Monte Carlo (MCMC) algorithm making
use of auxiliary variables is proposed to sample from the graphical changepoint
model. The merit of the proposed approach is demonstrated through a changepoint
analysis of computer network authentication logs from Los Alamos National
Laboratory (LANL), demonstrating an improvement at detecting weak signals for
network intrusions across users linked by network connectivity, whilst limiting
the number of false alerts.",http://arxiv.org/pdf/2102.04112v2,stat.ME
2021-02-06 17:40:56+00:00,Deep Semi-Supervised Learning for Time Series Classification,"['Jann Goschenhofer', 'Rasmus Hvingelby', 'David Rügamer', 'Janek Thomas', 'Moritz Wagner', 'Bernd Bischl']","While Semi-supervised learning has gained much attention in computer vision
on image data, yet limited research exists on its applicability in the time
series domain. In this work, we investigate the transferability of
state-of-the-art deep semi-supervised models from image to time series
classification. We discuss the necessary model adaptations, in particular an
appropriate model backbone architecture and the use of tailored data
augmentation strategies. Based on these adaptations, we explore the potential
of deep semi-supervised learning in the context of time series classification
by evaluating our methods on large public time series classification problems
with varying amounts of labelled samples. We perform extensive comparisons
under a decidedly realistic and appropriate evaluation scheme with a unified
reimplementation of all algorithms considered, which is yet lacking in the
field. We find that these transferred semi-supervised models show significant
performance gains over strong supervised, semi-supervised and self-supervised
alternatives, especially for scenarios with very few labelled samples.",http://arxiv.org/pdf/2102.03622v2,cs.LG
2021-02-05 18:41:25+00:00,NRTSI: Non-Recurrent Time Series Imputation,"['Siyuan Shan', 'Yang Li', 'Junier B. Oliva']","Time series imputation is a fundamental task for understanding time series
with missing data. Existing methods either do not directly handle
irregularly-sampled data or degrade severely with sparsely observed data. In
this work, we reformulate time series as permutation-equivariant sets and
propose a novel imputation model NRTSI that does not impose any recurrent
structures. Taking advantage of the permutation equivariant formulation, we
design a principled and efficient hierarchical imputation procedure. In
addition, NRTSI can directly handle irregularly-sampled time series, perform
multiple-mode stochastic imputation, and handle data with partially observed
dimensions. Empirically, we show that NRTSI achieves state-of-the-art
performance across a wide range of time series imputation benchmarks.",http://arxiv.org/pdf/2102.03340v3,cs.LG
2021-02-04 18:29:27+00:00,Classification of Categorical Time Series Using the Spectral Envelope and Optimal Scalings,"['Zeda Li', 'Scott A. Bruce', 'Tian Cai']","This article introduces a novel approach to the classification of categorical
time series under the supervised learning paradigm. To construct meaningful
features for categorical time series classification, we consider two relevant
quantities: the spectral envelope and its corresponding set of optimal
scalings. These quantities characterize oscillatory patterns in a categorical
time series as the largest possible power at each frequency, or spectral
envelope, obtained by assigning numerical values, or scalings, to categories
that optimally emphasize oscillations at each frequency. Our procedure combines
these two quantities to produce an interpretable and parsimonious feature-based
classifier that can be used to accurately determine group membership for
categorical time series. Classification consistency of the proposed method is
investigated, and simulation studies are used to demonstrate accuracy in
classifying categorical time series with various underlying group structures.
Finally, we use the proposed method to explore key differences in oscillatory
patterns of sleep stage time series for patients with different sleep disorders
and accurately classify patients accordingly.",http://arxiv.org/pdf/2102.02794v1,stat.ME
2021-02-03 14:46:01+00:00,Uncertain Time Series Classification With Shapelet Transform,"['Michael Franklin Mbouopda', 'Engelbert Mephu Nguifo']","Time series classification is a task that aims at classifying chronological
data. It is used in a diverse range of domains such as meteorology, medicine
and physics. In the last decade, many algorithms have been built to perform
this task with very appreciable accuracy. However, applications where time
series have uncertainty has been under-explored. Using uncertainty propagation
techniques, we propose a new uncertain dissimilarity measure based on Euclidean
distance. We then propose the uncertain shapelet transform algorithm for the
classification of uncertain time series. The large experiments we conducted on
state of the art datasets show the effectiveness of our contribution. The
source code of our contribution and the datasets we used are all available on a
public repository.",http://arxiv.org/pdf/2102.02090v1,cs.LG
2021-02-03 09:09:05+00:00,Time Series Classification via Topological Data Analysis,"['Alperen Karan', 'Atabey Kaygun']","In this paper, we develop topological data analysis methods for
classification tasks on univariate time series. As an application, we perform
binary and ternary classification tasks on two public datasets that consist of
physiological signals collected under stress and non-stress conditions. We
accomplish our goal by using persistent homology to engineer stable topological
features after we use a time delay embedding of the signals and perform a
subwindowing instead of using windows of fixed length. The combination of
methods we use can be applied to any univariate time series and in this
application allows us to reduce noise and use long window sizes without
incurring an extra computational cost. We then use machine learning models on
the features we algorithmically engineered to obtain higher accuracies with
fewer features.",http://arxiv.org/pdf/2102.01956v2,stat.ML
2021-02-03 08:43:35+00:00,A Frequency Domain Bootstrap for General Multivariate Stationary Processes,"['Marco Meyer', 'Efstathios Paparoditis']","For many relevant statistics of multivariate time series, no valid frequency
domain bootstrap procedures exist. This is mainly due to the fact that the
distribution of such statistics depends on the fourth-order moment structure of
the underlying process in nearly every scenario, except for some special cases
like Gaussian time series. In contrast to the univariate case, even additional
structural assumptions such as linearity of the multivariate process or a
standardization of the statistic of interest do not solve the problem. This
paper focuses on integrated periodogram statistics as well as functions thereof
and presents a new frequency domain bootstrap procedure for multivariate time
series, the multivariate frequency domain hybrid bootstrap (MFHB), to fill this
gap. Asymptotic validity of the MFHB procedure is established for general
classes of periodogram-based statistics and for stationary multivariate
processes satisfying rather weak dependence conditions. A simulation study is
carried out which compares the finite sample performance of the MFHB with that
of the moving block bootstrap.",http://arxiv.org/pdf/2102.01943v1,stat.ME
2021-02-02 22:33:37+00:00,Adaptive Frequency Band Analysis for Functional Time Series,"['Pramita Bagchi', 'Scott A. Bruce']","The frequency-domain properties of nonstationary functional time series often
contain valuable information. These properties are characterized through its
time-varying power spectrum. Practitioners seeking low-dimensional summary
measures of the power spectrum often partition frequencies into bands and
create collapsed measures of power within bands. However, standard frequency
bands have largely been developed through manual inspection of time series data
and may not adequately summarize power spectra. In this article, we propose a
framework for adaptive frequency band estimation of nonstationary functional
time series that optimally summarizes the time-varying dynamics of the series.
We develop a scan statistic and search algorithm to detect changes in the
frequency domain. We establish theoretical properties of this framework and
develop a computationally-efficient implementation. The validity of our method
is also justified through numerous simulation studies and an application to
analyzing electroencephalogram data in participants alternating between eyes
open and eyes closed conditions.",http://arxiv.org/pdf/2102.01784v2,stat.ME
2021-02-02 16:07:39+00:00,Policy Analysis using Synthetic Controls in Continuous-Time,"['Alexis Bellot', 'Mihaela van der Schaar']","Counterfactual estimation using synthetic controls is one of the most
successful recent methodological developments in causal inference. Despite its
popularity, the current description only considers time series aligned across
units and synthetic controls expressed as linear combinations of observed
control units. We propose a continuous-time alternative that models the latent
counterfactual path explicitly using the formalism of controlled differential
equations. This model is directly applicable to the general setting of
irregularly-aligned multivariate time series and may be optimized in rich
function spaces -- thereby improving on some limitations of existing
approaches.",http://arxiv.org/pdf/2102.01577v1,stat.ML
2021-02-02 06:15:15+00:00,Anomaly Detection of Time Series with Smoothness-Inducing Sequential Variational Auto-Encoder,"['Longyuan Li', 'Junchi Yan', 'Haiyang Wang', 'Yaohui Jin']","Deep generative models have demonstrated their effectiveness in learning
latent representation and modeling complex dependencies of time series. In this
paper, we present a Smoothness-Inducing Sequential Variational Auto-Encoder
(SISVAE) model for robust estimation and anomaly detection of multi-dimensional
time series. Our model is based on Variational Auto-Encoder (VAE), and its
backbone is fulfilled by a Recurrent Neural Network to capture latent temporal
structures of time series for both generative model and inference model.
Specifically, our model parameterizes mean and variance for each time-stamp
with flexible neural networks, resulting in a non-stationary model that can
work without the assumption of constant noise as commonly made by existing
Markov models. However, such a flexibility may cause the model fragile to
anomalies. To achieve robust density estimation which can also benefit
detection tasks, we propose a smoothness-inducing prior over possible
estimations. The proposed prior works as a regularizer that places penalty at
non-smooth reconstructions. Our model is learned efficiently with a novel
stochastic gradient variational Bayes estimator. In particular, we study two
decision criteria for anomaly detection: reconstruction probability and
reconstruction error. We show the effectiveness of our model on both synthetic
datasets and public real-world benchmarks.",http://arxiv.org/pdf/2102.01331v1,cs.LG
2021-02-01 09:49:15+00:00,Stochastic Online Convex Optimization. Application to probabilistic time series forecasting,['Olivier Wintenberger'],"We introduce a general framework of stochastic online convex optimization to
obtain fast-rate stochastic regret bounds. We prove that algorithms such as
online newton steps and a scale-free 10 version of Bernstein online aggregation
achieve best-known rates in unbounded stochastic settings. We apply our
approach to calibrate parametric probabilistic forecasters of non-stationary
sub-gaussian time series. Our fast-rate stochastic regret bounds are any-time
valid. Our proofs combine self-bounded and Poissonnian inequalities for
martingales and sub-gaussian random variables, respectively, under a stochastic
exp-concavity assumption.",http://arxiv.org/pdf/2102.00729v3,cs.LG
2021-01-31 14:04:10+00:00,MultiRocket: Multiple pooling operators and transformations for fast and effective time series classification,"['Chang Wei Tan', 'Angus Dempster', 'Christoph Bergmeir', 'Geoffrey I. Webb']","We propose MultiRocket, a fast time series classification (TSC) algorithm
that achieves state-of-the-art performance with a tiny fraction of the time and
without the complex ensembling structure of many state-of-the-art methods.
MultiRocket improves on MiniRocket, one of the fastest TSC algorithms to date,
by adding multiple pooling operators and transformations to improve the
diversity of the features generated. In addition to processing the raw input
series, MultiRocket also applies first order differences to transform the
original series. Convolutions are applied to both representations, and four
pooling operators are applied to the convolution outputs. When benchmarked
using the University of California Riverside TSC benchmark datasets,
MultiRocket is significantly more accurate than MiniRocket, and competitive
with the best ranked current method in terms of accuracy, HIVE-COTE 2.0, while
being orders of magnitude faster.",http://arxiv.org/pdf/2102.00457v4,cs.LG
2021-01-31 11:00:55+00:00,Synergetic Learning of Heterogeneous Temporal Sequences for Multi-Horizon Probabilistic Forecasting,"['Longyuan Li', 'Jihai Zhang', 'Junchi Yan', 'Yaohui Jin', 'Yunhao Zhang', 'Yanjie Duan', 'Guangjian Tian']","Time-series is ubiquitous across applications, such as transportation,
finance and healthcare. Time-series is often influenced by external factors,
especially in the form of asynchronous events, making forecasting difficult.
However, existing models are mainly designated for either synchronous
time-series or asynchronous event sequence, and can hardly provide a synthetic
way to capture the relation between them. We propose Variational Synergetic
Multi-Horizon Network (VSMHN), a novel deep conditional generative model. To
learn complex correlations across heterogeneous sequences, a tailored encoder
is devised to combine the advances in deep point processes models and
variational recurrent neural networks. In addition, an aligned time coding and
an auxiliary transition scheme are carefully devised for batched training on
unaligned sequences. Our model can be trained effectively using stochastic
variational inference and generates probabilistic predictions with Monte-Carlo
simulation. Furthermore, our model produces accurate, sharp and more realistic
probabilistic forecasts. We also show that modeling asynchronous event
sequences is crucial for multi-horizon time-series forecasting.",http://arxiv.org/pdf/2102.00431v1,cs.LG
2021-01-31 06:49:33+00:00,Learning Interpretable Deep State Space Model for Probabilistic Time Series Forecasting,"['Longyuan Li', 'Junchi Yan', 'Xiaokang Yang', 'Yaohui Jin']","Probabilistic time series forecasting involves estimating the distribution of
future based on its history, which is essential for risk management in
downstream decision-making. We propose a deep state space model for
probabilistic time series forecasting whereby the non-linear emission model and
transition model are parameterized by networks and the dependency is modeled by
recurrent neural nets. We take the automatic relevance determination (ARD) view
and devise a network to exploit the exogenous variables in addition to time
series. In particular, our ARD network can incorporate the uncertainty of the
exogenous variables and eventually helps identify useful exogenous variables
and suppress those irrelevant for forecasting. The distribution of multi-step
ahead forecasts are approximated by Monte Carlo simulation. We show in
experiments that our model produces accurate and sharp probabilistic forecasts.
The estimated uncertainty of our forecasting also realistically increases over
time, in a spontaneous manner.",http://arxiv.org/pdf/2102.00397v1,cs.LG
2021-01-30 10:58:15+00:00,Time Series (re)sampling using Generative Adversarial Networks,"['Christian M. Dahl', 'Emil N. Sørensen']","We propose a novel bootstrap procedure for dependent data based on Generative
Adversarial networks (GANs). We show that the dynamics of common stationary
time series processes can be learned by GANs and demonstrate that GANs trained
on a single sample path can be used to generate additional samples from the
process. We find that temporal convolutional neural networks provide a suitable
design for the generator and discriminator, and that convincing samples can be
generated on the basis of a vector of iid normal noise. We demonstrate the
finite sample properties of GAN sampling and the suggested bootstrap using
simulations where we compare the performance to circular block bootstrapping in
the case of resampling an AR(1) time series processes. We find that resampling
using the GAN can outperform circular block bootstrapping in terms of empirical
coverage.",http://arxiv.org/pdf/2102.00208v1,cs.LG
2021-01-29 08:31:38+00:00,AGSTN: Learning Attention-adjusted Graph Spatio-Temporal Networks for Short-term Urban Sensor Value Forecasting,"['Yi-Ju Lu', 'Cheng-Te Li']","Forecasting spatio-temporal correlated time series of sensor values is
crucial in urban applications, such as air pollution alert, biking resource
management, and intelligent transportation systems. While recent advances
exploit graph neural networks (GNN) to better learn spatial and temporal
dependencies between sensors, they cannot model time-evolving spatio-temporal
correlation (STC) between sensors, and require pre-defined graphs, which are
neither always available nor totally reliable, and target at only a specific
type of sensor data at one time. Moreover, since the form of time-series
fluctuation is varied across sensors, a model needs to learn fluctuation
modulation. To tackle these issues, in this work, we propose a novel GNN-based
model, Attention-adjusted Graph Spatio-Temporal Network (AGSTN). In AGSTN,
multi-graph convolution with sequential learning is developed to learn
time-evolving STC. Fluctuation modulation is realized by a proposed attention
adjustment mechanism. Experiments on three sensor data, air quality, bike
demand, and traffic flow, exhibit that AGSTN outperforms the state-of-the-art
methods.",http://arxiv.org/pdf/2101.12465v1,cs.LG
2021-01-28 04:25:51+00:00,Adjusting for Autocorrelated Errors in Neural Networks for Time Series,"['Fan-Keng Sun', 'Christopher I. Lang', 'Duane S. Boning']","An increasing body of research focuses on using neural networks to model time
series. A common assumption in training neural networks via maximum likelihood
estimation on time series is that the errors across time steps are
uncorrelated. However, errors are actually autocorrelated in many cases due to
the temporality of the data, which makes such maximum likelihood estimations
inaccurate. In this paper, in order to adjust for autocorrelated errors, we
propose to learn the autocorrelation coefficient jointly with the model
parameters. In our experiments, we verify the effectiveness of our approach on
time series forecasting. Results across a wide range of real-world datasets
with various state-of-the-art models show that our method enhances performance
in almost all cases. Based on these results, we suggest empirical critical
values to determine the severity of autocorrelated errors. We also analyze
several aspects of our method to demonstrate its advantages. Finally, other
time series tasks are also considered to validate that our method is not
restricted to only forecasting.",http://arxiv.org/pdf/2101.12578v4,cs.LG
2021-01-26 10:42:57+00:00,A fast algorithm for complex discord searches in time series: HOT SAX Time,"['Paolo Avogadro', 'Matteo Alessandro Dominoni']","Time series analysis is quickly proceeding towards long and complex tasks. In
recent years, fast approximate algorithms for discord search have been proposed
in order to compensate for the increasing size of the time series. It is more
interesting, however, to find quick exact solutions. In this research, we
improved HOT SAX by exploiting two main ideas: the warm-up process, and the
similarity between sequences close in time. The resulting algorithm, called HOT
SAX Time (HST), has been validated with real and synthetic time series, and
successfully compared with HOT SAX, RRA, SCAMP, and DADD. The complexity of a
discord search has been evaluated with a new indicator, the cost per sequence
(cps), which allows one to compare searches on time series of different
lengths. Numerical evidence suggests that two conditions are involved in
determining the complexity of a discord search in a non-trivial way: the length
of the discords, and the noise/signal ratio. In the case of complex searches,
HST can be more than 100 times faster than HOT SAX, thus being at the forefront
of the exact discord search.",http://arxiv.org/pdf/2101.10698v1,cs.LG
2021-01-25 22:29:40+00:00,Temporal Latent Auto-Encoder: A Method for Probabilistic Multivariate Time Series Forecasting,"['Nam Nguyen', 'Brian Quanz']","Probabilistic forecasting of high dimensional multivariate time series is a
notoriously challenging task, both in terms of computational burden and
distribution modeling. Most previous work either makes simple distribution
assumptions or abandons modeling cross-series correlations. A promising line of
work exploits scalable matrix factorization for latent-space forecasting, but
is limited to linear embeddings, unable to model distributions, and not
trainable end-to-end when using deep learning forecasting. We introduce a novel
temporal latent auto-encoder method which enables nonlinear factorization of
multivariate time series, learned end-to-end with a temporal deep learning
latent space forecast model. By imposing a probabilistic latent space model,
complex distributions of the input series are modeled via the decoder.
Extensive experiments demonstrate that our model achieves state-of-the-art
performance on many popular multivariate datasets, with gains sometimes as high
as $50\%$ for several standard metrics.",http://arxiv.org/pdf/2101.10460v1,cs.LG
2021-01-25 21:14:05+00:00,Spectrum Attention Mechanism for Time Series Classification,"['Shibo Zhou', 'Yu Pan']","Time series classification(TSC) has always been an important and challenging
research task. With the wide application of deep learning, more and more
researchers use deep learning models to solve TSC problems. Since time series
always contains a lot of noise, which has a negative impact on network
training, people usually filter the original data before training the network.
The existing schemes are to treat the filtering and training as two stages, and
the design of the filter requires expert experience, which increases the design
difficulty of the algorithm and is not universal. We note that the essence of
filtering is to filter out the insignificant frequency components and highlight
the important ones, which is similar to the attention mechanism. In this paper,
we propose an attention mechanism that acts on spectrum (SAM). The network can
assign appropriate weights to each frequency component to achieve adaptive
filtering. We use L1 regularization to further enhance the frequency screening
capability of SAM. We also propose a segmented-SAM (SSAM) to avoid the loss of
time domain information caused by using the spectrum of the whole sequence. In
which, a tumbling window is introduced to segment the original data. Then SAM
is applied to each segment to generate new features. We propose a heuristic
strategy to search for the appropriate number of segments. Experimental results
show that SSAM can produce better feature representations, make the network
converge faster, and improve the robustness and classification accuracy.",http://arxiv.org/pdf/2101.10420v1,cs.LG
2021-01-25 18:57:42+00:00,Multi-Time Attention Networks for Irregularly Sampled Time Series,"['Satya Narayan Shukla', 'Benjamin M. Marlin']","Irregular sampling occurs in many time series modeling applications where it
presents a significant challenge to standard deep learning models. This work is
motivated by the analysis of physiological time series data in electronic
health records, which are sparse, irregularly sampled, and multivariate. In
this paper, we propose a new deep learning framework for this setting that we
call Multi-Time Attention Networks. Multi-Time Attention Networks learn an
embedding of continuous-time values and use an attention mechanism to produce a
fixed-length representation of a time series containing a variable number of
observations. We investigate the performance of this framework on interpolation
and classification tasks using multiple datasets. Our results show that the
proposed approach performs as well or better than a range of baseline and
recently proposed models while offering significantly faster training times
than current state-of-the-art methods.",http://arxiv.org/pdf/2101.10318v2,cs.LG
2021-01-25 12:07:46+00:00,Optimizing Convergence for Iterative Learning of ARIMA for Stationary Time Series,"['Kevin Styp-Rekowski', 'Florian Schmidt', 'Odej Kao']","Forecasting of time series in continuous systems becomes an increasingly
relevant task due to recent developments in IoT and 5G. The popular forecasting
model ARIMA is applied to a large variety of applications for decades. An
online variant of ARIMA applies the Online Newton Step in order to learn the
underlying process of the time series. This optimization method has pitfalls
concerning the computational complexity and convergence. Thus, this work
focuses on the computational less expensive Online Gradient Descent
optimization method, which became popular for learning of neural networks in
recent years. For the iterative training of such models, we propose a new
approach combining different Online Gradient Descent learners (such as Adam,
AMSGrad, Adagrad, Nesterov) to achieve fast convergence. The evaluation on
synthetic data and experimental datasets show that the proposed approach
outperforms the existing methods resulting in an overall lower prediction
error.",http://arxiv.org/pdf/2101.10037v1,cs.LG
2021-01-25 10:02:50+00:00,Multi-view Integration Learning for Irregularly-sampled Clinical Time Series,"['Yurim Lee', 'Eunji Jun', 'Heung-Il Suk']","Electronic health record (EHR) data is sparse and irregular as it is recorded
at irregular time intervals, and different clinical variables are measured at
each observation point. In this work, we propose a multi-view features
integration learning from irregular multivariate time series data by
self-attention mechanism in an imputation-free manner. Specifically, we devise
a novel multi-integration attention module (MIAM) to extract complex
information inherent in irregular time series data. In particular, we
explicitly learn the relationships among the observed values, missing
indicators, and time interval between the consecutive observations,
simultaneously. The rationale behind our approach is the use of human knowledge
such as what to measure and when to measure in different situations, which are
indirectly represented in the data. In addition, we build an attention-based
decoder as a missing value imputer that helps empower the representation
learning of the inter-relations among multi-view observations for the
prediction task, which operates at the training phase only. We validated the
effectiveness of our method over the public MIMIC-III and PhysioNet challenge
2012 datasets by comparing with and outperforming the state-of-the-art methods
for in-hospital mortality prediction.",http://arxiv.org/pdf/2101.09986v2,cs.LG
2021-01-24 04:25:08+00:00,Multi-Task Time Series Forecasting With Shared Attention,"['Zekai Chen', 'Jiaze E', 'Xiao Zhang', 'Hao Sheng', 'Xiuzheng Cheng']","Time series forecasting is a key component in many industrial and business
decision processes and recurrent neural network (RNN) based models have
achieved impressive progress on various time series forecasting tasks. However,
most of the existing methods focus on single-task forecasting problems by
learning separately based on limited supervised objectives, which often suffer
from insufficient training instances. As the Transformer architecture and other
attention-based models have demonstrated its great capability of capturing long
term dependency, we propose two self-attention based sharing schemes for
multi-task time series forecasting which can train jointly across multiple
tasks. We augment a sequence of paralleled Transformer encoders with an
external public multi-head attention function, which is updated by all data of
all tasks. Experiments on a number of real-world multi-task time series
forecasting tasks show that our proposed architectures can not only outperform
the state-of-the-art single-task forecasting baselines but also outperform the
RNN-based multi-task forecasting method.",http://arxiv.org/pdf/2101.09645v1,cs.LG
2021-01-23 14:19:56+00:00,Short-term daily precipitation forecasting with seasonally-integrated autoencoder,['Donlapark Ponnoprat'],"Short-term precipitation forecasting is essential for planning of human
activities in multiple scales, ranging from individuals' planning, urban
management to flood prevention. Yet the short-term atmospheric dynamics are
highly nonlinear that it cannot be easily captured with classical time series
models. On the other hand, deep learning models are good at learning nonlinear
interactions, but they are not designed to deal with the seasonality in time
series. In this study, we aim to develop a forecasting model that can both
handle the nonlinearities and detect the seasonality hidden within the daily
precipitation data. To this end, we propose a seasonally-integrated autoencoder
(SSAE) consisting of two long short-term memory (LSTM) autoencoders: one for
learning short-term dynamics, and the other for learning the seasonality in the
time series. Our experimental results show that not only does the SSAE
outperform various time series models regardless of the climate type, but it
also has low output variance compared to other deep learning models. The
results also show that the seasonal component of the SSAE helped improve the
correlation between the forecast and the actual values from 4% at horizon 1 to
37% at horizon 3.",http://arxiv.org/pdf/2101.09509v1,cs.LG
2021-01-22 16:56:54+00:00,Graphical Models for Financial Time Series and Portfolio Selection,"['Ni Zhan', 'Yijia Sun', 'Aman Jakhar', 'He Liu']","We examine a variety of graphical models to construct optimal portfolios.
Graphical models such as PCA-KMeans, autoencoders, dynamic clustering, and
structural learning can capture the time varying patterns in the covariance
matrix and allow the creation of an optimal and robust portfolio. We compared
the resulting portfolios from the different models with baseline methods. In
many cases our graphical strategies generated steadily increasing returns with
low risk and outgrew the S&P 500 index. This work suggests that graphical
models can effectively learn the temporal dependencies in time series data and
are proved useful in asset management.",http://arxiv.org/pdf/2101.09214v1,cs.LG
2021-01-21 10:27:05+00:00,Information theoretic results for stationary time series and the Gaussian-generalized von Mises time series,['Riccardo Gatto'],"This chapter presents some novel information theoretic results for the
analysis of stationary time series in the frequency domain. In particular, the
spectral distribution that corresponds to the most uncertain or unpredictable
time series with some values of the autocovariance function fixed, is the
generalized von Mises spectral distribution. It is thus a maximum entropy
spectral distribution and the corresponding stationary time series is called
the generalized von Mises time series. The generalized von Mises distribution
is used in directional statistics for modelling planar directions that follow a
multimodal distribution. Furthermore, the Gaussian-generalized von Mises times
series is presented as the stationary time series that maximizes entropies in
frequency and time domains, respectively referred to as spectral and temporal
entropies. Parameter estimation and some computational aspects with this time
series are briefly analyzed.",http://arxiv.org/pdf/2101.08529v1,math.ST
2021-01-19 07:24:54+00:00,Optimizing Hyperparameters in CNNs using Bilevel Programming in Time Series Data,"['Taniya Seth', 'Pranab K. Muhuri']","Hyperparameter optimization has remained a central topic within the machine
learning community due to its ability to produce state-of-the-art results. With
the recent interest growing in the usage of CNNs for time series prediction, we
propose the notion of optimizing Hyperparameters in CNNs for the purpose of
time series prediction. In this position paper, we give away the idea of
modeling the concerned hyperparameter optimization problem using bilevel
programming.",http://arxiv.org/pdf/2101.07492v1,cs.LG
2021-01-19 02:41:45+00:00,Submodular Maximization via Taylor Series Approximation,"['Gözde Özcan', 'Armin Moharrer', 'Stratis Ioannidis']","We study submodular maximization problems with matroid constraints, in
particular, problems where the objective can be expressed via compositions of
analytic and multilinear functions. We show that for functions of this form,
the so-called continuous greedy algorithm attains a ratio arbitrarily close to
$(1-1/e) \approx 0.63$ using a deterministic estimation via Taylor series
approximation. This drastically reduces execution time over prior art that uses
sampling.",http://arxiv.org/pdf/2101.07423v1,cs.LG
2021-01-18 03:36:33+00:00,Discrete Graph Structure Learning for Forecasting Multiple Time Series,"['Chao Shang', 'Jie Chen', 'Jinbo Bi']","Time series forecasting is an extensively studied subject in statistics,
economics, and computer science. Exploration of the correlation and causation
among the variables in a multivariate time series shows promise in enhancing
the performance of a time series model. When using deep neural networks as
forecasting models, we hypothesize that exploiting the pairwise information
among multiple (multivariate) time series also improves their forecast. If an
explicit graph structure is known, graph neural networks (GNNs) have been
demonstrated as powerful tools to exploit the structure. In this work, we
propose learning the structure simultaneously with the GNN if the graph is
unknown. We cast the problem as learning a probabilistic graph model through
optimizing the mean performance over the graph distribution. The distribution
is parameterized by a neural network so that discrete graphs can be sampled
differentiably through reparameterization. Empirical evaluations show that our
method is simpler, more efficient, and better performing than a recently
proposed bilevel learning approach for graph structure learning, as well as a
broad array of forecasting models, either deep or non-deep learning based, and
graph or non-graph based.",http://arxiv.org/pdf/2101.06861v3,cs.LG
2021-01-17 23:34:55+00:00,Free congruence: an exploration of expanded similarity measures for time series data,['Lucas Cassiel Jacaruso'],"Time series similarity measures are highly relevant in a wide range of
emerging applications including training machine learning models,
classification, and predictive modeling. Standard similarity measures for time
series most often involve point-to-point distance measures including Euclidean
distance and Dynamic Time Warping. Such similarity measures fundamentally
require the fluctuation of values in the time series being compared to follow a
corresponding order or cadence for similarity to be established. This paper is
spurred by the exploration of a broader definition of similarity, namely one
that takes into account the sheer numerical resemblance between sets of
statistical properties for time series segments irrespectively of value
labeling. Further, the presence of common pattern components between time
series segments was examined even if they occur in a permuted order, which
would not necessarily satisfy the criteria of more conventional point-to-point
distance measures. Results were compared with those of Dynamic Time Warping on
the same data for context. Surprisingly, the test for the numerical resemblance
between sets of statistical properties established a stronger resemblance for
pairings of decline years with greater statistical significance than Dynamic
Time Warping on the particular data and sample size used.",http://arxiv.org/pdf/2101.08659v1,cs.LG
2021-01-13 13:00:51+00:00,"Untargeted, Targeted and Universal Adversarial Attacks and Defenses on Time Series","['Pradeep Rathore', 'Arghya Basak', 'Sri Harsha Nistala', 'Venkataramana Runkana']","Deep learning based models are vulnerable to adversarial attacks. These
attacks can be much more harmful in case of targeted attacks, where an attacker
tries not only to fool the deep learning model, but also to misguide the model
to predict a specific class. Such targeted and untargeted attacks are
specifically tailored for an individual sample and require addition of an
imperceptible noise to the sample. In contrast, universal adversarial attack
calculates a special imperceptible noise which can be added to any sample of
the given dataset so that, the deep learning model is forced to predict a wrong
class. To the best of our knowledge these targeted and universal attacks on
time series data have not been studied in any of the previous works. In this
work, we have performed untargeted, targeted and universal adversarial attacks
on UCR time series datasets. Our results show that deep learning based time
series classification models are vulnerable to these attacks. We also show that
universal adversarial attacks have good generalization property as it need only
a fraction of the training data. We have also performed adversarial training
based adversarial defense. Our results show that models trained adversarially
using Fast gradient sign method (FGSM), a single step attack, are able to
defend against FGSM as well as Basic iterative method (BIM), a popular
iterative attack.",http://arxiv.org/pdf/2101.05639v1,cs.LG
2021-01-12 20:08:18+00:00,Deep Cellular Recurrent Network for Efficient Analysis of Time-Series Data with Spatial Information,"['Lasitha Vidyaratne', 'Mahbubul Alam', 'Alexander Glandon', 'Anna Shabalina', 'Christopher Tennant', 'Khan Iftekharuddin']","Efficient processing of large-scale time series data is an intricate problem
in machine learning. Conventional sensor signal processing pipelines with hand
engineered feature extraction often involve huge computational cost with high
dimensional data. Deep recurrent neural networks have shown promise in
automated feature learning for improved time-series processing. However,
generic deep recurrent models grow in scale and depth with increased complexity
of the data. This is particularly challenging in presence of high dimensional
data with temporal and spatial characteristics. Consequently, this work
proposes a novel deep cellular recurrent neural network (DCRNN) architecture to
efficiently process complex multi-dimensional time series data with spatial
information. The cellular recurrent architecture in the proposed model allows
for location-aware synchronous processing of time series data from spatially
distributed sensor signal sources. Extensive trainable parameter sharing due to
cellularity in the proposed architecture ensures efficiency in the use of
recurrent processing units with high-dimensional inputs. This study also
investigates the versatility of the proposed DCRNN model for classification of
multi-class time series data from different application domains. Consequently,
the proposed DCRNN architecture is evaluated using two time-series datasets: a
multichannel scalp EEG dataset for seizure detection, and a machine fault
detection dataset obtained in-house. The results suggest that the proposed
architecture achieves state-of-the-art performance while utilizing
substantially less trainable parameters when compared to comparable methods in
the literature.",http://arxiv.org/pdf/2101.05608v1,cs.LG
2021-01-11 22:36:21+00:00,Challenges and approaches to time-series forecasting in data center telemetry: A Survey,"['Shruti Jadon', 'Jan Kanty Milczek', 'Ajit Patankar']","Time-series forecasting has been an important research domain for so many
years. Its applications include ECG predictions, sales forecasting, weather
conditions, even COVID-19 spread predictions. These applications have motivated
many researchers to figure out an optimal forecasting approach, but the
modeling approach also changes as the application domain changes. This work has
focused on reviewing different forecasting approaches for telemetry data
predictions collected at data centers. Forecasting of telemetry data is a
critical feature of network and data center management products. However, there
are multiple options of forecasting approaches that range from a simple linear
statistical model to high capacity deep learning architectures. In this paper,
we attempted to summarize and evaluate the performance of well known time
series forecasting techniques. We hope that this evaluation provides a
comprehensive summary to innovate in forecasting approaches for telemetry data.",http://arxiv.org/pdf/2101.04224v2,cs.LG
2021-01-11 22:03:02+00:00,General Hannan and Quinn Criterion for Common Time Series,['Kare Kamila'],"This paper aims to study data driven model selection criteria for a large
class of time series, which includes ARMA or AR($\infty$) processes, as well as
GARCH or ARCH($\infty$), APARCH and many others processes. We tackled the
challenging issue of designing adaptive criteria which enjoys the strong
consistency property. When the observations are generated from one of the
aforementioned models, the new criteria, select the true model almost surely
asymptotically. The proposed criteria are based on the minimization of a
penalized contrast akin to the Hannan and Quinn's criterion and then involved a
term which is known for most classical time series models and for more complex
models, this term can be data driven calibrated. Monte-Carlo experiments and an
illustrative example on the CAC 40 index are performed to highlight the
obtained results.",http://arxiv.org/pdf/2101.04210v1,math.ST
2021-01-11 17:23:46+00:00,Modelling Time-Varying Rankings with Autoregressive and Score-Driven Dynamics,"['Vladimír Holý', 'Jan Zouhar']","We develop a new statistical model to analyse time-varying ranking data. The
model can be used with a large number of ranked items, accommodates exogenous
time-varying covariates and partial rankings, and is estimated via the maximum
likelihood in a straightforward manner. Rankings are modelled using the
Plackett-Luce distribution with time-varying worth parameters that follow a
mean-reverting time series process. To capture the dependence of the worth
parameters on past rankings, we utilise the conditional score in the fashion of
the generalised autoregressive score (GAS) models. Simulation experiments show
that the small-sample properties of the maximum-likelihood estimator improve
rapidly with the length of the time series and suggest that statistical
inference relying on conventional Hessian-based standard errors is usable even
for medium-sized samples. In an empirical study, we apply the model to the
results of the Ice Hockey World Championships. We also discuss applications to
rankings based on underlying indices, repeated surveys, and non-parametric
efficiency analysis.",http://arxiv.org/pdf/2101.04040v2,stat.ME
2021-01-11 08:03:57+00:00,Hierarchical Clustering using Auto-encoded Compact Representation for Time-series Analysis,"['Soma Bandyopadhyay', 'Anish Datta', 'Arpan Pal']","Getting a robust time-series clustering with best choice of distance measure
and appropriate representation is always a challenge. We propose a novel
mechanism to identify the clusters combining learned compact representation of
time-series, Auto Encoded Compact Sequence (AECS) and hierarchical clustering
approach. Proposed algorithm aims to address the large computing time issue of
hierarchical clustering as learned latent representation AECS has a length much
less than the original length of time-series and at the same time want to
enhance its performance.Our algorithm exploits Recurrent Neural Network (RNN)
based under complete Sequence to Sequence(seq2seq) autoencoder and
agglomerative hierarchical clustering with a choice of best distance measure to
recommend the best clustering. Our scheme selects the best distance measure and
corresponding clustering for both univariate and multivariate time-series. We
have experimented with real-world time-series from UCR and UCI archive taken
from diverse application domains like health, smart-city, manufacturing etc.
Experimental results show that proposed method not only produce close to
benchmark results but also in some cases outperform the benchmark.",http://arxiv.org/pdf/2101.03742v1,cs.LG
2021-01-11 05:08:19+00:00,Condition Assessment of Stay Cables through Enhanced Time Series Classification Using a Deep Learning Approach,"['Zhiming Zhang', 'Jin Yan', 'Liangding Li', 'Hong Pan', 'Chuanzhi Dong']","This study proposes a data-driven method that detects cable damage from
measured cable forces by recognizing biased patterns from the intact
conditions. The proposed method solves the pattern recognition problem for
cable damage detection through time series classification (TSC) in deep
learning, considering that the cable's behavior can be implicitly represented
by the measured cable force series. A deep learning model, long short term
memory fully convolutional network (LSTM-FCN), is leveraged by assigning
appropriate inputs and representative class labels for the TSC problem, First,
a TSC classifier is trained and validated using the data collected under intact
conditions of stay cables, setting the segmented data series as input and the
cable (or cable pair) ID as class labels. Subsequently, the classifier is
tested using the data collected under possible damaged conditions. Finally, the
cable or cable pair corresponding to the least classification accuracy is
recommended as the most probable damaged cable or cable pair. The proposed
method was tested on an in-service cable-stayed bridge with damaged stay
cables. Two scenarios in the proposed TSC scheme were investigated: 1) raw time
series of cable forces were fed into the classifiers; and 2) cable force ratios
were inputted in the classifiers considering the possible variation of force
distribution between cable pairs due to cable damage. Combining the results of
TSC testing in these two scenarios, the cable with rupture was correctly
identified. This study proposes a data-driven methodology for cable damage
detection that requires the least data preprocessing and feature engineering,
which enables fast and convenient early detection in real applications.",http://arxiv.org/pdf/2101.03701v1,cs.LG
2021-01-08 08:35:15+00:00,NVAE-GAN Based Approach for Unsupervised Time Series Anomaly Detection,"['Liang Xu', 'Liying Zheng', 'Weijun Li', 'Zhenbo Chen', 'Weishun Song', 'Yue Deng', 'Yongzhe Chang', 'Jing Xiao', 'Bo Yuan']","In recent studies, Lots of work has been done to solve time series anomaly
detection by applying Variational Auto-Encoders (VAEs). Time series anomaly
detection is a very common but challenging task in many industries, which plays
an important role in network monitoring, facility maintenance, information
security, and so on. However, it is very difficult to detect anomalies in time
series with high accuracy, due to noisy data collected from real world, and
complicated abnormal patterns. From recent studies, we are inspired by Nouveau
VAE (NVAE) and propose our anomaly detection model: Time series to Image VAE
(T2IVAE), an unsupervised model based on NVAE for univariate series,
transforming 1D time series to 2D image as input, and adopting the
reconstruction error to detect anomalies. Besides, we also apply the Generative
Adversarial Networks based techniques to T2IVAE training strategy, aiming to
reduce the overfitting. We evaluate our model performance on three datasets,
and compare it with other several popular models using F1 score. T2IVAE
achieves 0.639 on Numenta Anomaly Benchmark, 0.651 on public dataset from NASA,
and 0.504 on our dataset collected from real-world scenario, outperforms other
comparison models.",http://arxiv.org/pdf/2101.02908v1,cs.LG
2021-01-06 10:36:57+00:00,A Comparison of Single and Multiple Changepoint Techniques for Time Series Data,"['Xueheng Shi', 'Colin Gallagher', 'Robert Lund', 'Rebecca Killick']","This paper describes and compares several prominent single and multiple
changepoint techniques for time series data. Due to their importance in
inferential matters, changepoint research on correlated data has accelerated
recently. Unfortunately, small perturbations in model assumptions can
drastically alter changepoint conclusions; for example, heavy positive
correlation in a time series can be misattributed to a mean shift should
correlation be ignored. This paper considers both single and multiple
changepoint techniques. The paper begins by examining cumulative sum (CUSUM)
and likelihood ratio tests and their variants for the single changepoint
problem; here, various statistics, boundary cropping scenarios, and scaling
methods (e.g., scaling to an extreme value or Brownian Bridge limit) are
compared. A recently developed test based on summing squared CUSUM statistics
over all times is shown to have realistic Type I errors and superior detection
power. The paper then turns to the multiple changepoint setting. Here,
penalized likelihoods drive the discourse, with AIC, BIC, mBIC, and MDL
penalties being considered. Binary and wild binary segmentation techniques are
also compared. We introduce a new distance metric specifically designed to
compare two multiple changepoint segmentations. Algorithmic and computational
concerns are discussed and simulations are provided to support all conclusions.
In the end, the multiple changepoint setting admits no clear methodological
winner, performance depending on the particular scenario. Nonetheless, some
practical guidance will emerge.",http://arxiv.org/pdf/2101.01960v1,stat.ME
2021-01-06 07:55:15+00:00,Factor Modelling for Clustering High-dimensional Time Series,"['Bo Zhang', 'Guangming Pan', 'Qiwei Yao', 'Wang Zhou']","We propose a new unsupervised learning method for clustering a large number
of time series based on a latent factor structure. Each cluster is
characterized by its own cluster-specific factors in addition to some common
factors which impact on all the time series concerned. Our setting also offers
the flexibility that some time series may not belong to any clusters. The
consistency with explicit convergence rates is established for the estimation
of the common factors, the cluster-specific factors, the latent clusters.
Numerical illustration with both simulated data as well as a real data example
is also reported. As a spin-off, the proposed new approach also advances
significantly the statistical inference for the factor model of Lam and Yao
(2012).",http://arxiv.org/pdf/2101.01908v2,math.ST
2021-01-06 00:40:47+00:00,Large-Scale Extended Granger Causality for Classification of Marijuana Users From Functional MRI,"['M. Ali Vosoughi', 'Axel Wismuller']","It has been shown in the literature that marijuana use is associated with
changes in brain network connectivity. We propose large-scale Extended Granger
Causality (lsXGC) and investigate whether it can capture such changes using
resting-state fMRI. This method combines dimension reduction with source
time-series augmentation and uses predictive time-series modeling for
estimating directed causal relationships among fMRI time-series. It is a
multivariate approach, since it is capable of identifying the interdependence
of time-series in the presence of all other time-series of the underlying
dynamic system. Here, we investigate whether this model can serve as a
biomarker for classifying marijuana users from typical controls using 126 adult
subjects with a childhood diagnosis of ADHD from the Addiction Connectome
Preprocessed Initiative (ACPI) database. We use brain connections estimated by
lsXGC as features for classification. After feature extraction, we perform
feature selection by Kendall's-tau rank correlation coefficient followed by
classification using a support vector machine. As a reference method, we
compare our results with cross-correlation, which is typically used in the
literature as a standard measure of functional connectivity. Within a
cross-validation scheme of 100 different training/test (90%/10%) data splits,
we obtain a mean accuracy range of [0.714, 0.985] and a mean Area Under the
receiver operating characteristic Curve (AUC) range of [0.779, 0.999] across
all tested numbers of features for lsXGC, which is significantly better than
results obtained with cross-correlation, namely mean accuracy of [0.728, 0.912]
and mean AUC of [0.825, 0.969]. Our results suggest the applicability of lsXGC
as a potential biomarker for marijuana use.",http://arxiv.org/pdf/2101.01832v1,cs.LG
2021-01-05 09:26:18+00:00,Data-Driven Copy-Paste Imputation for Energy Time Series,"['Moritz Weber', 'Marian Turowski', 'Hüseyin K. Çakmak', 'Ralf Mikut', 'Uwe Kühnapfel', 'Veit Hagenmeyer']","A cornerstone of the worldwide transition to smart grids are smart meters.
Smart meters typically collect and provide energy time series that are vital
for various applications, such as grid simulations, fault-detection, load
forecasting, load analysis, and load management. Unfortunately, these time
series are often characterized by missing values that must be handled before
the data can be used. A common approach to handle missing values in time series
is imputation. However, existing imputation methods are designed for power time
series and do not take into account the total energy of gaps, resulting in
jumps or constant shifts when imputing energy time series. In order to overcome
these issues, the present paper introduces the new Copy-Paste Imputation (CPI)
method for energy time series. The CPI method copies data blocks with similar
properties and pastes them into gaps of the time series while preserving the
total energy of each gap. The new method is evaluated on a real-world dataset
that contains six shares of artificially inserted missing values between 1 and
30%. It outperforms by far the three benchmark imputation methods selected for
comparison. The comparison furthermore shows that the CPI method uses matching
patterns and preserves the total energy of each gap while requiring only a
moderate run-time.",http://arxiv.org/pdf/2101.01423v1,cs.LG
2021-01-05 03:21:07+00:00,A Trainable Reconciliation Method for Hierarchical Time-Series,"['Davide Burba', 'Trista Chen']","In numerous applications, it is required to produce forecasts for multiple
time-series at different hierarchy levels. An obvious example is given by the
supply chain in which demand forecasting may be needed at a store, city, or
country level. The independent forecasts typically do not add up properly
because of the hierarchical constraints, so a reconciliation step is needed. In
this paper, we propose a new general, flexible, and easy-to-implement
reconciliation strategy based on an encoder-decoder neural network. By testing
our method on four real-world datasets, we show that it can consistently reach
or surpass the performance of existing methods in the reconciliation setting.",http://arxiv.org/pdf/2101.01329v1,cs.LG
2020-12-30 06:33:51+00:00,Ensembles of Localised Models for Time Series Forecasting,"['Rakshitha Godahewa', 'Kasun Bandara', 'Geoffrey I. Webb', 'Slawek Smyl', 'Christoph Bergmeir']","With large quantities of data typically available nowadays, forecasting
models that are trained across sets of time series, known as Global Forecasting
Models (GFM), are regularly outperforming traditional univariate forecasting
models that work on isolated series. As GFMs usually share the same set of
parameters across all time series, they often have the problem of not being
localised enough to a particular series, especially in situations where
datasets are heterogeneous. We study how ensembling techniques can be used with
generic GFMs and univariate models to solve this issue. Our work systematises
and compares relevant current approaches, namely clustering series and training
separate submodels per cluster, the so-called ensemble of specialists approach,
and building heterogeneous ensembles of global and local models. We fill some
gaps in the existing GFM localisation approaches, in particular by
incorporating varied clustering techniques such as feature-based clustering,
distance-based clustering and random clustering, and generalise them to use
different underlying GFM model types. We then propose a new methodology of
clustered ensembles where we train multiple GFMs on different clusters of
series, obtained by changing the number of clusters and cluster seeds. Using
Feed-forward Neural Networks, Recurrent Neural Networks, and Pooled Regression
models as the underlying GFMs, in our evaluation on eight publicly available
datasets, the proposed models are able to achieve significantly higher accuracy
than baseline GFM models and univariate forecasting methods.",http://arxiv.org/pdf/2012.15059v2,cs.LG
2020-12-23 04:45:52+00:00,Global Models for Time Series Forecasting: A Simulation Study,"['Hansika Hewamalage', 'Christoph Bergmeir', 'Kasun Bandara']","In the current context of Big Data, the nature of many forecasting problems
has changed from predicting isolated time series to predicting many time series
from similar sources. This has opened up the opportunity to develop competitive
global forecasting models that simultaneously learn from many time series. But,
it still remains unclear when global forecasting models can outperform the
univariate benchmarks, especially along the dimensions of the
homogeneity/heterogeneity of series, the complexity of patterns in the series,
the complexity of forecasting models, and the lengths/number of series. Our
study attempts to address this problem through investigating the effect from
these factors, by simulating a number of datasets that have controllable time
series characteristics. Specifically, we simulate time series from simple data
generating processes (DGP), such as Auto Regressive (AR) and Seasonal AR, to
complex DGPs, such as Chaotic Logistic Map, Self-Exciting Threshold
Auto-Regressive, and Mackey-Glass Equations. The data heterogeneity is
introduced by mixing time series generated from several DGPs into a single
dataset. The lengths and the number of series in the dataset are varied in
different scenarios. We perform experiments on these datasets using global
forecasting models including Recurrent Neural Networks (RNN), Feed-Forward
Neural Networks, Pooled Regression (PR) models and Light Gradient Boosting
Models (LGBM), and compare their performance against standard statistical
univariate forecasting techniques. Our experiments demonstrate that when
trained as global forecasting models, techniques such as RNNs and LGBMs, which
have complex non-linear modelling capabilities, are competitive methods in
general under challenging forecasting scenarios such as series having short
lengths, datasets with heterogeneous series and having minimal prior knowledge
of the patterns of the series.",http://arxiv.org/pdf/2012.12485v3,cs.LG
2020-12-22 02:30:40+00:00,Time Series Domain Adaptation via Sparse Associative Structure Alignment,"['Ruichu Cai', 'Jiawei Chen', 'Zijian Li', 'Wei Chen', 'Keli Zhang', 'Junjian Ye', 'Zhuozhang Li', 'Xiaoyan Yang', 'Zhenjie Zhang']","Domain adaptation on time series data is an important but challenging task.
Most of the existing works in this area are based on the learning of the
domain-invariant representation of the data with the help of restrictions like
MMD. However, such extraction of the domain-invariant representation is a
non-trivial task for time series data, due to the complex dependence among the
timestamps. In detail, in the fully dependent time series, a small change of
the time lags or the offsets may lead to difficulty in the domain invariant
extraction. Fortunately, the stability of the causality inspired us to explore
the domain invariant structure of the data. To reduce the difficulty in the
discovery of causal structure, we relax it to the sparse associative structure
and propose a novel sparse associative structure alignment model for domain
adaptation. First, we generate the segment set to exclude the obstacle of
offsets. Second, the intra-variables and inter-variables sparse attention
mechanisms are devised to extract associative structure time-series data with
considering time lags. Finally, the associative structure alignment is used to
guide the transfer of knowledge from the source domain to the target one.
Experimental studies not only verify the good performance of our methods on
three real-world datasets but also provide some insightful discoveries on the
transferred knowledge.",http://arxiv.org/pdf/2012.11797v2,cs.LG
2020-12-21 16:42:07+00:00,Multi-Faceted Representation Learning with Hybrid Architecture for Time Series Classification,"['Zhenyu Liu', 'Jian Cheng']","Time series classification problems exist in many fields and have been
explored for a couple of decades. However, they still remain challenging, and
their solutions need to be further improved for real-world applications in
terms of both accuracy and efficiency. In this paper, we propose a hybrid
neural architecture, called Self-Attentive Recurrent Convolutional Networks
(SARCoN), to learn multi-faceted representations for univariate time series.
SARCoN is the synthesis of long short-term memory networks with self-attentive
mechanisms and Fully Convolutional Networks, which work in parallel to learn
the representations of univariate time series from different perspectives. The
component modules of the proposed architecture are trained jointly in an
end-to-end manner and they classify the input time series in a cooperative way.
Due to its domain-agnostic nature, SARCoN is able to generalize a diversity of
domain tasks. Our experimental results show that, compared to the
state-of-the-art approaches for time series classification, the proposed
architecture can achieve remarkable improvements for a set of univariate time
series benchmarks from the UCR repository. Moreover, the self-attention and the
global average pooling in the proposed architecture enable visible
interpretability by facilitating the identification of the contribution regions
of the original time series. An overall analysis confirms that multi-faceted
representations of time series aid in capturing deep temporal corrections
within complex time series, which is essential for the improvement of time
series classification performance. Our work provides a novel angle that deepens
the understanding of time series classification, qualifying our proposed model
as an ideal choice for real-world applications.",http://arxiv.org/pdf/2012.11472v1,cs.LG
2020-12-16 23:48:00+00:00,Series Saliency: Temporal Interpretation for Multivariate Time Series Forecasting,"['Qingyi Pan', 'Wenbo Hu', 'Jun Zhu']","Time series forecasting is an important yet challenging task. Though deep
learning methods have recently been developed to give superior forecasting
results, it is crucial to improve the interpretability of time series models.
Previous interpretation methods, including the methods for general neural
networks and attention-based methods, mainly consider the interpretation in the
feature dimension while ignoring the crucial temporal dimension. In this paper,
we present the series saliency framework for temporal interpretation for
multivariate time series forecasting, which considers the forecasting
interpretation in both feature and temporal dimensions. By extracting the
""series images"" from the sliding windows of the time series, we apply the
saliency map segmentation following the smallest destroying region principle.
The series saliency framework can be employed to any well-defined deep learning
models and works as a data augmentation to get more accurate forecasts.
Experimental results on several real datasets demonstrate that our framework
generates temporal interpretations for the time series forecasting task while
produces accurate time series forecast.",http://arxiv.org/pdf/2012.09324v1,cs.LG
2020-12-16 08:24:09+00:00,MINIROCKET: A Very Fast (Almost) Deterministic Transform for Time Series Classification,"['Angus Dempster', 'Daniel F. Schmidt', 'Geoffrey I. Webb']","Until recently, the most accurate methods for time series classification were
limited by high computational complexity. ROCKET achieves state-of-the-art
accuracy with a fraction of the computational expense of most existing methods
by transforming input time series using random convolutional kernels, and using
the transformed features to train a linear classifier. We reformulate ROCKET
into a new method, MINIROCKET, making it up to 75 times faster on larger
datasets, and making it almost deterministic (and optionally, with additional
computational expense, fully deterministic), while maintaining essentially the
same accuracy. Using this method, it is possible to train and test a classifier
on all of 109 datasets from the UCR archive to state-of-the-art accuracy in
less than 10 minutes. MINIROCKET is significantly faster than any other method
of comparable accuracy (including ROCKET), and significantly more accurate than
any other method of even roughly-similar computational expense. As such, we
suggest that MINIROCKET should now be considered and used as the default
variant of ROCKET.",http://arxiv.org/pdf/2012.08791v2,cs.LG
2020-12-15 17:27:39+00:00,Detection of Anomalies in a Time Series Data using InfluxDB and Python,"['Tochukwu John Anih', 'Chika Amadi Bede', 'Chima Festus Umeokpala']","Analysis of water and environmental data is an important aspect of many
intelligent water and environmental system applications where inference from
such analysis plays a significant role in decision making. Quite often these
data that are collected through sensible sensors can be anomalous due to
different reasons such as systems breakdown, malfunctioning of sensor
detectors, and more. Regardless of their root causes, such data severely affect
the results of the subsequent analysis. This paper demonstrates data cleaning
and preparation for time-series data and further proposes cost-sensitive
machine learning algorithms as a solution to detect anomalous data points in
time-series data. The following models: Logistic Regression, Random Forest,
Support Vector Machines have been modified to support the cost-sensitive
learning which penalizes misclassified samples thereby minimizing the total
misclassification cost. Our results showed that Random Forest outperformed the
rest of the models at predicting the positive class (i.e anomalies). Applying
predictive model improvement techniques like data oversampling seems to provide
little or no improvement to the Random Forest model. Interestingly, with
recursive feature elimination, we achieved a better model performance thereby
reducing the dimensions in the data. Finally, with Influxdb and Kapacitor the
data was ingested and streamed to generate new data points to further evaluate
the model performance on unseen data, this will allow for early recognition of
undesirable changes in the drinking water quality and will enable the water
supply companies to rectify on a timely basis whatever undesirable changes
abound.",http://arxiv.org/pdf/2012.08439v1,cs.LG
2020-12-15 12:23:30+00:00,Manifold-based time series forecasting,"['Nikita Puchkin', 'Aleksandr Timofeev', 'Vladimir Spokoiny']","Prediction for high dimensional time series is a challenging task due to the
curse of dimensionality problem. Classical parametric models like ARIMA or VAR
require strong modeling assumptions and time stationarity and are often
overparametrized. This paper offers a new flexible approach using recent ideas
of manifold learning. The considered model includes linear models such as the
central subspace model and ARIMA as particular cases. The proposed procedure
combines manifold denoising techniques with a simple nonparametric prediction
by local averaging. The resulting procedure demonstrates a very reasonable
performance for real-life econometric time series. We also provide a
theoretical justification of the manifold estimation procedure.",http://arxiv.org/pdf/2012.08244v1,math.ST
2020-12-15 11:26:08+00:00,Long-term prediction intervals with many covariates,"['Sayar Karmakar', 'Marek Chudy', 'Wei Biao Wu']","Accurate forecasting is one of the fundamental focus in the literature of
econometric time-series. Often practitioners and policy makers want to predict
outcomes of an entire time horizon in the future instead of just a single
$k$-step ahead prediction. These series, apart from their own possible
non-linear dependence, are often also influenced by many external predictors.
In this paper, we construct prediction intervals of time-aggregated forecasts
in a high-dimensional regression setting. Our approach is based on quantiles of
residuals obtained by the popular LASSO routine. We allow for general
heavy-tailed, long-memory, and nonlinear stationary error process and
stochastic predictors. Through a series of systematically arranged consistency
results we provide theoretical guarantees of our proposed quantile-based method
in all of these scenarios. After validating our approach using simulations we
also propose a novel bootstrap based method that can boost the coverage of the
theoretical intervals. Finally analyzing the EPEX Spot data, we construct
prediction intervals for hourly electricity prices over horizons spanning 17
weeks and contrast them to selected Bayesian and bootstrap interval forecasts.",http://arxiv.org/pdf/2012.08223v2,stat.ME
2020-12-15 01:44:21+00:00,Proofs and additional experiments on Second order techniques for learning time-series with structural breaks,['Takayuki Osogami'],"We provide complete proofs of the lemmas about the properties of the
regularized loss function that is used in the second order techniques for
learning time-series with structural breaks in Osogami (2021). In addition, we
show experimental results that support the validity of the techniques.",http://arxiv.org/pdf/2012.08037v2,cs.LG
2020-12-14 11:43:09+00:00,Informer: Beyond Efficient Transformer for Long Sequence Time-Series Forecasting,"['Haoyi Zhou', 'Shanghang Zhang', 'Jieqi Peng', 'Shuai Zhang', 'Jianxin Li', 'Hui Xiong', 'Wancai Zhang']","Many real-world applications require the prediction of long sequence
time-series, such as electricity consumption planning. Long sequence
time-series forecasting (LSTF) demands a high prediction capacity of the model,
which is the ability to capture precise long-range dependency coupling between
output and input efficiently. Recent studies have shown the potential of
Transformer to increase the prediction capacity. However, there are several
severe issues with Transformer that prevent it from being directly applicable
to LSTF, including quadratic time complexity, high memory usage, and inherent
limitation of the encoder-decoder architecture. To address these issues, we
design an efficient transformer-based model for LSTF, named Informer, with
three distinctive characteristics: (i) a $ProbSparse$ self-attention mechanism,
which achieves $O(L \log L)$ in time complexity and memory usage, and has
comparable performance on sequences' dependency alignment. (ii) the
self-attention distilling highlights dominating attention by halving cascading
layer input, and efficiently handles extreme long input sequences. (iii) the
generative style decoder, while conceptually simple, predicts the long
time-series sequences at one forward operation rather than a step-by-step way,
which drastically improves the inference speed of long-sequence predictions.
Extensive experiments on four large-scale datasets demonstrate that Informer
significantly outperforms existing methods and provides a new solution to the
LSTF problem.",http://arxiv.org/pdf/2012.07436v3,cs.LG
2020-12-12 17:09:13+00:00,A Shift Test for Independence in Generic Time Series,['Kenneth D. Harris'],"We describe a family of conservative statistical tests for independence of
two autocorrelated time series. The series may take values in any sets, and one
of them must be stationary. A user-specified function quantifying the
association of a segment of the two series is compared to an ensemble obtained
by time-shifting the stationary series -N to N steps. If the series are
independent, the unshifted value is in the top m shifted values with
probability at most m/(N+1). For large N, the probability approaches m/(2N+1).
A conservative test rejects independence at significance {\alpha} if the
unshifted value is in the top {\alpha}(N+1), and has half the power of an
approximate test valid in the large N limit. We illustrate this framework with
a test for correlation of autocorrelated categorical time series.",http://arxiv.org/pdf/2012.06862v1,stat.ME
2020-12-12 02:36:40+00:00,Transformed-Linear Models for Time Series Extremes,"['Nehali Mhatre', 'Daniel Cooley']","In order to capture the dependence in the upper tail of a time series, we
develop non-negative regularly-varying time series models that are constructed
similarly to classical non-extreme ARMA models. Rather than fully
characterizing tail dependence of the time series, we define the concept of
weak tail stationarity which allows us to describe a regularly-varying time
series through the tail pairwise dependence function (TPDF) which is a measure
of pairwise extremal dependencies. We state consistency requirements among the
finite-dimensional collections of the elements of a regularly-varying time
series and show that the TPDF's value does not depend on the dimension being
considered. So that our models take nonnegative values, we use
transformed-linear operations. We show existence and stationarity of these
models, and develop their properties such as the model TPDF's. Additionally, we
show the class of transformed-linear MA($\infty$) models forms an inner product
space. Motivated by investigating conditions conducive to the spread of
wildfires, we fit models to hourly windspeed data and find that the fitted
transformed-linear models produce better estimates of upper tail quantities
than traditional ARMA models or than classical linear regularly varying models.",http://arxiv.org/pdf/2012.06705v3,stat.ME
2020-12-11 12:43:19+00:00,Sequential estimation of Spearman rank correlation using Hermite series estimators,"['Michael Stephanou', 'Melvin Varughese']","In this article we describe a new Hermite series based sequential estimator
for the Spearman rank correlation coefficient and provide algorithms applicable
in both the stationary and non-stationary settings. To treat the non-stationary
setting, we introduce a novel, exponentially weighted estimator for the
Spearman rank correlation, which allows the local nonparametric correlation of
a bivariate data stream to be tracked. To the best of our knowledge this is the
first algorithm to be proposed for estimating a time varying Spearman rank
correlation that does not rely on a moving window approach. We explore the
practical effectiveness of the Hermite series based estimators through real
data and simulation studies demonstrating good practical performance. The
simulation studies in particular reveal competitive performance compared to an
existing algorithm. The potential applications of this work are manifold. The
Hermite series based Spearman rank correlation estimator can be applied to fast
and robust online calculation of correlation which may vary over time. Possible
machine learning applications include, amongst others, fast feature selection
and hierarchical clustering on massive data sets.",http://arxiv.org/pdf/2012.06287v2,stat.ME
2020-12-09 09:39:48+00:00,Anomaly Detection in Time Series with Triadic Motif Fields and Application in Atrial Fibrillation ECG Classification,"['Yadong Zhang', 'Xin Chen']","In the time-series analysis, the time series motifs and the order patterns in
time series can reveal general temporal patterns and dynamic features. Triadic
Motif Field (TMF) is a simple and effective time-series image encoding method
based on triadic time series motifs. Electrocardiography (ECG) signals are
time-series data widely used to diagnose various cardiac anomalies. The TMF
images contain the features characterizing the normal and Atrial Fibrillation
(AF) ECG signals. Considering the quasi-periodic characteristics of ECG
signals, the dynamic features can be extracted from the TMF images with the
transfer learning pre-trained convolutional neural network (CNN) models. With
the extracted features, the simple classifiers, such as the Multi-Layer
Perceptron (MLP), the logistic regression, and the random forest, can be
applied for accurate anomaly detection. With the test dataset of the PhysioNet
Challenge 2017 database, the TMF classification model with the VGG16 transfer
learning model and MLP classifier demonstrates the best performance with the
95.50% ROC-AUC and 88.43% F1 score in the AF classification. Besides, the TMF
classification model can identify AF patients in the test dataset with high
precision. The feature vectors extracted from the TMF images show clear
patient-wise clustering with the t-distributed Stochastic Neighbor Embedding
technique. Above all, the TMF classification model has very good clinical
interpretability. The patterns revealed by symmetrized Gradient-weighted Class
Activation Mapping have a clear clinical interpretation at the beat and rhythm
levels.",http://arxiv.org/pdf/2012.04936v1,cs.LG
2020-12-09 04:36:34+00:00,Enhanced Recurrent Neural Tangent Kernels for Non-Time-Series Data,"['Sina Alemohammad', 'Randall Balestriero', 'Zichao Wang', 'Richard Baraniuk']","Kernels derived from deep neural networks (DNNs) in the infinite-width regime
provide not only high performance in a range of machine learning tasks but also
new theoretical insights into DNN training dynamics and generalization. In this
paper, we extend the family of kernels associated with recurrent neural
networks (RNNs), which were previously derived only for simple RNNs, to more
complex architectures including bidirectional RNNs and RNNs with average
pooling. We also develop a fast GPU implementation to exploit the full
practical potential of the kernels. Though RNNs are typically only applied to
time-series data, we demonstrate that classifiers using RNN-based kernels
outperform a range of baseline methods on 90 non-time-series datasets from the
UCI data repository.",http://arxiv.org/pdf/2012.04859v2,cs.LG
2020-12-08 21:51:21+00:00,Automatic Registration and Clustering of Time Series,"['Michael Weylandt', 'George Michailidis']","Clustering of time series data exhibits a number of challenges not present in
other settings, notably the problem of registration (alignment) of observed
signals. Typical approaches include pre-registration to a user-specified
template or time warping approaches which attempt to optimally align series
with a minimum of distortion. For many signals obtained from recording or
sensing devices, these methods may be unsuitable as a template signal is not
available for pre-registration, while the distortion of warping approaches may
obscure meaningful temporal information. We propose a new method for automatic
time series alignment within a clustering problem. Our approach, Temporal
Registration using Optimal Unitary Transformations (TROUT), is based on a novel
dissimilarity measure between time series that is easy to compute and
automatically identifies optimal alignment between pairs of time series. By
embedding our new measure in a optimization formulation, we retain well-known
advantages of computational and statistical performance. We provide an
efficient algorithm for TROUT-based clustering and demonstrate its superior
performance over a range of competitors.",http://arxiv.org/pdf/2012.04756v2,stat.ML
2020-12-08 10:33:57+00:00,An Empirical Study of Explainable AI Techniques on Deep Learning Models For Time Series Tasks,"['Udo Schlegel', 'Daniela Oelke', 'Daniel A. Keim', 'Mennatallah El-Assady']","Decision explanations of machine learning black-box models are often
generated by applying Explainable AI (XAI) techniques. However, many proposed
XAI methods produce unverified outputs. Evaluation and verification are usually
achieved with a visual interpretation by humans on individual images or text.
In this preregistration, we propose an empirical study and benchmark framework
to apply attribution methods for neural networks developed for images and text
data on time series. We present a methodology to automatically evaluate and
rank attribution techniques on time series using perturbation methods to
identify reliable approaches.",http://arxiv.org/pdf/2012.04344v1,cs.LG
2020-12-04 19:21:37+00:00,Learning summary features of time series for likelihood free inference,"['Pedro L. C. Rodrigues', 'Alexandre Gramfort']","There has been an increasing interest from the scientific community in using
likelihood-free inference (LFI) to determine which parameters of a given
simulator model could best describe a set of experimental data. Despite
exciting recent results and a wide range of possible applications, an important
bottleneck of LFI when applied to time series data is the necessity of defining
a set of summary features, often hand-tailored based on domain knowledge. In
this work, we present a data-driven strategy for automatically learning summary
features from univariate time series and apply it to signals generated from
autoregressive-moving-average (ARMA) models and the Van der Pol Oscillator. Our
results indicate that learning summary features from data can compete and even
outperform LFI methods based on hand-crafted values such as autocorrelation
coefficients even in the linear case.",http://arxiv.org/pdf/2012.02807v1,stat.ML
2020-12-02 09:14:30+00:00,Fast Automatic Feature Selection for Multi-Period Sliding Window Aggregate in Time Series,"['Rui An', 'Xingtian Shi', 'Baohan Xu']","As one of the most well-known artificial feature sampler, the sliding window
is widely used in scenarios where spatial and temporal information exists, such
as computer vision, natural language process, data stream, and time series.
Among which time series is common in many scenarios like credit card payment,
user behavior, and sensors. General feature selection for features extracted by
sliding window aggregate calls for time-consuming iteration to generate
features, and then traditional feature selection methods are employed to rank
them. The decision of key parameter, i.e. the period of sliding windows,
depends on the domain knowledge and calls for trivial. Currently, there is no
automatic method to handle the sliding window aggregate features selection. As
the time consumption of feature generation with different periods and sliding
windows is huge, it is very hard to enumerate them all and then select them.
  In this paper, we propose a general framework using Markov Chain to solve
this problem. This framework is very efficient and has high accuracy, such that
it is able to perform feature selection on a variety of features and period
options. We show the detail by 2 common sliding windows and 3 types of
aggregation operators. And it is easy to extend more sliding windows and
aggregation operators in this framework by employing existing theory about
Markov Chain.",http://arxiv.org/pdf/2012.01037v1,cs.LG
2020-12-01 18:37:56+00:00,Regular multidimensional stationary time series,['Tamás Szabados'],"The aim of this paper is to give a simpler, more usable sufficient condition
to the regularity of generic weakly stationary time series. Also, this
condition is used to show how regular processes satisfying these sufficient
conditions can be approximated by a lower rank \emph{regular} process. The
relevance of these issues is shown by the ever increasing presence of
high-dimensional data in many fields lately, and because of this, low rank
processes and low rank approximations are becoming more important. Moreover,
regular processes are the ones which are completely influenced by random
innovations, so they are primary targets both in the theory and applications.",http://arxiv.org/pdf/2012.00725v2,math.ST
2020-11-30 23:41:47+00:00,"A Survey on Principles, Models and Methods for Learning from Irregularly Sampled Time Series","['Satya Narayan Shukla', 'Benjamin M. Marlin']","Irregularly sampled time series data arise naturally in many application
domains including biology, ecology, climate science, astronomy, and health.
Such data represent fundamental challenges to many classical models from
machine learning and statistics due to the presence of non-uniform intervals
between observations. However, there has been significant progress within the
machine learning community over the last decade on developing specialized
models and architectures for learning from irregularly sampled univariate and
multivariate time series data. In this survey, we first describe several axes
along which approaches to learning from irregularly sampled time series differ
including what data representations they are based on, what modeling primitives
they leverage to deal with the fundamental problem of irregular sampling, and
what inference tasks they are designed to perform. We then survey the recent
literature organized primarily along the axis of modeling primitives. We
describe approaches based on temporal discretization, interpolation,
recurrence, attention and structural invariance. We discuss similarities and
differences between approaches and highlight primary strengths and weaknesses.",http://arxiv.org/pdf/2012.00168v2,cs.LG
2020-11-30 18:32:19+00:00,The Impact of Time Series Length and Discretization on Longitudinal Causal Estimation Methods,"['Roy Adams', 'Suchi Saria', 'Michael Rosenblum']","The use of observational time series data to assess the impact of multi-time
point interventions is becoming increasingly common as more health and activity
data are collected and digitized via wearables, social media, and electronic
health records. Such time series may involve hundreds or thousands of
irregularly sampled observations. One common analysis approach is to simplify
such time series by first discretizing them into sequences before applying a
discrete-time estimation method that adjusts for time-dependent confounding. In
certain settings, this discretization results in sequences with many time
points; however, the empirical properties of longitudinal causal estimators
have not been systematically compared on long sequences. We compare three
representative longitudinal causal estimation methods on simulated and real
clinical data. Our simulations and analyses assume a Markov structure and that
longitudinal treatments/exposures are binary-valued and have at most a single
jump point. We identify sources of bias that arise from temporally discretizing
the data and provide practical guidance for discretizing data and choosing
between methods when working with long sequences. Additionally, we compare
these estimators on real electronic health record data, evaluating the impact
of early treatment for patients with a life-threatening complication of
infection called sepsis.",http://arxiv.org/pdf/2011.15099v1,stat.ME
2020-11-28 09:36:18+00:00,Time Series Change Point Detection with Self-Supervised Contrastive Predictive Coding,"['Shohreh Deldari', 'Daniel V. Smith', 'Hao Xue', 'Flora D. Salim']","Change Point Detection (CPD) methods identify the times associated with
changes in the trends and properties of time series data in order to describe
the underlying behaviour of the system. For instance, detecting the changes and
anomalies associated with web service usage, application usage or human
behaviour can provide valuable insights for downstream modelling tasks. We
propose a novel approach for self-supervised Time Series Change Point detection
method based onContrastivePredictive coding (TS-CP^2). TS-CP^2 is the first
approach to employ a contrastive learning strategy for CPD by learning an
embedded representation that separates pairs of embeddings of time adjacent
intervals from pairs of interval embeddings separated across time. Through
extensive experiments on three diverse, widely used time series datasets, we
demonstrate that our method outperforms five state-of-the-art CPD methods,
which include unsupervised and semi-supervisedapproaches. TS-CP^2 is shown to
improve the performance of methods that use either handcrafted statistical or
temporal features by 79.4% and deep learning-based methods by 17.0% with
respect to the F1-score averaged across the three datasets.",http://arxiv.org/pdf/2011.14097v5,cs.LG
2020-11-27 21:16:48+00:00,Functional Autoregressive Processes in Reproducing Kernel Hilbert Spaces,"['Daren Wang', 'Zifeng Zhao', 'Rebecca Willett', 'Chun Yip Yau']","We study the estimation and prediction of functional autoregressive~(FAR)
processes, a statistical tool for modeling functional time series data. Due to
the infinite-dimensional nature of FAR processes, the existing literature
addresses its inference via dimension reduction and theoretical results therein
require the (unrealistic) assumption of fully observed functional time series.
We propose an alternative inference framework based on Reproducing Kernel
Hilbert Spaces~(RKHS). Specifically, a nuclear norm regularization method is
proposed for estimating the transition operators of the FAR process directly
from discrete samples of the functional time series. We derive a representer
theorem for the FAR process, which enables infinite-dimensional inference
without dimension reduction. Sharp theoretical guarantees are established under
the (more realistic) assumption that we only have finite discrete samples of
the FAR process. Extensive numerical experiments and a real data application of
energy consumption prediction are further conducted to illustrate the promising
performance of the proposed approach compared to the state-of-the-art methods
in the literature.",http://arxiv.org/pdf/2011.13993v1,stat.ME
2020-11-27 04:04:17+00:00,Self-Supervised Time Series Representation Learning by Inter-Intra Relational Reasoning,"['Haoyi Fan', 'Fengbin Zhang', 'Yue Gao']","Self-supervised learning achieves superior performance in many domains by
extracting useful representations from the unlabeled data. However, most of
traditional self-supervised methods mainly focus on exploring the inter-sample
structure while less efforts have been concentrated on the underlying
intra-temporal structure, which is important for time series data. In this
paper, we present SelfTime: a general self-supervised time series
representation learning framework, by exploring the inter-sample relation and
intra-temporal relation of time series to learn the underlying structure
feature on the unlabeled time series. Specifically, we first generate the
inter-sample relation by sampling positive and negative samples of a given
anchor sample, and intra-temporal relation by sampling time pieces from this
anchor. Then, based on the sampled relation, a shared feature extraction
backbone combined with two separate relation reasoning heads are employed to
quantify the relationships of the sample pairs for inter-sample relation
reasoning, and the relationships of the time piece pairs for intra-temporal
relation reasoning, respectively. Finally, the useful representations of time
series are extracted from the backbone under the supervision of relation
reasoning heads. Experimental results on multiple real-world time series
datasets for time series classification task demonstrate the effectiveness of
the proposed method. Code and data are publicly available at
https://haoyfan.github.io/.",http://arxiv.org/pdf/2011.13548v1,cs.LG
2020-11-26 08:29:50+00:00,Explainable Tensorized Neural Ordinary Differential Equations forArbitrary-step Time Series Prediction,"['Penglei Gao', 'Xi Yang', 'Rui Zhang', 'Kaizhu Huang']","We propose a continuous neural network architecture, termed Explainable
Tensorized Neural Ordinary Differential Equations (ETN-ODE), for multi-step
time series prediction at arbitrary time points. Unlike the existing
approaches, which mainly handle univariate time series for multi-step
prediction or multivariate time series for single-step prediction, ETN-ODE
could model multivariate time series for arbitrary-step prediction. In
addition, it enjoys a tandem attention, w.r.t. temporal attention and variable
attention, being able to provide explainable insights into the data.
Specifically, ETN-ODE combines an explainable Tensorized Gated Recurrent Unit
(Tensorized GRU or TGRU) with Ordinary Differential Equations (ODE). The
derivative of the latent states is parameterized with a neural network. This
continuous-time ODE network enables a multi-step prediction at arbitrary time
points. We quantitatively and qualitatively demonstrate the effectiveness and
the interpretability of ETN-ODE on five different multi-step prediction tasks
and one arbitrary-step prediction task. Extensive experiments show that ETN-ODE
can lead to accurate predictions at arbitrary time points while attaining best
performance against the baseline methods in standard multi-step time series
prediction.",http://arxiv.org/pdf/2011.13174v1,cs.LG
2020-11-25 14:43:30+00:00,Functional Principal Component Analysis for Cointegrated Functional Time Series,['Won-Ki Seo'],"Functional principal component analysis (FPCA) has played an important role
in the development of functional time series analysis. This note investigates
how FPCA can be used to analyze cointegrated functional time series and
proposes a modification of FPCA as a novel statistical tool. Our modified FPCA
not only provides an asymptotically more efficient estimator of the
cointegrating vectors, but also leads to novel FPCA-based tests for examining
essential properties of cointegrated functional time series.",http://arxiv.org/pdf/2011.12781v8,stat.ME
2020-11-24 20:51:27+00:00,A Non-linear Function-on-Function Model for Regression with Time Series Data,"['Qiyao Wang', 'Haiyan Wang', 'Chetan Gupta', 'Aniruddha Rajendra Rao', 'Hamed Khorasgani']","In the last few decades, building regression models for non-scalar variables,
including time series, text, image, and video, has attracted increasing
interests of researchers from the data analytic community. In this paper, we
focus on a multivariate time series regression problem. Specifically, we aim to
learn mathematical mappings from multiple chronologically measured numerical
variables within a certain time interval S to multiple numerical variables of
interest over time interval T. Prior arts, including the multivariate
regression model, the Seq2Seq model, and the functional linear models, suffer
from several limitations. The first two types of models can only handle
regularly observed time series. Besides, the conventional multivariate
regression models tend to be biased and inefficient, as they are incapable of
encoding the temporal dependencies among observations from the same time
series. The sequential learning models explicitly use the same set of
parameters along time, which has negative impacts on accuracy. The
function-on-function linear model in functional data analysis (a branch of
statistics) is insufficient to capture complex correlations among the
considered time series and suffer from underfitting easily. In this paper, we
propose a general functional mapping that embraces the function-on-function
linear model as a special case. We then propose a non-linear
function-on-function model using the fully connected neural network to learn
the mapping from data, which addresses the aforementioned concerns in the
existing approaches. For the proposed model, we describe in detail the
corresponding numerical implementation procedures. The effectiveness of the
proposed model is demonstrated through the application to two real-world
problems.",http://arxiv.org/pdf/2011.12378v1,cs.LG
2020-11-24 01:24:04+00:00,RTFN: A Robust Temporal Feature Network for Time Series Classification,"['Zhiwen Xiao', 'Xin Xu', 'Huanlai Xing', 'Shouxi Luo', 'Penglin Dai', 'Dawei Zhan']","Time series data usually contains local and global patterns. Most of the
existing feature networks pay more attention to local features rather than the
relationships among them. The latter is, however, also important yet more
difficult to explore. To obtain sufficient representations by a feature network
is still challenging. To this end, we propose a novel robust temporal feature
network (RTFN) for feature extraction in time series classification, containing
a temporal feature network (TFN) and an LSTM-based attention network (LSTMaN).
TFN is a residual structure with multiple convolutional layers. It functions as
a local-feature extraction network to mine sufficient local features from data.
LSTMaN is composed of two identical layers, where attention and long short-term
memory (LSTM) networks are hybridized. This network acts as a relation
extraction network to discover the intrinsic relationships among the extracted
features at different positions in sequential data. In experiments, we embed
RTFN into a supervised structure as a feature extractor and into an
unsupervised structure as an encoder, respectively. The results show that the
RTFN-based structures achieve excellent supervised and unsupervised performance
on a large number of UCR2018 and UEA2018 datasets.",http://arxiv.org/pdf/2011.11829v2,cs.LG
2020-11-23 19:16:46+00:00,Explainable Multivariate Time Series Classification: A Deep Neural Network Which Learns To Attend To Important Variables As Well As Informative Time Intervals,"['Tsung-Yu Hsieh', 'Suhang Wang', 'Yiwei Sun', 'Vasant Honavar']","Time series data is prevalent in a wide variety of real-world applications
and it calls for trustworthy and explainable models for people to understand
and fully trust decisions made by AI solutions. We consider the problem of
building explainable classifiers from multi-variate time series data. A key
criterion to understand such predictive models involves elucidating and
quantifying the contribution of time varying input variables to the
classification. Hence, we introduce a novel, modular, convolution-based feature
extraction and attention mechanism that simultaneously identifies the variables
as well as time intervals which determine the classifier output. We present
results of extensive experiments with several benchmark data sets that show
that the proposed method outperforms the state-of-the-art baseline methods on
multi-variate time series classification task. The results of our case studies
demonstrate that the variables and time intervals identified by the proposed
method make sense relative to available domain knowledge.",http://arxiv.org/pdf/2011.11631v1,cs.LG
2020-11-23 11:57:27+00:00,Time Series Data Imputation: A Survey on Deep Learning Approaches,"['Chenguang Fang', 'Chen Wang']","Time series are all around in real-world applications. However, unexpected
accidents for example broken sensors or missing of the signals will cause
missing values in time series, making the data hard to be utilized. It then
does harm to the downstream applications such as traditional classification or
regression, sequential data integration and forecasting tasks, thus raising the
demand for data imputation. Currently, time series data imputation is a
well-studied problem with different categories of methods. However, these works
rarely take the temporal relations among the observations and treat the time
series as normal structured data, losing the information from the time data. In
recent, deep learning models have raised great attention. Time series methods
based on deep learning have made progress with the usage of models like RNN,
since it captures time information from data. In this paper, we mainly focus on
time series imputation technique with deep learning methods, which recently
made progress in this field. We will review and discuss their model
architectures, their pros and cons as well as their effects to show the
development of the time series imputation methods.",http://arxiv.org/pdf/2011.11347v1,cs.LG
2020-11-21 03:31:23+00:00,A Worrying Analysis of Probabilistic Time-series Models for Sales Forecasting,"['Seungjae Jung', 'Kyung-Min Kim', 'Hanock Kwak', 'Young-Jin Park']","Probabilistic time-series models become popular in the forecasting field as
they help to make optimal decisions under uncertainty. Despite the growing
interest, a lack of thorough analysis hinders choosing what is worth applying
for the desired task. In this paper, we analyze the performance of three
prominent probabilistic time-series models for sales forecasting. To remove the
role of random chance in architecture's performance, we make two experimental
principles; 1) Large-scale dataset with various cross-validation sets. 2) A
standardized training and hyperparameter selection. The experimental results
show that a simple Multi-layer Perceptron and Linear Regression outperform the
probabilistic models on RMSE without any feature engineering. Overall, the
probabilistic models fail to achieve better performance on point estimation,
such as RMSE and MAPE, than comparably simple baselines. We analyze and discuss
the performances of probabilistic time-series models.",http://arxiv.org/pdf/2011.10715v1,cs.LG
2020-11-20 18:35:02+00:00,Two-Step Meta-Learning for Time-Series Forecasting Ensemble,"['Evaldas Vaiciukynas', 'Paulius Danenas', 'Vilius Kontrimas', 'Rimantas Butleris']","Amounts of historical data collected increase and business intelligence
applicability with automatic forecasting of time series are in high demand.
While no single time series modeling method is universal to all types of
dynamics, forecasting using an ensemble of several methods is often seen as a
compromise. Instead of fixing ensemble diversity and size, we propose to
predict these aspects adaptively using meta-learning. Meta-learning here
considers two separate random forest regression models, built on 390
time-series features, to rank 22 univariate forecasting methods and recommend
ensemble size. The forecasting ensemble is consequently formed from methods
ranked as the best, and forecasts are pooled using either simple or weighted
average (with a weight corresponding to reciprocal rank). The proposed approach
was tested on 12561 micro-economic time-series (expanded to 38633 for various
forecasting horizons) of M4 competition where meta-learning outperformed Theta
and Comb benchmarks by relative forecasting errors for all data types and
horizons. Best overall results were achieved by weighted pooling with a
symmetric mean absolute percentage error of 9.21% versus 11.05% obtained using
the Theta method.",http://arxiv.org/pdf/2011.10545v2,stat.ML
2020-11-20 04:00:06+00:00,Detecting systematic anomalies affecting systems when inputs are stationary time series,"['Ning Sun', 'Chen Yang', 'Ričardas Zitikis']","We develop an anomaly-detection method when systematic anomalies, possibly
statistically very similar to genuine inputs, are affecting control systems at
the input and/or output stages. The method allows anomaly-free inputs (i.e.,
those before contamination) to originate from a wide class of random sequences,
thus opening up possibilities for diverse applications. To illustrate how the
method works on data, and how to interpret its results and make decisions, we
analyze several actual time series, which are originally non-stationary but in
the process of analysis are converted into stationary. As a further
illustration, we provide a controlled experiment with anomaly-free inputs
following an ARMA time series model under various contamination scenarios.",http://arxiv.org/pdf/2011.10195v5,stat.ME
2020-11-16 20:30:19+00:00,Large-scale kernelized GRANGER causality to infer topology of directed graphs with applications to brain networks,"['M. Ali Vosoughi', 'Axel Wismuller']","Graph topology inference of network processes with co-evolving and
interacting time-series is crucial for network studies. Vector autoregressive
models (VAR) are popular approaches for topology inference of directed graphs;
however, in large networks with short time-series, topology estimation becomes
ill-posed. The present paper proposes a novel nonlinearity-preserving topology
inference method for directed networks with co-evolving nodal processes that
solves the ill-posedness problem. The proposed method, large-scale kernelized
Granger causality (lsKGC), uses kernel functions to transform data into a
low-dimensional feature space and solves the autoregressive problem in the
feature space, then finds the pre-images in the input space to infer the
topology. Extensive simulations on synthetic datasets with nonlinear and linear
dependencies and known ground-truth demonstrate significant improvement in the
Area Under the receiver operating characteristic Curve ( AUC ) of the receiver
operating characteristic for network recovery compared to existing methods.
Furthermore, tests on real datasets from a functional magnetic resonance
imaging (fMRI) study demonstrate 96.3 percent accuracy in diagnosis tasks of
schizophrenia patients, which is the highest in the literature with only brain
time-series information.",http://arxiv.org/pdf/2011.08261v1,cs.LG
2020-11-16 00:12:55+00:00,Robust bootstrap prediction intervals for univariate and multivariate autoregressive time series models,"['Ufuk Beyaztas', 'Han Lin Shang']","The bootstrap procedure has emerged as a general framework to construct
prediction intervals for future observations in autoregressive time series
models. Such models with outlying data points are standard in real data
applications, especially in the field of econometrics. These outlying data
points tend to produce high forecast errors, which reduce the forecasting
performances of the existing bootstrap prediction intervals calculated based on
non-robust estimators. In the univariate and multivariate autoregressive time
series, we propose a robust bootstrap algorithm for constructing prediction
intervals and forecast regions. The proposed procedure is based on the weighted
likelihood estimates and weighted residuals. Its finite sample properties are
examined via a series of Monte Carlo studies and two empirical data examples.",http://arxiv.org/pdf/2011.07664v1,stat.ME
2020-11-15 15:10:57+00:00,Discovering long term dependencies in noisy time series data using deep learning,['Alexey Kurochkin'],"Time series modelling is essential for solving tasks such as predictive
maintenance, quality control and optimisation. Deep learning is widely used for
solving such problems. When managing complex manufacturing process with neural
networks, engineers need to know why machine learning model made specific
decision and what are possible outcomes of following model recommendation. In
this paper we develop framework for capturing and explaining temporal
dependencies in time series data using deep neural networks and test it on
various synthetic and real world datasets.",http://arxiv.org/pdf/2011.07551v1,cs.LG
2020-11-13 21:04:47+00:00,Rank Determination in Tensor Factor Model,"['Yuefeng Han', 'Rong Chen', 'Cun-Hui Zhang']","Factor model is an appealing and effective analytic tool for high-dimensional
time series, with a wide range of applications in economics, finance and
statistics. This paper develops two criteria for the determination of the
number of factors for tensor factor models where the signal part of an observed
tensor time series assumes a Tucker decomposition with the core tensor as the
factor tensor. The task is to determine the dimensions of the core tensor. One
of the proposed criteria is similar to information based criteria of model
selection, and the other is an extension of the approaches based on the ratios
of consecutive eigenvalues often used in factor analysis for panel time series.
Theoretically results, including sufficient conditions and convergence rates,
are established. The results include the vector factor models as special cases,
with an additional convergence rates. Simulation studies provide promising
finite sample performance for the two criteria.",http://arxiv.org/pdf/2011.07131v3,stat.ME
2020-11-11 02:27:00+00:00,Energy consumption forecasting using a stacked nonparametric Bayesian approach,"['Dilusha Weeraddana', 'Nguyen Lu Dang Khoa', 'Lachlan O Neil', 'Weihong Wang', 'Chen Cai']","In this paper, the process of forecasting household energy consumption is
studied within the framework of the nonparametric Gaussian Process (GP), using
multiple short time series data. As we begin to use smart meter data to paint a
clearer picture of residential electricity use, it becomes increasingly
apparent that we must also construct a detailed picture and understanding of
consumer's complex relationship with gas consumption. Both electricity and gas
consumption patterns are highly dependent on various factors, and the intricate
interplay of these factors is sophisticated. Moreover, since typical gas
consumption data is low granularity with very few time points, naive
application of conventional time-series forecasting techniques can lead to
severe over-fitting. Given these considerations, we construct a stacked GP
method where the predictive posteriors of each GP applied to each task are used
in the prior and likelihood of the next level GP. We apply our model to a
real-world dataset to forecast energy consumption in Australian households
across several states. We compare intuitively appealing results against other
commonly used machine learning techniques. Overall, the results indicate that
the proposed stacked GP model outperforms other forecasting techniques that we
tested, especially when we have a multiple short time-series instances.",http://arxiv.org/pdf/2011.05519v1,cs.LG
2020-11-10 17:26:49+00:00,ATCN: Resource-Efficient Processing of Time Series on Edge,"['Mohammadreza Baharani', 'Hamed Tabkhi']","This paper presents a scalable deep learning model called Agile Temporal
Convolutional Network (ATCN) for high-accurate fast classification and time
series prediction in resource-constrained embedded systems. ATCN is a family of
compact networks with formalized hyperparameters that enable
application-specific adjustments to be made to the model architecture. It is
primarily designed for embedded edge devices with very limited performance and
memory, such as wearable biomedical devices and real-time reliability
monitoring systems. ATCN makes fundamental improvements over the mainstream
temporal convolutional neural networks, including residual connections to
increase the network depth and accuracy, and the incorporation of separable
depth-wise convolution to reduce the computational complexity of the model. As
part of the present work, two ATCN families, namely T0, and T1 are also
presented and evaluated on different ranges of embedded processors - Cortex-M7
and Cortex-A57 processor. An evaluation of the ATCN models against the
best-in-class InceptionTime and MiniRocket shows that ATCN almost maintains
accuracy while improving the execution time on a broad range of embedded and
cyber-physical applications with demand for real-time processing on the
embedded edge. At the same time, in contrast to existing solutions, ATCN is the
first time-series classifier based on deep learning that can be run bare-metal
on embedded microcontrollers (Cortex-M7) with limited computational performance
and memory capacity while delivering state-of-the-art accuracy.",http://arxiv.org/pdf/2011.05260v4,cs.LG
2020-11-10 01:44:22+00:00,Using flexible noise models to avoid noise model misspecification in inference of differential equation time series models,"['Richard Creswell', 'Ben Lambert', 'Chon Lok Lei', 'Martin Robinson', 'David Gavaghan']","When modelling time series, it is common to decompose observed variation into
a ""signal"" process, the process of interest, and ""noise"", representing nuisance
factors that obfuscate the signal. To separate signal from noise, assumptions
must be made about both parts of the system. If the signal process is
incorrectly specified, our predictions using this model may generalise poorly;
similarly, if the noise process is incorrectly specified, we can attribute too
much or too little observed variation to the signal. With little justification,
independent Gaussian noise is typically chosen, which defines a statistical
model that is simple to implement but often misstates system uncertainty and
may underestimate error autocorrelation. There are a range of alternative noise
processes available but, in practice, none of these may be entirely
appropriate, as actual noise may be better characterised as a time-varying
mixture of these various types. Here, we consider systems where the signal is
modelled with ordinary differential equations and present classes of flexible
noise processes that adapt to a system's characteristics. Our noise models
include a multivariate normal kernel where Gaussian processes allow for
non-stationary persistence and variance, and nonparametric Bayesian models that
partition time series into distinct blocks of separate noise structures. Across
the scenarios we consider, these noise processes faithfully reproduce true
system uncertainty: that is, parameter estimate uncertainty when doing
inference using the correct noise model. The models themselves and the methods
for fitting them are scalable to large datasets and could help to ensure more
appropriate quantification of uncertainty in a host of time series models.",http://arxiv.org/pdf/2011.04854v1,stat.ME
2020-11-09 20:19:20+00:00,Statistical analysis for stationary time series at extreme levels: new estimators for the limiting cluster size distribution,"['Axel Bücher', 'Tobias Jennessen']","A measure of primal importance for capturing the serial dependence of a
stationary time series at extreme levels is provided by the limiting cluster
size distribution. New estimators based on a blocks declustering scheme are
proposed and analyzed both theoretically and by means of a large-scale
simulation study. A sliding blocks version of the estimators is shown to
outperform a disjoint blocks version. In contrast to some competitors from the
literature, the estimators only depend on one unknown parameter to be chosen by
the statistician.",http://arxiv.org/pdf/2011.04733v1,math.ST
2020-11-09 10:41:28+00:00,ConFuse: Convolutional Transform Learning Fusion Framework For Multi-Channel Data Analysis,"['Pooja Gupta', 'Jyoti Maggu', 'Angshul Majumdar', 'Emilie Chouzenoux', 'Giovanni Chierchia']","This work addresses the problem of analyzing multi-channel time series data
%. In this paper, we by proposing an unsupervised fusion framework based on
%the recently proposed convolutional transform learning. Each channel is
processed by a separate 1D convolutional transform; the output of all the
channels are fused by a fully connected layer of transform learning. The
training procedure takes advantage of the proximal interpretation of activation
functions. We apply the developed framework to multi-channel financial data for
stock forecasting and trading. We compare our proposed formulation with
benchmark deep time series analysis networks. The results show that our method
yields considerably better results than those compared against.",http://arxiv.org/pdf/2011.04317v1,cs.LG
2020-11-08 00:16:38+00:00,Modeling Interval Trendlines: Symbolic Singular Spectrum Analysis for Interval Time Series,"['Miguel de Carvalho', 'Gabriel Martos']","In this article we propose an extension of singular spectrum analysis for
interval-valued time series. The proposed methods can be used to decompose and
forecast the dynamics governing a set-valued stochastic process. The resulting
components on which the interval time series is decomposed can be understood as
interval trendlines, cycles, or noise. Forecasting can be conducted through a
linear recurrent method, and we devised generalizations of the decomposition
method for the multivariate setting. The performance of the proposed methods is
showcased in a simulation study. We apply the proposed methods so to track the
dynamics governing the Argentina Stock Market (MERVAL) in real time, in a case
study that covers the most recent period of turbulence that led to discussions
of the government of Argentina with the International Monetary Fund.",http://arxiv.org/pdf/2011.03872v1,stat.ME
2020-11-05 19:45:59+00:00,Statistical analysis of Wasserstein GANs with applications to time series forecasting,"['Moritz Haas', 'Stefan Richter']","We provide statistical theory for conditional and unconditional Wasserstein
generative adversarial networks (WGANs) in the framework of dependent
observations. We prove upper bounds for the excess Bayes risk of the WGAN
estimators with respect to a modified Wasserstein-type distance. Furthermore,
we formalize and derive statements on the weak convergence of the estimators
and use them to develop confidence intervals for new observations. The theory
is applied to the special case of high-dimensional time series forecasting. We
analyze the behavior of the estimators in simulations based on synthetic data
and investigate a real data example with temperature data. The dependency of
the data is quantified with absolutely regular beta-mixing coefficients.",http://arxiv.org/pdf/2011.03074v1,math.ST
2020-11-03 19:54:20+00:00,On Ordered Fuzzy Numbers Generated By Time Series,"['C. Gast', 'R. Traylor']","This paper proposes a new trapezoidal ordered fuzzy number representation of
windowed time series based on the idea of a Japanese candlestick to those
previously proposed in the literature. We define and illustrate several
descriptive statistics based on the information contained in the ordered fuzzy
numbers. We utilize financial trading data from three automotive companies as a
case study. Further expansion can be applied to any other forms of time series
data to offer further insight into many other data driven situations.",http://arxiv.org/pdf/2011.01980v1,math.ST
2020-11-03 16:58:08+00:00,Tabular Transformers for Modeling Multivariate Time Series,"['Inkit Padhi', 'Yair Schiff', 'Igor Melnyk', 'Mattia Rigotti', 'Youssef Mroueh', 'Pierre Dognin', 'Jerret Ross', 'Ravi Nair', 'Erik Altman']","Tabular datasets are ubiquitous in data science applications. Given their
importance, it seems natural to apply state-of-the-art deep learning algorithms
in order to fully unlock their potential. Here we propose neural network models
that represent tabular time series that can optionally leverage their
hierarchical structure. This results in two architectures for tabular time
series: one for learning representations that is analogous to BERT and can be
pre-trained end-to-end and used in downstream tasks, and one that is akin to
GPT and can be used for generation of realistic synthetic tabular sequences. We
demonstrate our models on two datasets: a synthetic credit card transaction
dataset, where the learned representations are used for fraud detection and
synthetic data generation, and on a real pollution dataset, where the learned
encodings are used to predict atmospheric pollutant concentrations. Code and
data are available at https://github.com/IBM/TabFormer.",http://arxiv.org/pdf/2011.01843v2,cs.LG
2020-11-02 23:21:57+00:00,Detecting direct causality in multivariate time series: A comparative study,"['Angeliki Papana', 'Elsa Siggiridou', 'Dimitris Kugiumtzis']","The concept of Granger causality is increasingly being applied for the
characterization of directional interactions in different applications. A
multivariate framework for estimating Granger causality is essential in order
to account for all the available information from multivariate time series.
However, the inclusion of non-informative or non-significant variables creates
estimation problems related to the 'curse of dimensionality'. To deal with this
issue, direct causality measures using variable selection and dimension
reduction techniques have been introduced. In this comparative work, the
performance of an ensemble of bivariate and multivariate causality measures in
the time domain is assessed, focusing on dimension reduction causality
measures. In particular, different types of high-dimensional coupled discrete
systems are used (involving up to 100 variables) and the robustness of the
causality measures to time series length and different noise types is examined.
The results of the simulation study highlight the superiority of the dimension
reduction measures, especially for high-dimensional systems.",http://arxiv.org/pdf/2011.01379v1,stat.ME
2020-11-02 03:09:23+00:00,Time Series Forecasting with Stacked Long Short-Term Memory Networks,['Frank Xiao'],"Long Short-Term Memory (LSTM) networks are often used to capture temporal
dependency patterns. By stacking multi-layer LSTM networks, it can capture even
more complex patterns. This paper explores the effectiveness of applying
stacked LSTM networks in the time series prediction domain, specifically, the
traffic volume forecasting. Being able to predict traffic volume more
accurately can result in better planning, thus greatly reduce the operation
cost and improve overall efficiency.",http://arxiv.org/pdf/2011.00697v1,cs.LG
2020-10-29 23:56:57+00:00,Modern strategies for time series regression,"['Stephanie Clark', 'Rob J Hyndman', 'Dan Pagendam', 'Louise M Ryan']","This paper discusses several modern approaches to regression analysis
involving time series data where some of the predictor variables are also
indexed by time. We discuss classical statistical approaches as well as methods
that have been proposed recently in the machine learning literature. The
approaches are compared and contrasted, and it will be seen that there are
advantages and disadvantages to most currently available approaches. There is
ample room for methodological developments in this area. The work is motivated
by an application involving the prediction of water levels as a function of
rainfall and other climate variables in an aquifer in eastern Australia.",http://arxiv.org/pdf/2010.15997v1,stat.ME
2020-10-26 22:07:53+00:00,Benchmarking Deep Learning Interpretability in Time Series Predictions,"['Aya Abdelsalam Ismail', 'Mohamed Gunady', 'Héctor Corrada Bravo', 'Soheil Feizi']","Saliency methods are used extensively to highlight the importance of input
features in model predictions. These methods are mostly used in vision and
language tasks, and their applications to time series data is relatively
unexplored. In this paper, we set out to extensively compare the performance of
various saliency-based interpretability methods across diverse neural
architectures, including Recurrent Neural Network, Temporal Convolutional
Networks, and Transformers in a new benchmark of synthetic time series data. We
propose and report multiple metrics to empirically evaluate the performance of
saliency methods for detecting feature importance over time using both
precision (i.e., whether identified features contain meaningful signals) and
recall (i.e., the number of features with signal identified as important).
Through several experiments, we show that (i) in general, network architectures
and saliency methods fail to reliably and accurately identify feature
importance over time in time series data, (ii) this failure is mainly due to
the conflation of time and feature domains, and (iii) the quality of saliency
maps can be improved substantially by using our proposed two-step temporal
saliency rescaling (TSR) approach that first calculates the importance of each
time step before calculating the importance of each feature at a time step.",http://arxiv.org/pdf/2010.13924v1,cs.LG
2020-10-23 15:51:23+00:00,A Review of Deep Learning Methods for Irregularly Sampled Medical Time Series Data,"['Chenxi Sun', 'Shenda Hong', 'Moxian Song', 'Hongyan Li']","Irregularly sampled time series (ISTS) data has irregular temporal intervals
between observations and different sampling rates between sequences. ISTS
commonly appears in healthcare, economics, and geoscience. Especially in the
medical environment, the widely used Electronic Health Records (EHRs) have
abundant typical irregularly sampled medical time series (ISMTS) data.
Developing deep learning methods on EHRs data is critical for personalized
treatment, precise diagnosis and medical management. However, it is challenging
to directly use deep learning models for ISMTS data. On the one hand, ISMTS
data has the intra-series and inter-series relations. Both the local and global
structures should be considered. On the other hand, methods should consider the
trade-off between task accuracy and model complexity and remain generality and
interpretability. So far, many existing works have tried to solve the above
problems and have achieved good results. In this paper, we review these deep
learning methods from the perspectives of technology and task. Under the
technology-driven perspective, we summarize them into two categories - missing
data-based methods and raw data-based methods. Under the task-driven
perspective, we also summarize them into two categories - data
imputation-oriented and downstream task-oriented. For each of them, we point
out their advantages and disadvantages. Moreover, we implement some
representative methods and compare them on four medical datasets with two
tasks. Finally, we discuss the challenges and opportunities in this area.",http://arxiv.org/pdf/2010.12493v2,cs.LG
2020-10-22 05:17:07+00:00,PLSO: A generative framework for decomposing nonstationary time-series into piecewise stationary oscillatory components,"['Andrew H. Song', 'Demba Ba', 'Emery N. Brown']","To capture the slowly time-varying spectral content of real-world
time-series, a common paradigm is to partition the data into approximately
stationary intervals and perform inference in the time-frequency domain.
However, this approach lacks a corresponding nonstationary time-domain
generative model for the entire data and thus, time-domain inference occurs in
each interval separately. This results in distortion/discontinuity around
interval boundaries and can consequently lead to erroneous inferences based on
any quantities derived from the posterior, such as the phase. To address these
shortcomings, we propose the Piecewise Locally Stationary Oscillation (PLSO)
model for decomposing time-series data with slowly time-varying spectra into
several oscillatory, piecewise-stationary processes. PLSO, as a nonstationary
time-domain generative model, enables inference on the entire time-series
without boundary effects and simultaneously provides a characterization of its
time-varying spectral properties. We also propose a novel two-stage inference
algorithm that combines Kalman theory and an accelerated proximal gradient
algorithm. We demonstrate these points through experiments on simulated data
and real neural data from the rat and the human brain.",http://arxiv.org/pdf/2010.11449v3,stat.ME
2020-10-21 03:40:35+00:00,Model selection in reconciling hierarchical time series,"['Mahdi Abolghasemi', 'Rob J Hyndman', 'Evangelos Spiliotis', 'Christoph Bergmeir']","Model selection has been proven an effective strategy for improving accuracy
in time series forecasting applications. However, when dealing with
hierarchical time series, apart from selecting the most appropriate forecasting
model, forecasters have also to select a suitable method for reconciling the
base forecasts produced for each series to make sure they are coherent.
Although some hierarchical forecasting methods like minimum trace are strongly
supported both theoretically and empirically for reconciling the base
forecasts, there are still circumstances under which they might not produce the
most accurate results, being outperformed by other methods. In this paper we
propose an approach for dynamically selecting the most appropriate hierarchical
forecasting method and succeeding better forecasting accuracy along with
coherence. The approach, to be called conditional hierarchical forecasting, is
based on Machine Learning classification methods and uses time series features
as leading indicators for performing the selection for each hierarchy examined
considering a variety of alternatives. Our results suggest that conditional
hierarchical forecasting leads to significantly more accurate forecasts than
standard approaches, especially at lower hierarchical levels.",http://arxiv.org/pdf/2010.10742v2,cs.LG
2020-10-20 08:14:02+00:00,A novel method of fuzzy time series forecasting based on interval index number and membership value using support vector machine,"['Kiran Bisht', 'Arun Kumar']","Fuzzy time series forecasting methods are very popular among researchers for
predicting future values as they are not based on the strict assumptions of
traditional time series forecasting methods. Non-stochastic methods of fuzzy
time series forecasting are preferred by the researchers as they provide more
significant forecasting results. There are generally, four factors that
determine the performance of the forecasting method (1) number of intervals
(NOIs) and length of intervals to partition universe of discourse (UOD) (2)
fuzzification rules or feature representation of crisp time series (3) method
of establishing fuzzy logic rule (FLRs) between input and target values (4)
defuzzification rule to get crisp forecasted value. Considering the first two
factors to improve the forecasting accuracy, we proposed a novel non-stochastic
method fuzzy time series forecasting in which interval index number and
membership value are used as input features to predict future value. We
suggested a simple rounding-off range and suitable step size method to find the
optimal number of intervals (NOIs) and used fuzzy c-means clustering process to
divide UOD into intervals of unequal length. We implement support vector
machine (SVM) to establish FLRs. To test our proposed method we conduct a
simulated study on five widely used real time series and compare the
performance with some recently developed models. We also examine the
performance of the proposed model by using multi-layer perceptron (MLP) instead
of SVM. Two performance measures RSME and SMAPE are used for performance
analysis and observed better forecasting accuracy by the proposed model.",http://arxiv.org/pdf/2010.11274v1,cs.LG
2020-10-20 07:04:25+00:00,RDIS: Random Drop Imputation with Self-Training for Incomplete Time Series Data,"['Tae-Min Choi', 'Ji-Su Kang', 'Jong-Hwan Kim']","Time-series data with missing values are commonly encountered in many fields,
such as healthcare, meteorology, and robotics. The imputation aims to fill the
missing values with valid values. Most imputation methods trained the models
implicitly because missing values have no ground truth. In this paper, we
propose Random Drop Imputation with Self-training (RDIS), a novel training
method for time-series data imputation models. In RDIS, we generate extra
missing values by applying a random drop on the observed values in incomplete
data. We can explicitly train the imputation models by filling in the randomly
dropped values. In addition, we adopt self-training with pseudo values to
exploit the original missing values. To improve the quality of pseudo values,
we set the threshold and filter them by calculating the entropy. To verify the
effectiveness of RDIS on the time series imputation, we test RDIS to various
imputation models and achieve competitive results on two real-world datasets.",http://arxiv.org/pdf/2010.10075v2,cs.LG
2020-10-20 06:59:50+00:00,Volterra bootstrap: Resampling higher-order statistics for strictly stationary univariate time series,"['Natalia Sirotko-Sibirskaya', 'Matthias O. Franz', 'Thorsten Dickhaus']","We are concerned with nonparametric hypothesis testing of time series
functionals. It is known that the popular autoregressive sieve bootstrap is, in
general, not valid for statistics whose (asymptotic) distribution depends on
moments of order higher than two, irrespective of whether the data come from a
linear time series or a nonlinear one. Inspired by nonlinear system theory we
circumvent this non-validity by introducing a higher-order bootstrap scheme
based on the Volterra series representation of the process. In order to
estimate coefficients of such a representation efficiently, we rely on the
alternative formulation of Volterra operators in reproducing kernel Hilbert
space. We perform polynomial kernel regression which scales linearly with the
input dimensionality and is independent of the degree of nonlinearity. We
illustrate the applicability of the suggested Volterra-representation-based
bootstrap procedure in a simulation study where we consider strictly stationary
linear and nonlinear processes.",http://arxiv.org/pdf/2010.10071v1,stat.ME
2020-10-19 14:02:14+00:00,A semi-supervised autoencoder framework for joint generation and classification of breathing,"['Oscar Pastor-Serrano', 'Danny Lathouwers', 'Zoltán Perkó']","One of the main problems with biomedical signals is the limited amount of
patient-specific data and the significant amount of time needed to record the
sufficient number of samples needed for diagnostic and treatment purposes. In
this study, we present a framework to simultaneously generate and classify
biomedical time series based on a modified Adversarial Autoencoder (AAE)
algorithm and one-dimensional convolutions. Our work is based on breathing time
series, with specific motivation to capture breathing motion during
radiotherapy lung cancer treatments. First, we explore the potential in using
the Variational Autoencoder (VAE) and AAE algorithms to model breathing from
individual patients. We extend the AAE algorithm to allow joint semi-supervised
classification and generation of different types of signals. To simplify the
modeling task, we introduce a pre-processing and post-processing compressing
algorithm that transforms the multi-dimensional time series into vectors
containing time and position values, which are transformed back into time
series through an additional neural network. By incorporating few labeled
samples during training, our model outperforms other purely discriminative
networks in classifying breathing baseline shift irregularities from a dataset
completely different from the training set. To our knowledge, the presented
framework is the first approach that unifies generation and classification
within a single model for this type of biomedical data, enabling both computer
aided diagnosis and augmentation of labeled samples within a single framework.",http://arxiv.org/pdf/2010.15579v2,cs.LG
2020-10-19 12:44:25+00:00,Neural Additive Vector Autoregression Models for Causal Discovery in Time Series,"['Bart Bussmann', 'Jannes Nys', 'Steven Latré']","Causal structure discovery in complex dynamical systems is an important
challenge for many scientific domains. Although data from (interventional)
experiments is usually limited, large amounts of observational time series data
sets are usually available. Current methods that learn causal structure from
time series often assume linear relationships. Hence, they may fail in
realistic settings that contain nonlinear relations between the variables. We
propose Neural Additive Vector Autoregression (NAVAR) models, a neural approach
to causal structure learning that can discover nonlinear relationships. We
train deep neural networks that extract the (additive) Granger causal
influences from the time evolution in multi-variate time series. The method
achieves state-of-the-art results on various benchmark data sets for causal
discovery, while providing clear interpretations of the mapped causal
relations.",http://arxiv.org/pdf/2010.09429v2,cs.LG
2020-10-18 08:28:12+00:00,Inverse Problem for Dynamic Computer Simulators via Multiple Scalar-valued Contour Estimation,"['Joseph Resch', 'Abhyuday Mandal', 'Pritam Ranjan']","In this paper we consider a dynamic computer simulator that produces a
time-series response $y_t(x)$ over $L$ time points, for every given input
parameter $x$. We propose a method for solving inverse problems, which refer to
the finding of a set of inputs that generates a pre-specified simulator output.
Inspired by the sequential approach of contour estimation via expected
improvement criterion developed by Ranjan et al. (2008, DOI:
10.1198/004017008000000541), our proposed method discretizes the target
response series on $k \; (\ll L)$ time points, and then iteratively solves $k$
scalar-valued inverse problems with respect to the discretized targets. We also
propose to use spline smoothing of the target response series to identify the
optimal number of knots, $k$, and the actual location of the knots for
discretization. The performance of the proposed methods is compared for several
test-function based computer simulators and the motivating real application
that uses a rainfall-runoff measurement model named Matlab-Simulink model.",http://arxiv.org/pdf/2010.08941v2,stat.ME
2020-10-16 12:45:13+00:00,Differentiable Divergences Between Time Series,"['Mathieu Blondel', 'Arthur Mensch', 'Jean-Philippe Vert']","Computing the discrepancy between time series of variable sizes is
notoriously challenging. While dynamic time warping (DTW) is popularly used for
this purpose, it is not differentiable everywhere and is known to lead to bad
local optima when used as a ""loss"". Soft-DTW addresses these issues, but it is
not a positive definite divergence: due to the bias introduced by entropic
regularization, it can be negative and it is not minimized when the time series
are equal. We propose in this paper a new divergence, dubbed soft-DTW
divergence, which aims to correct these issues. We study its properties; in
particular, under conditions on the ground cost, we show that it is a valid
divergence: it is non-negative and minimized if and only if the two time series
are equal. We also propose a new ""sharp"" variant by further removing entropic
bias. We showcase our divergences on time series averaging and demonstrate
significant accuracy improvements compared to both DTW and soft-DTW on 84 time
series classification datasets.",http://arxiv.org/pdf/2010.08354v3,cs.LG
2020-10-16 10:32:06+00:00,Uncertainty-Aware Deep Ensembles for Reliable and Explainable Predictions of Clinical Time Series,"['Kristoffer Wickstrøm', 'Karl Øyvind Mikalsen', 'Michael Kampffmeyer', 'Arthur Revhaug', 'Robert Jenssen']","Deep learning-based support systems have demonstrated encouraging results in
numerous clinical applications involving the processing of time series data.
While such systems often are very accurate, they have no inherent mechanism for
explaining what influenced the predictions, which is critical for clinical
tasks. However, existing explainability techniques lack an important component
for trustworthy and reliable decision support, namely a notion of uncertainty.
In this paper, we address this lack of uncertainty by proposing a deep ensemble
approach where a collection of DNNs are trained independently. A measure of
uncertainty in the relevance scores is computed by taking the standard
deviation across the relevance scores produced by each model in the ensemble,
which in turn is used to make the explanations more reliable. The class
activation mapping method is used to assign a relevance score for each time
step in the time series. Results demonstrate that the proposed ensemble is more
accurate in locating relevant time steps and is more consistent across random
initializations, thus making the model more trustworthy. The proposed
methodology paves the way for constructing trustworthy and dependable support
systems for processing clinical time series for healthcare related tasks.",http://arxiv.org/pdf/2010.11310v1,cs.LG
2020-10-15 08:32:27+00:00,An Improved Online Penalty Parameter Selection Procedure for $\ell_1$-Penalized Autoregressive with Exogenous Variables,"['William B. Nicholson', 'Xiaohan Yan']","Many recent developments in the high-dimensional statistical time series
literature have centered around time-dependent applications that can be adapted
to regularized least squares. Of particular interest is the lasso, which both
serves to regularize and provide feature selection. The lasso requires the
specification of a penalty parameter that determines the degree of sparsity to
impose. The most popular penalty parameter selection approaches that respect
time dependence are very computationally intensive and are not appropriate for
modeling certain classes of time series. We propose enhancing a canonical time
series model, the autoregressive model with exogenous variables, with a novel
online penalty parameter selection procedure that takes advantage of the
sequential nature of time series data to improve both computational performance
and forecast accuracy relative to existing methods in both a simulation and
empirical application involving macroeconomic indicators.",http://arxiv.org/pdf/2010.07594v1,stat.ME
2020-10-14 19:25:26+00:00,Graph Deep Factors for Forecasting,"['Hongjie Chen', 'Ryan A. Rossi', 'Kanak Mahadik', 'Sungchul Kim', 'Hoda Eldardiry']","Deep probabilistic forecasting techniques have recently been proposed for
modeling large collections of time-series. However, these techniques explicitly
assume either complete independence (local model) or complete dependence
(global model) between time-series in the collection. This corresponds to the
two extreme cases where every time-series is disconnected from every other
time-series in the collection or likewise, that every time-series is related to
every other time-series resulting in a completely connected graph. In this
work, we propose a deep hybrid probabilistic graph-based forecasting framework
called Graph Deep Factors (GraphDF) that goes beyond these two extremes by
allowing nodes and their time-series to be connected to others in an arbitrary
fashion. GraphDF is a hybrid forecasting framework that consists of a
relational global and relational local model. In particular, we propose a
relational global model that learns complex non-linear time-series patterns
globally using the structure of the graph to improve both forecasting accuracy
and computational efficiency. Similarly, instead of modeling every time-series
independently, we learn a relational local model that not only considers its
individual time-series but also the time-series of nodes that are connected in
the graph. The experiments demonstrate the effectiveness of the proposed deep
hybrid graph-based forecasting model compared to the state-of-the-art methods
in terms of its forecasting accuracy, runtime, and scalability. Our case study
reveals that GraphDF can successfully generate cloud usage forecasts and
opportunistically schedule workloads to increase cloud cluster utilization by
47.5% on average.",http://arxiv.org/pdf/2010.07373v1,cs.LG
2020-10-14 14:54:56+00:00,VEST: Automatic Feature Engineering for Forecasting,"['Vitor Cerqueira', 'Nuno Moniz', 'Carlos Soares']","Time series forecasting is a challenging task with applications in a wide
range of domains. Auto-regression is one of the most common approaches to
address these problems. Accordingly, observations are modelled by multiple
regression using their past lags as predictor variables. We investigate the
extension of auto-regressive processes using statistics which summarise the
recent past dynamics of time series. The result of our research is a novel
framework called VEST, designed to perform feature engineering using univariate
and numeric time series automatically. The proposed approach works in three
main steps. First, recent observations are mapped onto different
representations. Second, each representation is summarised by statistical
functions. Finally, a filter is applied for feature selection. We discovered
that combining the features generated by VEST with auto-regression
significantly improves forecasting performance. We provide evidence using 90
time series with high sampling frequency. VEST is publicly available online.",http://arxiv.org/pdf/2010.07137v1,stat.ML
2020-10-14 10:37:03+00:00,Scalable changepoint and anomaly detection in cross-correlated data with an application to condition monitoring,"['Martin Tveten', 'Idris A. Eckley', 'Paul Fearnhead']","Motivated by a condition monitoring application arising from subsea
engineering we derive a novel, scalable approach to detecting anomalous mean
structure in a subset of correlated multivariate time series. Given the need to
analyse such series efficiently we explore a computationally efficient
approximation of the maximum likelihood solution to the resulting modelling
framework, and develop a new dynamic programming algorithm for solving the
resulting Binary Quadratic Programme when the precision matrix of the time
series at any given time-point is banded. Through a comprehensive simulation
study, we show that the resulting methods perform favourably compared to
competing methods both in the anomaly and change detection settings, even when
the sparsity structure of the precision matrix estimate is misspecified. We
also demonstrate its ability to correctly detect faulty time-periods of a pump
within the motivating application.",http://arxiv.org/pdf/2010.06937v2,stat.ME
2020-10-14 07:10:55+00:00,Reconstruct Anomaly to Normal: Adversarial Learned and Latent Vector-constrained Autoencoder for Time-series Anomaly Detection,"['Chunkai Zhang', 'Wei Zuo', 'Xuan Wang']","Anomaly detection in time series has been widely researched and has important
practical applications. In recent years, anomaly detection algorithms are
mostly based on deep-learning generative models and use the reconstruction
error to detect anomalies. They try to capture the distribution of normal data
by reconstructing normal data in the training phase, then calculate the
reconstruction error of test data to do anomaly detection. However, most of
them only use the normal data in the training phase and can not ensure the
reconstruction process of anomaly data. So, anomaly data can also be well
reconstructed sometimes and gets low reconstruction error, which leads to the
omission of anomalies. What's more, the neighbor information of data points in
time series data has not been fully utilized in these algorithms. In this
paper, we propose RAN based on the idea of Reconstruct Anomalies to Normal and
apply it for unsupervised time series anomaly detection. To minimize the
reconstruction error of normal data and maximize this of anomaly data, we do
not just ensure normal data to reconstruct well, but also try to make the
reconstruction of anomaly data consistent with the distribution of normal data,
then anomalies will get higher reconstruction errors. We implement this idea by
introducing the ""imitated anomaly data"" and combining a specially designed
latent vector-constrained Autoencoder with the discriminator to construct an
adversary network. Extensive experiments on time-series datasets from different
scenes such as ECG diagnosis also show that RAN can detect meaningful
anomalies, and it outperforms other algorithms in terms of AUC-ROC.",http://arxiv.org/pdf/2010.06846v1,cs.LG
2020-10-12 17:18:57+00:00,Model-based bias correction for short AR(1) and AR(2) processes,"['Sigrunn H. Sørbye', 'Pedro G. Nicolau', 'Håvard Rue']","The class of autoregressive (AR) processes is extensively used to model
temporal dependence in observed time series. Such models are easily available
and routinely fitted using freely available statistical software like R. A
potential caveat in analyzing short time series is that commonly applied
estimators for the coefficients of AR processes are severely biased. This paper
suggests a model-based approach for bias correction of well-known estimators
for the coefficients of first and second-order stationary AR processes, taking
the sampling distribution of the original estimator into account. This is
achieved by modeling the relationship between the true and estimated AR
coefficients using weighted orthogonal polynomial regression, fitted to a huge
number of simulations. The finite-sample distributions of the new estimators
are approximated using transformations of skew-normal densities and their
properties are demonstrated by simulations and in the analysis of a real
ecological data set. The new estimators are easily available in our
accompanying R-package ARbiascorrect for time series of length n = 10, 11, ...
, 50, where original estimates are found using exact or conditional maximum
likelihood, Burg's method or the Yule-Walker equations.",http://arxiv.org/pdf/2010.05870v1,stat.ME
2020-10-11 19:03:18+00:00,Granger causality of bivariate stationary curve time series,"['Han Lin Shang', 'Kaiying Ji', 'Ufuk Beyaztas']","We study causality between bivariate curve time series using the Granger
causality generalized measures of correlation. With this measure, we can
investigate which curve time series Granger-causes the other; in turn, it helps
determine the predictability of any two curve time series. Illustrated by a
climatology example, we find that the sea surface temperature Granger-causes
the sea-level atmospheric pressure. Motivated by a portfolio management
application in finance, we single out those stocks that lead or lag behind
Dow-Jones industrial averages. Given a close relationship between S&P 500 index
and crude oil price, we determine the leading and lagging variables.",http://arxiv.org/pdf/2010.05320v2,stat.ME
2020-10-11 15:21:21+00:00,A Case-Study on the Impact of Dynamic Time Warping in Time Series Regression,"['Vivek Mahato', 'Pádraig Cunningham']","It is well understood that Dynamic Time Warping (DTW) is effective in
revealing similarities between time series that do not align perfectly. In this
paper, we illustrate this on spectroscopy time-series data. We show that DTW is
effective in improving accuracy on a regression task when only a single
wavelength is considered. When combined with k-Nearest Neighbour, DTW has the
added advantage that it can reveal similarities and differences between samples
at the level of the time-series. However, in the problem, we consider here data
is available across a spectrum of wavelengths. If aggregate statistics (means,
variances) are used across many wavelengths the benefits of DTW are no longer
apparent. We present this as another example of a situation where big data
trumps sophisticated models in Machine Learning.",http://arxiv.org/pdf/2010.05270v1,cs.LG
2020-10-10 17:57:59+00:00,TOTOPO: Classifying univariate and multivariate time series with Topological Data Analysis,"['Polina Pilyugina', 'Rodrigo Rivera-Castro', 'Eugeny Burnaev']","This work is devoted to a comprehensive analysis of topological data analysis
fortime series classification. Previous works have significant shortcomings,
such aslack of large-scale benchmarking or missing state-of-the-art methods. In
this work,we propose TOTOPO for extracting topological descriptors from
different types ofpersistence diagrams. The results suggest that TOTOPO
significantly outperformsexisting baselines in terms of accuracy. TOTOPO is
also competitive with thestate-of-the-art, being the best on 20% of univariate
and 40% of multivariate timeseries datasets. This work validates the hypothesis
that TDA-based approaches arerobust to small perturbations in data and are
useful for cases where periodicity andshape help discriminate between classes.",http://arxiv.org/pdf/2010.05056v1,cs.LG
2020-10-09 11:55:39+00:00,Principal Component Analysis using Frequency Components of Multivariate Time Series,['Raanju R. Sundararajan'],"Dimension reduction techniques for multivariate time series decompose the
observed series into a few useful independent/orthogonal univariate components.
We develop a spectral domain method for multivariate second-order stationary
time series that linearly transforms the observed series into several groups of
lower-dimensional multivariate subseries. These multivariate subseries have
non-zero spectral coherence among components within a group but have zero
spectral coherence among components across groups. The observed series is
expressed as a sum of frequency components whose variances are proportional to
the spectral matrices at the respective frequencies. The demixing matrix is
then estimated using an eigendecomposition on the sum of the variance matrices
of these frequency components and its asymptotic properties are derived.
Finally, a consistent test on the cross-spectrum of pairs of components is used
to find the desired segmentation into the lower-dimensional subseries. The
numerical performance of the proposed method is illustrated through simulation
examples and an application to modeling and forecasting wind data is presented.",http://arxiv.org/pdf/2010.04515v1,stat.ME
2020-10-06 15:14:46+00:00,A Transformer-based Framework for Multivariate Time Series Representation Learning,"['George Zerveas', 'Srideepika Jayaraman', 'Dhaval Patel', 'Anuradha Bhamidipaty', 'Carsten Eickhoff']","In this work we propose for the first time a transformer-based framework for
unsupervised representation learning of multivariate time series. Pre-trained
models can be potentially used for downstream tasks such as regression and
classification, forecasting and missing value imputation. By evaluating our
models on several benchmark datasets for multivariate time series regression
and classification, we show that not only does our modeling approach represent
the most successful method employing unsupervised learning of multivariate time
series presented to date, but also that it exceeds the current state-of-the-art
performance of supervised methods; it does so even when the number of training
samples is very limited, while offering computational efficiency. Finally, we
demonstrate that unsupervised pre-training of our transformer models offers a
substantial performance benefit over fully supervised learning, even without
leveraging additional unlabeled data, i.e., by reusing the same data samples
through the unsupervised objective.",http://arxiv.org/pdf/2010.02803v3,cs.LG
2020-10-05 08:02:29+00:00,Deep Distributional Time Series Models and the Probabilistic Forecasting of Intraday Electricity Prices,"['Nadja Klein', 'Michael Stanley Smith', 'David J. Nott']","Recurrent neural networks (RNNs) with rich feature vectors of past values can
provide accurate point forecasts for series that exhibit complex serial
dependence. We propose two approaches to constructing deep time series
probabilistic models based on a variant of RNN called an echo state network
(ESN). The first is where the output layer of the ESN has stochastic
disturbances and a shrinkage prior for additional regularization. The second
approach employs the implicit copula of an ESN with Gaussian disturbances,
which is a deep copula process on the feature space. Combining this copula with
a non-parametrically estimated marginal distribution produces a deep
distributional time series model. The resulting probabilistic forecasts are
deep functions of the feature vector and also marginally calibrated. In both
approaches, Bayesian Markov chain Monte Carlo methods are used to estimate the
models and compute forecasts. The proposed models are suitable for the complex
task of forecasting intraday electricity prices. Using data from the Australian
National Electricity Market, we show that our deep time series models provide
accurate short term probabilistic price forecasts, with the copula model
dominating. Moreover, the models provide a flexible framework for incorporating
probabilistic forecasts of electricity demand as additional features, which
increases upper tail forecast accuracy from the copula model significantly.",http://arxiv.org/pdf/2010.01844v2,stat.ME
2020-10-04 18:56:34+00:00,Bayesian Feature Selection in Joint Quantile Time Series Analysis,['Ning Ning'],"Quantile feature selection over correlated multivariate time series data has
always been a methodological challenge and is an open problem. In this paper,
we propose a general Bayesian dimension reduction methodology for feature
selection in high-dimensional joint quantile time series analysis, under the
name of the quantile feature selection time series (QFSTS) model. The QFSTS
model is a general structural time series model, where each component yields an
additive contribution to the time series modeling with direct interpretations.
Its flexibility is compound in the sense that users can add/deduct components
for each time series and each time series can have its own specific valued
components of different sizes. Feature selection is conducted in the quantile
regression component, where each time series has its own pool of
contemporaneous external predictors allowing nowcasting. Bayesian methodology
in extending feature selection to the quantile time series research area is
developed using multivariate asymmetric Laplace distribution, spike-and-slab
prior setup, the Metropolis-Hastings algorithm, and the Bayesian model
averaging technique, all implemented consistently in the Bayesian paradigm. The
QFSTS model requires small datasets to train and converges fast. Extensive
examinations confirmed that the QFSTS model has superior performance in feature
selection, parameter estimation, and forecast.",http://arxiv.org/pdf/2010.01654v3,stat.ML
2020-10-02 10:12:31+00:00,An Evaluation of Classification Methods for 3D Printing Time-Series Data,"['Vivek Mahato', 'Muhannad Ahmed Obeidi', 'Dermot Brabazon', 'Padraig Cunningham']","Additive Manufacturing presents a great application area for Machine Learning
because of the vast volume of data generated and the potential to mine this
data to control outcomes. In this paper we present preliminary work on
classifying infrared time-series data representing melt-pool temperature in a
metal 3D printing process. Our ultimate objective is to use this data to
predict process outcomes (e.g. hardness, porosity, surface roughness). In the
work presented here we simply show that there is a signal in this data that can
be used for the classification of different components and stages of the AM
process. In line with other Machine Learning research on time-series
classification we use k-Nearest Neighbour classifiers. The results we present
suggests that Dynamic Time Warping is an effective distance measure compared
with alternatives for 3D printing data of this type.",http://arxiv.org/pdf/2010.00903v1,cs.LG
2020-10-02 09:08:16+00:00,From Time Series to Euclidean Spaces: On Spatial Transformations for Temporal Clustering,"['Nuno Mota Goncalves', 'Ioana Giurgiu', 'Anika Schumann']","Unsupervised clustering of temporal data is both challenging and crucial in
machine learning. In this paper, we show that neither traditional clustering
methods, time series specific or even deep learning-based alternatives
generalise well when both varying sampling rates and high dimensionality are
present in the input data. We propose a novel approach to temporal clustering,
in which we (1) transform the input time series into a distance-based projected
representation by using similarity measures suitable for dealing with temporal
data,(2) feed these projections into a multi-layer CNN-GRU autoencoder to
generate meaningful domain-aware latent representations, which ultimately (3)
allow for a natural separation of clusters beneficial for most important
traditional clustering algorithms. We evaluate our approach on time series
datasets from various domains and show that it not only outperforms existing
methods in all cases, by up to 32%, but is also robust and incurs negligible
computation overheads.",http://arxiv.org/pdf/2010.05681v1,cs.LG
2020-10-02 00:17:08+00:00,Extreme-SAX: Extreme Points Based Symbolic Representation for Time Series Classification,['Muhammad Marwan Muhammad Fuad'],"Time series classification is an important problem in data mining with
several applications in different domains. Because time series data are usually
high dimensional, dimensionality reduction techniques have been proposed as an
efficient approach to lower their dimensionality. One of the most popular
dimensionality reduction techniques of time series data is the Symbolic
Aggregate Approximation (SAX), which is inspired by algorithms from text mining
and bioinformatics. SAX is simple and efficient because it uses precomputed
distances. The disadvantage of SAX is its inability to accurately represent
important points in the time series. In this paper we present Extreme-SAX
(E-SAX), which uses only the extreme points of each segment to represent the
time series. E-SAX has exactly the same simplicity and efficiency of the
original SAX, yet it gives better results in time series classification than
the original SAX, as we show in extensive experiments on a variety of time
series datasets.",http://arxiv.org/pdf/2010.00732v1,cs.LG
2020-10-01 17:38:40+00:00,Deep learning for time series classification,['Hassan Ismail Fawaz'],"Time series analysis is a field of data science which is interested in
analyzing sequences of numerical values ordered in time. Time series are
particularly interesting because they allow us to visualize and understand the
evolution of a process over time. Their analysis can reveal trends,
relationships and similarities across the data. There exists numerous fields
containing data in the form of time series: health care (electrocardiogram,
blood sugar, etc.), activity recognition, remote sensing, finance (stock market
price), industry (sensors), etc. Time series classification consists of
constructing algorithms dedicated to automatically label time series data. The
sequential aspect of time series data requires the development of algorithms
that are able to harness this temporal property, thus making the existing
off-the-shelf machine learning models for traditional tabular data suboptimal
for solving the underlying task. In this context, deep learning has emerged in
recent years as one of the most effective methods for tackling the supervised
classification task, particularly in the field of computer vision. The main
objective of this thesis was to study and develop deep neural networks
specifically constructed for the classification of time series data. We thus
carried out the first large scale experimental study allowing us to compare the
existing deep methods and to position them compared other non-deep learning
based state-of-the-art methods. Subsequently, we made numerous contributions in
this area, notably in the context of transfer learning, data augmentation,
ensembling and adversarial attacks. Finally, we have also proposed a novel
architecture, based on the famous Inception network (Google), which ranks among
the most efficient to date.",http://arxiv.org/pdf/2010.00567v1,cs.LG
2020-09-30 12:34:56+00:00,Concurrent Neural Network : A model of competition between times series,['Rémy Garnier'],"Competition between times series often arises in sales prediction, when
similar products are on sale on a marketplace. This article provides a model of
the presence of cannibalization between times series. This model creates a
""competitiveness"" function that depends on external features such as price and
margin. It also provides a theoretical guaranty on the error of the model under
some reasonable conditions, and implement this model using a neural network to
compute this competitiveness function. This implementation outperforms other
traditional time series methods and classical neural networks for market share
prediction on a real-world data set.",http://arxiv.org/pdf/2009.14610v2,stat.ML
2020-09-30 01:32:22+00:00,Few-shot Learning for Time-series Forecasting,"['Tomoharu Iwata', 'Atsutoshi Kumagai']","Time-series forecasting is important for many applications. Forecasting
models are usually trained using time-series data in a specific target task.
However, sufficient data in the target task might be unavailable, which leads
to performance degradation. In this paper, we propose a few-shot learning
method that forecasts a future value of a time-series in a target task given a
few time-series in the target task. Our model is trained using time-series data
in multiple training tasks that are different from target tasks. Our model uses
a few time-series to build a forecasting function based on a recurrent neural
network with an attention mechanism. With the attention mechanism, we can
retrieve useful patterns in a small number of time-series for the current
situation. Our model is trained by minimizing an expected test error of
forecasting next timestep values. We demonstrate the effectiveness of the
proposed method using 90 time-series datasets.",http://arxiv.org/pdf/2009.14379v1,stat.ML
2020-09-29 06:29:04+00:00,Current Time Series Anomaly Detection Benchmarks are Flawed and are Creating the Illusion of Progress,"['Renjie Wu', 'Eamonn J. Keogh']","Time series anomaly detection has been a perennially important topic in data
science, with papers dating back to the 1950s. However, in recent years there
has been an explosion of interest in this topic, much of it driven by the
success of deep learning in other domains and for other time series tasks. Most
of these papers test on one or more of a handful of popular benchmark datasets,
created by Yahoo, Numenta, NASA, etc. In this work we make a surprising claim.
The majority of the individual exemplars in these datasets suffer from one or
more of four flaws. Because of these four flaws, we believe that many published
comparisons of anomaly detection algorithms may be unreliable, and more
importantly, much of the apparent progress in recent years may be illusionary.
In addition to demonstrating these claims, with this paper we introduce the UCR
Time Series Anomaly Archive. We believe that this resource will perform a
similar role as the UCR Time Series Classification Archive, by providing the
community with a benchmark that allows meaningful comparisons between
approaches and a meaningful gauge of overall progress.",http://arxiv.org/pdf/2009.13807v5,cs.LG
2020-09-28 10:52:48+00:00,Instance-based Counterfactual Explanations for Time Series Classification,"['Eoin Delaney', 'Derek Greene', 'Mark T. Keane']","In recent years, there has been a rapidly expanding focus on explaining the
predictions made by black-box AI systems that handle image and tabular data.
However, considerably less attention has been paid to explaining the
predictions of opaque AI systems handling time series data. In this paper, we
advance a novel model-agnostic, case-based technique -- Native Guide -- that
generates counterfactual explanations for time series classifiers. Given a
query time series, $T_{q}$, for which a black-box classification system
predicts class, $c$, a counterfactual time series explanation shows how $T_{q}$
could change, such that the system predicts an alternative class, $c'$. The
proposed instance-based technique adapts existing counterfactual instances in
the case-base by highlighting and modifying discriminative areas of the time
series that underlie the classification. Quantitative and qualitative results
from two comparative experiments indicate that Native Guide generates
plausible, proximal, sparse and diverse explanations that are better than those
produced by key benchmark counterfactual methods.",http://arxiv.org/pdf/2009.13211v2,cs.LG
2020-09-26 20:37:38+00:00,Decision-Aware Conditional GANs for Time Series Data,"['He Sun', 'Zhun Deng', 'Hui Chen', 'David C. Parkes']","We introduce the decision-aware time-series conditional generative
adversarial network (DAT-CGAN) as a method for time-series generation. The
framework adopts a multi-Wasserstein loss on structured decision-related
quantities, capturing the heterogeneity of decision-related data and providing
new effectiveness in supporting the decision processes of end users. We improve
sample efficiency through an overlapped block-sampling method, and provide a
theoretical characterization of the generalization properties of DAT-CGAN. The
framework is demonstrated on financial time series for a multi-time-step
portfolio choice problem. We demonstrate better generative quality in regard to
underlying data and different decision-related quantities than strong,
GAN-based baselines.",http://arxiv.org/pdf/2009.12682v4,cs.LG
2020-09-25 22:55:36+00:00,A Context Integrated Relational Spatio-Temporal Model for Demand and Supply Forecasting,"['Hongjie Chen', 'Ryan A. Rossi', 'Kanak Mahadik', 'Hoda Eldardiry']","Traditional methods for demand forecasting only focus on modeling the
temporal dependency. However, forecasting on spatio-temporal data requires
modeling of complex nonlinear relational and spatial dependencies. In addition,
dynamic contextual information can have a significant impact on the demand
values, and therefore needs to be captured. For example, in a bike-sharing
system, bike usage can be impacted by weather. Existing methods assume the
contextual impact is fixed. However, we note that the contextual impact evolves
over time. We propose a novel context integrated relational model, Context
Integrated Graph Neural Network (CIGNN), which leverages the temporal,
relational, spatial, and dynamic contextual dependencies for multi-step ahead
demand forecasting. Our approach considers the demand network over various
geographical locations and represents the network as a graph. We define a
demand graph, where nodes represent demand time-series, and context graphs (one
for each type of context), where nodes represent contextual time-series.
Assuming that various contexts evolve and have a dynamic impact on the
fluctuation of demand, our proposed CIGNN model employs a fusion mechanism that
jointly learns from all available types of contextual information. To the best
of our knowledge, this is the first approach that integrates dynamic contexts
with graph neural networks for spatio-temporal demand forecasting, thereby
increasing prediction accuracy. We present empirical results on two real-world
datasets, demonstrating that CIGNN consistently outperforms state-of-the-art
baselines, in both periodic and irregular time-series networks.",http://arxiv.org/pdf/2009.12469v1,cs.LG
2020-09-24 19:09:37+00:00,Adversarial Examples in Deep Learning for Multivariate Time Series Regression,"['Gautam Raj Mode', 'Khaza Anuarul Hoque']","Multivariate time series (MTS) regression tasks are common in many real-world
data mining applications including finance, cybersecurity, energy, healthcare,
prognostics, and many others. Due to the tremendous success of deep learning
(DL) algorithms in various domains including image recognition and computer
vision, researchers started adopting these techniques for solving MTS data
mining problems, many of which are targeted for safety-critical and
cost-critical applications. Unfortunately, DL algorithms are known for their
susceptibility to adversarial examples which also makes the DL regression
models for MTS forecasting also vulnerable to those attacks. To the best of our
knowledge, no previous work has explored the vulnerability of DL MTS regression
models to adversarial time series examples, which is an important step,
specifically when the forecasting from such models is used in safety-critical
and cost-critical applications. In this work, we leverage existing adversarial
attack generation techniques from the image classification domain and craft
adversarial multivariate time series examples for three state-of-the-art deep
learning regression models, specifically Convolutional Neural Network (CNN),
Long Short-Term Memory (LSTM), and Gated Recurrent Unit (GRU). We evaluate our
study using Google stock and household power consumption dataset. The obtained
results show that all the evaluated DL regression models are vulnerable to
adversarial attacks, transferable, and thus can lead to catastrophic
consequences in safety-critical and cost-critical domains, such as energy and
finance.",http://arxiv.org/pdf/2009.11911v1,cs.LG
2020-09-23 13:04:09+00:00,Finite sample inference for generic autoregressive models,['Hien Duy Nguyen'],"Autoregressive models are a class of time series models that are important in
both applied and theoretical statistics. Typically, inferential devices such as
confidence sets and hypothesis tests for time series models require nuanced
asymptotic arguments and constructions. We present a simple alternative to such
arguments that allow for the construction of finite sample valid inferential
devices, using a data splitting approach. We prove the validity of our
constructions, as well as the validity of related sequential inference tools. A
set of simulation studies are presented to demonstrate the applicability of our
methodology.",http://arxiv.org/pdf/2009.11124v2,math.ST
2020-09-21 16:48:29+00:00,From Static to Dynamic Node Embeddings,"['Di Jin', 'Sungchul Kim', 'Ryan A. Rossi', 'Danai Koutra']","We introduce a general framework for leveraging graph stream data for
temporal prediction-based applications. Our proposed framework includes novel
methods for learning an appropriate graph time-series representation, modeling
and weighting the temporal dependencies, and generalizing existing embedding
methods for such data. While previous work on dynamic modeling and embedding
has focused on representing a stream of timestamped edges using a time-series
of graphs based on a specific time-scale (e.g., 1 month), we propose the notion
of an $\epsilon$-graph time-series that uses a fixed number of edges for each
graph, and show its superiority over the time-scale representation used in
previous work. In addition, we propose a number of new temporal models based on
the notion of temporal reachability graphs and weighted temporal summary
graphs. These temporal models are then used to generalize existing base
(static) embedding methods by enabling them to incorporate and appropriately
model temporal dependencies in the data. From the 6 temporal network models
investigated (for each of the 7 base embedding methods), we find that the top-3
temporal models are always those that leverage the new $\epsilon$-graph
time-series representation. Furthermore, the dynamic embedding methods from the
framework almost always achieve better predictive performance than existing
state-of-the-art dynamic node embedding methods that are developed specifically
for such temporal prediction tasks. Finally, the findings of this work are
useful for designing better dynamic embedding methods.",http://arxiv.org/pdf/2009.10017v1,cs.LG
2020-09-19 01:45:41+00:00,Gated Res2Net for Multivariate Time Series Analysis,"['Chao Yang', 'Mingxing Jiang', 'Zhongwen Guo', 'Yuan Liu']","Multivariate time series analysis is an important problem in data mining
because of its widespread applications. With the increase of time series data
available for training, implementing deep neural networks in the field of time
series analysis is becoming common. Res2Net, a recently proposed backbone, can
further improve the state-of-the-art networks as it improves the multi-scale
representation ability through connecting different groups of filters. However,
Res2Net ignores the correlations of the feature maps and lacks the control on
the information interaction process. To address that problem, in this paper, we
propose a backbone convolutional neural network based on the thought of gated
mechanism and Res2Net, namely Gated Res2Net (GRes2Net), for multivariate time
series analysis. The hierarchical residual-like connections are influenced by
gates whose values are calculated based on the original feature maps, the
previous output feature maps and the next input feature maps thus considering
the correlations between the feature maps more effectively. Through the
utilization of gated mechanism, the network can control the process of
information sending hence can better capture and utilize the both the temporal
information and the correlations between the feature maps. We evaluate the
GRes2Net on four multivariate time series datasets including two classification
datasets and two forecasting datasets. The results demonstrate that GRes2Net
have better performances over the state-of-the-art methods thus indicating the
superiority",http://arxiv.org/pdf/2009.11705v1,cs.LG
2020-09-18 22:31:42+00:00,Explainable boosted linear regression for time series forecasting,"['Igor Ilic', 'Berk Gorgulu', 'Mucahit Cevik', 'Mustafa Gokce Baydogan']","Time series forecasting involves collecting and analyzing past observations
to develop a model to extrapolate such observations into the future.
Forecasting of future events is important in many fields to support decision
making as it contributes to reducing the future uncertainty. We propose
explainable boosted linear regression (EBLR) algorithm for time series
forecasting, which is an iterative method that starts with a base model, and
explains the model's errors through regression trees. At each iteration, the
path leading to highest error is added as a new variable to the base model. In
this regard, our approach can be considered as an improvement over general time
series models since it enables incorporating nonlinear features by residuals
explanation. More importantly, use of the single rule that contributes to the
error most allows for interpretable results. The proposed approach extends to
probabilistic forecasting through generating prediction intervals based on the
empirical error distribution. We conduct a detailed numerical study with EBLR
and compare against various other approaches. We observe that EBLR
substantially improves the base model performance through extracted features,
and provide a comparable performance to other well established approaches. The
interpretability of the model predictions and high predictive accuracy of EBLR
makes it a promising method for time series forecasting.",http://arxiv.org/pdf/2009.09110v1,cs.LG
2020-09-18 21:15:28+00:00,Evaluation of Local Explanation Methods for Multivariate Time Series Forecasting,"['Ozan Ozyegen', 'Igor Ilic', 'Mucahit Cevik']","Being able to interpret a machine learning model is a crucial task in many
applications of machine learning. Specifically, local interpretability is
important in determining why a model makes particular predictions. Despite the
recent focus on AI interpretability, there has been a lack of research in local
interpretability methods for time series forecasting while the few
interpretable methods that exist mainly focus on time series classification
tasks. In this study, we propose two novel evaluation metrics for time series
forecasting: Area Over the Perturbation Curve for Regression and Ablation
Percentage Threshold. These two metrics can measure the local fidelity of local
explanation models. We extend the theoretical foundation to collect
experimental results on two popular datasets, \textit{Rossmann sales} and
\textit{electricity}. Both metrics enable a comprehensive comparison of
numerous local explanation models and find which metrics are more sensitive.
Lastly, we provide heuristical reasoning for this analysis.",http://arxiv.org/pdf/2009.09092v1,cs.LG
2020-09-18 15:47:51+00:00,Time-series Imputation and Prediction with Bi-Directional Generative Adversarial Networks,"['Mehak Gupta', 'Rahmatollah Beheshti']","Multivariate time-series data are used in many classification and regression
predictive tasks, and recurrent models have been widely used for such tasks.
Most common recurrent models assume that time-series data elements are of equal
length and the ordered observations are recorded at regular intervals. However,
real-world time-series data have neither a similar length nor a same number of
observations. They also have missing entries, which hinders the performance of
predictive tasks. In this paper, we approach these issues by presenting a model
for the combined task of imputing and predicting values for the irregularly
observed and varying length time-series data with missing entries. Our proposed
model (Bi-GAN) uses a bidirectional recurrent network in a generative
adversarial setting. The generator is a bidirectional recurrent network that
receives actual incomplete data and imputes the missing values. The
discriminator attempts to discriminate between the actual and the imputed
values in the output of the generator. Our model learns how to impute missing
elements in-between (imputation) or outside of the input time steps
(prediction), hence working as an effective any-time prediction tool for
time-series data. Our method has three advantages to the state-of-the-art
methods in the field: (a) single model can be used for both imputation and
prediction tasks; (b) it can perform prediction task for time-series of varying
length with missing data; (c) it does not require to know the observation and
prediction time window during training which provides a flexible length of
prediction window for both long-term and short-term predictions. We evaluate
our model on two public datasets and on another large real-world electronic
health records dataset to impute and predict body mass index (BMI) values in
children and show its superior performance in both settings.",http://arxiv.org/pdf/2009.08900v1,cs.LG
2020-09-17 19:47:05+00:00,Automatic deep learning for trend prediction in time series data,"['Kouame Hermann Kouassi', 'Deshendran Moodley']","Recently, Deep Neural Network (DNN) algorithms have been explored for
predicting trends in time series data. In many real world applications, time
series data are captured from dynamic systems. DNN models must provide stable
performance when they are updated and retrained as new observations becomes
available. In this work we explore the use of automatic machine learning
techniques to automate the algorithm selection and hyperparameter optimisation
process for trend prediction. We demonstrate how a recent AutoML tool,
specifically the HpBandSter framework, can be effectively used to automate DNN
model development. Our AutoML experiments found optimal configurations that
produced models that compared well against the average performance and
stability levels of configurations found during the manual experiments across
four data sets.",http://arxiv.org/pdf/2009.08510v1,cs.LG
2020-09-17 13:43:47+00:00,Neural Rough Differential Equations for Long Time Series,"['James Morrill', 'Cristopher Salvi', 'Patrick Kidger', 'James Foster', 'Terry Lyons']","Neural controlled differential equations (CDEs) are the continuous-time
analogue of recurrent neural networks, as Neural ODEs are to residual networks,
and offer a memory-efficient continuous-time way to model functions of
potentially irregular time series. Existing methods for computing the forward
pass of a Neural CDE involve embedding the incoming time series into path
space, often via interpolation, and using evaluations of this path to drive the
hidden state. Here, we use rough path theory to extend this formulation.
Instead of directly embedding into path space, we instead represent the input
signal over small time intervals through its \textit{log-signature}, which are
statistics describing how the signal drives a CDE. This is the approach for
solving \textit{rough differential equations} (RDEs), and correspondingly we
describe our main contribution as the introduction of Neural RDEs. This
extension has a purpose: by generalising the Neural CDE approach to a broader
class of driving signals, we demonstrate particular advantages for tackling
long time series. In this regime, we demonstrate efficacy on problems of length
up to 17k observations and observe significant training speed-ups, improvements
in model performance, and reduced memory requirements compared to existing
approaches.",http://arxiv.org/pdf/2009.08295v4,cs.LG
2020-09-17 09:05:40+00:00,Indoor environment data time-series reconstruction using autoencoder neural networks,"['Antonio Liguori', 'Romana Markovic', 'Thi Thu Ha Dam', 'Jérôme Frisch', 'Christoph van Treeck', 'Francesco Causone']","As the number of installed meters in buildings increases, there is a growing
number of data time-series that could be used to develop data-driven models to
support and optimize building operation. However, building data sets are often
characterized by errors and missing values, which are considered, by the recent
research, among the main limiting factors on the performance of the proposed
models. Motivated by the need to address the problem of missing data in
building operation, this work presents a data-driven approach to fill these
gaps. In this study, three different autoencoder neural networks are trained to
reconstruct missing short-term indoor environment data time-series in a data
set collected in an office building in Aachen, Germany. This consisted of a
four year-long monitoring campaign in and between the years 2014 and 2017, of
84 different rooms. The models are applicable for different time-series
obtained from room automation, such as indoor air temperature, relative
humidity and $CO_{2}$ data streams. The results prove that the proposed methods
outperform classic numerical approaches and they result in reconstructing the
corresponding variables with average RMSEs of 0.42 {\deg}C, 1.30 % and 78.41
ppm, respectively.",http://arxiv.org/pdf/2009.08155v2,stat.ML
2020-09-17 06:46:51+00:00,Time series forecasting with Gaussian Processes needs priors,"['Giorgio Corani', 'Alessio Benavoli', 'Marco Zaffalon']","Automatic forecasting is the task of receiving a time series and returning a
forecast for the next time steps without any human intervention. Gaussian
Processes (GPs) are a powerful tool for modeling time series, but so far there
are no competitive approaches for automatic forecasting based on GPs. We
propose practical solutions to two problems: automatic selection of the optimal
kernel and reliable estimation of the hyperparameters. We propose a fixed
composition of kernels, which contains the components needed to model most time
series: linear trend, periodic patterns, and other flexible kernel for modeling
the non-linear trend. Not all components are necessary to model each time
series; during training the unnecessary components are automatically made
irrelevant via automatic relevance determination (ARD). We moreover assign
priors to the hyperparameters, in order to keep the inference within a
plausible range; we design such priors through an empirical Bayes approach. We
present results on many time series of different types; our GP model is more
accurate than state-of-the-art time series models. Thanks to the priors, a
single restart is enough the estimate the hyperparameters; hence the model is
also fast to train.",http://arxiv.org/pdf/2009.08102v2,stat.ML
2020-09-16 21:24:20+00:00,An analysis of deep neural networks for predicting trends in time series data,"['Kouame Hermann Kouassi', 'Deshendran Moodley']","Recently, a hybrid Deep Neural Network (DNN) algorithm, TreNet was proposed
for predicting trends in time series data. While TreNet was shown to have
superior performance for trend prediction to other DNN and traditional ML
approaches, the validation method used did not take into account the sequential
nature of time series data sets and did not deal with model update. In this
research we replicated the TreNet experiments on the same data sets using a
walk-forward validation method and tested our optimal model over multiple
independent runs to evaluate model stability. We compared the performance of
the hybrid TreNet algorithm, on four data sets to vanilla DNN algorithms that
take in point data, and also to traditional ML algorithms. We found that in
general TreNet still performs better than the vanilla DNN models, but not on
all data sets as reported in the original TreNet study. This study highlights
the importance of using an appropriate validation method and evaluating model
stability for evaluating and developing machine learning models for trend
prediction in time series data.",http://arxiv.org/pdf/2009.07943v2,cs.LG
2020-09-16 19:35:43+00:00,Matrix Profile XXII: Exact Discovery of Time Series Motifs under DTW,"['Sara Alaee', 'Kaveh Kamgar', 'Eamonn Keogh']","Over the last decade, time series motif discovery has emerged as a useful
primitive for many downstream analytical tasks, including clustering,
classification, rule discovery, segmentation, and summarization. In parallel,
there has been an increased understanding that Dynamic Time Warping (DTW) is
the best time series similarity measure in a host of settings. Surprisingly
however, there has been virtually no work on using DTW to discover motifs. The
most obvious explanation of this is the fact that both motif discovery and the
use of DTW can be computationally challenging, and the current best mechanisms
to address their lethargy are mutually incompatible. In this work, we present
the first scalable exact method to discover time series motifs under DTW. Our
method automatically performs the best trade-off between time-to-compute and
tightness-of-lower-bounds for a novel hierarchy of lower bounds representation
we introduce. We show that under realistic settings, our algorithm can
admissibly prune up to 99.99% of the DTW computations.",http://arxiv.org/pdf/2009.07907v1,cs.LG
2020-09-16 15:52:04+00:00,TadGAN: Time Series Anomaly Detection Using Generative Adversarial Networks,"['Alexander Geiger', 'Dongyu Liu', 'Sarah Alnegheimish', 'Alfredo Cuesta-Infante', 'Kalyan Veeramachaneni']","Time series anomalies can offer information relevant to critical situations
facing various fields, from finance and aerospace to the IT, security, and
medical domains. However, detecting anomalies in time series data is
particularly challenging due to the vague definition of anomalies and said
data's frequent lack of labels and highly complex temporal correlations.
Current state-of-the-art unsupervised machine learning methods for anomaly
detection suffer from scalability and portability issues, and may have high
false positive rates. In this paper, we propose TadGAN, an unsupervised anomaly
detection approach built on Generative Adversarial Networks (GANs). To capture
the temporal correlations of time series distributions, we use LSTM Recurrent
Neural Networks as base models for Generators and Critics. TadGAN is trained
with cycle consistency loss to allow for effective time-series data
reconstruction. We further propose several novel methods to compute
reconstruction errors, as well as different approaches to combine
reconstruction errors and Critic outputs to compute anomaly scores. To
demonstrate the performance and generalizability of our approach, we test
several anomaly scoring techniques and report the best-suited one. We compare
our approach to 8 baseline anomaly detection methods on 11 datasets from
multiple reputable sources such as NASA, Yahoo, Numenta, Amazon, and Twitter.
The results show that our approach can effectively detect anomalies and
outperform baseline methods in most cases (6 out of 11). Notably, our method
has the highest averaged F1 score across all the datasets. Our code is open
source and is available as a benchmarking tool.",http://arxiv.org/pdf/2009.07769v3,cs.LG
2020-09-15 18:25:02+00:00,A Portmanteau-type test for detecting serial correlation in locally stationary functional time series,"['Axel Bücher', 'Holger Dette', 'Florian Heinrichs']","The Portmanteau test provides the vanilla method for detecting serial
correlations in classical univariate time series analysis. The method is
extended to the case of observations from a locally stationary functional time
series. Asymptotic critical values are obtained by a suitable block multiplier
bootstrap procedure. The test is shown to asymptotically hold its level and to
be consistent against general alternatives.",http://arxiv.org/pdf/2009.07312v1,math.ST
2020-09-15 04:45:02+00:00,Structural time series grammar over variable blocks,['David Rushing Dewhurst'],"A structural time series model additively decomposes into generative,
semantically-meaningful components, each of which depends on a vector of
parameters. We demonstrate that considering each generative component together
with its vector of parameters as a single latent structural time series node
can simplify reasoning about collections of structural time series components.
We then introduce a formal grammar over structural time series nodes and
parameter vectors. Valid sentences in the grammar can be interpreted as
generative structural time series models. An extension of the grammar can also
express structural time series models that include changepoints, though these
models are necessarily not generative. We demonstrate a preliminary
implementation of the language generated by this grammar. We close with a
discussion of possible future work.",http://arxiv.org/pdf/2009.06865v1,stat.ME
2020-09-14 23:11:19+00:00,Learning Hidden Patterns from Patient Multivariate Time Series Data Using Convolutional Neural Networks: A Case Study of Healthcare Cost Prediction,"['Mohammad Amin Morid', 'Olivia R. Liu Sheng', 'Kensaku Kawamoto', 'Samir Abdelrahman']","Objective: To develop an effective and scalable individual-level patient cost
prediction method by automatically learning hidden temporal patterns from
multivariate time series data in patient insurance claims using a convolutional
neural network (CNN) architecture.
  Methods: We used three years of medical and pharmacy claims data from 2013 to
2016 from a healthcare insurer, where data from the first two years were used
to build the model to predict costs in the third year. The data consisted of
the multivariate time series of cost, visit and medical features that were
shaped as images of patients' health status (i.e., matrices with time windows
on one dimension and the medical, visit and cost features on the other
dimension). Patients' multivariate time series images were given to a CNN
method with a proposed architecture. After hyper-parameter tuning, the proposed
architecture consisted of three building blocks of convolution and pooling
layers with an LReLU activation function and a customized kernel size at each
layer for healthcare data. The proposed CNN learned temporal patterns became
inputs to a fully connected layer.
  Conclusions: Feature learning through the proposed CNN configuration
significantly improved individual-level healthcare cost prediction. The
proposed CNN was able to outperform temporal pattern detection methods that
look for a pre-defined set of pattern shapes, since it is capable of extracting
a variable number of patterns with various shapes. Temporal patterns learned
from medical, visit and cost data made significant contributions to the
prediction performance. Hyper-parameter tuning showed that considering
three-month data patterns has the highest prediction accuracy. Our results
showed that patients' images extracted from multivariate time series data are
different from regular images, and hence require unique designs of CNN
architectures.",http://arxiv.org/pdf/2009.06783v1,cs.LG
2020-09-13 21:50:49+00:00,Time-varying auto-regressive models for count time-series,"['Arkaprava Roy', 'Sayar Karmakar']","Count-valued time series data are routinely collected in many application
areas. We are particularly motivated to study the count time series of daily
new cases, arising from COVID-19 spread. We propose two Bayesian models, a
time-varying semiparametric AR(p) model for count and then a time-varying
INGARCH model considering the rapid changes in the spread. We calculate
posterior contraction rates of the proposed Bayesian methods with respect to
average Hellinger metric. Our proposed structures of the models are amenable to
Hamiltonian Monte Carlo (HMC) sampling for efficient computation. We
substantiate our methods by simulations that show superiority compared to some
of the close existing methods. Finally we analyze the daily time series data of
newly confirmed cases to study its spread through different government
interventions.",http://arxiv.org/pdf/2009.07634v2,stat.ME
2020-09-10 06:27:57+00:00,"Large-scale nonlinear Granger causality: A data-driven, multivariate approach to recovering directed networks from short time-series data","['Axel Wismüller', 'Adora M. DSouza', 'Anas Z. Abidin']","To gain insight into complex systems it is a key challenge to infer nonlinear
causal directional relations from observational time-series data. Specifically,
estimating causal relationships between interacting components in large systems
with only short recordings over few temporal observations remains an important,
yet unresolved problem. Here, we introduce a large-scale Nonlinear Granger
Causality (lsNGC) approach for inferring directional, nonlinear, multivariate
causal interactions between system components from short high-dimensional
time-series recordings. By modeling interactions with nonlinear state-space
transformations from limited observational data, lsNGC identifies casual
relations with no explicit a priori assumptions on functional interdependence
between component time-series in a computationally efficient manner.
Additionally, our method provides a mathematical formulation revealing
statistical significance of inferred causal relations. We extensively study the
ability of lsNGC to recovering network structure from two-node to thirty-four
node chaotic time-series systems. Our results suggest that lsNGC captures
meaningful interactions from limited observational data, where it performs
favorably when compared to traditionally used methods. Finally, we demonstrate
the applicability of lsNGC to estimating causality in large, real-world systems
by inferring directional nonlinear, multivariate causal relationships among a
large number of relatively short time-series acquired from functional Magnetic
Resonance Imaging (fMRI) data of the human brain.",http://arxiv.org/pdf/2009.04681v1,cs.LG
2020-09-09 23:10:40+00:00,tsBNgen: A Python Library to Generate Time Series Data from an Arbitrary Dynamic Bayesian Network Structure,"['Manie Tadayon', 'Greg Pottie']","Synthetic data is widely used in various domains. This is because many modern
algorithms require lots of data for efficient training, and data collection and
labeling usually are a time-consuming process and are prone to errors.
Furthermore, some real-world data, due to its nature, is confidential and
cannot be shared. Bayesian networks are a type of probabilistic graphical model
widely used to model the uncertainties in real-world processes. Dynamic
Bayesian networks are a special class of Bayesian networks that model temporal
and time series data. In this paper, we introduce the tsBNgen, a Python library
to generate time series and sequential data based on an arbitrary dynamic
Bayesian network. The package, documentation, and examples can be downloaded
from https://github.com/manitadayon/tsBNgen.",http://arxiv.org/pdf/2009.04595v1,cs.LG
2020-09-08 12:10:10+00:00,Topology-based Clusterwise Regression for User Segmentation and Demand Forecasting,"['Rodrigo Rivera-Castro', 'Aleksandr Pletnev', 'Polina Pilyugina', 'Grecia Diaz', 'Ivan Nazarov', 'Wanyi Zhu', 'Evgeny Burnaev']","Topological Data Analysis (TDA) is a recent approach to analyze data sets
from the perspective of their topological structure. Its use for time series
data has been limited. In this work, a system developed for a leading provider
of cloud computing combining both user segmentation and demand forecasting is
presented. It consists of a TDA-based clustering method for time series
inspired by a popular managerial framework for customer segmentation and
extended to the case of clusterwise regression using matrix factorization
methods to forecast demand. Increasing customer loyalty and producing accurate
forecasts remain active topics of discussion both for researchers and managers.
Using a public and a novel proprietary data set of commercial data, this
research shows that the proposed system enables analysts to both cluster their
user base and plan demand at a granular level with significantly higher
accuracy than a state of the art baseline. This work thus seeks to introduce
TDA-based clustering of time series and clusterwise regression with matrix
factorization methods as viable tools for the practitioner.",http://arxiv.org/pdf/2009.03661v1,cs.LG
2020-09-08 09:44:03+00:00,Multivariable times series classification through an interpretable representation,"['Francisco J. Baldán', 'José M. Benítez']","Multivariate time series classification is a task with increasing importance
due to the proliferation of new problems in various fields (economy, health,
energy, transport, crops, etc.) where a large number of information sources are
available. Direct extrapolation of methods that traditionally worked in
univariate environments cannot frequently be applied to obtain the best results
in multivariate problems. This is mainly due to the inability of these methods
to capture the relationships between the different variables that conform a
multivariate time series. The multivariate proposals published to date offer
competitive results but are hard to interpret. In this paper we propose a time
series classification method that considers an alternative representation of
time series through a set of descriptive features taking into account the
relationships between the different variables of a multivariate time series. We
have applied traditional classification algorithms obtaining interpretable and
competitive results.",http://arxiv.org/pdf/2009.03614v1,cs.LG
2020-09-04 07:46:19+00:00,Multivariate Time-series Anomaly Detection via Graph Attention Network,"['Hang Zhao', 'Yujing Wang', 'Juanyong Duan', 'Congrui Huang', 'Defu Cao', 'Yunhai Tong', 'Bixiong Xu', 'Jing Bai', 'Jie Tong', 'Qi Zhang']","Anomaly detection on multivariate time-series is of great importance in both
data mining research and industrial applications. Recent approaches have
achieved significant progress in this topic, but there is remaining
limitations. One major limitation is that they do not capture the relationships
between different time-series explicitly, resulting in inevitable false alarms.
In this paper, we propose a novel self-supervised framework for multivariate
time-series anomaly detection to address this issue. Our framework considers
each univariate time-series as an individual feature and includes two graph
attention layers in parallel to learn the complex dependencies of multivariate
time-series in both temporal and feature dimensions. In addition, our approach
jointly optimizes a forecasting-based model and are construction-based model,
obtaining better time-series representations through a combination of
single-timestamp prediction and reconstruction of the entire time-series. We
demonstrate the efficacy of our model through extensive experiments. The
proposed method outperforms other state-of-the-art models on three real-world
datasets. Further analysis shows that our method has good interpretability and
is useful for anomaly diagnosis.",http://arxiv.org/pdf/2009.02040v1,cs.LG
2020-09-02 10:57:28+00:00,LAVARNET: Neural Network Modeling of Causal Variable Relationships for Multivariate Time Series Forecasting,"['Christos Koutlis', 'Symeon Papadopoulos', 'Manos Schinas', 'Ioannis Kompatsiaris']","Multivariate time series forecasting is of great importance to many
scientific disciplines and industrial sectors. The evolution of a multivariate
time series depends on the dynamics of its variables and the connectivity
network of causal interrelationships among them. Most of the existing time
series models do not account for the causal effects among the system's
variables and even if they do they rely just on determining the
between-variables causality network. Knowing the structure of such a complex
network and even more specifically knowing the exact lagged variables that
contribute to the underlying process is crucial for the task of multivariate
time series forecasting. The latter is a rather unexplored source of
information to leverage. In this direction, here a novel neural network-based
architecture is proposed, termed LAgged VAriable Representation NETwork
(LAVARNET), which intrinsically estimates the importance of lagged variables
and combines high dimensional latent representations of them to predict future
values of time series. Our model is compared with other baseline and state of
the art neural network architectures on one simulated data set and four real
data sets from meteorology, music, solar activity, and finance areas. The
proposed architecture outperforms the competitive architectures in most of the
experiments.",http://arxiv.org/pdf/2009.00945v1,cs.LG
2020-08-30 20:03:35+00:00,Benchmarking adversarial attacks and defenses for time-series data,"['Shoaib Ahmed Siddiqui', 'Andreas Dengel', 'Sheraz Ahmed']","The adversarial vulnerability of deep networks has spurred the interest of
researchers worldwide. Unsurprisingly, like images, adversarial examples also
translate to time-series data as they are an inherent weakness of the model
itself rather than the modality. Several attempts have been made to defend
against these adversarial attacks, particularly for the visual modality. In
this paper, we perform detailed benchmarking of well-proven adversarial defense
methodologies on time-series data. We restrict ourselves to the $L_{\infty}$
threat model. We also explore the trade-off between smoothness and clean
accuracy for regularization-based defenses to better understand the trade-offs
that they offer. Our analysis shows that the explored adversarial defenses
offer robustness against both strong white-box as well as black-box attacks.
This paves the way for future research in the direction of adversarial attacks
and defenses, particularly for time-series data.",http://arxiv.org/pdf/2008.13261v1,cs.LG
2020-08-29 00:33:26+00:00,An autocovariance-based learning framework for high-dimensional functional time series,"['Jinyuan Chang', 'Cheng Chen', 'Xinghao Qiao', 'Qiwei Yao']","Many scientific and economic applications involve the statistical learning of
high-dimensional functional time series, where the number of functional
variables is comparable to, or even greater than, the number of serially
dependent functional observations. In this paper, we model observed functional
time series, which are subject to errors in the sense that each functional
datum arises as the sum of two uncorrelated components, one dynamic and one
white noise. Motivated from the fact that the autocovariance function of
observed functional time series automatically filters out the noise term, we
propose a three-step procedure by first performing autocovariance-based
dimension reduction, then formulating a novel autocovariance-based block
regularized minimum distance estimation framework to produce block sparse
estimates, and based on which obtaining the final functional sparse estimates.
We investigate theoretical properties of the proposed estimators, and
illustrate the proposed estimation procedure via three sparse high-dimensional
functional time series models. We demonstrate via both simulated and real
datasets that our proposed estimators significantly outperform the competitors.",http://arxiv.org/pdf/2008.12885v3,math.ST
2020-08-28 20:10:07+00:00,Pay Attention to Evolution: Time Series Forecasting with Deep Graph-Evolution Learning,"['Gabriel Spadon', 'Shenda Hong', 'Bruno Brandoli', 'Stan Matwin', 'Jose F. Rodrigues-Jr', 'Jimeng Sun']","Time-series forecasting is one of the most active research topics in
artificial intelligence. Applications in real-world time series should consider
two factors for achieving reliable predictions: modeling dynamic dependencies
among multiple variables and adjusting the model's intrinsic hyperparameters. A
still open gap in that literature is that statistical and ensemble learning
approaches systematically present lower predictive performance than deep
learning methods. They generally disregard the data sequence aspect entangled
with multivariate data represented in more than one time series. Conversely,
this work presents a novel neural network architecture for time-series
forecasting that combines the power of graph evolution with deep recurrent
learning on distinct data distributions; we named our method Recurrent Graph
Evolution Neural Network (ReGENN). The idea is to infer multiple multivariate
relationships between co-occurring time-series by assuming that the temporal
data depends not only on inner variables and intra-temporal relationships
(i.e., observations from itself) but also on outer variables and inter-temporal
relationships (i.e., observations from other-selves). An extensive set of
experiments was conducted comparing ReGENN with dozens of ensemble methods and
classical statistical ones, showing sound improvement of up to 64.87% over the
competing algorithms. Furthermore, we present an analysis of the intermediate
weights arising from ReGENN, showing that by looking at inter and
intra-temporal relationships simultaneously, time-series forecasting is majorly
improved if paying attention to how multiple multivariate data synchronously
evolve.",http://arxiv.org/pdf/2008.12833v4,cs.LG
2020-08-27 19:08:30+00:00,Forecasting with Multiple Seasonality,"['Tianyang Xie', 'Jie Ding']","An emerging number of modern applications involve forecasting time series
data that exhibit both short-time dynamics and long-time seasonality.
Specifically, time series with multiple seasonality is a difficult task with
comparatively fewer discussions. In this paper, we propose a two-stage method
for time series with multiple seasonality, which does not require
pre-determined seasonality periods. In the first stage, we generalize the
classical seasonal autoregressive moving average (ARMA) model in multiple
seasonality regime. In the second stage, we utilize an appropriate criterion
for lag order selection. Simulation and empirical studies show the excellent
predictive performance of our method, especially compared to a recently popular
`Facebook Prophet' model for time series.",http://arxiv.org/pdf/2008.12340v1,cs.LG
2020-08-26 18:33:35+00:00,Minimizing post-shock forecasting error through aggregation of outside information,"['Jilei Lin', 'Daniel J. Eck']","We develop a forecasting methodology for providing credible forecasts for
time series that have recently undergone a shock. We achieve this by borrowing
knowledge from other time series that have undergone similar shocks for which
post-shock outcomes are observed. Three shock effect estimators are motivated
with the aim of minimizing average forecast risk. We propose risk-reduction
propositions that provide conditions that establish when our methodology works.
Bootstrap and leave-one-out cross validation procedures are provided to
prospectively assess the performance of our methodology. Several simulated data
examples, and a real data example of forecasting Conoco Phillips stock price
are provided for verification and illustration.",http://arxiv.org/pdf/2008.11756v1,stat.ME
2020-08-25 07:23:43+00:00,Automated Model Selection for Time-Series Anomaly Detection,"['Yuanxiang Ying', 'Juanyong Duan', 'Chunlei Wang', 'Yujing Wang', 'Congrui Huang', 'Bixiong Xu']","Time-series anomaly detection is a popular topic in both academia and
industrial fields. Many companies need to monitor thousands of temporal signals
for their applications and services and require instant feedback and alerts for
potential incidents in time. The task is challenging because of the complex
characteristics of time-series, which are messy, stochastic, and often without
proper labels. This prohibits training supervised models because of lack of
labels and a single model hardly fits different time series. In this paper, we
propose a solution to address these issues. We present an automated model
selection framework to automatically find the most suitable detection model
with proper parameters for the incoming data. The model selection layer is
extensible as it can be updated without too much effort when a new detector is
available to the service. Finally, we incorporate a customized tuning algorithm
to flexibly filter anomalies to meet customers' criteria. Experiments on
real-world datasets show the effectiveness of our solution.",http://arxiv.org/pdf/2009.04395v1,cs.LG
2020-08-25 02:04:59+00:00,Counterfactual Explanations for Machine Learning on Multivariate Time Series Data,"['Emre Ates', 'Burak Aksar', 'Vitus J. Leung', 'Ayse K. Coskun']","Applying machine learning (ML) on multivariate time series data has growing
popularity in many application domains, including in computer system
management. For example, recent high performance computing (HPC) research
proposes a variety of ML frameworks that use system telemetry data in the form
of multivariate time series so as to detect performance variations, perform
intelligent scheduling or node allocation, and improve system security. Common
barriers for adoption for these ML frameworks include the lack of user trust
and the difficulty of debugging. These barriers need to be overcome to enable
the widespread adoption of ML frameworks in production systems. To address this
challenge, this paper proposes a novel explainability technique for providing
counterfactual explanations for supervised ML frameworks that use multivariate
time series data. The proposed method outperforms state-of-the-art
explainability methods on several different ML frameworks and data sets in
metrics such as faithfulness and robustness. The paper also demonstrates how
the proposed method can be used to debug ML frameworks and gain a better
understanding of HPC system telemetry data.",http://arxiv.org/pdf/2008.10781v1,cs.LG
2020-08-24 12:23:07+00:00,ATM Cash demand forecasting in an Indian Bank with chaos and deep learning,"['Sarveswararao Vangala', 'Ravi Vadlamani']","This paper proposes to model chaos in the ATM cash withdrawal time series of
a big Indian bank and forecast the withdrawals using deep learning methods. It
also considers the importance of day-of-the-week and includes it as a dummy
exogenous variable. We first modelled the chaos present in the withdrawal time
series by reconstructing the state space of each series using the lag, and
embedding dimension found using an auto-correlation function and Cao's method.
This process converts the uni-variate time series into multi variate time
series. The ""day-of-the-week"" is converted into seven features with the help of
one-hot encoding. Then these seven features are augmented to the multivariate
time series. For forecasting the future cash withdrawals, using algorithms
namely ARIMA, random forest (RF), support vector regressor (SVR), multi-layer
perceptron (MLP), group method of data handling (GMDH), general regression
neural network (GRNN), long short term memory neural network and 1-dimensional
convolutional neural network. We considered a daily cash withdrawals data set
from an Indian commercial bank. After modelling chaos and adding exogenous
features to the data set, we observed improvements in the forecasting for all
models. Even though the random forest (RF) yielded better Symmetric Mean
Absolute Percentage Error (SMAPE) value, deep learning algorithms, namely LSTM
and 1D CNN, showed similar performance compared to RF, based on t-test.",http://arxiv.org/pdf/2008.10365v1,cs.LG
2020-08-23 14:56:59+00:00,Multiple Network Embedding for Anomaly Detection in Time Series of Graphs,"['Guodong Chen', 'Jesús Arroyo', 'Avanti Athreya', 'Joshua Cape', 'Joshua T. Vogelstein', 'Youngser Park', 'Chris White', 'Jonathan Larson', 'Weiwei Yang', 'Carey E. Priebe']","This paper considers the graph signal processing problem of anomaly detection
in time series of graphs. We examine two related, complementary inference
tasks: the detection of anomalous graphs within a time series, and the
detection of temporally anomalous vertices. We approach these tasks via the
adaptation of statistically principled methods for joint graph inference,
specifically \emph{multiple adjacency spectral embedding} (MASE). We
demonstrate that our method is effective for our inference tasks. Moreover, we
assess the performance of our method in terms of the underlying nature of
detectable anomalies. We further provide the theoretical justification for our
method and insight into its use. Applied to the Enron communication graph and a
large-scale commercial search engine time series of graphs, our approaches
demonstrate their applicability and identify the anomalous vertices beyond just
large degree change.",http://arxiv.org/pdf/2008.10055v5,stat.ME
2020-08-20 19:26:24+00:00,The Canonical Interval Forest (CIF) Classifier for Time Series Classification,"['Matthew Middlehurst', 'James Large', 'Anthony Bagnall']","Time series classification (TSC) is home to a number of algorithm groups that
utilise different kinds of discriminatory patterns. One of these groups
describes classifiers that predict using phase dependant intervals. The time
series forest (TSF) classifier is one of the most well known interval methods,
and has demonstrated strong performance as well as relative speed in training
and predictions. However, recent advances in other approaches have left TSF
behind. TSF originally summarises intervals using three simple summary
statistics. The `catch22' feature set of 22 time series features was recently
proposed to aid time series analysis through a concise set of diverse and
informative descriptive characteristics. We propose combining TSF and catch22
to form a new classifier, the Canonical Interval Forest (CIF). We outline
additional enhancements to the training procedure, and extend the classifier to
include multivariate classification capabilities. We demonstrate a large and
significant improvement in accuracy over both TSF and catch22, and show it to
be on par with top performers from other algorithmic classes. By upgrading the
interval-based component from TSF to CIF, we also demonstrate a significant
improvement in the hierarchical vote collective of transformation-based
ensembles (HIVE-COTE) that combines different time series representations.
HIVE-COTE using CIF is significantly more accurate on the UCR archive than any
other classifier we are aware of and represents a new state of the art for TSC.",http://arxiv.org/pdf/2008.09172v1,cs.LG
2020-08-20 10:40:42+00:00,Reinforcement Learning based dynamic weighing of Ensemble Models for Time Series Forecasting,"['Satheesh K. Perepu', 'Bala Shyamala Balaji', 'Hemanth Kumar Tanneru', 'Sudhakar Kathari', 'Vivek Shankar Pinnamaraju']","Ensemble models are powerful model building tools that are developed with a
focus to improve the accuracy of model predictions. They find applications in
time series forecasting in varied scenarios including but not limited to
process industries, health care, and economics where a single model might not
provide optimal performance. It is known that if models selected for data
modelling are distinct (linear/non-linear, static/dynamic) and independent
(minimally correlated models), the accuracy of the predictions is improved.
Various approaches suggested in the literature to weigh the ensemble models use
a static set of weights. Due to this limitation, approaches using a static set
of weights for weighing ensemble models cannot capture the dynamic changes or
local features of the data effectively. To address this issue, a Reinforcement
Learning (RL) approach to dynamically assign and update weights of each of the
models at different time instants depending on the nature of data and the
individual model predictions is proposed in this work. The RL method
implemented online, essentially learns to update the weights and reduce the
errors as the time progresses. Simulation studies on time series data showed
that the dynamic weighted approach using RL learns the weight better than
existing approaches. The accuracy of the proposed method is compared with an
existing approach of online Neural Network tuning quantitatively through
normalized mean square error(NMSE) values.",http://arxiv.org/pdf/2008.08878v1,cs.LG
2020-08-20 05:19:46+00:00,Strong consistent model selection for general causal time series,['William Kengne'],"We consider the strongly consistent question for model selection in a large
class of causal time series models, including AR($\infty$), ARCH($\infty$),
TARCH($\infty$), ARMA-GARCH and many classical others processes.
  We propose a penalized criterion based on the quasi likelihood of the model.
  We provide sufficient conditions that ensure the strong consistency of the
proposed procedure. Also, the estimator of the parameter of the selected model
obeys the law of iterated logarithm.
  It appears that, unlike the result of the weak consistency obtained by Bardet
{\it et al.} \cite{Bardet2020}, a dependence between the regularization
parameter and the model structure is not needed.",http://arxiv.org/pdf/2008.08778v1,math.ST
2020-08-19 18:21:22+00:00,MTHetGNN: A Heterogeneous Graph Embedding Framework for Multivariate Time Series Forecasting,"['Yueyang Wang', 'Ziheng Duan', 'Yida Huang', 'Haoyan Xu', 'Jie Feng', 'Anni Ren']","Multivariate time series forecasting, which analyzes historical time series
to predict future trends, can effectively help decision-making. Complex
relations among variables in MTS, including static, dynamic, predictable, and
latent relations, have made it possible to mining more features of MTS.
Modeling complex relations are not only essential in characterizing latent
dependency as well as modeling temporal dependence but also brings great
challenges in the MTS forecasting task. However, existing methods mainly focus
on modeling certain relations among MTS variables. In this paper, we propose a
novel end-to-end deep learning model, termed Multivariate Time Series
Forecasting via Heterogeneous Graph Neural Networks (MTHetGNN). To characterize
complex relations among variables, a relation embedding module is designed in
MTHetGNN, where each variable is regarded as a graph node, and each type of
edge represents a specific static or dynamic relationship. Meanwhile, a
temporal embedding module is introduced for time series features extraction,
where involving convolutional neural network (CNN) filters with different
perception scales. Finally, a heterogeneous graph embedding module is adopted
to handle the complex structural information generated by the two modules.
Three benchmark datasets from the real world are used to evaluate the proposed
MTHetGNN. The comprehensive experiments show that MTHetGNN achieves
state-of-the-art results in the MTS forecasting task.",http://arxiv.org/pdf/2008.08617v4,cs.LG
2020-08-18 22:48:24+00:00,New Goodness-of-Fit Tests for Time Series Models,['Esam Mahdi'],"This article proposes omnibus portmanteau tests for contrasting adequacy of
time series models. The test statistics are based on combining the
autocorrelation function of the conditional residuals, the autocorrelation
function of the conditional squared residuals, and the cross-correlation
function between these residuals and their squares. The maximum likelihood
estimator is used to derive the asymptotic distribution of the proposed test
statistics under a general class of time series models, including ARMA, GARCH,
and other nonlinear structures. An extensive Monte Carlo simulation study shows
that the proposed tests successfully control the type I error probability and
tend to have more power than other competitor tests in many scenarios. Two
applications to a set of weekly stock returns for 92 companies from the S&P 500
demonstrate the practical use of the proposed tests.",http://arxiv.org/pdf/2008.08176v3,stat.ME
2020-08-18 11:28:50+00:00,A Formally Robust Time Series Distance Metric,"['Maximilian Toller', 'Bernhard C. Geiger', 'Roman Kern']","Distance-based classification is among the most competitive classification
methods for time series data. The most critical component of distance-based
classification is the selected distance function. Past research has proposed
various different distance metrics or measures dedicated to particular aspects
of real-world time series data, yet there is an important aspect that has not
been considered so far: Robustness against arbitrary data contamination. In
this work, we propose a novel distance metric that is robust against
arbitrarily ""bad"" contamination and has a worst-case computational complexity
of $\mathcal{O}(n\log n)$. We formally argue why our proposed metric is robust,
and demonstrate in an empirical evaluation that the metric yields competitive
classification accuracy when applied in k-Nearest Neighbor time series
classification.",http://arxiv.org/pdf/2008.07865v1,cs.LG
2020-08-18 03:55:29+00:00,Parallel Extraction of Long-term Trends and Short-term Fluctuation Framework for Multivariate Time Series Forecasting,"['Yifu Zhou', 'Ziheng Duan', 'Haoyan Xu', 'Jie Feng', 'Anni Ren', 'Yueyang Wang', 'Xiaoqian Wang']","Multivariate time series forecasting is widely used in various fields.
Reasonable prediction results can assist people in planning and
decision-making, generate benefits and avoid risks. Normally, there are two
characteristics of time series, that is, long-term trend and short-term
fluctuation. For example, stock prices will have a long-term upward trend with
the market, but there may be a small decline in the short term. These two
characteristics are often relatively independent of each other. However, the
existing prediction methods often do not distinguish between them, which
reduces the accuracy of the prediction model. In this paper, a MTS forecasting
framework that can capture the long-term trends and short-term fluctuations of
time series in parallel is proposed. This method uses the original time series
and its first difference to characterize long-term trends and short-term
fluctuations. Three prediction sub-networks are constructed to predict
long-term trends, short-term fluctuations and the final value to be predicted.
In the overall optimization goal, the idea of multi-task learning is used for
reference, which is to make the prediction results of long-term trends and
short-term fluctuations as close to the real values as possible while requiring
to approximate the values to be predicted. In this way, the proposed method
uses more supervision information and can more accurately capture the changing
trend of the time series, thereby improving the forecasting performance.",http://arxiv.org/pdf/2008.07730v3,cs.LG
2020-08-18 02:48:43+00:00,Selecting Data Adaptive Learner from Multiple Deep Learners using Bayesian Networks,"['Shusuke Kobayashi', 'Susumu Shirayama']","A method to predict time-series using multiple deep learners and a Bayesian
network is proposed. In this study, the input explanatory variables are
Bayesian network nodes that are associated with learners. Training data are
divided using K-means clustering, and multiple deep learners are trained
depending on the cluster. A Bayesian network is used to determine which deep
learner is in charge of predicting a time-series. We determine a threshold
value and select learners with a posterior probability equal to or greater than
the threshold value, which could facilitate more robust prediction. The
proposed method is applied to financial time-series data, and the predicted
results for the Nikkei 225 index are demonstrated.",http://arxiv.org/pdf/2008.07709v1,cs.LG
2020-08-17 20:01:55+00:00,Learning from Irregularly-Sampled Time Series: A Missing Data Perspective,"['Steven Cheng-Xian Li', 'Benjamin M. Marlin']","Irregularly-sampled time series occur in many domains including healthcare.
They can be challenging to model because they do not naturally yield a
fixed-dimensional representation as required by many standard machine learning
models. In this paper, we consider irregular sampling from the perspective of
missing data. We model observed irregularly-sampled time series data as a
sequence of index-value pairs sampled from a continuous but unobserved
function. We introduce an encoder-decoder framework for learning from such
generic indexed sequences. We propose learning methods for this framework based
on variational autoencoders and generative adversarial networks. For continuous
irregularly-sampled time series, we introduce continuous convolutional layers
that can efficiently interface with existing neural network architectures.
Experiments show that our models are able to achieve competitive or better
classification results on irregularly-sampled multivariate time series compared
to recent RNN models while offering significantly faster training times.",http://arxiv.org/pdf/2008.07599v1,cs.LG
2020-08-13 15:40:38+00:00,A Survey on Knowledge integration techniques with Artificial Neural Networks for seq-2-seq/time series models,"['Pramod Vadiraja', 'Muhammad Ali Chattha']","In recent years, with the advent of massive computational power and the
availability of huge amounts of data, Deep neural networks have enabled the
exploration of uncharted areas in several domains. But at times, they
under-perform due to insufficient data, poor data quality, data that might not
be covering the domain broadly, etc. Knowledge-based systems leverage expert
knowledge for making decisions and suitably take actions. Such systems retain
interpretability in the decision-making process. This paper focuses on
exploring techniques to integrate expert knowledge to the Deep Neural Networks
for sequence-to-sequence and time series models to improve their performance
and interpretability.",http://arxiv.org/pdf/2008.05972v1,cs.LG
2020-08-11 17:34:55+00:00,Spatiotemporal Attention for Multivariate Time Series Prediction and Interpretation,"['Tryambak Gangopadhyay', 'Sin Yong Tan', 'Zhanhong Jiang', 'Rui Meng', 'Soumik Sarkar']","Multivariate time series modeling and prediction problems are abundant in
many machine learning application domains. Accurate interpretation of such
prediction outcomes from a machine learning model that explicitly captures
temporal correlations can significantly benefit the domain experts. In this
context, temporal attention has been successfully applied to isolate the
important time steps for the input time series. However, in multivariate time
series problems, spatial interpretation is also critical to understand the
contributions of different variables on the model outputs. We propose a novel
deep learning architecture, called spatiotemporal attention mechanism (STAM)
for simultaneous learning of the most important time steps and variables. STAM
is a causal (i.e., only depends on past inputs and does not use future inputs)
and scalable (i.e., scales well with an increase in the number of variables)
approach that is comparable to the state-of-the-art models in terms of
computational tractability. We demonstrate our models' performance on two
popular public datasets and a domain-specific dataset. When compared with the
baseline models, the results show that STAM maintains state-of-the-art
prediction accuracy while offering the benefit of accurate spatiotemporal
interpretability. The learned attention weights are validated from a domain
knowledge perspective for these real-world datasets.",http://arxiv.org/pdf/2008.04882v2,cs.LG
2020-08-06 13:52:20+00:00,Improving the Accuracy of Global Forecasting Models using Time Series Data Augmentation,"['Kasun Bandara', 'Hansika Hewamalage', 'Yuan-Hao Liu', 'Yanfei Kang', 'Christoph Bergmeir']","Forecasting models that are trained across sets of many time series, known as
Global Forecasting Models (GFM), have shown recently promising results in
forecasting competitions and real-world applications, outperforming many
state-of-the-art univariate forecasting techniques. In most cases, GFMs are
implemented using deep neural networks, and in particular Recurrent Neural
Networks (RNN), which require a sufficient amount of time series to estimate
their numerous model parameters. However, many time series databases have only
a limited number of time series. In this study, we propose a novel, data
augmentation based forecasting framework that is capable of improving the
baseline accuracy of the GFM models in less data-abundant settings. We use
three time series augmentation techniques: GRATIS, moving block bootstrap
(MBB), and dynamic time warping barycentric averaging (DBA) to synthetically
generate a collection of time series. The knowledge acquired from these
augmented time series is then transferred to the original dataset using two
different approaches: the pooled approach and the transfer learning approach.
When building GFMs, in the pooled approach, we train a model on the augmented
time series alongside the original time series dataset, whereas in the transfer
learning approach, we adapt a pre-trained model to the new dataset. In our
evaluation on competition and real-world time series datasets, our proposed
variants can significantly improve the baseline accuracy of GFM models and
outperform state-of-the-art univariate forecasting methods.",http://arxiv.org/pdf/2008.02663v1,cs.LG
2020-08-06 07:02:10+00:00,Modeling of time series using random forests: theoretical developments,"['Richard A. Davis', 'Mikkel S. Nielsen']","In this paper we study asymptotic properties of random forests within the
framework of nonlinear time series modeling. While random forests have been
successfully applied in various fields, the theoretical justification has not
been considered for their use in a time series setting. Under mild conditions,
we prove a uniform concentration inequality for regression trees built on
nonlinear autoregressive processes and, subsequently, we use this result to
prove consistency for a large class of random forests. The results are
supported by various simulations.",http://arxiv.org/pdf/2008.02479v1,stat.ML
2020-08-05 14:48:02+00:00,A Causal-based Framework for Multimodal Multivariate Time Series Validation Enhanced by Unsupervised Deep Learning as an Enabler for Industry 4.0,['Cedric Schockaert'],"An advanced conceptual validation framework for multimodal multivariate time
series defines a multi-level contextual anomaly detection ranging from an
univariate context definition, to a multimodal abstract context representation
learnt by an Autoencoder from heterogeneous data (images, time series, sounds,
etc.) associated to an industrial process. Each level of the framework is
either applicable to historical data and/or live data. The ultimate level is
based on causal discovery to identify causal relations in observational data in
order to exclude biased data to train machine learning models and provide means
to the domain expert to discover unknown causal relations in the underlying
process represented by the data sample. A Long Short-Term Memory Autoencoder is
successfully evaluated on multivariate time series to validate the learnt
representation of abstract contexts associated to multiple assets of a blast
furnace. A research roadmap is identified to combine causal discovery and
representation learning as an enabler for unsupervised Root Cause Analysis
applied to the process industry.",http://arxiv.org/pdf/2008.02171v1,cs.LG
2020-08-05 05:17:42+00:00,A long memory time series with a periodic degree of fractional differencing,"['Amine Amimour', 'Karima Belaide']","This article develops a periodic version of a time varying parameter
fractional process in the stationary region. It is a partial extension of
Hosking (1981)'s article which dealt with the case where the coefficients are
invariant in time. We will describe the probabilistic theories of this periodic
model. The results are followed by a graphical representation of the
autocovariances functions.",http://arxiv.org/pdf/2008.01939v1,math.ST
2020-08-04 13:09:41+00:00,Asymptotic Theory of Principal Component Analysis for Time Series Data with Cautionary Comments,"['Xinyu Zhang', 'Howell Tong']","Principal component analysis (PCA) is a most frequently used statistical tool
in almost all branches of data science. However, like many other statistical
tools, there is sometimes the risk of misuse or even abuse. In this paper, we
highlight possible pitfalls in using the theoretical results of PCA based on
the assumption of independent data when the data are time series. For the
latter, we state with proof a central limit theorem of the eigenvalues and
eigenvectors (loadings), give direct and bootstrap estimation of their
asymptotic covariances, and assess their efficacy via simulation. Specifically,
we pay attention to the proportion of variation, which decides the number of
principal components (PCs), and the loadings, which help interpret the meaning
of PCs. Our findings are that while the proportion of variation is quite robust
to different dependence assumptions, the inference of PC loadings requires
careful attention. We initiate and conclude our investigation with an empirical
example on portfolio management, in which the PC loadings play a prominent
role. It is given as a paradigm of correct usage of PCA for time series data.",http://arxiv.org/pdf/2008.01496v2,stat.ME
2020-08-02 10:22:05+00:00,Principles and Algorithms for Forecasting Groups of Time Series: Locality and Globality,"['Pablo Montero-Manso', 'Rob J Hyndman']","Forecasting groups of time series is of increasing practical importance, e.g.
forecasting the demand for multiple products offered by a retailer or server
loads within a data center. The local approach to this problem considers each
time series separately and fits a function or model to each series. The global
approach fits a single function to all series. For groups of similar time
series, global methods outperform the more established local methods. However,
recent results show good performance of global models even in heterogeneous
datasets. This suggests a more general applicability of global methods,
potentially leading to more accurate tools and new scenarios to study.
  Formalizing the setting of forecasting a set of time series with local and
global methods, we provide the following contributions:
  1) Global methods are not more restrictive than local methods, both can
produce the same forecasts without any assumptions about similarity of the
series. Global models can succeed in a wider range of problems than previously
thought.
  2) Basic generalization bounds for local and global algorithms. The
complexity of local methods grows with the size of the set while it remains
constant for global methods. In large datasets, a global algorithm can afford
to be quite complex and still benefit from better generalization. These bounds
serve to clarify and support recent experimental results in the field, and
guide the design of new algorithms. For the class of autoregressive models,
this implies that global models can have much larger memory than local methods.
  3) In an extensive empirical study, purposely naive algorithms derived from
these principles, such as global linear models or deep networks result in
superior accuracy.
  In particular, global linear models can provide competitive accuracy with two
orders of magnitude fewer parameters than local methods.",http://arxiv.org/pdf/2008.00444v3,cs.LG
2020-07-31 10:33:54+00:00,An Empirical Survey of Data Augmentation for Time Series Classification with Neural Networks,"['Brian Kenji Iwana', 'Seiichi Uchida']","In recent times, deep artificial neural networks have achieved many successes
in pattern recognition. Part of this success can be attributed to the reliance
on big data to increase generalization. However, in the field of time series
recognition, many datasets are often very small. One method of addressing this
problem is through the use of data augmentation. In this paper, we survey data
augmentation techniques for time series and their application to time series
classification with neural networks. We propose a taxonomy and outline the four
families in time series data augmentation, including transformation-based
methods, pattern mixing, generative models, and decomposition methods.
Furthermore, we empirically evaluate 12 time series data augmentation methods
on 128 time series classification datasets with six different types of neural
networks. Through the results, we are able to analyze the characteristics,
advantages and disadvantages, and recommendations of each data augmentation
method. This survey aims to help in the selection of time series data
augmentation for neural network applications.",http://arxiv.org/pdf/2007.15951v4,cs.LG
2020-07-30 15:48:55+00:00,Anomaly Detection at Scale: The Case for Deep Distributional Time Series Models,"['Fadhel Ayed', 'Lorenzo Stella', 'Tim Januschowski', 'Jan Gasthaus']","This paper introduces a new methodology for detecting anomalies in time
series data, with a primary application to monitoring the health of (micro-)
services and cloud resources. The main novelty in our approach is that instead
of modeling time series consisting of real values or vectors of real values, we
model time series of probability distributions over real values (or vectors).
This extension to time series of probability distributions allows the technique
to be applied to the common scenario where the data is generated by requests
coming in to a service, which is then aggregated at a fixed temporal frequency.
Our method is amenable to streaming anomaly detection and scales to monitoring
for anomalies on millions of time series. We show the superior accuracy of our
method on synthetic and public real-world data. On the Yahoo Webscope data set,
we outperform the state of the art in 3 out of 4 data sets and we show that we
outperform popular open-source anomaly detection tools by up to 17% average
improvement for a real-world data set.",http://arxiv.org/pdf/2007.15541v1,cs.LG
2020-07-30 15:35:15+00:00,FC-GAGA: Fully Connected Gated Graph Architecture for Spatio-Temporal Traffic Forecasting,"['Boris N. Oreshkin', 'Arezou Amini', 'Lucy Coyle', 'Mark J. Coates']","Forecasting of multivariate time-series is an important problem that has
applications in traffic management, cellular network configuration, and
quantitative finance. A special case of the problem arises when there is a
graph available that captures the relationships between the time-series. In
this paper we propose a novel learning architecture that achieves performance
competitive with or better than the best existing algorithms, without requiring
knowledge of the graph. The key element of our proposed architecture is the
learnable fully connected hard graph gating mechanism that enables the use of
the state-of-the-art and highly computationally efficient fully connected
time-series forecasting architecture in traffic forecasting applications.
Experimental results for two public traffic network datasets illustrate the
value of our approach, and ablation studies confirm the importance of each
element of the architecture. The code is available here:
https://github.com/boreshkinai/fc-gaga.",http://arxiv.org/pdf/2007.15531v2,cs.LG
2020-07-30 00:30:32+00:00,Prediction of hierarchical time series using structured regularization and its application to artificial neural networks,"['Tomokaze Shiratori', 'Ken Kobayashi', 'Yuichi Takano']","This paper discusses the prediction of hierarchical time series, where each
upper-level time series is calculated by summing appropriate lower-level time
series. Forecasts for such hierarchical time series should be coherent, meaning
that the forecast for an upper-level time series equals the sum of forecasts
for corresponding lower-level time series. Previous methods for making coherent
forecasts consist of two phases: first computing base (incoherent) forecasts
and then reconciling those forecasts based on their inherent hierarchical
structure. With the aim of improving time series predictions, we propose a
structured regularization method for completing both phases simultaneously. The
proposed method is based on a prediction model for bottom-level time series and
uses a structured regularization term to incorporate upper-level forecasts into
the prediction model. We also develop a backpropagation algorithm specialized
for application of our method to artificial neural networks for time series
prediction. Experimental results using synthetic and real-world datasets
demonstrate the superiority of our method in terms of prediction accuracy and
computational efficiency.",http://arxiv.org/pdf/2007.15159v1,cs.LG
2020-07-26 15:56:40+00:00,Benchmarking Multivariate Time Series Classification Algorithms,"['Alejandro Pasos Ruiz', 'Michael Flynn', 'Anthony Bagnall']","Time Series Classification (TSC) involved building predictive models for a
discrete target variable from ordered, real valued, attributes. Over recent
years, a new set of TSC algorithms have been developed which have made
significant improvement over the previous state of the art. The main focus has
been on univariate TSC, i.e. the problem where each case has a single series
and a class label. In reality, it is more common to encounter multivariate TSC
(MTSC) problems where multiple series are associated with a single label.
Despite this, much less consideration has been given to MTSC than the
univariate case. The UEA archive of 30 MTSC problems released in 2018 has made
comparison of algorithms easier. We review recently proposed bespoke MTSC
algorithms based on deep learning, shapelets and bag of words approaches. The
simplest approach to MTSC is to ensemble univariate classifiers over the
multivariate dimensions. We compare the bespoke algorithms to these dimension
independent approaches on the 26 of the 30 MTSC archive problems where the data
are all of equal length. We demonstrate that the independent ensemble of
HIVE-COTE classifiers is the most accurate, but that, unlike with univariate
classification, dynamic time warping is still competitive at MTSC.",http://arxiv.org/pdf/2007.13156v2,cs.LG
2020-07-25 04:16:34+00:00,Graph Gamma Process Generalized Linear Dynamical Systems,"['Rahi Kalantari', 'Mingyuan Zhou']","We introduce graph gamma process (GGP) linear dynamical systems to model
real-valued multivariate time series. For temporal pattern discovery, the
latent representation under the model is used to decompose the time series into
a parsimonious set of multivariate sub-sequences. In each sub-sequence,
different data dimensions often share similar temporal patterns but may exhibit
distinct magnitudes, and hence allowing the superposition of all sub-sequences
to exhibit diverse behaviors at different data dimensions. We further
generalize the proposed model by replacing the Gaussian observation layer with
the negative binomial distribution to model multivariate count time series.
Generated from the proposed GGP is an infinite dimensional directed sparse
random graph, which is constructed by taking the logical OR operation of
countably infinite binary adjacency matrices that share the same set of
countably infinite nodes. Each of these adjacency matrices is associated with a
weight to indicate its activation strength, and places a finite number of edges
between a finite subset of nodes belonging to the same node community. We use
the generated random graph, whose number of nonzero-degree nodes is finite, to
define both the sparsity pattern and dimension of the latent state transition
matrix of a (generalized) linear dynamical system. The activation strength of
each node community relative to the overall activation strength is used to
extract a multivariate sub-sequence, revealing the data pattern captured by the
corresponding community. On both synthetic and real-world time series, the
proposed nonparametric Bayesian dynamic models, which are initialized at
random, consistently exhibit good predictive performance in comparison to a
variety of baseline models, revealing interpretable latent state transition
patterns and decomposing the time series into distinctly behaved sub-sequences.",http://arxiv.org/pdf/2007.12852v1,stat.ME
2020-07-25 01:32:00+00:00,Improving Robustness on Seasonality-Heavy Multivariate Time Series Anomaly Detection,"['Farzaneh Khoshnevisan', 'Zhewen Fan', 'Vitor R. Carvalho']","Robust Anomaly Detection (AD) on time series data is a key component for
monitoring many complex modern systems. These systems typically generate
high-dimensional time series that can be highly noisy, seasonal, and
inter-correlated. This paper explores some of the challenges in such data, and
proposes a new approach that makes inroads towards increased robustness on
seasonal and contaminated data, while providing a better root cause
identification of anomalies. In particular, we propose the use of Robust
Seasonal Multivariate Generative Adversarial Network (RSM-GAN) that extends
recent advancements in GAN with the adoption of convolutional-LSTM layers and
attention mechanisms to produce excellent performance on various settings. We
conduct extensive experiments in which not only do this model displays more
robust behavior on complex seasonality patterns, but also shows increased
resistance to training data contamination. We compare it with existing
classical and deep-learning AD models, and show that this architecture is
associated with the lowest false positive rate and improves precision by 30%
and 16% in real-world and synthetic data, respectively.",http://arxiv.org/pdf/2007.14254v1,cs.LG
2020-07-24 10:41:20+00:00,ESPRESSO: Entropy and ShaPe awaRe timE-Series SegmentatiOn for processing heterogeneous sensor data,"['Shohreh Deldari', 'Daniel V. Smith', 'Amin Sadri', 'Flora D. Salim']","Extracting informative and meaningful temporal segments from high-dimensional
wearable sensor data, smart devices, or IoT data is a vital preprocessing step
in applications such as Human Activity Recognition (HAR), trajectory
prediction, gesture recognition, and lifelogging. In this paper, we propose
ESPRESSO (Entropy and ShaPe awaRe timE-Series SegmentatiOn), a hybrid
segmentation model for multi-dimensional time-series that is formulated to
exploit the entropy and temporal shape properties of time-series. ESPRESSO
differs from existing methods that focus upon particular statistical or
temporal properties of time-series exclusively. As part of model development, a
novel temporal representation of time-series $WCAC$ was introduced along with a
greedy search approach that estimate segments based upon the entropy metric.
ESPRESSO was shown to offer superior performance to four state-of-the-art
methods across seven public datasets of wearable and wear-free sensing. In
addition, we undertake a deeper investigation of these datasets to understand
how ESPRESSO and its constituent methods perform with respect to different
dataset characteristics. Finally, we provide two interesting case-studies to
show how applying ESPRESSO can assist in inferring daily activity routines and
the emotional state of humans.",http://arxiv.org/pdf/2008.03230v1,cs.LG
2020-07-23 15:50:59+00:00,Hide-and-Seek Privacy Challenge,"['James Jordon', 'Daniel Jarrett', 'Jinsung Yoon', 'Tavian Barnes', 'Paul Elbers', 'Patrick Thoral', 'Ari Ercole', 'Cheng Zhang', 'Danielle Belgrave', 'Mihaela van der Schaar']","The clinical time-series setting poses a unique combination of challenges to
data modeling and sharing. Due to the high dimensionality of clinical time
series, adequate de-identification to preserve privacy while retaining data
utility is difficult to achieve using common de-identification techniques. An
innovative approach to this problem is synthetic data generation. From a
technical perspective, a good generative model for time-series data should
preserve temporal dynamics, in the sense that new sequences respect the
original relationships between high-dimensional variables across time. From the
privacy perspective, the model should prevent patient re-identification by
limiting vulnerability to membership inference attacks. The NeurIPS 2020
Hide-and-Seek Privacy Challenge is a novel two-tracked competition to
simultaneously accelerate progress in tackling both problems. In our
head-to-head format, participants in the synthetic data generation track (i.e.
""hiders"") and the patient re-identification track (i.e. ""seekers"") are directly
pitted against each other by way of a new, high-quality intensive care
time-series dataset: the AmsterdamUMCdb dataset. Ultimately, we seek to advance
generative techniques for dense and high-dimensional temporal data streams that
are (1) clinically meaningful in terms of fidelity and predictivity, as well as
(2) capable of minimizing membership privacy risks in terms of the concrete
notion of patient re-identification.",http://arxiv.org/pdf/2007.12087v2,cs.LG
2020-07-22 10:33:17+00:00,Shape-CD: Change-Point Detection in Time-Series Data with Shapes and Neurons,"['Varsha Suresh', 'Wei Tsang Ooi']","Change-point detection in a time series aims to discover the time points at
which some unknown underlying physical process that generates the time-series
data has changed. We found that existing approaches become less accurate when
the underlying process is complex and generates large varieties of patterns in
the time series. To address this shortcoming, we propose Shape-CD, a simple,
fast, and accurate change point detection method. Shape-CD uses shape-based
features to model the patterns and a conditional neural field to model the
temporal correlations among the time regions. We evaluated the performance of
Shape-CD using four highly dynamic time-series datasets, including the
ExtraSensory dataset with up to 2000 classes. Shape-CD demonstrated improved
accuracy (7-60% higher in AUC) and faster computational speed compared to
existing approaches. Furthermore, the Shape-CD model consists of only hundreds
of parameters and require less data to train than other deep supervised
learning models.",http://arxiv.org/pdf/2007.11985v3,cs.LG
2020-07-20 15:15:27+00:00,Time Series Source Separation with Slow Flows,"['Edouard Pineau', 'Sébastien Razakarivony', 'Thomas Bonald']","In this paper, we show that slow feature analysis (SFA), a common time series
decomposition method, naturally fits into the flow-based models (FBM)
framework, a type of invertible neural latent variable models. Building upon
recent advances on blind source separation, we show that such a fit makes the
time series decomposition identifiable.",http://arxiv.org/pdf/2007.10182v1,cs.LG
2020-07-19 16:47:26+00:00,Deep Anomaly Detection for Time-series Data in Industrial IoT: A Communication-Efficient On-device Federated Learning Approach,"['Yi Liu', 'Sahil Garg', 'Jiangtian Nie', 'Yang Zhang', 'Zehui Xiong', 'Jiawen Kang', 'M. Shamim Hossain']","Since edge device failures (i.e., anomalies) seriously affect the production
of industrial products in Industrial IoT (IIoT), accurately and timely
detecting anomalies is becoming increasingly important. Furthermore, data
collected by the edge device may contain the user's private data, which is
challenging the current detection approaches as user privacy is calling for the
public concern in recent years. With this focus, this paper proposes a new
communication-efficient on-device federated learning (FL)-based deep anomaly
detection framework for sensing time-series data in IIoT. Specifically, we
first introduce a FL framework to enable decentralized edge devices to
collaboratively train an anomaly detection model, which can improve its
generalization ability. Second, we propose an Attention Mechanism-based
Convolutional Neural Network-Long Short Term Memory (AMCNN-LSTM) model to
accurately detect anomalies. The AMCNN-LSTM model uses attention
mechanism-based CNN units to capture important fine-grained features, thereby
preventing memory loss and gradient dispersion problems. Furthermore, this
model retains the advantages of LSTM unit in predicting time series data.
Third, to adapt the proposed framework to the timeliness of industrial anomaly
detection, we propose a gradient compression mechanism based on Top-\textit{k}
selection to improve communication efficiency. Extensive experiment studies on
four real-world datasets demonstrate that the proposed framework can accurately
and timely detect anomalies and also reduce the communication overhead by 50\%
compared to the federated learning framework that does not use a gradient
compression scheme.",http://arxiv.org/pdf/2007.09712v1,cs.LG
2020-07-16 16:51:43+00:00,Spectral Simulation of Functional Time Series,"['Tomáš Rubín', 'Victor M. Panaretos']","We develop methodology allowing to simulate a stationary functional time
series defined by means of its spectral density operators. Our framework is
general, in that it encompasses any such stationary functional time series,
whether linear or not. The methodology manifests particularly significant
computational gains if the spectral density operators are specified by means of
their eigendecomposition or as a filtering of white noise. In the special case
of linear processes, we determine the analytical expressions for the spectral
density operators of functional autoregressive (fractionally integrated) moving
average processes, and leverage these as part of our spectral approach, leading
to substantial improvements over time-domain simulation methods in some cases.
The methods are implemented as an R package (specsimfts) accompanied by several
demo files that are easy to modify and can be easily used by researchers aiming
to probe the finite-sample performance of their functional time series
methodology by means of simulation.",http://arxiv.org/pdf/2007.08458v1,stat.ME
2020-07-16 01:32:48+00:00,A fast noise filtering algorithm for time series prediction using recurrent neural networks,['Boris Rubinstein'],"Recent research demonstrate that prediction of time series by recurrent
neural networks (RNNs) based on the noisy input generates a smooth anticipated
trajectory. We examine the internal dynamics of RNNs and establish a set of
conditions required for such behavior. Based on this analysis we propose a new
approximate algorithm and show that it significantly speeds up the predictive
process without loss of accuracy.",http://arxiv.org/pdf/2007.08063v3,cs.LG
2020-07-15 10:32:43+00:00,timeXplain -- A Framework for Explaining the Predictions of Time Series Classifiers,"['Felix Mujkanovic', 'Vanja Doskoč', 'Martin Schirneck', 'Patrick Schäfer', 'Tobias Friedrich']","Modern time series classifiers display impressive predictive capabilities,
yet their decision-making processes mostly remain black boxes to the user. At
the same time, model-agnostic explainers, such as the recently proposed SHAP,
promise to make the predictions of machine learning models interpretable,
provided there are well-designed domain mappings. We bring both worlds together
in our timeXplain framework, extending the reach of explainable artificial
intelligence to time series classification and value prediction. We present
novel domain mappings for the time and the frequency domain as well as series
statistics and analyze their explicative power as well as their limits. We
employ timeXplain in a large-scale experimental comparison of several
state-of-the-art time series classifiers and discover similarities between
seemingly distinct classification concepts such as residual neural networks and
elastic ensembles.",http://arxiv.org/pdf/2007.07606v1,cs.LG
2020-07-15 07:33:25+00:00,MTS-CycleGAN: An Adversarial-based Deep Mapping Learning Network for Multivariate Time Series Domain Adaptation Applied to the Ironmaking Industry,"['Cedric Schockaert', 'Henri Hoyez']","In the current era, an increasing number of machine learning models is
generated for the automation of industrial processes. To that end, machine
learning models are trained using historical data of each single asset leading
to the development of asset-based models. To elevate machine learning models to
a higher level of learning capability, domain adaptation has opened the door
for extracting relevant patterns from several assets combined together. In this
research we are focusing on translating the specific asset-based historical
data (source domain) into data corresponding to one reference asset (target
domain), leading to the creation of a multi-assets global dataset required for
training domain invariant generic machine learning models. This research is
conducted to apply domain adaptation to the ironmaking industry, and
particularly for the creation of a domain invariant dataset by gathering data
from different blast furnaces. The blast furnace data is characterized by
multivariate time series. Domain adaptation for multivariate time series data
hasn't been covered extensively in the literature. We propose MTS-CycleGAN, an
algorithm for Multivariate Time Series data based on CycleGAN. To the best of
our knowledge, this is the first time CycleGAN is applied on multivariate time
series data. Our contribution is the integration in the CycleGAN architecture
of a Long Short-Term Memory (LSTM)-based AutoEncoder (AE) for the generator and
a stacked LSTM-based discriminator, together with dedicated extended features
extraction mechanisms. MTS-CycleGAN is validated using two artificial datasets
embedding the complex temporal relations between variables reflecting the blast
furnace process. MTS-CycleGAN is successfully learning the mapping between both
artificial multivariate time series datasets, allowing an efficient translation
from a source to a target artificial blast furnace dataset.",http://arxiv.org/pdf/2007.07518v1,cs.LG
2020-07-13 20:48:03+00:00,GeoStat Representations of Time Series for Fast Classification,"['Robert J. Ravier', 'Mohammadreza Soltani', 'Miguel Simões', 'Denis Garagic', 'Vahid Tarokh']","Recent advances in time series classification have largely focused on methods
that either employ deep learning or utilize other machine learning models for
feature extraction. Though successful, their power often comes at the
requirement of computational complexity. In this paper, we introduce GeoStat
representations for time series. GeoStat representations are based off of a
generalization of recent methods for trajectory classification, and summarize
the information of a time series in terms of comprehensive statistics of
(possibly windowed) distributions of easy to compute differential geometric
quantities, requiring no dynamic time warping. The features used are intuitive
and require minimal parameter tuning. We perform an exhaustive evaluation of
GeoStat on a number of real datasets, showing that simple KNN and SVM
classifiers trained on these representations exhibit surprising performance
relative to modern single model methods requiring significant computational
power, achieving state of the art results in many cases. In particular, we show
that this methodology achieves good performance on a challenging dataset
involving the classification of fishing vessels, where our methods achieve good
performance relative to the state of the art despite only having access to
approximately two percent of the dataset used in training and evaluating this
state of the art.",http://arxiv.org/pdf/2007.06682v3,cs.LG
2020-07-10 11:07:32+00:00,Multi-future Merchant Transaction Prediction,"['Chin-Chia Michael Yeh', 'Zhongfang Zhuang', 'Wei Zhang', 'Liang Wang']","The multivariate time series generated from merchant transaction history can
provide critical insights for payment processing companies. The capability of
predicting merchants' future is crucial for fraud detection and recommendation
systems. Conventionally, this problem is formulated to predict one multivariate
time series under the multi-horizon setting. However, real-world applications
often require more than one future trend prediction considering the
uncertainties, where more than one multivariate time series needs to be
predicted. This problem is called multi-future prediction. In this work, we
combine the two research directions and propose to study this new problem:
multi-future, multi-horizon and multivariate time series prediction. This
problem is crucial as it has broad use cases in the financial industry to
reduce the risk while improving user experience by providing alternative
futures. This problem is also challenging as now we not only need to capture
the patterns and insights from the past but also train a model that has a
strong inference capability to project multiple possible outcomes. To solve
this problem, we propose a new model using convolutional neural networks and a
simple yet effective encoder-decoder structure to learn the time series pattern
from multiple perspectives. We use experiments on real-world merchant
transaction data to demonstrate the effectiveness of our proposed model. We
also provide extensive discussions on different model design choices in our
experimental section.",http://arxiv.org/pdf/2007.05303v1,cs.LG
2020-07-09 17:37:35+00:00,Bayesian Computation in Dynamic Latent Factor Models,"['Isaac Lavine', 'Andrew Cron', 'Mike West']","Bayesian computation for filtering and forecasting analysis is developed for
a broad class of dynamic models. The ability to scale-up such analyses in
non-Gaussian, nonlinear multivariate time series models is advanced through the
introduction of a novel copula construction in sequential filtering of coupled
sets of dynamic generalized linear models. The new copula approach is
integrated into recently introduced multiscale models in which univariate time
series are coupled via nonlinear forms involving dynamic latent factors
representing cross-series relationships. The resulting methodology offers
dramatic speed-up in online Bayesian computations for sequential filtering and
forecasting in this broad, flexible class of multivariate models. Two examples
in nonlinear models for very heterogeneous time series of non-negative counts
demonstrate massive computational efficiencies relative to existing
simulation-based methods, while defining similar filtering and forecasting
outcomes.",http://arxiv.org/pdf/2007.04956v1,stat.ME
2020-07-03 18:01:04+00:00,High-recall causal discovery for autocorrelated time series with latent confounders,"['Andreas Gerhardus', 'Jakob Runge']","We present a new method for linear and nonlinear, lagged and contemporaneous
constraint-based causal discovery from observational time series in the
presence of latent confounders. We show that existing causal discovery methods
such as FCI and variants suffer from low recall in the autocorrelated time
series case and identify low effect size of conditional independence tests as
the main reason. Information-theoretical arguments show that effect size can
often be increased if causal parents are included in the conditioning sets. To
identify parents early on, we suggest an iterative procedure that utilizes
novel orientation rules to determine ancestral relationships already during the
edge removal phase. We prove that the method is order-independent, and sound
and complete in the oracle case. Extensive simulation studies for different
numbers of variables, time lags, sample sizes, and further cases demonstrate
that our method indeed achieves much higher recall than existing methods for
the case of autocorrelated continuous variables while keeping false positives
at the desired level. This performance gain grows with stronger
autocorrelation. At https://github.com/jakobrunge/tigramite we provide Python
code for all methods involved in the simulation studies.",http://arxiv.org/pdf/2007.01884v3,stat.ME
2020-07-02 13:03:09+00:00,Accurate Characterization of Non-Uniformly Sampled Time Series using Stochastic Differential Equations,['Stijn de Waele'],"Non-uniform sampling arises when an experimenter does not have full control
over the sampling characteristics of the process under investigation. Moreover,
it is introduced intentionally in algorithms such as Bayesian optimization and
compressive sensing. We argue that Stochastic Differential Equations (SDEs) are
especially well-suited for characterizing second order moments of such time
series. We introduce new initial estimates for the numerical optimization of
the likelihood, based on incremental estimation and initialization from
autoregressive models. Furthermore, we introduce model truncation as a purely
data-driven method to reduce the order of the estimated model based on the SDE
likelihood. We show the increased accuracy achieved with the new estimator in
simulation experiments, covering all challenging circumstances that may be
encountered in characterizing a non-uniformly sampled time series. Finally, we
apply the new estimator to experimental rainfall variability data.",http://arxiv.org/pdf/2007.01073v1,stat.ML
2020-07-01 12:11:16+00:00,Handling Variable-Dimensional Time Series with Graph Neural Networks,"['Vibhor Gupta', 'Jyoti Narwariya', 'Pankaj Malhotra', 'Lovekesh Vig', 'Gautam Shroff']","Several applications of Internet of Things (IoT) technology involve capturing
data from multiple sensors resulting in multi-sensor time series. Existing
neural networks based approaches for such multi-sensor or multivariate time
series modeling assume fixed input dimension or number of sensors. Such
approaches can struggle in the practical setting where different instances of
the same device or equipment such as mobiles, wearables, engines, etc. come
with different combinations of installed sensors. We consider training neural
network models from such multi-sensor time series, where the time series have
varying input dimensionality owing to availability or installation of a
different subset of sensors at each source of time series. We propose a novel
neural network architecture suitable for zero-shot transfer learning allowing
robust inference for multivariate time series with previously unseen
combination of available dimensions or sensors at test time. Such a
combinatorial generalization is achieved by conditioning the layers of a core
neural network-based time series model with a ""conditioning vector"" that
carries information of the available combination of sensors for each time
series. This conditioning vector is obtained by summarizing the set of learned
""sensor embedding vectors"" corresponding to the available sensors in a time
series via a graph neural network. We evaluate the proposed approach on
publicly available activity recognition and equipment prognostics datasets, and
show that the proposed approach allows for better generalization in comparison
to a deep gated recurrent neural network baseline.",http://arxiv.org/pdf/2007.00411v5,cs.LG
2020-07-01 10:10:41+00:00,Spectral methods for small sample time series: A complete periodogram approach,"['Sourav Das', 'Suhasini Subba Rao', 'Junho Yang']","The periodogram is a widely used tool to analyze second order stationary time
series. An attractive feature of the periodogram is that the expectation of the
periodogram is approximately equal to the underlying spectral density of the
time series. However, this is only an approximation, and it is well known that
the periodogram has a finite sample bias, which can be severe in small samples.
In this paper, we show that the bias arises because of the finite boundary of
observation in one of the discrete Fourier transforms which is used in the
construction of the periodogram. Moreover, we show that by using the best
linear predictors of the time series over the boundary of observation we can
obtain a ""complete periodogram"" that is an unbiased estimator of the spectral
density. In practice, the ""complete periodogram"" cannot be evaluated as the
best linear predictors are unknown. We propose a method for estimating the best
linear predictors and prove that the resulting ""estimated complete periodogram""
has a smaller bias than the regular periodogram. The estimated complete
periodogram and a tapered version of it are used to estimate parameters, which
can be represented in terms of the integrated spectral density. We prove that
the resulting estimators have a smaller bias than their regular periodogram
counterparts. The proposed method is illustrated with simulations and real
data.",http://arxiv.org/pdf/2007.00363v2,math.ST
2020-07-01 06:30:45+00:00,Reconstructing regime-dependent causal relationships from observational time series,"['Elena Saggioro', 'Jana de Wiljes', 'Marlene Kretschmer', 'Jakob Runge']","Inferring causal relations from observational time series data is a key
problem across science and engineering whenever experimental interventions are
infeasible or unethical. Increasing data availability over the past decades has
spurred the development of a plethora of causal discovery methods, each
addressing particular challenges of this difficult task. In this paper we focus
on an important challenge that is at the core of time series causal discovery:
regime-dependent causal relations. Often dynamical systems feature transitions
depending on some, often persistent, unobserved background regime, and
different regimes may exhibit different causal relations. Here, we assume a
persistent and discrete regime variable leading to a finite number of regimes
within which we may assume stationary causal relations. To detect
regime-dependent causal relations, we combine the conditional
independence-based PCMCI method with a regime learning optimisation approach.
PCMCI allows for linear and nonlinear, high-dimensional time series causal
discovery. Our method, Regime-PCMCI, is evaluated on a number of numerical
experiments demonstrating that it can distinguish regimes with different causal
directions, time lags, effects and sign of causal links, as well as changes in
the variables' autocorrelation. Further, Regime-PCMCI is employed to
observations of El Ni\~no Southern Oscillation and Indian rainfall,
demonstrating skill also in real-world datasets.",http://arxiv.org/pdf/2007.00267v1,stat.ME
2020-06-30 05:38:27+00:00,Autoregressive Mixture Models for Serial Correlation Clustering of Time Series Data,"['Benny Ren', 'Ian Barnett']","Clustering time series into similar groups can improve models by combining
information across like time series. While there is a well developed body of
literature for clustering of time series, these approaches tend to generate
clusters independently of model training which can lead to poor model fit. We
propose a novel distributed approach that simultaneously clusters and fits
autoregression models for groups of similar individuals. We apply a Wishart
mixture model so as to cluster individuals while modeling the corresponding
autocovariance matrices at the same time. The fitted Wishart scale matrices map
to cluster-level autoregressive coefficients through the Yule-Walker equations,
fitting robust parsimonious autoregressive mixture models. This approach is
able to discern differences in underlying autocorrelation variation of time
series in settings with large heterogeneous datasets. We prove consistency of
our cluster membership estimator, asymptotic distributions of coefficients and
compare our approach against competing methods through simulation as well as by
fitting a COVID-19 forecast model.",http://arxiv.org/pdf/2006.16539v2,stat.ME
2020-06-30 02:19:18+00:00,Conditional GAN for timeseries generation,"['Kaleb E Smith', 'Anthony O Smith']","It is abundantly clear that time dependent data is a vital source of
information in the world. The challenge has been for applications in machine
learning to gain access to a considerable amount of quality data needed for
algorithm development and analysis. Modeling synthetic data using a Generative
Adversarial Network (GAN) has been at the heart of providing a viable solution.
Our work focuses on one dimensional times series and explores the few shot
approach, which is the ability of an algorithm to perform well with limited
data. This work attempts to ease the frustration by proposing a new
architecture, Time Series GAN (TSGAN), to model realistic time series data. We
evaluate TSGAN on 70 data sets from a benchmark time series database. Our
results demonstrate that TSGAN performs better than the competition both
quantitatively using the Frechet Inception Score (FID) metric, and
qualitatively when classification is used as the evaluation criteria.",http://arxiv.org/pdf/2006.16477v1,cs.LG
2020-06-29 00:16:40+00:00,Neural Time Warping For Multiple Sequence Alignment,"['Keisuke Kawano', 'Takuro Kutsuna', 'Satoshi Koide']","Multiple sequences alignment (MSA) is a traditional and challenging task for
time-series analyses. The MSA problem is formulated as a discrete optimization
problem and is typically solved by dynamic programming. However, the
computational complexity increases exponentially with respect to the number of
input sequences. In this paper, we propose neural time warping (NTW) that
relaxes the original MSA to a continuous optimization and obtains the
alignments using a neural network. The solution obtained by NTW is guaranteed
to be a feasible solution for the original discrete optimization problem under
mild conditions. Our experimental results show that NTW successfully aligns a
hundred time-series and significantly outperforms existing methods for solving
the MSA problem. In addition, we show a method for obtaining average
time-series data as one of applications of NTW. Compared to the existing
barycenters, the mean time series data retains the features of the input
time-series data.",http://arxiv.org/pdf/2006.15753v1,cs.LG
2020-06-24 03:17:01+00:00,On Multivariate Singular Spectrum Analysis and its Variants,"['Anish Agarwal', 'Abdullah Alomar', 'Devavrat Shah']","We introduce and analyze a variant of multivariate singular spectrum analysis
(mSSA), a popular time series method to impute and forecast a multivariate time
series. Under a spatio-temporal factor model we introduce, given $N$ time
series and $T$ observations per time series, we establish prediction
mean-squared-error for both imputation and out-of-sample forecasting
effectively scale as $1 / \sqrt{\min(N, T )T}$. This is an improvement over:
(i) $1 /\sqrt{T}$ error scaling of SSA, the restriction of mSSA to a univariate
time series; (ii) $1/\min(N, T)$ error scaling for matrix estimation methods
which do not exploit temporal structure in the data. The spatio-temporal model
we introduce includes any finite sum and products of: harmonics, polynomials,
differentiable periodic functions, and Holder continuous functions. Our
out-of-sample forecasting result could be of independent interest for online
learning under a spatio-temporal factor model. Empirically, on benchmark
datasets, our variant of mSSA performs competitively with state-of-the-art
neural-network time series methods (e.g. DeepAR, LSTM) and significantly
outperforms classical methods such as vector autoregression (VAR). Finally, we
propose extensions of mSSA: (i) a variant to estimate time-varying variance of
a time series; (ii) a tensor variant which has better sample complexity for
certain regimes of $N$ and $T$.",http://arxiv.org/pdf/2006.13448v5,cs.LG
2020-06-23 00:15:10+00:00,Time Series Extrinsic Regression,"['Chang Wei Tan', 'Christoph Bergmeir', 'Francois Petitjean', 'Geoffrey I. Webb']","This paper studies Time Series Extrinsic Regression (TSER): a regression task
of which the aim is to learn the relationship between a time series and a
continuous scalar variable; a task closely related to time series
classification (TSC), which aims to learn the relationship between a time
series and a categorical class label. This task generalizes time series
forecasting (TSF), relaxing the requirement that the value predicted be a
future value of the input series or primarily depend on more recent values.
  In this paper, we motivate and study this task, and benchmark existing
solutions and adaptations of TSC algorithms on a novel archive of 19 TSER
datasets which we have assembled. Our results show that the state-of-the-art
TSC algorithm Rocket, when adapted for regression, achieves the highest overall
accuracy compared to adaptations of other TSC algorithms and state-of-the-art
machine learning (ML) algorithms such as XGBoost, Random Forest and Support
Vector Regression. More importantly, we show that much research is needed in
this field to improve the accuracy of ML models. We also find evidence that
further research has excellent prospects of improving upon these
straightforward baselines.",http://arxiv.org/pdf/2006.12672v3,cs.LG
2020-06-22 22:19:28+00:00,Aligning Time Series on Incomparable Spaces,"['Samuel Cohen', 'Giulia Luise', 'Alexander Terenin', 'Brandon Amos', 'Marc Peter Deisenroth']","Dynamic time warping (DTW) is a useful method for aligning, comparing and
combining time series, but it requires them to live in comparable spaces. In
this work, we consider a setting in which time series live on different spaces
without a sensible ground metric, causing DTW to become ill-defined. To
alleviate this, we propose Gromov dynamic time warping (GDTW), a distance
between time series on potentially incomparable spaces that avoids the
comparability requirement by instead considering intra-relational geometry. We
demonstrate its effectiveness at aligning, combining and comparing time series
living on incomparable spaces. We further propose a smoothed version of GDTW as
a differentiable loss and assess its properties in a variety of settings,
including barycentric averaging, generative modeling and imitation learning.",http://arxiv.org/pdf/2006.12648v2,cs.LG
2020-06-19 21:04:47+00:00,Supporting Optimal Phase Space Reconstructions Using Neural Network Architecture for Time Series Modeling,"['Lucas Pagliosa', 'Alexandru Telea', 'Rodrigo Mello']","The reconstruction of phase spaces is an essential step to analyze time
series according to Dynamical System concepts. A regression performed on such
spaces unveils the relationships among system states from which we can derive
their generating rules, that is, the most probable set of functions responsible
for generating observations along time. In this sense, most approaches rely on
Takens' embedding theorem to unfold the phase space, which requires the
embedding dimension and the time delay. Moreover, although several methods have
been proposed to empirically estimate those parameters, they still face
limitations due to their lack of consistency and robustness, which has
motivated this paper. As an alternative, we here propose an artificial neural
network with a forgetting mechanism to implicitly learn the phase spaces
properties, whatever they are. Such network trains on forecasting errors and,
after converging, its architecture is used to estimate the embedding
parameters. Experimental results confirm that our approach is either as
competitive as or better than most state-of-the-art strategies while revealing
the temporal relationship among time-series observations.",http://arxiv.org/pdf/2006.11381v1,cs.LG
2020-06-19 11:48:42+00:00,Time series copula models using d-vines and v-transforms,"['Martin Bladt', 'Alexander J. McNeil']","An approach to modelling volatile financial return series using stationary
d-vine copula processes combined with Lebesgue-measure-preserving
transformations known as v-transforms is proposed. By developing a method of
stochastically inverting v-transforms, models are constructed that can describe
both stochastic volatility in the magnitude of price movements and serial
correlation in their directions. In combination with parametric marginal
distributions it is shown that these models can rival and sometimes outperform
well-known models in the extended GARCH family.",http://arxiv.org/pdf/2006.11088v4,stat.ME
2020-06-19 07:47:57+00:00,"Monash University, UEA, UCR Time Series Extrinsic Regression Archive","['Chang Wei Tan', 'Christoph Bergmeir', 'Francois Petitjean', 'Geoffrey I. Webb']","Time series research has gathered lots of interests in the last decade,
especially for Time Series Classification (TSC) and Time Series Forecasting
(TSF). Research in TSC has greatly benefited from the University of California
Riverside and University of East Anglia (UCR/UEA) Time Series Archives. On the
other hand, the advancement in Time Series Forecasting relies on time series
forecasting competitions such as the Makridakis competitions, NN3 and NN5
Neural Network competitions, and a few Kaggle competitions. Each year,
thousands of papers proposing new algorithms for TSC and TSF have utilized
these benchmarking archives. These algorithms are designed for these specific
problems, but may not be useful for tasks such as predicting the heart rate of
a person using photoplethysmogram (PPG) and accelerometer data. We refer to
this problem as Time Series Extrinsic Regression (TSER), where we are
interested in a more general methodology of predicting a single continuous
value, from univariate or multivariate time series. This prediction can be from
the same time series or not directly related to the predictor time series and
does not necessarily need to be a future value or depend heavily on recent
values. To the best of our knowledge, research into TSER has received much less
attention in the time series research community and there are no models
developed for general time series extrinsic regression problems. Most models
are developed for a specific problem. Therefore, we aim to motivate and support
the research into TSER by introducing the first TSER benchmarking archive. This
archive contains 19 datasets from different domains, with varying number of
dimensions, unequal length dimensions, and missing values. In this paper, we
introduce the datasets in this archive and did an initial benchmark on existing
models.",http://arxiv.org/pdf/2006.10996v3,cs.LG
2020-06-18 19:59:12+00:00,Amortized Causal Discovery: Learning to Infer Causal Graphs from Time-Series Data,"['Sindy Löwe', 'David Madras', 'Richard Zemel', 'Max Welling']","On time-series data, most causal discovery methods fit a new model whenever
they encounter samples from a new underlying causal graph. However, these
samples often share relevant information which is lost when following this
approach. Specifically, different samples may share the dynamics which describe
the effects of their causal relations. We propose Amortized Causal Discovery, a
novel framework that leverages such shared dynamics to learn to infer causal
relations from time-series data. This enables us to train a single, amortized
model that infers causal relations across samples with different underlying
causal graphs, and thus leverages the shared dynamics information. We
demonstrate experimentally that this approach, implemented as a variational
model, leads to significant improvements in causal discovery performance, and
show how it can be extended to perform well under added noise and hidden
confounding.",http://arxiv.org/pdf/2006.10833v3,cs.LG
2020-06-18 11:31:16+00:00,Low-Rank Autoregressive Tensor Completion for Multivariate Time Series Forecasting,"['Xinyu Chen', 'Lijun Sun']","Time series prediction has been a long-standing research topic and an
essential application in many domains. Modern time series collected from sensor
networks (e.g., energy consumption and traffic flow) are often large-scale and
incomplete with considerable corruption and missing values, making it difficult
to perform accurate predictions. In this paper, we propose a low-rank
autoregressive tensor completion (LATC) framework to model multivariate time
series data. The key of LATC is to transform the original multivariate time
series matrix (e.g., sensor$\times$time point) to a third-order tensor
structure (e.g., sensor$\times$time of day$\times$day) by introducing an
additional temporal dimension, which allows us to model the inherent rhythms
and seasonality of time series as global patterns. With the tensor structure,
we can transform the time series prediction and missing data imputation
problems into a universal low-rank tensor completion problem. Besides
minimizing tensor rank, we also integrate a novel autoregressive norm on the
original matrix representation into the objective function. The two components
serve different roles. The low-rank structure allows us to effectively capture
the global consistency and trends across all the three dimensions (i.e.,
similarity among sensors, similarity of different days, and current time v.s.
the same time of historical days). The autoregressive norm can better model the
local temporal trends. Our numerical experiments on three real-world data sets
demonstrate the superiority of the integration of global and local trends in
LATC in both missing data imputation and rolling prediction tasks.",http://arxiv.org/pdf/2006.10436v1,stat.ML
2020-06-14 03:53:42+00:00,Dynamic Window-level Granger Causality of Multi-channel Time Series,"['Zhiheng Zhang', 'Wenbo Hu', 'Tian Tian', 'Jun Zhu']","Granger causality method analyzes the time series causalities without
building a complex causality graph. However, the traditional Granger causality
method assumes that the causalities lie between time series channels and remain
constant, which cannot model the real-world time series data with dynamic
causalities along the time series channels. In this paper, we present the
dynamic window-level Granger causality method (DWGC) for multi-channel time
series data. We build the causality model on the window-level by doing the
F-test with the forecasting errors on the sliding windows. We propose the
causality indexing trick in our DWGC method to reweight the original time
series data. Essentially, the causality indexing is to decrease the
auto-correlation and increase the cross-correlation causal effects, which
improves the DWGC method. Theoretical analysis and experimental results on two
synthetic and one real-world datasets show that the improved DWGC method with
causality indexing better detects the window-level causalities.",http://arxiv.org/pdf/2006.07788v1,stat.ME
2020-06-12 16:15:56+00:00,Detecting relevant differences in the covariance operators of functional time series -- a sup-norm approach,"['Holger Dette', 'Kevin Kokot']","In this paper we propose statistical inference tools for the covariance
operators of functional time series in the two sample and change point problem.
In contrast to most of the literature the focus of our approach is not testing
the null hypothesis of exact equality of the covariance operators. Instead we
propose to formulate the null hypotheses in them form that ""the distance
between the operators is small"", where we measure deviations by the sup-norm.
We provide powerful bootstrap tests for these type of hypotheses, investigate
their asymptotic properties and study their finite sample properties by means
of a simulation study.",http://arxiv.org/pdf/2006.07291v1,math.ST
2020-06-11 16:06:35+00:00,Stanza: A Nonlinear State Space Model for Probabilistic Inference in Non-Stationary Time Series,"['Anna K. Yanchenko', 'Sayan Mukherjee']","Time series with long-term structure arise in a variety of contexts and
capturing this temporal structure is a critical challenge in time series
analysis for both inference and forecasting settings. Traditionally, state
space models have been successful in providing uncertainty estimates of
trajectories in the latent space. More recently, deep learning, attention-based
approaches have achieved state of the art performance for sequence modeling,
though often require large amounts of data and parameters to do so. We propose
Stanza, a nonlinear, non-stationary state space model as an intermediate
approach to fill the gap between traditional models and modern deep learning
approaches for complex time series. Stanza strikes a balance between
competitive forecasting accuracy and probabilistic, interpretable inference for
highly structured time series. In particular, Stanza achieves forecasting
accuracy competitive with deep LSTMs on real-world datasets, especially for
multi-step ahead forecasting.",http://arxiv.org/pdf/2006.06553v1,stat.ML
2020-06-11 01:40:34+00:00,Learning Continuous-Time Dynamics by Stochastic Differential Networks,"['Yingru Liu', 'Yucheng Xing', 'Xuewen Yang', 'Xin Wang', 'Jing Shi', 'Di Jin', 'Zhaoyue Chen']","Learning continuous-time stochastic dynamics is a fundamental and essential
problem in modeling sporadic time series, whose observations are irregular and
sparse in both time and dimension. For a given system whose latent states and
observed data are high-dimensional, it is generally impossible to derive a
precise continuous-time stochastic process to describe the system behaviors. To
solve the above problem, we apply Variational Bayesian method and propose a
flexible continuous-time stochastic recurrent neural network named Variational
Stochastic Differential Networks (VSDN), which embeds the complicated dynamics
of the sporadic time series by neural Stochastic Differential Equations (SDE).
VSDNs capture the stochastic dependency among latent states and observations by
deep neural networks. We also incorporate two differential Evidence Lower
Bounds to efficiently train the models. Through comprehensive experiments, we
show that VSDNs outperform state-of-the-art continuous-time deep learning
models and achieve remarkable performance on prediction and interpolation tasks
for sporadic time series.",http://arxiv.org/pdf/2006.06145v3,cs.LG
2020-06-09 17:38:55+00:00,Conditional Sig-Wasserstein GANs for Time Series Generation,"['Shujian Liao', 'Hao Ni', 'Lukasz Szpruch', 'Magnus Wiese', 'Marc Sabate-Vidales', 'Baoren Xiao']","Generative adversarial networks (GANs) have been extremely successful in
generating samples, from seemingly high dimensional probability measures.
However, these methods struggle to capture the temporal dependence of joint
probability distributions induced by time-series data. Furthermore, long
time-series data streams hugely increase the dimension of the target space,
which may render generative modelling infeasible. To overcome these challenges,
motivated by the autoregressive models in econometric, we are interested in the
conditional distribution of future time series given the past information. We
propose the generic conditional Sig-WGAN framework by integrating
Wasserstein-GANs (WGANs) with mathematically principled and efficient path
feature extraction called the signature of a path. The signature of a path is a
graded sequence of statistics that provides a universal description for a
stream of data, and its expected value characterises the law of the time-series
model. In particular, we develop the conditional Sig-$W_1$ metric, that
captures the conditional joint law of time series models, and use it as a
discriminator. The signature feature space enables the explicit representation
of the proposed discriminators which alleviates the need for expensive
training. We validate our method on both synthetic and empirical dataset and
observe that our method consistently and significantly outperforms
state-of-the-art benchmarks with respect to measures of similarity and
predictive ability.",http://arxiv.org/pdf/2006.05421v2,cs.LG
2020-06-09 15:25:20+00:00,Statistical Estimation of High-Dimensional Vector Autoregressive Models,"['Jonas Krampe', 'Efstathios Paparoditis']","High-dimensional vector autoregressive (VAR) models are important tools for
the analysis of multivariate time series. This paper focuses on
high-dimensional time series and on the different regularized estimation
procedures proposed for fitting sparse VAR models to such time series.
Attention is paid to the different sparsity assumptions imposed on the VAR
parameters and how these sparsity assumptions are related to the particular
consistency properties of the estimators established. A sparsity scheme for
high-dimensional VAR models is proposed which is found to be more appropriate
for the time series setting considered. Furthermore, it is shown that, under
this sparsity setting, threholding extents the consistency properties of
regularized estimators to a wide range of matrix norms. Among other things,
this enables application of the VAR parameters estimators to different
inference problems, like forecasting or estimating the second-order
characteristics of the underlying VAR process. Extensive simulations compare
the finite sample behavior of the different regularized estimators proposed
using a variety of performance criteria.",http://arxiv.org/pdf/2006.05345v1,stat.ML
2020-06-09 09:28:52+00:00,Sparse Dynamic Distribution Decomposition: Efficient Integration of Trajectory and Snapshot Time Series Data,"['Jake P. Taylor-King', 'Cristian Regep', 'Jyothish Soman', 'Flawnson Tong', 'Catalina Cangea', 'Charlie Roberts']","Dynamic Distribution Decomposition (DDD) was introduced in Taylor-King et.
al. (PLOS Comp Biol, 2020) as a variation on Dynamic Mode Decomposition. In
brief, by using basis functions over a continuous state space, DDD allows for
the fitting of continuous-time Markov chains over these basis functions and as
a result continuously maps between distributions. The number of parameters in
DDD scales by the square of the number of basis functions; we reformulate the
problem and restrict the method to compact basis functions which leads to the
inference of sparse matrices only -- hence reducing the number of parameters.
Finally, we demonstrate how DDD is suitable to integrate both trajectory time
series (paired between subsequent time points) and snapshot time series
(unpaired time points). Methods capable of integrating both scenarios are
particularly relevant for the analysis of biomedical data, whereby studies
observe population at fixed time points (snapshots) and individual patient
journeys with repeated follow ups (trajectories).",http://arxiv.org/pdf/2006.05138v2,cs.LG
2020-06-08 12:09:16+00:00,Cointegration and unit root tests: A fully Bayesian approach,"['Marcio Alves Diniz', 'Carlos Alberto de Braganca Pereira', 'Julio Michael Stern']","To perform statistical inference for time series, one should be able to
assess if they present deterministic or stochastic trends. For univariate
analysis one way to detect stochastic trends is to test if the series has unit
roots, and for multivariate studies it is often relevant to search for
stationary linear relationships between the series, or if they cointegrate. The
main goal of this article is to briefly review the shortcomings of unit root
and cointegration tests proposed by the Bayesian approach of statistical
inference and to show how they can be overcome by the fully Bayesian
significance test (FBST), a procedure designed to test sharp or precise
hypothesis. We will compare its performance with the most used frequentist
alternatives, namely, the Augmented Dickey-Fuller for unit roots and the
maximum eigenvalue test for cointegration. Keywords: Time series; Bayesian
inference; Hypothesis testing; Unit root; Cointegration.",http://arxiv.org/pdf/2006.04499v4,math.ST
2020-06-08 09:53:35+00:00,Liquid Time-constant Networks,"['Ramin Hasani', 'Mathias Lechner', 'Alexander Amini', 'Daniela Rus', 'Radu Grosu']","We introduce a new class of time-continuous recurrent neural network models.
Instead of declaring a learning system's dynamics by implicit nonlinearities,
we construct networks of linear first-order dynamical systems modulated via
nonlinear interlinked gates. The resulting models represent dynamical systems
with varying (i.e., liquid) time-constants coupled to their hidden state, with
outputs being computed by numerical differential equation solvers. These neural
networks exhibit stable and bounded behavior, yield superior expressivity
within the family of neural ordinary differential equations, and give rise to
improved performance on time-series prediction tasks. To demonstrate these
properties, we first take a theoretical approach to find bounds over their
dynamics and compute their expressive power by the trajectory length measure in
latent trajectory space. We then conduct a series of time-series prediction
experiments to manifest the approximation capability of Liquid Time-Constant
Networks (LTCs) compared to classical and modern RNNs. Code and data are
available at https://github.com/raminmh/liquid_time_constant_networks",http://arxiv.org/pdf/2006.04439v4,cs.LG
2020-06-08 08:46:58+00:00,Learning Long-Term Dependencies in Irregularly-Sampled Time Series,"['Mathias Lechner', 'Ramin Hasani']","Recurrent neural networks (RNNs) with continuous-time hidden states are a
natural fit for modeling irregularly-sampled time series. These models,
however, face difficulties when the input data possess long-term dependencies.
We prove that similar to standard RNNs, the underlying reason for this issue is
the vanishing or exploding of the gradient during training. This phenomenon is
expressed by the ordinary differential equation (ODE) representation of the
hidden state, regardless of the ODE solver's choice. We provide a solution by
designing a new algorithm based on the long short-term memory (LSTM) that
separates its memory from its time-continuous state. This way, we encode a
continuous-time dynamical flow within the RNN, allowing it to respond to inputs
arriving at arbitrary time-lags while ensuring a constant error propagation
through the memory path. We call these RNN models ODE-LSTMs. We experimentally
show that ODE-LSTMs outperform advanced RNN-based counterparts on non-uniformly
sampled data with long-term dependencies. All code and data is available at
https://github.com/mlech26l/ode-lstms.",http://arxiv.org/pdf/2006.04418v4,cs.LG
2020-06-05 20:07:48+00:00,Time Series Analysis and Forecasting of COVID-19 Cases Using LSTM and ARIMA Models,['Arko Barman'],"Coronavirus disease 2019 (COVID-19) is a global public health crisis that has
been declared a pandemic by World Health Organization. Forecasting country-wise
COVID-19 cases is necessary to help policymakers and healthcare providers
prepare for the future. This study explores the performance of several Long
Short-Term Memory (LSTM) models and Auto-Regressive Integrated Moving Average
(ARIMA) model in forecasting the number of confirmed COVID-19 cases. Time
series of daily cumulative COVID-19 cases were used for generating 1-day,
3-day, and 5-day forecasts using several LSTM models and ARIMA. Two novel
k-period performance metrics - k-day Mean Absolute Percentage Error (kMAPE) and
k-day Median Symmetric Accuracy (kMdSA) - were developed for evaluating the
performance of the models in forecasting time series values for multiple days.
Errors in prediction using kMAPE and kMdSA for LSTM models were both as low as
0.05%, while those for ARIMA were 0.07% and 0.06% respectively. LSTM models
slightly underestimated while ARIMA slightly overestimated the numbers in the
forecasts. The performance of LSTM models is comparable to ARIMA in forecasting
COVID-19 cases. While ARIMA requires longer sequences, LSTMs can perform
reasonably well with sequence sizes as small as 3. However, LSTMs require a
large number of training samples. Further, the development of k-period
performance metrics proposed is likely to be useful for performance evaluation
of time series models in predicting multiple periods. Based on the k-period
performance metrics proposed, both LSTMs and ARIMA are useful for time series
analysis and forecasting for COVID-19.",http://arxiv.org/pdf/2006.13852v1,cs.LG
2020-06-05 14:42:49+00:00,Anomaly detection on streamed data,"['Thomas Cochrane', 'Peter Foster', 'Terry Lyons', 'Imanol Perez Arribas']","We introduce powerful but simple methodology for identifying anomalous
observations against a corpus of `normal' observations. All data are observed
through a vector-valued feature map. Our approach depends on the choice of
corpus and that feature map but is invariant to affine transformations of the
map and has no other external dependencies, such as choices of metric; we call
it conformance. Applying this method to (signatures) of time series and other
types of streamed data we provide an effective methodology of broad
applicability for identifying anomalous complex multimodal sequential data. We
demonstrate the applicability and effectiveness of our method by evaluating it
against multiple data sets. Based on quantifying performance using the receiver
operating characteristic (ROC) area under the curve (AUC), our method yields an
AUC score of 98.9\% for the PenDigits data set; in a subsequent experiment
involving marine vessel traffic data our approach yields an AUC score of
89.1\%. Based on comparison involving univariate time series from the UEA \&
UCR time series repository with performance quantified using balanced accuracy
and assuming an optimal operating point, our approach outperforms a
state-of-the-art shapelet method for 19 out of 28 data sets.",http://arxiv.org/pdf/2006.03487v1,cs.LG
2020-06-04 06:49:20+00:00,Change-point tests for the tail parameter of Long Memory Stochastic Volatility time series,"['Annika Betken', 'Davide Giraudo', 'Rafał Kulik']","We consider a change-point test based on the Hill estimator to test for
structural changes in the tail index of Long Memory Stochastic Volatility time
series. In order to determine the asymptotic distribution of the corresponding
test statistic, we prove a uniform reduction principle for the tail empirical
process in a two-parameter Skorohod space. It is shown that such a process
displays a dichotomous behavior according to an interplay between the Hurst
parameter, i.e., a parameter characterizing the dependence in the data, and the
tail index. Our theoretical results are accompanied by simulation studies and
the analysis of financial time series with regard to structural changes in the
tail index.",http://arxiv.org/pdf/2006.02667v1,math.ST
2020-06-04 02:11:37+00:00,Tensor Factor Model Estimation by Iterative Projection,"['Yuefeng Han', 'Rong Chen', 'Dan Yang', 'Cun-Hui Zhang']","Tensor time series, which is a time series consisting of tensorial
observations, has become ubiquitous. It typically exhibits high dimensionality.
One approach for dimension reduction is to use a factor model structure, in a
form similar to Tucker tensor decomposition, except that the time dimension is
treated as a dynamic process with a time dependent structure. In this paper we
introduce two approaches to estimate such a tensor factor model by using
iterative orthogonal projections of the original tensor time series. These
approaches extend the existing estimation procedures and improve the estimation
accuracy and convergence rate significantly as proven in our theoretical
investigation. Our algorithms are similar to the higher order orthogonal
projection method for tensor decomposition, but with significant differences
due to the need to unfold tensors in the iterations and the use of
autocorrelation. Consequently, our analysis is significantly different from the
existing ones. Computational and statistical lower bounds are derived to prove
the optimality of the sample size requirement and convergence rate for the
proposed methods. Simulation study is conducted to further illustrate the
statistical properties of these estimators.",http://arxiv.org/pdf/2006.02611v2,stat.ME
2020-06-03 03:47:14+00:00,Interpretable Time-series Classification on Few-shot Samples,"['Wensi Tang', 'Lu Liu', 'Guodong Long']","Recent few-shot learning works focus on training a model with prior
meta-knowledge to fast adapt to new tasks with unseen classes and samples.
However, conventional time-series classification algorithms fail to tackle the
few-shot scenario. Existing few-shot learning methods are proposed to tackle
image or text data, and most of them are neural-based models that lack
interpretability. This paper proposes an interpretable neural-based framework,
namely \textit{Dual Prototypical Shapelet Networks (DPSN)} for few-shot
time-series classification, which not only trains a neural network-based model
but also interprets the model from dual granularity: 1) global overview using
representative time series samples, and 2) local highlights using
discriminative shapelets. In particular, the generated dual prototypical
shapelets consist of representative samples that can mostly demonstrate the
overall shapes of all samples in the class and discriminative partial-length
shapelets that can be used to distinguish different classes. We have derived 18
few-shot TSC datasets from public benchmark datasets and evaluated the proposed
method by comparing with baselines. The DPSN framework outperforms
state-of-the-art time-series classification methods, especially when training
with limited amounts of data. Several case studies have been given to
demonstrate the interpret ability of our model.",http://arxiv.org/pdf/2006.02031v2,cs.LG
2020-06-01 12:10:47+00:00,A Generalised Signature Method for Multivariate Time Series Feature Extraction,"['James Morrill', 'Adeline Fermanian', 'Patrick Kidger', 'Terry Lyons']","The 'signature method' refers to a collection of feature extraction
techniques for multivariate time series, derived from the theory of controlled
differential equations. There is a great deal of flexibility as to how this
method can be applied. On the one hand, this flexibility allows the method to
be tailored to specific problems, but on the other hand, can make precise
application challenging. This paper makes two contributions. First, the
variations on the signature method are unified into a general approach, the
\emph{generalised signature method}, of which previous variations are special
cases. A primary aim of this unifying framework is to make the signature method
more accessible to any machine learning practitioner, whereas it is now mostly
used by specialists. Second, and within this framework, we derive a canonical
collection of choices that provide a domain-agnostic starting point. We derive
these choices as a result of an extensive empirical study on 26 datasets and go
on to show competitive performance against current benchmarks for multivariate
time series classification. Finally, to ease practical application, we make our
techniques available as part of the open-source [redacted] project.",http://arxiv.org/pdf/2006.00873v2,cs.LG
2020-05-31 22:26:16+00:00,A machine learning approach for forecasting hierarchical time series,"['Paolo Mancuso', 'Veronica Piccialli', 'Antonio M. Sudoso']","In this paper, we propose a machine learning approach for forecasting
hierarchical time series. When dealing with hierarchical time series, apart
from generating accurate forecasts, one needs to select a suitable method for
producing reconciled forecasts. Forecast reconciliation is the process of
adjusting forecasts to make them coherent across the hierarchy. In literature,
coherence is often enforced by using a post-processing technique on the base
forecasts produced by suitable time series forecasting methods. On the
contrary, our idea is to use a deep neural network to directly produce accurate
and reconciled forecasts. We exploit the ability of a deep neural network to
extract information capturing the structure of the hierarchy. We impose the
reconciliation at training time by minimizing a customized loss function. In
many practical applications, besides time series data, hierarchical time series
include explanatory variables that are beneficial for increasing the
forecasting accuracy. Exploiting this further information, our approach links
the relationship between time series features extracted at any level of the
hierarchy and the explanatory variables into an end-to-end neural network
providing accurate and reconciled point forecasts. The effectiveness of the
approach is validated on three real-world datasets, where our method
outperforms state-of-the-art competitors in hierarchical forecasting.",http://arxiv.org/pdf/2006.00630v2,cs.LG
2020-05-31 15:32:08+00:00,Interpretable Time Series Classification using Linear Models and Multi-resolution Multi-domain Symbolic Representations,"['Thach Le Nguyen', 'Severin Gsponer', 'Iulia Ilie', ""Martin O'Reilly"", 'Georgiana Ifrim']","The time series classification literature has expanded rapidly over the last
decade, with many new classification approaches published each year. Prior
research has mostly focused on improving the accuracy and efficiency of
classifiers, with interpretability being somewhat neglected. This aspect of
classifiers has become critical for many application domains and the
introduction of the EU GDPR legislation in 2018 is likely to further emphasize
the importance of interpretable learning algorithms. Currently,
state-of-the-art classification accuracy is achieved with very complex models
based on large ensembles (COTE) or deep neural networks (FCN). These approaches
are not efficient with regard to either time or space, are difficult to
interpret and cannot be applied to variable-length time series, requiring
pre-processing of the original series to a set fixed-length. In this paper we
propose new time series classification algorithms to address these gaps. Our
approach is based on symbolic representations of time series, efficient
sequence mining algorithms and linear classification models. Our linear models
are as accurate as deep learning models but are more efficient regarding
running time and memory, can work with variable-length time series and can be
interpreted by highlighting the discriminative symbolic features on the
original time series. We show that our multi-resolution multi-domain linear
classifier (mtSS-SEQL+LR) achieves a similar accuracy to the state-of-the-art
COTE ensemble, and to recent deep learning methods (FCN, ResNet), but uses a
fraction of the time and memory required by either COTE or deep models. To
further analyse the interpretability of our classifier, we present a case study
on a human motion dataset collected by the authors. We release all the results,
source code and data to encourage reproducibility.",http://arxiv.org/pdf/2006.01667v1,cs.LG
2020-05-28 12:32:19+00:00,Generalised Interpretable Shapelets for Irregular Time Series,"['Patrick Kidger', 'James Morrill', 'Terry Lyons']","The shapelet transform is a form of feature extraction for time series, in
which a time series is described by its similarity to each of a collection of
`shapelets'. However it has previously suffered from a number of limitations,
such as being limited to regularly-spaced fully-observed time series, and
having to choose between efficient training and interpretability. Here, we
extend the method to continuous time, and in doing so handle the general case
of irregularly-sampled partially-observed multivariate time series.
Furthermore, we show that a simple regularisation penalty may be used to train
efficiently without sacrificing interpretability. The continuous-time
formulation additionally allows for learning the length of each shapelet
(previously a discrete object) in a differentiable manner. Finally, we
demonstrate that the measure of similarity between time series may be
generalised to a learnt pseudometric. We validate our method by demonstrating
its performance and interpretability on several datasets; for example we
discover (purely from data) that the digits 5 and 6 may be distinguished by the
chirality of their bottom loop, and that a kind of spectral gap exists in
spoken audio classification.",http://arxiv.org/pdf/2005.13948v2,cs.LG
2020-05-27 15:28:11+00:00,Discretize-Optimize vs. Optimize-Discretize for Time-Series Regression and Continuous Normalizing Flows,"['Derek Onken', 'Lars Ruthotto']","We compare the discretize-optimize (Disc-Opt) and optimize-discretize
(Opt-Disc) approaches for time-series regression and continuous normalizing
flows (CNFs) using neural ODEs. Neural ODEs are ordinary differential equations
(ODEs) with neural network components. Training a neural ODE is an optimal
control problem where the weights are the controls and the hidden features are
the states. Every training iteration involves solving an ODE forward and
another backward in time, which can require large amounts of computation, time,
and memory. Comparing the Opt-Disc and Disc-Opt approaches in image
classification tasks, Gholami et al. (2019) suggest that Disc-Opt is preferable
due to the guaranteed accuracy of gradients. In this paper, we extend the
comparison to neural ODEs for time-series regression and CNFs. Unlike in
classification, meaningful models in these tasks must also satisfy additional
requirements beyond accurate final-time output, e.g., the invertibility of the
CNF. Through our numerical experiments, we demonstrate that with careful
numerical treatment, Disc-Opt methods can achieve similar performance as
Opt-Disc at inference with drastically reduced training costs. Disc-Opt reduced
costs in six out of seven separate problems with training time reduction
ranging from 39% to 97%, and in one case, Disc-Opt reduced training from nine
days to less than one day.",http://arxiv.org/pdf/2005.13420v2,cs.LG
2020-05-27 14:50:29+00:00,Portfolio optimization with mixture vector autoregressive models,"['Davide Ravagli', 'Georgi N. Boshnakov']","Obtaining reliable estimates of conditional covariance matrices is an
important task of heteroskedastic multivariate time series. In portfolio
optimization and financial risk management, it is crucial to provide measures
of uncertainty and risk as accurately as possible. We propose using mixture
vector autoregressive (MVAR) models for portfolio optimization. Combining a
mixture of distributions that depend on the recent history of the process, MVAR
models can accommodate asymmetry, multimodality, heteroskedasticity and
cross-correlation in multivariate time series data. For mixtures of Normal
components, we exploit a property of the multivariate Normal distribution to
obtain explicit formulas of conditional predictive distributions of returns on
a portfolio of assets. After showing how the method works, we perform a
comparison with other relevant multivariate time series models on real stock
return data.",http://arxiv.org/pdf/2005.13396v2,stat.ME
2020-05-27 06:37:49+00:00,TSML (Time Series Machine Learnng),"['Paulito Palmes', 'Joern Ploennigs', 'Niall Brady']","Over the past years, the industrial sector has seen many innovations brought
about by automation. Inherent in this automation is the installation of sensor
networks for status monitoring and data collection. One of the major challenges
in these data-rich environments is how to extract and exploit information from
these large volume of data to detect anomalies, discover patterns to reduce
downtimes and manufacturing errors, reduce energy usage, predict
faults/failures, effective maintenance schedules, etc. To address these issues,
we developed TSML. Its technology is based on using the pipeline of lightweight
filters as building blocks to process huge amount of industrial time series
data in parallel.",http://arxiv.org/pdf/2005.13191v1,cs.LG
2020-05-25 19:31:21+00:00,Path Imputation Strategies for Signature Models of Irregular Time Series,"['Michael Moor', 'Max Horn', 'Christian Bock', 'Karsten Borgwardt', 'Bastian Rieck']","The signature transform is a 'universal nonlinearity' on the space of
continuous vector-valued paths, and has received attention for use in machine
learning on time series. However, real-world temporal data is typically
observed at discrete points in time, and must first be transformed into a
continuous path before signature techniques can be applied. We make this step
explicit by characterising it as an imputation problem, and empirically assess
the impact of various imputation strategies when applying signature-based
neural nets to irregular time series data. For one of these strategies,
Gaussian process (GP) adapters, we propose an extension~(GP-PoM) that makes
uncertainty information directly available to the subsequent classifier while
at the same time preventing costly Monte-Carlo (MC) sampling. In our
experiments, we find that the choice of imputation drastically affects shallow
signature models, whereas deeper architectures are more robust. Next, we
observe that uncertainty-aware predictions (based on GP-PoM or indicator
imputations) are beneficial for predictive performance, even compared to the
uncertainty-aware training of conventional GP adapters. In conclusion, we have
demonstrated that the path construction is indeed crucial for signature models
and that our proposed strategy leads to competitive performance in general,
while improving robustness of signature models in particular.",http://arxiv.org/pdf/2005.12359v2,cs.LG
2020-05-24 04:02:18+00:00,Connecting the Dots: Multivariate Time Series Forecasting with Graph Neural Networks,"['Zonghan Wu', 'Shirui Pan', 'Guodong Long', 'Jing Jiang', 'Xiaojun Chang', 'Chengqi Zhang']","Modeling multivariate time series has long been a subject that has attracted
researchers from a diverse range of fields including economics, finance, and
traffic. A basic assumption behind multivariate time series forecasting is that
its variables depend on one another but, upon looking closely, it is fair to
say that existing methods fail to fully exploit latent spatial dependencies
between pairs of variables. In recent years, meanwhile, graph neural networks
(GNNs) have shown high capability in handling relational dependencies. GNNs
require well-defined graph structures for information propagation which means
they cannot be applied directly for multivariate time series where the
dependencies are not known in advance. In this paper, we propose a general
graph neural network framework designed specifically for multivariate time
series data. Our approach automatically extracts the uni-directed relations
among variables through a graph learning module, into which external knowledge
like variable attributes can be easily integrated. A novel mix-hop propagation
layer and a dilated inception layer are further proposed to capture the spatial
and temporal dependencies within the time series. The graph learning, graph
convolution, and temporal convolution modules are jointly learned in an
end-to-end framework. Experimental results show that our proposed model
outperforms the state-of-the-art baseline methods on 3 of 4 benchmark datasets
and achieves on-par performance with other approaches on two traffic datasets
which provide extra structural information.",http://arxiv.org/pdf/2005.11650v1,cs.LG
2020-05-22 20:24:19+00:00,Estimation of cluster functionals for regularly varying time series: sliding blocks estimators,"['Youssouph Cissokho', 'Rafal Kulik']","Cluster indices describe extremal behaviour of stationary time series. We
consider their sliding blocks estimators. Using a modern theory of
multivariate, regularly varying time series, we obtain central limit theorems
under conditions that can be easily verified for a large class of models. In
particular, we show that in the Peak over Threshold framework, sliding and
disjoint blocks estimators have the same limiting variance.",http://arxiv.org/pdf/2005.11378v1,math.ST
2020-05-22 04:16:58+00:00,Multi-Source Deep Domain Adaptation with Weak Supervision for Time-Series Sensor Data,"['Garrett Wilson', 'Janardhan Rao Doppa', 'Diane J. Cook']","Domain adaptation (DA) offers a valuable means to reuse data and models for
new problem domains. However, robust techniques have not yet been considered
for time series data with varying amounts of data availability. In this paper,
we make three main contributions to fill this gap. First, we propose a novel
Convolutional deep Domain Adaptation model for Time Series data (CoDATS) that
significantly improves accuracy and training time over state-of-the-art DA
strategies on real-world sensor data benchmarks. By utilizing data from
multiple source domains, we increase the usefulness of CoDATS to further
improve accuracy over prior single-source methods, particularly on complex time
series datasets that have high variability between domains. Second, we propose
a novel Domain Adaptation with Weak Supervision (DA-WS) method by utilizing
weak supervision in the form of target-domain label distributions, which may be
easier to collect than additional data labels. Third, we perform comprehensive
experiments on diverse real-world datasets to evaluate the effectiveness of our
domain adaptation and weak supervision methods. Results show that CoDATS for
single-source DA significantly improves over the state-of-the-art methods, and
we achieve additional improvements in accuracy using data from multiple source
domains and weakly supervised signals. Code is available at:
https://github.com/floft/codats",http://arxiv.org/pdf/2005.10996v1,cs.LG
2020-05-20 15:09:28+00:00,The Effectiveness of Discretization in Forecasting: An Empirical Study on Neural Time Series Models,"['Stephan Rabanser', 'Tim Januschowski', 'Valentin Flunkert', 'David Salinas', 'Jan Gasthaus']","Time series modeling techniques based on deep learning have seen many
advancements in recent years, especially in data-abundant settings and with the
central aim of learning global models that can extract patterns across multiple
time series. While the crucial importance of appropriate data pre-processing
and scaling has often been noted in prior work, most studies focus on improving
model architectures. In this paper we empirically investigate the effect of
data input and output transformations on the predictive performance of several
neural forecasting architectures. In particular, we investigate the
effectiveness of several forms of data binning, i.e. converting real-valued
time series into categorical ones, when combined with feed-forward, recurrent
neural networks, and convolution-based sequence models. In many non-forecasting
applications where these models have been very successful, the model inputs and
outputs are categorical (e.g. words from a fixed vocabulary in natural language
processing applications or quantized pixel color intensities in computer
vision). For forecasting applications, where the time series are typically
real-valued, various ad-hoc data transformations have been proposed, but have
not been systematically compared. To remedy this, we evaluate the forecasting
accuracy of instances of the aforementioned model classes when combined with
different types of data scaling and binning. We find that binning almost always
improves performance (compared to using normalized real-valued inputs), but
that the particular type of binning chosen is of lesser importance.",http://arxiv.org/pdf/2005.10111v1,cs.LG
2020-05-20 10:08:30+00:00,Early Classification of Time Series. Cost-based Optimization Criterion and Algorithms,"['Youssef Achenchabe', 'Alexis Bondu', 'Antoine Cornuéjols', 'Asma Dachraoui']","An increasing number of applications require to recognize the class of an
incoming time series as quickly as possible without unduly compromising the
accuracy of the prediction. In this paper, we put forward a new optimization
criterion which takes into account both the cost of misclassification and the
cost of delaying the decision. Based on this optimization criterion, we derived
a family of non-myopic algorithms which try to anticipate the expected future
gain in information in balance with the cost of waiting. In one class of
algorithms, unsupervised-based, the expectations use the clustering of time
series, while in a second class, supervised-based, time series are grouped
according to the confidence level of the classifier used to label them.
Extensive experiments carried out on real data sets using a large range of
delay cost functions show that the presented algorithms are able to
satisfactorily solving the earliness vs. accuracy trade-off, with the
supervised-based approaches faring better than the unsupervised-based ones. In
addition, all these methods perform better in a wide variety of conditions than
a state of the art method based on a myopic strategy which is recognized as
very competitive.",http://arxiv.org/pdf/2005.09945v2,cs.LG
2020-05-20 01:02:29+00:00,Neural Ordinary Differential Equation based Recurrent Neural Network Model,"['Mansura Habiba', 'Barak A. Pearlmutter']","Neural differential equations are a promising new member in the neural
network family. They show the potential of differential equations for time
series data analysis. In this paper, the strength of the ordinary differential
equation (ODE) is explored with a new extension. The main goal of this work is
to answer the following questions: (i)~can ODE be used to redefine the existing
neural network model? (ii)~can Neural ODEs solve the irregular sampling rate
challenge of existing neural network models for a continuous time series, i.e.,
length and dynamic nature, (iii)~how to reduce the training and evaluation time
of existing Neural ODE systems? This work leverages the mathematical foundation
of ODEs to redesign traditional RNNs such as Long Short-Term Memory (LSTM) and
Gated Recurrent Unit (GRU). The main contribution of this paper is to
illustrate the design of two new ODE-based RNN models (GRU-ODE model and
LSTM-ODE) which can compute the hidden state and cell state at any point of
time using an ODE solver. These models reduce the computation overhead of
hidden state and cell state by a vast amount. The performance evaluation of
these two new models for learning continuous time series with irregular
sampling rate is then demonstrated. Experiments show that these new ODE based
RNN models require less training time than Latent ODEs and conventional Neural
ODEs. They can achieve higher accuracy quickly, and the design of the neural
network is simpler than, previous neural ODE systems.",http://arxiv.org/pdf/2005.09807v1,cs.LG
2020-05-20 00:28:30+00:00,Neural ODEs for Informative Missingness in Multivariate Time Series,"['Mansura Habiba', 'Barak A. Pearlmutter']","Informative missingness is unavoidable in the digital processing of
continuous time series, where the value for one or more observations at
different time points are missing. Such missing observations are one of the
major limitations of time series processing using deep learning. Practical
applications, e.g., sensor data, healthcare, weather, generates data that is in
truth continuous in time, and informative missingness is a common phenomenon in
these datasets. These datasets often consist of multiple variables, and often
there are missing values for one or many of these variables. This
characteristic makes time series prediction more challenging, and the impact of
missing input observations on the accuracy of the final output can be
significant. A recent novel deep learning model called GRU-D is one early
attempt to address informative missingness in time series data. On the other
hand, a new family of neural networks called Neural ODEs (Ordinary Differential
Equations) are natural and efficient for processing time series data which is
continuous in time. In this paper, a deep learning model is proposed that
leverages the effective imputation of GRU-D, and the temporal continuity of
Neural ODEs. A time series classification task performed on the PhysioNet
dataset demonstrates the performance of this architecture.",http://arxiv.org/pdf/2005.10693v1,cs.LG
2020-05-18 09:14:34+00:00,Necessary and sufficient conditions for causal feature selection in time series with latent common causes,"['Atalanti A. Mastakouri', 'Bernhard Schölkopf', 'Dominik Janzing']","We study the identification of direct and indirect causes on time series and
provide conditions in the presence of latent variables, which we prove to be
necessary and sufficient under some graph constraints. Our theoretical results
and estimation algorithms require two conditional independence tests for each
observed candidate time series to determine whether or not it is a cause of an
observed target time series. We provide experimental results in simulations, as
well as real data. Our results show that our method leads to very low false
positives and relatively low false negative rates, outperforming the widely
used Granger causality.",http://arxiv.org/pdf/2005.08543v3,stat.ME
2020-05-14 15:45:11+00:00,Anomaly Detection And Classification In Time Series With Kervolutional Neural Networks,"['Oliver Ammann', 'Gabriel Michau', 'Olga Fink']","Recently, with the development of deep learning, end-to-end neural network
architectures have been increasingly applied to condition monitoring signals.
They have demonstrated superior performance for fault detection and
classification, in particular using convolutional neural networks. Even more
recently, an extension of the concept of convolution to the concept of
kervolution has been proposed with some promising results in image
classification tasks. In this paper, we explore the potential of kervolutional
neural networks applied to time series data. We demonstrate that using a
mixture of convolutional and kervolutional layers improves the model
performance. The mixed model is first applied to a classification task in time
series, as a benchmark dataset. Subsequently, the proposed mixed architecture
is used to detect anomalies in time series data recorded by accelerometers on
helicopters. We propose a residual-based anomaly detection approach using a
temporal auto-encoder. We demonstrate that mixing kervolutional with
convolutional layers in the encoder is more sensitive to variations in the
input data and is able to detect anomalous time series in a better way.",http://arxiv.org/pdf/2005.07078v1,cs.LG
2020-05-14 14:42:06+00:00,Temporal signals to images: Monitoring the condition of industrial assets with deep learning image processing algorithms,"['Gabriel Rodriguez Garcia', 'Gabriel Michau', 'Mélanie Ducoffe', 'Jayant Sen Gupta', 'Olga Fink']","The ability to detect anomalies in time series is considered highly valuable
in numerous application domains. The sequential nature of time series objects
is responsible for an additional feature complexity, ultimately requiring
specialized approaches in order to solve the task. Essential characteristics of
time series, situated outside the time domain, are often difficult to capture
with state-of-the-art anomaly detection methods when no transformations have
been applied to the time series. Inspired by the success of deep learning
methods in computer vision, several studies have proposed transforming time
series into image-like representations, used as inputs for deep learning
models, and have led to very promising results in classification tasks. In this
paper, we first review the signal to image encoding approaches found in the
literature. Second, we propose modifications to some of their original
formulations to make them more robust to the variability in large datasets.
Third, we compare them on the basis of a common unsupervised task to
demonstrate how the choice of the encoding can impact the results when used in
the same deep learning architecture. We thus provide a comparison between six
encoding algorithms with and without the proposed modifications. The selected
encoding methods are Gramian Angular Field, Markov Transition Field, recurrence
plot, grey scale encoding, spectrogram, and scalogram. We also compare the
results achieved with the raw signal used as input for another deep learning
model. We demonstrate that some encodings have a competitive advantage and
might be worth considering within a deep learning framework. The comparison is
performed on a dataset collected and released by Airbus SAS, containing highly
complex vibration measurements from real helicopter flight tests. The different
encodings provide competitive results for anomaly detection.",http://arxiv.org/pdf/2005.07031v4,cs.LG
2020-05-07 12:47:31+00:00,Predictive Analysis of COVID-19 Time-series Data from Johns Hopkins University,"['Alireza M. Javid', 'Xinyue Liang', 'Arun Venkitaraman', 'Saikat Chatterjee']","We provide a predictive analysis of the spread of COVID-19, also known as
SARS-CoV-2, using the dataset made publicly available online by the Johns
Hopkins University. Our main objective is to provide predictions of the number
of infected people for different countries in the next 14 days. The predictive
analysis is done using time-series data transformed on a logarithmic scale. We
use two well-known methods for prediction: polynomial regression and neural
network. As the number of training data for each country is limited, we use a
single-layer neural network called the extreme learning machine (ELM) to avoid
over-fitting. Due to the non-stationary nature of the time-series, a sliding
window approach is used to provide a more accurate prediction.",http://arxiv.org/pdf/2005.05060v3,cs.LG
2020-05-06 05:12:22+00:00,Approaches and Applications of Early Classification of Time Series: A Review,"['Ashish Gupta', 'Hari Prabhat Gupta', 'Bhaskar Biswas', 'Tanima Dutta']","Early classification of time series has been extensively studied for
minimizing class prediction delay in time-sensitive applications such as
healthcare and finance. A primary task of an early classification approach is
to classify an incomplete time series as soon as possible with some desired
level of accuracy. Recent years have witnessed several approaches for early
classification of time series. As most of the approaches have solved the early
classification problem with different aspects, it becomes very important to
make a thorough review of the existing solutions to know the current status of
the area. These solutions have demonstrated reasonable performance in a wide
range of applications including human activity recognition, gene expression
based health diagnostic, industrial monitoring, and so on. In this paper, we
present a systematic review of current literature on early classification
approaches for both univariate and multivariate time series. We divide various
existing approaches into four exclusive categories based on their proposed
solution strategies. The four categories include prefix based, shapelet based,
model based, and miscellaneous approaches. The authors also discuss the
applications of early classification in many areas including industrial
monitoring, intelligent transportation, and medical. Finally, we provide a
quick summary of the current literature with future research directions.",http://arxiv.org/pdf/2005.02595v2,cs.LG
2020-05-05 20:40:23+00:00,Modeling High-Dimensional Unit-Root Time Series,"['Zhaoxing Gao', 'Ruey S. Tsay']","This paper proposes a new procedure to build factor models for
high-dimensional unit-root time series by postulating that a $p$-dimensional
unit-root process is a nonsingular linear transformation of a set of unit-root
processes, a set of stationary common factors, which are dynamically dependent,
and some idiosyncratic white noise components. For the stationary components,
we assume that the factor process captures the temporal-dependence and the
idiosyncratic white noise series explains, jointly with the factors, the
cross-sectional dependence. The estimation of nonsingular linear loading spaces
is carried out in two steps. First, we use an eigenanalysis of a nonnegative
definite matrix of the data to separate the unit-root processes from the
stationary ones and a modified method to specify the number of unit roots. We
then employ another eigenanalysis and a projected principal component analysis
to identify the stationary common factors and the white noise series. We
propose a new procedure to specify the number of white noise series and, hence,
the number of stationary common factors, establish asymptotic properties of the
proposed method for both fixed and diverging $p$ as the sample size $n$
increases, and use simulation and a real example to demonstrate the performance
of the proposed method in finite samples. We also compare our method with some
commonly used ones in the literature regarding the forecast ability of the
extracted factors and find that the proposed method performs well in
out-of-sample forecasting of a 508-dimensional PM$_{2.5}$ series in Taiwan.",http://arxiv.org/pdf/2005.03496v2,stat.ME
2020-05-05 01:20:04+00:00,Frequency Detection and Change Point Estimation for Time Series of Complex Oscillation,"['Hau-Tieng Wu', 'Zhou Zhou']","We consider detecting the evolutionary oscillatory pattern of a signal when
it is contaminated by non-stationary noises with complexly time-varying data
generating mechanism. A high-dimensional dense progressive periodogram test is
proposed to accurately detect all oscillatory frequencies. A further
phase-adjusted local change point detection algorithm is applied in the
frequency domain to detect the locations at which the oscillatory pattern
changes. Our method is shown to be able to detect all oscillatory frequencies
and the corresponding change points within an accurate range with a prescribed
probability asymptotically. This study is motivated by oscillatory frequency
estimation and change point detection problems encountered in physiological
time series analysis. An application to spindle detection and estimation in
sleep EEG data is used to illustrate the usefulness of the proposed
methodology. A Gaussian approximation scheme and an overlapping-block
multiplier bootstrap methodology for sums of complex-valued high dimensional
non-stationary time series without variance lower bounds are established, which
could be of independent interest.",http://arxiv.org/pdf/2005.01899v2,stat.ME
2020-05-03 02:56:08+00:00,Bootstrapping a Powerful Mixed Portmanteau Test for Time Series,"['Esam Mahdi', 'Thomas J. Fisher']","A new portmanteau test statistic is proposed for detecting nonlinearity in
time series data. In this paper, we elaborate on the Toeplitz autocorrelation
matrix to the autocorrelation and cross-correlation of residuals and squared
residuals block matrix. We derive a new portmanteau test statistic using the
log of the determinant of the mth autocorrelations and cross-correlations block
matrix. The asymptotic distribution of the proposed test statistic is derived
as a linear combination of chi-squared distributions and can be approximated by
a gamma distribution. This test is applied to identify the linearity and
nonlinearity dependency of some stationary time series models. It is shown that
the convergence of the new test to its asymptotic distribution is reasonable
with higher power than other tests in many situations. We demonstrate the
efficiency of the proposed test by investigating linear and nonlinear effects
in Vodafone Qatar and Nikkei-300 daily returns.",http://arxiv.org/pdf/2005.00971v2,math.ST
2020-05-02 22:41:15+00:00,Inference for nonstationary time series of counts with application to change-point problems,"['William Kengne', 'Isidore Séraphin Ngongo']","We consider an integer-valued time series $Y=(Y_t)_{t\in\Z}$ where the models
after a time $k^*$ is Poisson autoregressive with the conditional mean that
depends on a parameter $\theta^*\in\Theta\subset\R^d$. The structure of the
process before $k^*$ is unknown;? it could be any other integer-valued time
series, that is, the process $Y$ could be nonstationary.? It is established
that the maximum likelihood estimator of $\theta^*$ computed on the
nonstationary observations is consistent and asymptotically normal. Next, we
carry out the sequential change-point detection in a large class of Poisson
autoregressive models. We propose a monitoring scheme for detecting change in
the model. The procedure is based on an updated estimator which is computed
without the historical observations. The asymptotic behavior of the detector is
studied, in particular, the above result on the inference in a nonstationary
setting are applied to prove that the proposed procedure is consistent. A
simulation study as well as a real data application are provided.",http://arxiv.org/pdf/2005.00934v1,math.ST
2020-05-02 21:37:14+00:00,Pattern-Based Analysis of Time Series: Estimation,"['Elyas Sabeti', 'Peter X. K. Song', 'Alfred O. Hero']","While Internet of Things (IoT) devices and sensors create continuous streams
of information, Big Data infrastructures are deemed to handle the influx of
data in real-time. One type of such a continuous stream of information is time
series data. Due to the richness of information in time series and inadequacy
of summary statistics to encapsulate structures and patterns in such data,
development of new approaches to learn time series is of interest. In this
paper, we propose a novel method, called pattern tree, to learn patterns in the
times-series using a binary-structured tree. While a pattern tree can be used
for many purposes such as lossless compression, prediction and anomaly
detection, in this paper we focus on its application in time series estimation
and forecasting. In comparison to other methods, our proposed pattern tree
method improves the mean squared error of estimation.",http://arxiv.org/pdf/2005.00926v1,stat.ME
2020-05-01 07:46:29+00:00,Supervised Feature Subset Selection and Feature Ranking for Multivariate Time Series without Feature Extraction,"['Shuchu Han', 'Alexandru Niculescu-Mizil']","We introduce supervised feature ranking and feature subset selection
algorithms for multivariate time series (MTS) classification. Unlike most
existing supervised/unsupervised feature selection algorithms for MTS our
techniques do not require a feature extraction step to generate a
one-dimensional feature vector from the time series. Instead it is based on
directly computing similarity between individual time series and assessing how
well the resulting cluster structure matches the labels. The techniques are
amenable to heterogeneous MTS data, where the time series measurements may have
different sampling resolutions, and to multi-modal data.",http://arxiv.org/pdf/2005.00259v1,cs.LG
2020-04-29 08:25:07+00:00,Multi-Decoder RNN Autoencoder Based on Variational Bayes Method,"['Daisuke Kaji', 'Kazuho Watanabe', 'Masahiro Kobayashi']","Clustering algorithms have wide applications and play an important role in
data analysis fields including time series data analysis. However, in time
series analysis, most of the algorithms used signal shape features or the
initial value of hidden variable of a neural network. Little has been discussed
on the methods based on the generative model of the time series. In this paper,
we propose a new clustering algorithm focusing on the generative process of the
signal with a recurrent neural network and the variational Bayes method. Our
experiments show that the proposed algorithm not only has a robustness against
for phase shift, amplitude and signal length variations but also provide a
flexible clustering based on the property of the variational Bayes method.",http://arxiv.org/pdf/2004.14016v1,stat.ML
2020-04-28 10:32:26+00:00,Time Series Forecasting With Deep Learning: A Survey,"['Bryan Lim', 'Stefan Zohren']","Numerous deep learning architectures have been developed to accommodate the
diversity of time series datasets across different domains. In this article, we
survey common encoder and decoder designs used in both one-step-ahead and
multi-horizon time series forecasting -- describing how temporal information is
incorporated into predictions by each model. Next, we highlight recent
developments in hybrid deep learning models, which combine well-studied
statistical models with neural network components to improve pure methods in
either category. Lastly, we outline some ways in which deep learning can also
facilitate decision support with time series data.",http://arxiv.org/pdf/2004.13408v2,stat.ML
2020-04-27 18:03:24+00:00,Application of Deep Interpolation Network for Clustering of Physiologic Time Series,"['Yanjun Li', 'Yuanfang Ren', 'Tyler J. Loftus', 'Shounak Datta', 'M. Ruppert', 'Ziyuan Guan', 'Dapeng Wu', 'Parisa Rashidi', 'Tezcan Ozrazgat-Baslanti', 'Azra Bihorac']","Background: During the early stages of hospital admission, clinicians must
use limited information to make diagnostic and treatment decisions as patient
acuity evolves. However, it is common that the time series vital sign
information from patients to be both sparse and irregularly collected, which
poses a significant challenge for machine / deep learning techniques to analyze
and facilitate the clinicians to improve the human health outcome. To deal with
this problem, We propose a novel deep interpolation network to extract latent
representations from sparse and irregularly sampled time-series vital signs
measured within six hours of hospital admission. Methods: We created a
single-center longitudinal dataset of electronic health record data for all
(n=75,762) adult patient admissions to a tertiary care center lasting six hours
or longer, using 55% of the dataset for training, 23% for validation, and 22%
for testing. All raw time series within six hours of hospital admission were
extracted for six vital signs (systolic blood pressure, diastolic blood
pressure, heart rate, temperature, blood oxygen saturation, and respiratory
rate). A deep interpolation network is proposed to learn from such irregular
and sparse multivariate time series data to extract the fixed low-dimensional
latent patterns. We use k-means clustering algorithm to clusters the patient
admissions resulting into 7 clusters. Findings: Training, validation, and
testing cohorts had similar age (55-57 years), sex (55% female), and admission
vital signs. Seven distinct clusters were identified. M Interpretation: In a
heterogeneous cohort of hospitalized patients, a deep interpolation network
extracted representations from vital sign data measured within six hours of
hospital admission. This approach may have important implications for clinical
decision-support under time constraints and uncertainty.",http://arxiv.org/pdf/2004.13066v1,cs.LG
2020-04-27 11:32:05+00:00,The Local Partial Autocorrelation Function and Some Applications,"['Rebecca Killick', 'Marina I. Knight', 'Guy P. Nason', 'Idris A. Eckley']","The classical regular and partial autocorrelation functions are powerful
tools for stationary time series modelling and analysis. However, it is
increasingly recognized that many time series are not stationary and the use of
classical global autocorrelations can give misleading answers. This article
introduces two estimators of the local partial autocorrelation function and
establishes their asymptotic properties. The article then illustrates the use
of these new estimators on both simulated and real time series. The examples
clearly demonstrate the strong practical benefits of local estimators for time
series that exhibit nonstationarities.",http://arxiv.org/pdf/2004.12716v1,math.ST
2020-04-27 02:35:46+00:00,Forecasting in Non-stationary Environments with Fuzzy Time Series,"['Petrônio Cândido de Lima e Silva', 'Carlos Alberto Severiano Junior', 'Marcos Antonio Alves', 'Rodrigo Silva', 'Miri Weiss Cohen', 'Frederico Gadelha Guimarães']","In this paper we introduce a Non-Stationary Fuzzy Time Series (NSFTS) method
with time varying parameters adapted from the distribution of the data. In this
approach, we employ Non-Stationary Fuzzy Sets, in which perturbation functions
are used to adapt the membership function parameters in the knowledge base in
response to statistical changes in the time series. The proposed method is
capable of dynamically adapting its fuzzy sets to reflect the changes in the
stochastic process based on the residual errors, without the need to retraining
the model. This method can handle non-stationary and heteroskedastic data as
well as scenarios with concept-drift. The proposed approach allows the model to
be trained only once and remain useful long after while keeping reasonable
accuracy. The flexibility of the method by means of computational experiments
was tested with eight synthetic non-stationary time series data with several
kinds of concept drifts, four real market indices (Dow Jones, NASDAQ, SP500 and
TAIEX), three real FOREX pairs (EUR-USD, EUR-GBP, GBP-USD), and two real
cryptocoins exchange rates (Bitcoin-USD and Ethereum-USD). As competitor models
the Time Variant fuzzy time series and the Incremental Ensemble were used,
these are two of the major approaches for handling non-stationary data sets.
Non-parametric tests are employed to check the significance of the results. The
proposed method shows resilience to concept drift, by adapting parameters of
the model, while preserving the symbolic structure of the knowledge base.",http://arxiv.org/pdf/2004.12554v1,cs.LG
2020-04-26 23:13:31+00:00,Ensemble Deep Learning on Time-Series Representation of Tweets for Rumor Detection in Social Media,"['Chandra Mouli Madhav Kotteti', 'Xishuang Dong', 'Lijun Qian']","Social media is a popular platform for timely information sharing. One of the
important challenges for social media platforms like Twitter is whether to
trust news shared on them when there is no systematic news verification
process. On the other hand, timely detection of rumors is a non-trivial task,
given the fast-paced social media environment. In this work, we proposed an
ensemble model, which performs majority-voting on a collection of predictions
by deep neural networks using time-series vector representation of Twitter data
for timely detection of rumors. By combining the proposed data pre-processing
method with the ensemble model, better performance of rumor detection has been
demonstrated in the experiments using PHEME dataset. Experimental results show
that the classification performance has been improved by 7.9% in terms of micro
F1 score compared to the baselines.",http://arxiv.org/pdf/2004.12500v1,cs.LG
2020-04-24 18:28:57+00:00,Correlation-aware Unsupervised Change-point Detection via Graph Neural Networks,"['Ruohong Zhang', 'Yu Hao', 'Donghan Yu', 'Wei-Cheng Chang', 'Guokun Lai', 'Yiming Yang']","Change-point detection (CPD) aims to detect abrupt changes over time series
data. Intuitively, effective CPD over multivariate time series should require
explicit modeling of the dependencies across input variables. However, existing
CPD methods either ignore the dependency structures entirely or rely on the
(unrealistic) assumption that the correlation structures are static over time.
In this paper, we propose a Correlation-aware Dynamics Model for CPD, which
explicitly models the correlation structure and dynamics of variables by
incorporating graph neural networks into an encoder-decoder framework.
Extensive experiments on synthetic and real-world datasets demonstrate the
advantageous performance of the proposed model on CPD tasks over strong
baselines, as well as its ability to classify the change-points as correlation
changes or independent changes. Keywords: Multivariate Time Series,
Change-point Detection, Graph Neural Networks",http://arxiv.org/pdf/2004.11934v2,cs.LG
2020-04-24 15:51:57+00:00,Sensor selection on graphs via data-driven node sub-sampling in network time series,"['Yiye Jiang', 'Jérémie Bigot', 'Sofian Maabout']","This paper is concerned by the problem of selecting an optimal sampling set
of sensors over a network of time series for the purpose of signal recovery at
non-observed sensors with a minimal reconstruction error. The problem is
motivated by applications where time-dependent graph signals are collected over
redundant networks. In this setting, one may wish to only use a subset of
sensors to predict data streams over the whole collection of nodes in the
underlying graph. A typical application is the possibility to reduce the power
consumption in a network of sensors that may have limited battery supplies. We
propose and compare various data-driven strategies to turn off a fixed number
of sensors or equivalently to select a sampling set of nodes. We also relate
our approach to the existing literature on sensor selection from multivariate
data with a (possibly) underlying graph structure. Our methodology combines
tools from multivariate time series analysis, graph signal processing,
statistical learning in high-dimension and deep learning. To illustrate the
performances of our approach, we report numerical experiments on the analysis
of real data from bike sharing networks in different cities.",http://arxiv.org/pdf/2004.11815v1,stat.ML
2020-04-23 21:39:14+00:00,Semiparametric time series models driven by latent factor,"['Gisele O. Maia', 'Wagner Barreto-Souza', 'Fernando S. Bastos', 'Hernando Ombao']","We introduce a class of semiparametric time series models by assuming a
quasi-likelihood approach driven by a latent factor process. More specifically,
given the latent process, we only specify the conditional mean and variance of
the time series and enjoy a quasi-likelihood function for estimating parameters
related to the mean. This proposed methodology has three remarkable features:
(i) no parametric form is assumed for the conditional distribution of the time
series given the latent process; (ii) able for modelling non-negative, count,
bounded/binary and real-valued time series; (iii) dispersion parameter is not
assumed to be known. Further, we obtain explicit expressions for the marginal
moments and for the autocorrelation function of the time series process so that
a method of moments can be employed for estimating the dispersion parameter and
also parameters related to the latent process. Simulated results aiming to
check the proposed estimation procedure are presented. Real data analysis on
unemployment rate and precipitation time series illustrate the potencial for
practice of our methodology.",http://arxiv.org/pdf/2004.11470v1,stat.ME
2020-04-22 10:17:24+00:00,"Applications of shapelet transform to time series classification of earthquake, wind and wave data","['Monica Arul', 'Ahsan Kareem']","Autonomous detection of desired events from large databases using time series
classification is becoming increasingly important in civil engineering as a
result of continued long-term health monitoring of a large number of
engineering structures encompassing buildings, bridges, towers, and offshore
platforms. In this context, this paper proposes the application of a relatively
new time series representation named ""Shapelet transform"", which is based on
local similarity in the shape of the time series subsequences. In consideration
of the individual attributes distinctive to time series signals in earthquake,
wind and ocean engineering, the application of this transform yields a new
shape-based feature representation. Combining this shape-based representation
with a standard machine learning algorithm, a truly ""white-box"" machine
learning model is proposed with understandable features and a transparent
algorithm. This model automates event detection without the intervention of
domain practitioners, yielding a practical event detection procedure. The
efficacy of this proposed shapelet transform-based autonomous detection
procedure is demonstrated by examples, to identify known and unknown earthquake
events from continuously recorded ground-motion measurements, to detect pulses
in the velocity time history of ground motions to distinguish between
near-field and far-field ground motions, to identify thunderstorms from
continuous wind speed measurements, to detect large-amplitude wind-induced
vibrations from the bridge monitoring data, and to identify plunging breaking
waves that have a significant impact on offshore structures.",http://arxiv.org/pdf/2004.11243v1,cs.LG
2020-04-20 18:06:42+00:00,A Benchmark Study on Time Series Clustering,"['Ali Javed', 'Byung Suk Lee', 'Dona M. Rizzo']","This paper presents the first time series clustering benchmark utilizing all
time series datasets currently available in the University of California
Riverside (UCR) archive -- the state of the art repository of time series data.
Specifically, the benchmark examines eight popular clustering methods
representing three categories of clustering algorithms (partitional,
hierarchical and density-based) and three types of distance measures
(Euclidean, dynamic time warping, and shape-based). We lay out six restrictions
with special attention to making the benchmark as unbiased as possible. A
phased evaluation approach was then designed for summarizing dataset-level
assessment metrics and discussing the results. The benchmark study presented
can be a useful reference for the research community on its own; and the
dataset-level assessment metrics reported may be used for designing evaluation
frameworks to answer different research questions.",http://arxiv.org/pdf/2004.09546v2,cs.LG
2020-04-20 08:02:03+00:00,COVID-19 Time-series Prediction by Joint Dictionary Learning and Online NMF,"['Hanbaek Lyu', 'Christopher Strohmeier', 'Georg Menz', 'Deanna Needell']","Predicting the spread and containment of COVID-19 is a challenge of utmost
importance that the broader scientific community is currently facing. One of
the main sources of difficulty is that a very limited amount of daily COVID-19
case data is available, and with few exceptions, the majority of countries are
currently in the ""exponential spread stage,"" and thus there is scarce
information available which would enable one to predict the phase transition
between spread and containment.
  In this paper, we propose a novel approach to predicting the spread of
COVID-19 based on dictionary learning and online nonnegative matrix
factorization (online NMF). The key idea is to learn dictionary patterns of
short evolution instances of the new daily cases in multiple countries at the
same time, so that their latent correlation structures are captured in the
dictionary patterns. We first learn such patterns by minibatch learning from
the entire time-series and then further adapt them to the time-series by online
NMF. As we progressively adapt and improve the learned dictionary patterns to
the more recent observations, we also use them to make one-step predictions by
the partial fitting. Lastly, by recursively applying the one-step predictions,
we can extrapolate our predictions into the near future. Our prediction results
can be directly attributed to the learned dictionary patterns due to their
interpretability.",http://arxiv.org/pdf/2004.09112v1,cs.LG
2020-04-19 06:33:44+00:00,Time Series Data Augmentation for Neural Networks by Time Warping with a Discriminative Teacher,"['Brian Kenji Iwana', 'Seiichi Uchida']","Neural networks have become a powerful tool in pattern recognition and part
of their success is due to generalization from using large datasets. However,
unlike other domains, time series classification datasets are often small. In
order to address this problem, we propose a novel time series data augmentation
called guided warping. While many data augmentation methods are based on random
transformations, guided warping exploits the element alignment properties of
Dynamic Time Warping (DTW) and shapeDTW, a high-level DTW method based on shape
descriptors, to deterministically warp sample patterns. In this way, the time
series are mixed by warping the features of a sample pattern to match the time
steps of a reference pattern. Furthermore, we introduce a discriminative
teacher in order to serve as a directed reference for the guided warping. We
evaluate the method on all 85 datasets in the 2015 UCR Time Series Archive with
a deep convolutional neural network (CNN) and a recurrent neural network (RNN).
The code with an easy to use implementation can be found at
https://github.com/uchidalab/time_series_augmentation .",http://arxiv.org/pdf/2004.08780v1,cs.LG
2020-04-18 07:51:54+00:00,Kernels for time series with irregularly-spaced multivariate observations,"['Ahmed Guecioueur', 'Franz J. Király']","Time series are an interesting frontier for kernel-based methods, for the
simple reason that there is no kernel designed to represent them and their
unique characteristics in full generality. Existing sequential kernels ignore
the time indices, with many assuming that the series must be regularly-spaced;
some such kernels are not even psd. In this manuscript, we show that a ""series
kernel"" that is general enough to represent irregularly-spaced multivariate
time series may be built out of well-known ""vector kernels"". We also show that
all series kernels constructed using our methodology are psd, and are thus
widely applicable. We demonstrate this point by formulating a Gaussian
process-based strategy - with our series kernel at its heart - to make
predictions about test series when given a training set. We validate the
strategy experimentally by estimating its generalisation error on multiple
datasets and comparing it to relevant baselines. We also demonstrate that our
series kernel may be used for the more traditional setting of time series
classification, where its performance is broadly in line with alternative
methods.",http://arxiv.org/pdf/2004.08545v1,stat.ML
2020-04-17 11:21:16+00:00,Exploring time-series motifs through DTW-SOM,"['Maria Inês Silva', 'Roberto Henriques']","Motif discovery is a fundamental step in data mining tasks for time-series
data such as clustering, classification and anomaly detection. Even though many
papers have addressed the problem of how to find motifs in time-series by
proposing new motif discovery algorithms, not much work has been done on the
exploration of the motifs extracted by these algorithms. In this paper, we
argue that visually exploring time-series motifs computed by motif discovery
algorithms can be useful to understand and debug results. To explore the output
of motif discovery algorithms, we propose the use of an adapted Self-Organizing
Map, the DTW-SOM, on the list of motif's centers. In short, DTW-SOM is a
vanilla Self-Organizing Map with three main differences, namely (1) the use the
Dynamic Time Warping distance instead of the Euclidean distance, (2) the
adoption of two new network initialization routines (a random sample
initialization and an anchor initialization) and (3) the adjustment of the
Adaptation phase of the training to work with variable-length time-series
sequences. We test DTW-SOM in a synthetic motif dataset and two real
time-series datasets from the UCR Time Series Classification Archive. After an
exploration of results, we conclude that DTW-SOM is capable of extracting
relevant information from a set of motifs and display it in a visualization
that is space-efficient.",http://arxiv.org/pdf/2004.08176v1,cs.LG
2020-04-16 17:22:33+00:00,Finite Sample Theory for High-Dimensional Functional/Scalar Time Series with Applications,"['Qin Fang', 'Shaojun Guo', 'Xinghao Qiao']","Statistical analysis of high-dimensional functional times series arises in
various applications. Under this scenario, in addition to the intrinsic
infinite-dimensionality of functional data, the number of functional variables
can grow with the number of serially dependent observations. In this paper, we
focus on the theoretical analysis of relevant estimated cross-(auto)covariance
terms between two multivariate functional time series or a mixture of
multivariate functional and scalar time series beyond the Gaussianity
assumption. We introduce a new perspective on dependence by proposing
functional cross-spectral stability measure to characterize the effect of
dependence on these estimated cross terms, which are essential in the estimates
for additive functional linear regressions. With the proposed functional
cross-spectral stability measure, we develop useful concentration inequalities
for estimated cross-(auto)covariance matrix functions to accommodate more
general sub-Gaussian functional linear processes and, furthermore, establish
finite sample theory for relevant estimated terms under a commonly adopted
functional principal component analysis framework. Using our derived
non-asymptotic results, we investigate the convergence properties of the
regularized estimates for two additive functional linear regression
applications under sparsity assumptions including functional linear lagged
regression and partially functional linear regression in the context of
high-dimensional functional/scalar time series.",http://arxiv.org/pdf/2004.07781v2,math.ST
2020-04-14 17:16:22+00:00,Co-eye: A Multi-resolution Symbolic Representation to TimeSeries Diversified Ensemble Classification,"['Zahraa S. Abdallah', 'Mohamed Medhat Gaber']","Time series classification (TSC) is a challenging task that attracted many
researchers in the last few years. One main challenge in TSC is the diversity
of domains where time series data come from. Thus, there is no ""one model that
fits all"" in TSC. Some algorithms are very accurate in classifying a specific
type of time series when the whole series is considered, while some only target
the existence/non-existence of specific patterns/shapelets. Yet other
techniques focus on the frequency of occurrences of discriminating
patterns/features. This paper presents a new classification technique that
addresses the inherent diversity problem in TSC using a nature-inspired method.
The technique is stimulated by how flies look at the world through ""compound
eyes"" that are made up of thousands of lenses, called ommatidia. Each
ommatidium is an eye with its own lens, and thousands of them together create a
broad field of vision. The developed technique similarly uses different lenses
and representations to look at the time series, and then combines them for
broader visibility. These lenses have been created through
hyper-parameterisation of symbolic representations (Piecewise Aggregate and
Fourier approximations). The algorithm builds a random forest for each lens,
then performs soft dynamic voting for classifying new instances using the most
confident eyes, i.e, forests. We evaluate the new technique, coined Co-eye,
using the recently released extended version of UCR archive, containing more
than 100 datasets across a wide range of domains. The results show the benefits
of bringing together different perspectives reflecting on the accuracy and
robustness of Co-eye in comparison to other state-of-the-art techniques.",http://arxiv.org/pdf/2004.06668v2,cs.LG
2020-04-14 09:20:12+00:00,Minority Oversampling for Imbalanced Time Series Classification,"['Tuanfei Zhu', 'Cheng Luo', 'Jing Li', 'Siqi Ren', 'Zhihong Zhang']","Many important real-world applications involve time-series data with skewed
distribution. Compared to conventional imbalance learning problems, the
classification of imbalanced time-series data is more challenging due to high
dimensionality and high inter-variable correlation. This paper proposes a
structure preserving Oversampling method to combat the High-dimensional
Imbalanced Time-series classification (OHIT). OHIT first leverages a
density-ratio based shared nearest neighbor clustering algorithm to capture the
modes of minority class in high-dimensional space. It then for each mode
applies the shrinkage technique of large-dimensional covariance matrix to
obtain accurate and reliable covariance structure. Finally, OHIT generates the
structure-preserving synthetic samples based on multivariate Gaussian
distribution by using the estimated covariance matrices. Experimental results
on several publicly available time-series datasets (including unimodal and
multimodal) demonstrate the superiority of OHIT against the state-of-the-art
oversampling algorithms in terms of F1, G-mean, and AUC.",http://arxiv.org/pdf/2004.06373v5,cs.LG
2020-04-13 09:00:26+00:00,Hybrid Attention Networks for Flow and Pressure Forecasting in Water Distribution Systems,"['Ziqing Ma', 'Shuming Liu', 'Guancheng Guo', 'Xipeng Yu']","Multivariate geo-sensory time series prediction is challenging because of the
complex spatial and temporal correlation. In urban water distribution systems
(WDS), numerous spatial-correlated sensors have been deployed to continuously
collect hydraulic data. Forecasts of monitored flow and pressure time series
are of vital importance for operational decision making, alerts and anomaly
detection. To address this issue, we proposed a hybrid dual-stage
spatial-temporal attention-based recurrent neural networks (hDS-RNN). Our model
consists of two stages: a spatial attention-based encoder and a temporal
attention-based decoder. Specifically, a hybrid spatial attention mechanism
that employs inputs along temporal and spatial axes is proposed. Experiments on
a real-world dataset are conducted and demonstrate that our model outperformed
9 baseline models in flow and pressure series prediction in WDS.",http://arxiv.org/pdf/2004.05828v2,cs.LG
2020-04-11 18:51:13+00:00,Clustering Time Series Data through Autoencoder-based Deep Learning Models,"['Neda Tavakoli', 'Sima Siami-Namini', 'Mahdi Adl Khanghah', 'Fahimeh Mirza Soltani', 'Akbar Siami Namin']","Machine learning and in particular deep learning algorithms are the emerging
approaches to data analysis. These techniques have transformed traditional data
mining-based analysis radically into a learning-based model in which existing
data sets along with their cluster labels (i.e., train set) are learned to
build a supervised learning model and predict the cluster labels of unseen data
(i.e., test set). In particular, deep learning techniques are capable of
capturing and learning hidden features in a given data sets and thus building a
more accurate prediction model for clustering and labeling problem. However,
the major problem is that time series data are often unlabeled and thus
supervised learning-based deep learning algorithms cannot be directly adapted
to solve the clustering problems for these special and complex types of data
sets. To address this problem, this paper introduces a two-stage method for
clustering time series data. First, a novel technique is introduced to utilize
the characteristics (e.g., volatility) of given time series data in order to
create labels and thus be able to transform the problem from unsupervised
learning into supervised learning. Second, an autoencoder-based deep learning
model is built to learn and model both known and hidden features of time series
data along with their created labels to predict the labels of unseen time
series data. The paper reports a case study in which financial and stock time
series data of selected 70 stock indices are clustered into distinct groups
using the introduced two-stage procedure. The results show that the proposed
procedure is capable of achieving 87.5\% accuracy in clustering and predicting
the labels for unseen time series data.",http://arxiv.org/pdf/2004.07296v1,cs.LG
2020-04-09 17:53:49+00:00,Industrial Forecasting with Exponentially Smoothed Recurrent Neural Networks,['Matthew F Dixon'],"Time series modeling has entered an era of unprecedented growth in the size
and complexity of data which require new modeling approaches. While many new
general purpose machine learning approaches have emerged, they remain poorly
understand and irreconcilable with more traditional statistical modeling
approaches. We present a general class of exponential smoothed recurrent neural
networks (RNNs) which are well suited to modeling non-stationary dynamical
systems arising in industrial applications. In particular, we analyze their
capacity to characterize the non-linear partial autocorrelation structure of
time series and directly capture dynamic effects such as seasonality and
trends. Application of exponentially smoothed RNNs to forecasting electricity
load, weather data, and stock prices highlight the efficacy of exponential
smoothing of the hidden state for multi-step time series forecasting. The
results also suggest that popular, but more complicated neural network
architectures originally designed for speech processing, such as LSTMs and
GRUs, are likely over-engineered for industrial forecasting and light-weight
exponentially smoothed architectures, trained in a fraction of the time,
capture the salient features while being superior and more robust than simple
RNNs and ARIMA models. Additionally uncertainty quantification of the
exponential smoothed recurrent neural networks, provided by Bayesian
estimation, is shown to provide improved coverage.",http://arxiv.org/pdf/2004.04717v2,stat.ML
2020-04-08 12:33:01+00:00,Bootstrap Prediction Bands for Functional Time Series,"['Efstathios Paparoditis', 'Han Lin Shang']","A bootstrap procedure for constructing prediction bands for a stationary
functional time series is proposed. The procedure exploits a general vector
autoregressive representation of the time-reversed series of Fourier
coefficients appearing in the Karhunen-Loeve representation of the functional
process. It generates backward-in-time, functional replicates that adequately
mimic the dependence structure of the underlying process in a model-free way
and have the same conditionally fixed curves at the end of each functional
pseudo-time series. The bootstrap prediction error distribution is then
calculated as the difference between the model-free, bootstrap-generated future
functional observations and the functional forecasts obtained from the model
used for prediction. This allows the estimated prediction error distribution to
account for the innovation and estimation errors associated with prediction and
the possible errors due to model misspecification. We establish the asymptotic
validity of the bootstrap procedure in estimating the conditional prediction
error distribution of interest, and we also show that the procedure enables the
construction of prediction bands that achieve (asymptotically) the desired
coverage. Prediction bands based on a consistent estimation of the conditional
distribution of the studentized prediction error process also are introduced.
Such bands allow for taking more appropriately into account the local
uncertainty of prediction. Through a simulation study and the analysis of two
data sets, we demonstrate the capabilities and the good finite-sample
performance of the proposed method.",http://arxiv.org/pdf/2004.03971v5,math.ST
2020-04-08 03:55:30+00:00,Mixture Density Conditional Generative Adversarial Network Models (MD-CGAN),"['Jaleh Zand', 'Stephen Roberts']","Generative Adversarial Networks (GANs) have gained significant attention in
recent years, with impressive applications highlighted in computer vision in
particular. Compared to such examples, however, there have been more limited
applications of GANs to time series modelling, including forecasting. In this
work, we present the Mixture Density Conditional Generative Adversarial Model
(MD-CGAN), with a focus on time series forecasting. We show that our model is
capable of estimating a probabilistic posterior distribution over forecasts and
that, in comparison to a set of benchmark methods, the MD-CGAN model performs
well, particularly in situations where noise is a significant component of the
observed time series. Further, by using a Gaussian mixture model as the output
distribution, MD-CGAN offers posterior predictions that are non-Gaussian.",http://arxiv.org/pdf/2004.03797v3,cs.LG
2020-04-06 19:34:25+00:00,TSInsight: A local-global attribution framework for interpretability in time-series data,"['Shoaib Ahmed Siddiqui', 'Dominique Mercier', 'Andreas Dengel', 'Sheraz Ahmed']","With the rise in the employment of deep learning methods in safety-critical
scenarios, interpretability is more essential than ever before. Although many
different directions regarding interpretability have been explored for visual
modalities, time-series data has been neglected with only a handful of methods
tested due to their poor intelligibility. We approach the problem of
interpretability in a novel way by proposing TSInsight where we attach an
auto-encoder to the classifier with a sparsity-inducing norm on its output and
fine-tune it based on the gradients from the classifier and a reconstruction
penalty. TSInsight learns to preserve features that are important for
prediction by the classifier and suppresses those that are irrelevant i.e.
serves as a feature attribution method to boost interpretability. In contrast
to most other attribution frameworks, TSInsight is capable of generating both
instance-based and model-based explanations. We evaluated TSInsight along with
9 other commonly used attribution methods on 8 different time-series datasets
to validate its efficacy. Evaluation results show that TSInsight naturally
achieves output space contraction, therefore, is an effective tool for the
interpretability of deep time-series models.",http://arxiv.org/pdf/2004.02958v1,cs.LG
2020-04-06 14:17:53+00:00,A novel change point approach for the detection of gas emission sources using remotely contained concentration data,"['Idris Eckley', 'Claudia Kirch', 'Silke Weber']","Motivated by an example from remote sensing of gas emission sources, we
derive two novel change point procedures for multivariate time series where, in
contrast to classical change point literature, the changes are not required to
be aligned in the different components of the time series. Instead the change
points are described by a functional relationship where the precise shape
depends on unknown parameters of interest such as the source of the gas
emission in the above example. Two different types of tests and the
corresponding estimators for the unknown parameters describing the change
locations are proposed. We derive the null asymptotics for both tests under
weak assumptions on the error time series and show asymptotic consistency under
alternatives. Furthermore, we prove consistency for the corresponding
estimators of the parameters of interest. The small sample behavior of the
methodology is assessed by means of a simulation study and the above remote
sensing example analyzed in detail.",http://arxiv.org/pdf/2004.02692v1,stat.ME
2020-04-06 01:49:46+00:00,Forecasting in multivariate irregularly sampled time series with missing values,"['Shivam Srivastava', 'Prithviraj Sen', 'Berthold Reinwald']","Sparse and irregularly sampled multivariate time series are common in
clinical, climate, financial and many other domains. Most recent approaches
focus on classification, regression or forecasting tasks on such data. In
forecasting, it is necessary to not only forecast the right value but also to
forecast when that value will occur in the irregular time series. In this work,
we present an approach to forecast not only the values but also the time at
which they are expected to occur.",http://arxiv.org/pdf/2004.03398v1,cs.LG
2020-04-05 21:26:24+00:00,ReRe: A Lightweight Real-time Ready-to-Go Anomaly Detection Approach for Time Series,"['Ming-Chang Lee', 'Jia-Chun Lin', 'Ernst Gunnar Gran']","Anomaly detection is an active research topic in many different fields such
as intrusion detection, network monitoring, system health monitoring, IoT
healthcare, etc. However, many existing anomaly detection approaches require
either human intervention or domain knowledge, and may suffer from high
computation complexity, consequently hindering their applicability in
real-world scenarios. Therefore, a lightweight and ready-to-go approach that is
able to detect anomalies in real-time is highly sought-after. Such an approach
could be easily and immediately applied to perform time series anomaly
detection on any commodity machine. The approach could provide timely anomaly
alerts and by that enable appropriate countermeasures to be undertaken as early
as possible. With these goals in mind, this paper introduces ReRe, which is a
Real-time Ready-to-go proactive Anomaly Detection algorithm for streaming time
series. ReRe employs two lightweight Long Short-Term Memory (LSTM) models to
predict and jointly determine whether or not an upcoming data point is
anomalous based on short-term historical data points and two long-term
self-adaptive thresholds. Experiments based on real-world time-series datasets
demonstrate the good performance of ReRe in real-time anomaly detection without
requiring human intervention or domain knowledge.",http://arxiv.org/pdf/2004.02319v4,cs.LG
2020-04-05 19:01:51+00:00,Analyzing initial stage of COVID-19 transmission through Bayesian time-varying model,"['Arkaprava Roy', 'Sayar Karmakar']","Recent outbreak of the novel coronavirus COVID-19 has affected all of our
lives in one way or the other. While medical researchers are working hard to
find a cure and doctors/nurses to attend the affected individuals, measures
such as `lockdown', `stay-at-home', `social distancing' are being implemented
in different parts of the world to curb its further spread. To model the
non-stationary spread, we propose a novel time-varying semiparametric AR$(p)$
model for the count valued time-series of newly affected cases, collected every
day and also extend it to propose a novel time-varying INGARCH model. Our
proposed structures of the models are amenable to Hamiltonian Monte Carlo (HMC)
sampling for efficient computation. We substantiate our methods by simulations
that show superiority compared to some of the close existing methods. Finally
we analyze the daily time series data of newly confirmed cases to study its
spread through different government interventions.",http://arxiv.org/pdf/2004.02281v4,stat.ME
2020-04-04 08:52:19+00:00,ForecastTB An R Package as a Test-Bench for Time Series Forecasting Application of Wind Speed and Solar Radiation Modeling,"['Neeraj Dhanraj Bokde', 'Zaher Mundher Yaseen', 'Gorm Bruun Andersen']","This paper introduces an R package ForecastTB that can be used to compare the
accuracy of different forecasting methods as related to the characteristics of
a time series dataset. The ForecastTB is a plug-and-play structured module, and
several forecasting methods can be included with simple instructions. The
proposed test-bench is not limited to the default forecasting and error metric
functions, and users are able to append, remove, or choose the desired methods
as per requirements. Besides, several plotting functions and statistical
performance metrics are provided to visualize the comparative performance and
accuracy of different forecasting methods. Furthermore, this paper presents
real application examples with natural time series datasets (i.e., wind speed
and solar radiation) to exhibit the features of the ForecastTB package to
evaluate forecasting comparison analysis as affected by the characteristics of
a dataset. Modeling results indicated the applicability and robustness of the
proposed R package ForecastTB for time series forecasting.",http://arxiv.org/pdf/2004.01893v2,stat.ME
2020-04-01 13:22:34+00:00,Anomaly Detection in Univariate Time-series: A Survey on the State-of-the-Art,"['Mohammad Braei', 'Sebastian Wagner']","Anomaly detection for time-series data has been an important research field
for a long time. Seminal work on anomaly detection methods has been focussing
on statistical approaches. In recent years an increasing number of machine
learning algorithms have been developed to detect anomalies on time-series.
Subsequently, researchers tried to improve these techniques using (deep) neural
networks. In the light of the increasing number of anomaly detection methods,
the body of research lacks a broad comparative evaluation of statistical,
machine learning and deep learning methods. This paper studies 20 univariate
anomaly detection methods from the all three categories. The evaluation is
conducted on publicly available datasets, which serve as benchmarks for
time-series anomaly detection. By analyzing the accuracy of each method as well
as the computation time of the algorithms, we provide a thorough insight about
the performance of these anomaly detection approaches, alongside some general
notion of which method is suited for a certain type of data.",http://arxiv.org/pdf/2004.00433v1,cs.LG
2020-03-31 03:34:51+00:00,On the the linear processes of a stationary time series AR(2),['Mouloud Goubi'],"Our aim in this work is to give explicit formula of the linear processes
solution of autoregressive time series AR(2) with hint of generating functions
theory by using the Horadam numbers and polynomials.",http://arxiv.org/pdf/2003.13938v1,math.ST
2020-03-31 00:15:41+00:00,Adversarial Attacks on Multivariate Time Series,"['Samuel Harford', 'Fazle Karim', 'Houshang Darabi']","Classification models for the multivariate time series have gained
significant importance in the research community, but not much research has
been done on generating adversarial samples for these models. Such samples of
adversaries could become a security concern. In this paper, we propose
transforming the existing adversarial transformation network (ATN) on a
distilled model to attack various multivariate time series classification
models. The proposed attack on the classification model utilizes a distilled
model as a surrogate that mimics the behavior of the attacked classical
multivariate time series classification models. The proposed methodology is
tested onto 1-Nearest Neighbor Dynamic Time Warping (1-NN DTW) and a Fully
Convolutional Network (FCN), all of which are trained on 18 University of East
Anglia (UEA) and University of California Riverside (UCR) datasets. We show
both models were susceptible to attacks on all 18 datasets. To the best of our
knowledge, adversarial attacks have only been conducted in the domain of
univariate time series and have not been conducted on multivariate time series.
such an attack on time series classification models has never been done before.
Additionally, we recommend future researchers that develop time series
classification models to incorporating adversarial data samples into their
training data sets to improve resilience on adversarial samples and to consider
model robustness as an evaluative metric.",http://arxiv.org/pdf/2004.00410v1,cs.LG
2020-03-30 16:48:30+00:00,Difference Attention Based Error Correction LSTM Model for Time Series Prediction,"['Yuxuan Liu', 'Jiangyong Duan', 'Juan Meng']","In this paper, we propose a novel model for time series prediction in which
difference-attention LSTM model and error-correction LSTM model are
respectively employed and combined in a cascade way. While difference-attention
LSTM model introduces a difference feature to perform attention in traditional
LSTM to focus on the obvious changes in time series. Error-correction LSTM
model refines the prediction error of difference-attention LSTM model to
further improve the prediction accuracy. Finally, we design a training strategy
to jointly train the both models simultaneously. With additional difference
features and new principle learning framework, our model can improve the
prediction accuracy in time series. Experiments on various time series are
conducted to demonstrate the effectiveness of our method.",http://arxiv.org/pdf/2003.13616v1,cs.LG
2020-03-28 14:17:05+00:00,Correlated daily time series and forecasting in the M4 competition,"['Anti Ingel', 'Novin Shahroudi', 'Markus Kängsepp', 'Andre Tättar', 'Viacheslav Komisarenko', 'Meelis Kull']","We participated in the M4 competition for time series forecasting and
describe here our methods for forecasting daily time series. We used an
ensemble of five statistical forecasting methods and a method that we refer to
as the correlator. Our retrospective analysis using the ground truth values
published by the M4 organisers after the competition demonstrates that the
correlator was responsible for most of our gains over the naive constant
forecasting method. We identify data leakage as one reason for its success,
partly due to test data selected from different time intervals, and partly due
to quality issues in the original time series. We suggest that future
forecasting competitions should provide actual dates for the time series so
that some of those leakages could be avoided by the participants.",http://arxiv.org/pdf/2003.12796v2,cs.LG
2020-03-27 15:30:32+00:00,ABBA: Adaptive Brownian bridge-based symbolic aggregation of time series,"['Steven Elsworth', 'Stefan Güttel']","A new symbolic representation of time series, called ABBA, is introduced. It
is based on an adaptive polygonal chain approximation of the time series into a
sequence of tuples, followed by a mean-based clustering to obtain the symbolic
representation. We show that the reconstruction error of this representation
can be modelled as a random walk with pinned start and end points, a so-called
Brownian bridge. This insight allows us to make ABBA essentially
parameter-free, except for the approximation tolerance which must be chosen.
Extensive comparisons with the SAX and 1d-SAX representations are included in
the form of performance profiles, showing that ABBA is able to better preserve
the essential shape information of time series compared to other approaches.
Advantages and applications of ABBA are discussed, including its in-built
differencing property and use for anomaly detection, and Python implementations
provided.",http://arxiv.org/pdf/2003.12469v1,cs.LG
2020-03-27 09:44:57+00:00,New Perspectives on the Use of Online Learning for Congestion Level Prediction over Traffic Data,"['Eric L. Manibardo', 'Ibai Laña', 'Jesus L. Lobo', 'Javier Del Ser']","This work focuses on classification over time series data. When a time series
is generated by non-stationary phenomena, the pattern relating the series with
the class to be predicted may evolve over time (concept drift). Consequently,
predictive models aimed to learn this pattern may become eventually obsolete,
hence failing to sustain performance levels of practical use. To overcome this
model degradation, online learning methods incrementally learn from new data
samples arriving over time, and accommodate eventual changes along the data
stream by implementing assorted concept drift strategies. In this manuscript we
elaborate on the suitability of online learning methods to predict the road
congestion level based on traffic speed time series data. We draw interesting
insights on the performance degradation when the forecasting horizon is
increased. As opposed to what is done in most literature, we provide evidence
of the importance of assessing the distribution of classes over time before
designing and tuning the learning model. This previous exercise may give a hint
of the predictability of the different congestion levels under target.
Experimental results are discussed over real traffic speed data captured by
inductive loops deployed over Seattle (USA). Several online learning methods
are analyzed, from traditional incremental learning algorithms to more
elaborated deep learning models. As shown by the reported results, when
increasing the prediction horizon, the performance of all models degrade
severely due to the distribution of classes along time, which supports our
claim about the importance of analyzing this distribution prior to the design
of the model.",http://arxiv.org/pdf/2003.14304v1,cs.LG
2020-03-26 21:33:10+00:00,Zero-shot and few-shot time series forecasting with ordinal regression recurrent neural networks,"['Bernardo Pérez Orozco', 'Stephen J Roberts']","Recurrent neural networks (RNNs) are state-of-the-art in several sequential
learning tasks, but they often require considerable amounts of data to
generalise well. For many time series forecasting (TSF) tasks, only a few
dozens of observations may be available at training time, which restricts use
of this class of models. We propose a novel RNN-based model that directly
addresses this problem by learning a shared feature embedding over the space of
many quantised time series. We show how this enables our RNN framework to
accurately and reliably forecast unseen time series, even when there is little
to no training data available.",http://arxiv.org/pdf/2003.12162v1,cs.LG
2020-03-26 14:15:41+00:00,Triad State Space Construction for Chaotic Signal Classification with Deep Learning,"['Yadong Zhang', 'Xin Chen']","Inspired by the well-known permutation entropy (PE), an effective image
encoding scheme for chaotic time series, Triad State Space Construction (TSSC),
is proposed. The TSSC image can recognize higher-order temporal patterns and
identify new forbidden regions in time series motifs beyond the Bandt-Pompe
probabilities. The Convolutional Neural Network (ConvNet) is widely used in
image classification. The ConvNet classifier based on TSSC images
(TSSC-ConvNet) are highly accurate and very robust in the chaotic signal
classification.",http://arxiv.org/pdf/2003.11931v1,cs.LG
2020-03-24 18:25:49+00:00,Integrating Physiological Time Series and Clinical Notes with Deep Learning for Improved ICU Mortality Prediction,"['Satya Narayan Shukla', 'Benjamin M. Marlin']","Intensive Care Unit Electronic Health Records (ICU EHRs) store multimodal
data about patients including clinical notes, sparse and irregularly sampled
physiological time series, lab results, and more. To date, most methods
designed to learn predictive models from ICU EHR data have focused on a single
modality. In this paper, we leverage the recently proposed
interpolation-prediction deep learning architecture(Shukla and Marlin 2019) as
a basis for exploring how physiological time series data and clinical notes can
be integrated into a unified mortality prediction model. We study both early
and late fusion approaches and demonstrate how the relative predictive value of
clinical text and physiological data change over time. Our results show that a
late fusion approach can provide a statistically significant improvement in
mortality prediction performance over using individual modalities in isolation.",http://arxiv.org/pdf/2003.11059v2,cs.LG
2020-03-20 14:21:25+00:00,Improving Irregularly Sampled Time Series Learning with Dense Descriptors of Time,"['Rafael T. Sousa', 'Lucas A. Pereira', 'Anderson S. Soares']","Supervised learning with irregularly sampled time series have been a
challenge to Machine Learning methods due to the obstacle of dealing with
irregular time intervals. Some papers introduced recently recurrent neural
network models that deals with irregularity, but most of them rely on complex
mechanisms to achieve a better performance. This work propose a novel method to
represent timestamps (hours or dates) as dense vectors using sinusoidal
functions, called Time Embeddings. As a data input method it and can be applied
to most machine learning models. The method was evaluated with two predictive
tasks from MIMIC III, a dataset of irregularly sampled time series of
electronic health records. Our tests showed an improvement to LSTM-based and
classical machine learning models, specially with very irregular data.",http://arxiv.org/pdf/2003.09291v1,cs.LG
2020-03-20 11:32:06+00:00,New statistical model for misreported data with application to current public health challenges,"['David Moriña', 'Amanda Fernández-Fontelo', 'Alejandra Cabaña', 'Pedro Puig']","The main goal of this work is to present a new model able to deal with
potentially misreported continuous time series. The proposed model is able to
handle the autocorrelation structure in continuous time series data, which
might be partially or totally underreported or overreported. Its performance is
illustrated through a comprehensive simulation study considering several
autocorrelation structures and two real data applications on human
papillomavirus incidence in Girona (Catalunya, Spain) and COVID-19 incidence in
the Chinese region of Heilongjiang.",http://arxiv.org/pdf/2003.09202v2,stat.ME
2020-03-17 21:51:45+00:00,A comparison of Hurst exponent estimators in long-range dependent curve time series,['Han Lin Shang'],"The Hurst exponent is the simplest numerical summary of self-similar
long-range dependent stochastic processes. We consider the estimation of Hurst
exponent in long-range dependent curve time series. Our estimation method
begins by constructing an estimate of the long-run covariance function, which
we use, via dynamic functional principal component analysis, in estimating the
orthonormal functions spanning the dominant sub-space of functional time
series. Within the context of functional autoregressive fractionally integrated
moving average models, we compare finite-sample bias, variance and mean square
error among some time- and frequency-domain Hurst exponent estimators and make
our recommendations.",http://arxiv.org/pdf/2003.08787v1,math.ST
2020-03-16 10:21:37+00:00,Drift-Adjusted And Arbitrated Ensemble Framework For Time Series Forecasting,"['Anirban Chatterjee', 'Subhadip Paul', 'Uddipto Dutta', 'Smaranya Dey']","Time Series Forecasting is at the core of many practical applications such as
sales forecasting for business, rainfall forecasting for agriculture and many
others. Though this problem has been extensively studied for years, it is still
considered a challenging problem due to complex and evolving nature of time
series data. Typical methods proposed for time series forecasting modeled
linear or non-linear dependencies between data observations. However it is a
generally accepted notion that no one method is universally effective for all
kinds of time series data. Attempts have been made to use dynamic and weighted
combination of heterogeneous and independent forecasting models and it has been
found to be a promising direction to tackle this problem. This method is based
on the assumption that different forecasters have different specialization and
varying performance for different distribution of data and weights are
dynamically assigned to multiple forecasters accordingly. However in many
practical time series data-set, the distribution of data slowly evolves with
time. We propose to employ a re-weighting based method to adjust the assigned
weights to various forecasters in order to account for such distribution-drift.
An exhaustive testing was performed against both real-world and synthesized
time-series. Experimental results show the competitiveness of the method in
comparison to state-of-the-art approaches for combining forecasters and
handling drift.",http://arxiv.org/pdf/2003.09311v1,cs.LG
2020-03-13 12:23:41+00:00,An Evaluation of Change Point Detection Algorithms,"['Gerrit J. J. van den Burg', 'Christopher K. I. Williams']","Change point detection is an important part of time series analysis, as the
presence of a change point indicates an abrupt and significant change in the
data generating process. While many algorithms for change point detection have
been proposed, comparatively little attention has been paid to evaluating their
performance on real-world time series. Algorithms are typically evaluated on
simulated data and a small number of commonly-used series with unreliable
ground truth. Clearly this does not provide sufficient insight into the
comparative performance of these algorithms. Therefore, instead of developing
yet another change point detection method, we consider it vastly more important
to properly evaluate existing algorithms on real-world data. To achieve this,
we present a data set specifically designed for the evaluation of change point
detection algorithms that consists of 37 time series from various application
domains. Each series was annotated by five human annotators to provide ground
truth on the presence and location of change points. We analyze the consistency
of the human annotators, and describe evaluation metrics that can be used to
measure algorithm performance in the presence of multiple ground truth
annotations. Next, we present a benchmark study where 14 algorithms are
evaluated on each of the time series in the data set. Our aim is that this data
set will serve as a proving ground in the development of novel change point
detection algorithms.",http://arxiv.org/pdf/2003.06222v3,stat.ML
2020-03-12 18:31:48+00:00,Statistical Inference for High Dimensional Panel Functional Time Series,"['Zhou Zhou', 'Holger Dette']","In this paper we develop statistical inference tools for high dimensional
functional time series. We introduce a new concept of physical dependent
processes in the space of square integrable functions, which adopts the idea of
basis decomposition of functional data in these spaces, and derive Gaussian and
multiplier bootstrap approximations for sums of high dimensional functional
time series. These results have numerous important statistical consequences.
Exemplarily, we consider the development of joint simultaneous confidence bands
for the mean functions and the construction of tests for the hypotheses that
the mean functions in the spatial dimension are parallel. The results are
illustrated by means of a small simulation study and in the analysis of
Canadian temperature data.",http://arxiv.org/pdf/2003.05968v1,math.ST
2020-03-12 09:18:22+00:00,Time Series Forecasting Using LSTM Networks: A Symbolic Approach,"['Steven Elsworth', 'Stefan Güttel']","Machine learning methods trained on raw numerical time series data exhibit
fundamental limitations such as a high sensitivity to the hyper parameters and
even to the initialization of random weights. A combination of a recurrent
neural network with a dimension-reducing symbolic representation is proposed
and applied for the purpose of time series forecasting. It is shown that the
symbolic representation can help to alleviate some of the aforementioned
problems and, in addition, might allow for faster training without sacrificing
the forecast performance.",http://arxiv.org/pdf/2003.05672v1,cs.LG
2020-03-09 04:16:43+00:00,Temporal Attribute Prediction via Joint Modeling of Multi-Relational Structure Evolution,"['Sankalp Garg', 'Navodita Sharma', 'Woojeong Jin', 'Xiang Ren']","Time series prediction is an important problem in machine learning. Previous
methods for time series prediction did not involve additional information. With
a lot of dynamic knowledge graphs available, we can use this additional
information to predict the time series better. Recently, there has been a focus
on the application of deep representation learning on dynamic graphs. These
methods predict the structure of the graph by reasoning over the interactions
in the graph at previous time steps. In this paper, we propose a new framework
to incorporate the information from dynamic knowledge graphs for time series
prediction. We show that if the information contained in the graph and the time
series data are closely related, then this inter-dependence can be used to
predict the time series with improved accuracy. Our framework, DArtNet, learns
a static embedding for every node in the graph as well as a dynamic embedding
which is dependent on the dynamic attribute value (time-series). Then it
captures the information from the neighborhood by taking a relation specific
mean and encodes the history information using RNN. We jointly train the model
link prediction and attribute prediction. We evaluate our method on five
specially curated datasets for this problem and show a consistent improvement
in time series prediction results. We release the data and code of model
DArtNet for future research at https://github.com/INK-USC/DArtNet .",http://arxiv.org/pdf/2003.03919v2,cs.LG
2020-03-09 02:06:01+00:00,Assessing the Significance of Directed and Multivariate Measures of Linear Dependence Between Time Series,"['Oliver M. Cliff', 'Leonardo Novelli', 'Ben D. Fulcher', 'James M. Shine', 'Joseph T. Lizier']","Inferring linear dependence between time series is central to our
understanding of natural and artificial systems. Unfortunately, the hypothesis
tests that are used to determine statistically significant directed or
multivariate relationships from time-series data often yield spurious
associations (Type I errors) or omit causal relationships (Type II errors).
This is due to the autocorrelation present in the analysed time series -- a
property that is ubiquitous across diverse applications, from brain dynamics to
climate change. Here we show that, for limited data, this issue cannot be
mediated by fitting a time-series model alone (e.g., in Granger causality or
prewhitening approaches), and instead that the degrees of freedom in
statistical tests should be altered to account for the effective sample size
induced by cross-correlations in the observations. This insight enabled us to
derive modified hypothesis tests for any multivariate correlation-based
measures of linear dependence between covariance-stationary time series,
including Granger causality and mutual information with Gaussian marginals. We
use both numerical simulations (generated by autoregressive models and digital
filtering) as well as recorded fMRI-neuroimaging data to show that our tests
are unbiased for a variety of stationary time series. Our experiments
demonstrate that the commonly used $F$- and $\chi^2$-tests can induce
significant false-positive rates of up to $100\%$ for both measures, with and
without prewhitening of the signals. These findings suggest that many
dependencies reported in the scientific literature may have been, and may
continue to be, spuriously reported or missed if modified hypothesis tests are
not used when analysing time series.",http://arxiv.org/pdf/2003.03887v3,stat.ME
2020-03-07 23:33:34+00:00,Discovering contemporaneous and lagged causal relations in autocorrelated nonlinear time series datasets,['Jakob Runge'],"The paper introduces a novel conditional independence (CI) based method for
linear and nonlinear, lagged and contemporaneous causal discovery from
observational time series in the causally sufficient case. Existing CI-based
methods such as the PC algorithm and also common methods from other frameworks
suffer from low recall and partially inflated false positives for strong
autocorrelation which is an ubiquitous challenge in time series. The novel
method, PCMCI$^+$, extends PCMCI [Runge et al., 2019b] to include discovery of
contemporaneous links. PCMCI$^+$ improves the reliability of CI tests by
optimizing the choice of conditioning sets and even benefits from
autocorrelation. The method is order-independent and consistent in the oracle
case. A broad range of numerical experiments demonstrates that PCMCI$^+$ has
higher adjacency detection power and especially more contemporaneous
orientation recall compared to other methods while better controlling false
positives. Optimized conditioning sets also lead to much shorter runtimes than
the PC algorithm. PCMCI$^+$ can be of considerable use in many real world
application scenarios where often time resolutions are too coarse to resolve
time delays and strong autocorrelation is present.",http://arxiv.org/pdf/2003.03685v2,stat.ME
2020-03-05 18:45:05+00:00,What went wrong and when? Instance-wise Feature Importance for Time-series Models,"['Sana Tonekaboni', 'Shalmali Joshi', 'Kieran Campbell', 'David Duvenaud', 'Anna Goldenberg']","Explanations of time series models are useful for high stakes applications
like healthcare but have received little attention in machine learning
literature. We propose FIT, a framework that evaluates the importance of
observations for a multivariate time-series black-box model by quantifying the
shift in the predictive distribution over time. FIT defines the importance of
an observation based on its contribution to the distributional shift under a
KL-divergence that contrasts the predictive distribution against a
counterfactual where the rest of the features are unobserved. We also
demonstrate the need to control for time-dependent distribution shifts. We
compare with state-of-the-art baselines on simulated and real-world clinical
data and demonstrate that our approach is superior in identifying important
time points and observations throughout the time series.",http://arxiv.org/pdf/2003.02821v3,cs.LG
2020-03-04 22:27:52+00:00,Nonlinear Time Series Classification Using Bispectrum-based Deep Convolutional Neural Networks,"['Paul A. Parker', 'Scott H. Holan', 'Nalini Ravishanker']","Time series classification using novel techniques has experienced a recent
resurgence and growing interest from statisticians, subject-domain scientists,
and decision makers in business and industry. This is primarily due to the ever
increasing amount of big and complex data produced as a result of technological
advances. A motivating example is that of Google trends data, which exhibit
highly nonlinear behavior. Although a rich literature exists for addressing
this problem, existing approaches mostly rely on first and second order
properties of the time series, since they typically assume linearity of the
underlying process. Often, these are inadequate for effective classification of
nonlinear time series data such as Google Trends data. Given these
methodological deficiencies and the abundance of nonlinear time series that
persist among real-world phenomena, we introduce an approach that merges higher
order spectral analysis (HOSA) with deep convolutional neural networks (CNNs)
for classifying time series. The effectiveness of our approach is illustrated
using simulated data and two motivating industry examples that involve Google
trends data and electronic device energy consumption data.",http://arxiv.org/pdf/2003.02353v1,stat.ML
2020-03-04 15:56:44+00:00,Adaptive exponential power distribution with moving estimator for nonstationary time series,['Jarek Duda'],"While standard estimation assumes that all datapoints are from probability
distribution of the same fixed parameters $\theta$, we will focus on maximum
likelihood (ML) adaptive estimation for nonstationary time series: separately
estimating parameters $\theta_T$ for each time $T$ based on the earlier values
$(x_t)_{t<T}$ using (exponential) moving ML estimator $\theta_T=\arg\max_\theta
l_T$ for $l_T=\sum_{t<T} \eta^{T-t} \ln(\rho_\theta (x_t))$ and some
$\eta\in(0,1]$. Computational cost of such moving estimator is generally much
higher as we need to optimize log-likelihood multiple times, however, in many
cases it can be made inexpensive thanks to dependencies. We focus on such
example: $\rho(x)\propto \exp(-|(x-\mu)/\sigma|^\kappa/\kappa)$ exponential
power distribution (EPD) family, which covers wide range of tail behavior like
Gaussian ($\kappa=2$) or Laplace ($\kappa=1$) distribution. It is also
convenient for such adaptive estimation of scale parameter $\sigma$ as its
standard ML estimation is $\sigma^\kappa$ being average $\|x-\mu\|^\kappa$. By
just replacing average with exponential moving average:
$(\sigma_{T+1})^\kappa=\eta(\sigma_T)^\kappa +(1-\eta)|x_T-\mu|^\kappa$ we can
inexpensively make it adaptive. It is tested on daily log-return series for
DJIA companies, leading to essentially better log-likelihoods than standard
(static) estimation, with optimal $\kappa$ tails types varying between
companies. Presented general alternative estimation philosophy provides tools
which might be useful for building better models for analysis of nonstationary
time-series.",http://arxiv.org/pdf/2003.02149v2,stat.ML
2020-03-03 10:41:56+00:00,Learning to Generate Time Series Conditioned Graphs with Generative Adversarial Nets,"['Shanchao Yang', 'Jing Liu', 'Kai Wu', 'Mingming Li']","Deep learning based approaches have been utilized to model and generate
graphs subjected to different distributions recently. However, they are
typically unsupervised learning based and unconditioned generative models or
simply conditioned on the graph-level contexts, which are not associated with
rich semantic node-level contexts. Differently, in this paper, we are
interested in a novel problem named Time Series Conditioned Graph Generation:
given an input multivariate time series, we aim to infer a target relation
graph modeling the underlying interrelationships between time series with each
node corresponding to each time series. For example, we can study the
interrelationships between genes in a gene regulatory network of a certain
disease conditioned on their gene expression data recorded as time series. To
achieve this, we propose a novel Time Series conditioned Graph
Generation-Generative Adversarial Networks (TSGG-GAN) to handle challenges of
rich node-level context structures conditioning and measuring similarities
directly between graphs and time series. Extensive experiments on synthetic and
real-word gene regulatory networks datasets demonstrate the effectiveness and
generalizability of the proposed TSGG-GAN.",http://arxiv.org/pdf/2003.01436v2,cs.LG
2020-03-03 09:49:30+00:00,CRATOS: Cognition of Reliable Algorithm for Time-series Optimal Solution,"['Ziling Wu', 'Ping Liu', 'Zheng Hu', 'Bocheng Li', 'Jun Wang']","Anomaly detection of time series plays an important role in reliability
systems engineering. However, in practical application, there is no precisely
defined boundary between normal and anomalous behaviors in different
application scenarios. Therefore, different anomaly detection algorithms and
processes ought to be adopted for time series in different situation. Although
such strategy improve the accuracy of anomaly detection, it takes a lot of time
for practitioners to configure various algorithms to millions of series, which
greatly increases the development and maintenance cost of anomaly detection
processes. In this paper, we propose CRATOS which is a self-adapt algorithms
that extract features from time series, and then cluster series with similar
features into one group. For each group we utilize evolutionary algorithm to
search the best anomaly detection methods and processes. Our methods can
significantly reduce the cost of development and maintenance of anomaly
detection. According to experiments, our clustering methods achieves the
state-of-art results. The accuracy of the anomaly detection algorithms in this
paper is 85.1%.",http://arxiv.org/pdf/2003.01412v3,cs.LG
2020-03-01 21:01:59+00:00,Online Hierarchical Forecasting for Power Consumption Data,"['Margaux Brégère', 'Malo Huard']","We study the forecasting of the power consumptions of a population of
households and of subpopulations thereof. These subpopulations are built
according to location, to exogenous information and/or to profiles we
determined from historical households consumption time series. Thus, we aim to
forecast the electricity consumption time series at several levels of
households aggregation. These time series are linked through some summation
constraints which induce a hierarchy. Our approach consists in three steps:
feature generation, aggregation and projection. Firstly (feature generation
step), we build, for each considering group for households, a benchmark
forecast (called features), using random forests or generalized additive
models. Secondly (aggregation step), aggregation algorithms, run in parallel,
aggregate these forecasts and provide new predictions. Finally (projection
step), we use the summation constraints induced by the time series underlying
hierarchy to re-conciliate the forecasts by projecting them in a well-chosen
linear subspace. We provide some theoretical guaranties on the average
prediction error of this methodology, through the minimization of a quantity
called regret. We also test our approach on households power consumption data
collected in Great Britain by multiple energy providers in the Energy Demand
Research Project context. We build and compare various population segmentations
for the evaluation of our approach performance.",http://arxiv.org/pdf/2003.00585v1,stat.ML
2020-02-27 23:38:11+00:00,Time Series Data Augmentation for Deep Learning: A Survey,"['Qingsong Wen', 'Liang Sun', 'Fan Yang', 'Xiaomin Song', 'Jingkun Gao', 'Xue Wang', 'Huan Xu']","Deep learning performs remarkably well on many time series analysis tasks
recently. The superior performance of deep neural networks relies heavily on a
large number of training data to avoid overfitting. However, the labeled data
of many real-world time series applications may be limited such as
classification in medical time series and anomaly detection in AIOps. As an
effective way to enhance the size and quality of the training data, data
augmentation is crucial to the successful application of deep learning models
on time series data. In this paper, we systematically review different data
augmentation methods for time series. We propose a taxonomy for the reviewed
methods, and then provide a structured review for these methods by highlighting
their strengths and limitations. We also empirically compare different data
augmentation methods for different tasks including time series classification,
anomaly detection, and forecasting. Finally, we discuss and highlight five
future directions to provide useful research guidance.",http://arxiv.org/pdf/2002.12478v4,cs.LG
2020-02-27 11:08:08+00:00,Complexity Measures and Features for Times Series classification,"['Francisco J. Baldán', 'José M. Benítez']","Classification of time series is a growing problem in different disciplines
due to the progressive digitalization of the world. Currently, the
state-of-the-art in time series classification is dominated by The Hierarchical
Vote Collective of Transformation-based Ensembles. This algorithm is composed
of several classifiers of different domains distributed in five large modules.
The combination of the results obtained by each module weighed based on an
internal evaluation process allows this algorithm to obtain the best results in
state-of-the-art. One Nearest Neighbour with Dynamic Time Warping remains the
base classifier in any time series classification problem for its simplicity
and good results. Despite their performance, they share a weakness, which is
that they are not interpretable. In the field of time series classification,
there is a tradeoff between accuracy and interpretability. In this work, we
propose a set of characteristics capable of extracting information on the
structure of the time series to face time series classification problems. The
use of these characteristics allows the use of traditional classification
algorithms in time series problems. The experimental results of our proposal
show no statistically significant differences from the second and third best
models of the state-of-the-art. Apart from competitive results in accuracy, our
proposal is able to offer interpretable results based on the set of
characteristics proposed",http://arxiv.org/pdf/2002.12036v3,cs.LG
2020-02-27 09:54:44+00:00,A Kernel to Exploit Informative Missingness in Multivariate Time Series from EHRs,"['Karl Øyvind Mikalsen', 'Cristina Soguero-Ruiz', 'Robert Jenssen']","A large fraction of the electronic health records (EHRs) consists of clinical
measurements collected over time, such as lab tests and vital signs, which
provide important information about a patient's health status. These sequences
of clinical measurements are naturally represented as time series,
characterized by multiple variables and large amounts of missing data, which
complicate the analysis. In this work, we propose a novel kernel which is
capable of exploiting both the information from the observed values as well the
information hidden in the missing patterns in multivariate time series (MTS)
originating e.g. from EHRs. The kernel, called TCK$_{IM}$, is designed using an
ensemble learning strategy in which the base models are novel mixed mode
Bayesian mixture models which can effectively exploit informative missingness
without having to resort to imputation methods. Moreover, the ensemble approach
ensures robustness to hyperparameters and therefore TCK$_{IM}$ is particularly
well suited if there is a lack of labels - a known challenge in medical
applications. Experiments on three real-world clinical datasets demonstrate the
effectiveness of the proposed kernel.",http://arxiv.org/pdf/2002.12359v1,stat.ML
2020-02-25 11:29:56+00:00,Block Hankel Tensor ARIMA for Multiple Short Time Series Forecasting,"['Qiquan Shi', 'Jiaming Yin', 'Jiajun Cai', 'Andrzej Cichocki', 'Tatsuya Yokota', 'Lei Chen', 'Mingxuan Yuan', 'Jia Zeng']","This work proposes a novel approach for multiple time series forecasting. At
first, multi-way delay embedding transform (MDT) is employed to represent time
series as low-rank block Hankel tensors (BHT). Then, the higher-order tensors
are projected to compressed core tensors by applying Tucker decomposition. At
the same time, the generalized tensor Autoregressive Integrated Moving Average
(ARIMA) is explicitly used on consecutive core tensors to predict future
samples. In this manner, the proposed approach tactically incorporates the
unique advantages of MDT tensorization (to exploit mutual correlations) and
tensor ARIMA coupled with low-rank Tucker decomposition into a unified
framework. This framework exploits the low-rank structure of block Hankel
tensors in the embedded space and captures the intrinsic correlations among
multiple TS, which thus can improve the forecasting results, especially for
multiple short time series. Experiments conducted on three public datasets and
two industrial datasets verify that the proposed BHT-ARIMA effectively improves
forecasting accuracy and reduces computational cost compared with the
state-of-the-art methods.",http://arxiv.org/pdf/2002.12135v1,cs.LG
2020-02-25 03:26:52+00:00,Multivariate time-series modeling with generative neural networks,"['Marius Hofert', 'Avinash Prasad', 'Mu Zhu']","Generative moment matching networks (GMMNs) are introduced as dependence
models for the joint innovation distribution of multivariate time series (MTS).
Following the popular copula-GARCH approach for modeling dependent MTS data, a
framework based on a GMMN-GARCH approach is presented. First, ARMA-GARCH models
are utilized to capture the serial dependence within each univariate marginal
time series. Second, if the number of marginal time series is large, principal
component analysis (PCA) is used as a dimension-reduction step. Last, the
remaining cross-sectional dependence is modeled via a GMMN, the main
contribution of this work. GMMNs are highly flexible and easy to simulate from,
which is a major advantage over the copula-GARCH approach. Applications
involving yield curve modeling and the analysis of foreign exchange-rate
returns demonstrate the utility of the GMMN-GARCH approach, especially in terms
of producing better empirical predictive distributions and making better
probabilistic forecasts.",http://arxiv.org/pdf/2002.10645v4,stat.ME
2020-02-24 20:13:43+00:00,Modeling Continuous Stochastic Processes with Dynamic Normalizing Flows,"['Ruizhi Deng', 'Bo Chang', 'Marcus A. Brubaker', 'Greg Mori', 'Andreas Lehrmann']","Normalizing flows transform a simple base distribution into a complex target
distribution and have proved to be powerful models for data generation and
density estimation. In this work, we propose a novel type of normalizing flow
driven by a differential deformation of the Wiener process. As a result, we
obtain a rich time series model whose observable process inherits many of the
appealing properties of its base process, such as efficient computation of
likelihoods and marginals. Furthermore, our continuous treatment provides a
natural framework for irregular time series with an independent arrival
process, including straightforward interpolation. We illustrate the desirable
properties of the proposed model on popular stochastic processes and
demonstrate its superior flexibility to variational RNN and latent ODE
baselines in a series of experiments on synthetic and real-world data.",http://arxiv.org/pdf/2002.10516v4,cs.LG
2020-02-24 03:33:58+00:00,Omni-Scale CNNs: a simple and effective kernel size configuration for time series classification,"['Wensi Tang', 'Guodong Long', 'Lu Liu', 'Tianyi Zhou', 'Michael Blumenstein', 'Jing Jiang']","The Receptive Field (RF) size has been one of the most important factors for
One Dimensional Convolutional Neural Networks (1D-CNNs) on time series
classification tasks. Large efforts have been taken to choose the appropriate
size because it has a huge influence on the performance and differs
significantly for each dataset. In this paper, we propose an Omni-Scale block
(OS-block) for 1D-CNNs, where the kernel sizes are decided by a simple and
universal rule. Particularly, it is a set of kernel sizes that can efficiently
cover the best RF size across different datasets via consisting of multiple
prime numbers according to the length of the time series. The experiment result
shows that models with the OS-block can achieve a similar performance as models
with the searched optimal RF size and due to the strong optimal RF size capture
ability, simple 1D-CNN models with OS-block achieves the state-of-the-art
performance on four time series benchmarks, including both univariate and
multivariate data from multiple domains. Comprehensive analysis and discussions
shed light on why the OS-block can capture optimal RF sizes across different
datasets. Code available [https://github.com/Wensi-Tang/OS-CNN]",http://arxiv.org/pdf/2002.10061v3,cs.LG
2020-02-22 20:01:59+00:00,Longitudinal Support Vector Machines for High Dimensional Time Series,"['Kristiaan Pelckmans', 'Hong-Li Zeng']","We consider the problem of learning a classifier from observed functional
data. Here, each data-point takes the form of a single time-series and contains
numerous features. Assuming that each such series comes with a binary label,
the problem of learning to predict the label of a new coming time-series is
considered. Hereto, the notion of {\em margin} underlying the classical support
vector machine is extended to the continuous version for such data. The
longitudinal support vector machine is also a convex optimization problem and
its dual form is derived as well. Empirical results for specified cases with
significance tests indicate the efficacy of this innovative algorithm for
analyzing such long-term multivariate data.",http://arxiv.org/pdf/2002.09763v1,cs.LG
2020-02-22 12:57:50+00:00,A New Unified Deep Learning Approach with Decomposition-Reconstruction-Ensemble Framework for Time Series Forecasting,"['Guowei Zhang', 'Tao Ren', 'Yifan Yang']","A new variational mode decomposition (VMD) based deep learning approach is
proposed in this paper for time series forecasting problem. Firstly, VMD is
adopted to decompose the original time series into several sub-signals. Then, a
convolutional neural network (CNN) is applied to learn the reconstruction
patterns on the decomposed sub-signals to obtain several reconstructed
sub-signals. Finally, a long short term memory (LSTM) network is employed to
forecast the time series with the decomposed sub-signals and the reconstructed
sub-signals as inputs. The proposed VMD-CNN-LSTM approach is originated from
the decomposition-reconstruction-ensemble framework, and innovated by embedding
the reconstruction, single forecasting, and ensemble steps in a unified deep
learning approach. To verify the forecasting performance of the proposed
approach, four typical time series datasets are introduced for empirical
analysis. The empirical results demonstrate that the proposed approach
outperforms consistently the benchmark approaches in terms of forecasting
accuracy, and also indicate that the reconstructed sub-signals obtained by CNN
is of importance for further improving the forecasting performance.",http://arxiv.org/pdf/2002.09695v1,stat.ML
2020-02-21 23:02:00+00:00,Causal structure learning from time series: Large regression coefficients may predict causal links better in practice than small p-values,"['Sebastian Weichwald', 'Martin E Jakobsen', 'Phillip B Mogensen', 'Lasse Petersen', 'Nikolaj Thams', 'Gherardo Varando']","In this article, we describe the algorithms for causal structure learning
from time series data that won the Causality 4 Climate competition at the
Conference on Neural Information Processing Systems 2019 (NeurIPS). We examine
how our combination of established ideas achieves competitive performance on
semi-realistic and realistic time series data exhibiting common challenges in
real-world Earth sciences data. In particular, we discuss a) a rationale for
leveraging linear methods to identify causal links in non-linear systems, b) a
simulation-backed explanation as to why large regression coefficients may
predict causal links better in practice than small p-values and thus why
normalising the data may sometimes hinder causal structure learning.
  For benchmark usage, we detail the algorithms here and provide
implementations at https://github.com/sweichwald/tidybench . We propose the
presented competition-proven methods for baseline benchmark comparisons to
guide the development of novel algorithms for structure learning from time
series.",http://arxiv.org/pdf/2002.09573v2,stat.ML
2020-02-21 20:43:45+00:00,RobustTAD: Robust Time Series Anomaly Detection via Decomposition and Convolutional Neural Networks,"['Jingkun Gao', 'Xiaomin Song', 'Qingsong Wen', 'Pichao Wang', 'Liang Sun', 'Huan Xu']","The monitoring and management of numerous and diverse time series data at
Alibaba Group calls for an effective and scalable time series anomaly detection
service. In this paper, we propose RobustTAD, a Robust Time series Anomaly
Detection framework by integrating robust seasonal-trend decomposition and
convolutional neural network for time series data. The seasonal-trend
decomposition can effectively handle complicated patterns in time series, and
meanwhile significantly simplifies the architecture of the neural network,
which is an encoder-decoder architecture with skip connections. This
architecture can effectively capture the multi-scale information from time
series, which is very useful in anomaly detection. Due to the limited labeled
data in time series anomaly detection, we systematically investigate data
augmentation methods in both time and frequency domains. We also introduce
label-based weight and value-based weight in the loss function by utilizing the
unbalanced nature of the time series anomaly detection problem. Compared with
the widely used forecasting-based anomaly detection algorithms,
decomposition-based algorithms, traditional statistical algorithms, as well as
recent neural network based algorithms, RobustTAD performs significantly better
on public benchmark datasets. It is deployed as a public online service and
widely adopted in different business scenarios at Alibaba Group.",http://arxiv.org/pdf/2002.09545v2,cs.LG
2020-02-21 20:10:36+00:00,RobustPeriod: Time-Frequency Mining for Robust Multiple Periodicity Detection,"['Qingsong Wen', 'Kai He', 'Liang Sun', 'Yingying Zhang', 'Min Ke', 'Huan Xu']","Periodicity detection is a crucial step in time series tasks, including
monitoring and forecasting of metrics in many areas, such as IoT applications
and self-driving database management system. In many of these applications,
multiple periodic components exist and are often interlaced with each other.
Such dynamic and complicated periodic patterns make the accurate periodicity
detection difficult. In addition, other components in the time series, such as
trend, outliers and noises, also pose additional challenges for accurate
periodicity detection. In this paper, we propose a robust and general framework
for multiple periodicity detection. Our algorithm applies maximal overlap
discrete wavelet transform to transform the time series into multiple
temporal-frequency scales such that different periodic components can be
isolated. We rank them by wavelet variance, and then at each scale detect
single periodicity by our proposed Huber-periodogram and Huber-ACF robustly. We
rigorously prove the theoretical properties of Huber-periodogram and justify
the use of Fisher's test on Huber-periodogram for periodicity detection. To
further refine the detected periods, we compute unbiased autocorrelation
function based on Wiener-Khinchin theorem from Huber-periodogram for improved
robustness and efficiency. Experiments on synthetic and real-world datasets
show that our algorithm outperforms other popular ones for both single and
multiple periodicity detection.",http://arxiv.org/pdf/2002.09535v2,cs.LG
2020-02-20 20:20:06+00:00,SummerTime: Variable-length Time SeriesSummarization with Applications to PhysicalActivity Analysis,"['Kevin M. Amaral', 'Zihan Li', 'Wei Ding', 'Scott Crouter', 'Ping Chen']","\textit{SummerTime} seeks to summarize globally time series signals and
provides a fixed-length, robust summarization of the variable-length time
series. Many classical machine learning methods for classification and
regression depend on data instances with a fixed number of features. As a
result, those methods cannot be directly applied to variable-length time series
data. One common approach is to perform classification over a sliding window on
the data and aggregate the decisions made at local sections of the time series
in some way, through majority voting for classification or averaging for
regression. The downside to this approach is that minority local information is
lost in the voting process and averaging assumes that each time series
measurement is equal in significance. Also, since time series can be of varying
length, the quality of votes and averages could vary greatly in cases where
there is a close voting tie or bimodal distribution of regression domain.
Summarization conducted by the \textit{SummerTime} method will be a
fixed-length feature vector which can be used in-place of the time series
dataset for use with classical machine learning methods. We use Gaussian
Mixture models (GMM) over small same-length disjoint windows in the time series
to group local data into clusters. The time series' rate of membership for each
cluster will be a feature in the summarization. The model is naturally capable
of converging to an appropriate cluster count. We compare our results to
state-of-the-art studies in physical activity classification and show
high-quality improvement by classifying with only the summarization. Finally,
we show that regression using the summarization can augment energy expenditure
estimation, producing more robust and precise results.",http://arxiv.org/pdf/2002.09000v1,cs.LG
2020-02-20 15:12:10+00:00,Consistent model selection procedure for general integer-valued time series,"['Mamadou Lamine Diop', 'William Kengne']","This paper deals with the problem of model selection for a general class of
integer-valued time series.
  We propose a penalized criterion based on the Poisson quasi-likelihood of the
model.
  Under certain regularity conditions, the consistency of the procedure as well
as the consistency and the asymptotic normality of the Poisson quasi-likelihood
estimator of the selected model are established.
  Simulation experiments are conducted for some classical models such as
Poisson, binary INGARCH and negative binomial model with nonlinear dynamic.
Also, an application to a real dataset is provided.",http://arxiv.org/pdf/2002.08789v1,math.ST
2020-02-18 15:24:33+00:00,Conditional Mutual information-based Contrastive Loss for Financial Time Series Forecasting,"['Hanwei Wu', 'Ather Gattami', 'Markus Flierl']","We present a representation learning framework for financial time series
forecasting. One challenge of using deep learning models for finance
forecasting is the shortage of available training data when using small
datasets. Direct trend classification using deep neural networks trained on
small datasets is susceptible to the overfitting problem. In this paper, we
propose to first learn compact representations from time series data, then use
the learned representations to train a simpler model for predicting time series
movements. We consider a class-conditioned latent variable model. We train an
encoder network to maximize the mutual information between the latent variables
and the trend information conditioned on the encoded observed variables. We
show that conditional mutual information maximization can be approximated by a
contrastive loss. Then, the problem is transformed into a classification task
of determining whether two encoded representations are sampled from the same
class or not. This is equivalent to performing pairwise comparisons of the
training datapoints, and thus, improves the generalization ability of the
encoder network. We use deep autoregressive models as our encoder to capture
long-term dependencies of the sequence data. Empirical experiments indicate
that our proposed method has the potential to advance state-of-the-art
performance.",http://arxiv.org/pdf/2002.07638v3,cs.LG
2020-02-14 16:16:51+00:00,Multivariate Probabilistic Time Series Forecasting via Conditioned Normalizing Flows,"['Kashif Rasul', 'Abdul-Saboor Sheikh', 'Ingmar Schuster', 'Urs Bergmann', 'Roland Vollgraf']","Time series forecasting is often fundamental to scientific and engineering
problems and enables decision making. With ever increasing data set sizes, a
trivial solution to scale up predictions is to assume independence between
interacting time series. However, modeling statistical dependencies can improve
accuracy and enable analysis of interaction effects. Deep learning methods are
well suited for this problem, but multivariate models often assume a simple
parametric distribution and do not scale to high dimensions. In this work we
model the multivariate temporal dynamics of time series via an autoregressive
deep learning model, where the data distribution is represented by a
conditioned normalizing flow. This combination retains the power of
autoregressive models, such as good performance in extrapolation into the
future, with the flexibility of flows as a general purpose high-dimensional
distribution model, while remaining computationally tractable. We show that it
improves over the state-of-the-art for standard metrics on many real-world data
sets with several thousand interacting time-series.",http://arxiv.org/pdf/2002.06103v3,cs.LG
2020-02-13 17:56:42+00:00,Generalized Autoregressive Neural Network Models,['Renato Rodrigues Silva'],"A time series is a sequence of observations taken sequentially in time. The
autoregressive integrated moving average is a class of the model more used for
times series data. However, this class of model has two critical limitations.
It fits well onlyGaussian data with the linear structure of correlation. Here,
I present a new model named as generalized autoregressive neural networks,
GARNN. The GARNN is an extension of the generalized linear model where the mean
marginal depends on the lagged values via the inclusion of the neural network
in the link function. A practical application of the model is shown using a
well-known poliomyelitis case number, originated analyzed by Zeger and Qaqish
(1988),",http://arxiv.org/pdf/2002.05676v1,stat.ME
2020-02-11 21:38:51+00:00,Selecting time-series hyperparameters with the artificial jackknife,['Filippo Pellegrino'],"This article proposes a generalisation of the delete-$d$ jackknife to solve
hyperparameter selection problems for time series. I call it artificial
delete-$d$ jackknife to stress that this approach substitutes the classic
removal step with a fictitious deletion, wherein observed datapoints are
replaced with artificial missing values. This procedure keeps the data order
intact and allows plain compatibility with time series. This manuscript
justifies the use of this approach asymptotically and shows its finite-sample
advantages through simulation studies. Besides, this article describes its
real-world advantages by regulating high-dimensional forecasting models for
foreign exchange rates.",http://arxiv.org/pdf/2002.04697v5,stat.ME
2020-02-11 07:25:45+00:00,A review on outlier/anomaly detection in time series data,"['Ane Blázquez-García', 'Angel Conde', 'Usue Mori', 'Jose A. Lozano']","Recent advances in technology have brought major breakthroughs in data
collection, enabling a large amount of data to be gathered over time and thus
generating time series. Mining this data has become an important task for
researchers and practitioners in the past few years, including the detection of
outliers or anomalies that may represent errors or events of interest. This
review aims to provide a structured and comprehensive state-of-the-art on
outlier detection techniques in the context of time series. To this end, a
taxonomy is presented based on the main aspects that characterize an outlier
detection technique.",http://arxiv.org/pdf/2002.04236v1,cs.LG
2020-02-11 01:03:33+00:00,ForecastNet: A Time-Variant Deep Feed-Forward Neural Network Architecture for Multi-Step-Ahead Time-Series Forecasting,"['Joel Janek Dabrowski', 'YiFan Zhang', 'Ashfaqur Rahman']","Recurrent and convolutional neural networks are the most common architectures
used for time series forecasting in deep learning literature. These networks
use parameter sharing by repeating a set of fixed architectures with fixed
parameters over time or space. The result is that the overall architecture is
time-invariant (shift-invariant in the spatial domain) or stationary. We argue
that time-invariance can reduce the capacity to perform multi-step-ahead
forecasting, where modelling the dynamics at a range of scales and resolutions
is required. We propose ForecastNet which uses a deep feed-forward architecture
to provide a time-variant model. An additional novelty of ForecastNet is
interleaved outputs, which we show assist in mitigating vanishing gradients.
ForecastNet is demonstrated to outperform statistical and deep learning
benchmark models on several datasets.",http://arxiv.org/pdf/2002.04155v2,cs.LG
2020-02-10 15:11:50+00:00,Time Series Alignment with Global Invariances,"['Titouan Vayer', 'Romain Tavenard', 'Laetitia Chapel', 'Nicolas Courty', 'Rémi Flamary', 'Yann Soullard']","Multivariate time series are ubiquitous objects in signal processing.
Measuring a distance or similarity between two such objects is of prime
interest in a variety of applications, including machine learning, but can be
very difficult as soon as the temporal dynamics and the representation of the
time series, {\em i.e.} the nature of the observed quantities, differ from one
another. In this work, we propose a novel distance accounting both feature
space and temporal variabilities by learning a latent global transformation of
the feature space together with a temporal alignment, cast as a joint
optimization problem. The versatility of our framework allows for several
variants depending on the invariance class at stake. Among other contributions,
we define a differentiable loss for time series and present two algorithms for
the computation of time series barycenters under this new geometry. We
illustrate the interest of our approach on both simulated and real world data
and show the robustness of our approach compared to state-of-the-art methods.",http://arxiv.org/pdf/2002.03848v2,stat.ML
2020-02-10 10:04:29+00:00,Autoencoder-based time series clustering with energy applications,"['Guillaume Richard', 'Benoît Grossin', 'Guillaume Germaine', 'Georges Hébrail', 'Anne de Moliner']","Time series clustering is a challenging task due to the specific nature of
the data. Classical approaches do not perform well and need to be adapted
either through a new distance measure or a data transformation. In this paper
we investigate the combination of a convolutional autoencoder and a k-medoids
algorithm to perfom time series clustering. The convolutional autoencoder
allows to extract meaningful features and reduce the dimension of the data,
leading to an improvement of the subsequent clustering. Using simulation and
energy related data to validate the approach, experimental results show that
the clustering is robust to outliers thus leading to finer clusters than with
standard methods.",http://arxiv.org/pdf/2002.03624v1,stat.ML
2020-02-09 15:32:23+00:00,Segmenting High-dimensional Matrix-valued Time Series via Sequential Transformations,['Zhaoxing Gao'],"Modeling matrix-valued time series is an interesting and important research
topic. In this paper, we extend the method of Chang et al. (2017) to
matrix-valued time series. For any given $p\times q$ matrix-valued time series,
we look for linear transformations to segment the matrix into many small
sub-matrices for which each of them are uncorrelated with the others both
contemporaneously and serially, thus they can be analyzed separately, which
will greatly reduce the number of parameters to be estimated in terms of
modeling. To overcome the identification issue, we propose a two-step and more
structured procedure to segment the rows and columns separately. When
$\max(p,q)$ is large in relation to the sample size $n$, we assume the
transformation matrices are sparse and use threshold estimators for the
(auto)covariance matrices. We also propose a block-wisely thresholding method
to separate the columns (or rows) of the transformed matrix-valued data. The
asymptotic properties are established for both fixed and diverging $\max(p,q)$.
Unlike principal component analysis (PCA) for independent data, we cannot
guarantee that the required linear transformation exists. When it does not, the
proposed method provides an approximate segmentation, which may be useful for
forecasting. The proposed method is illustrated with both simulated and real
data examples. We also propose a sequential transformation algorithm to segment
higher-order tensor-valued time series.",http://arxiv.org/pdf/2002.03382v1,stat.ME
2020-02-07 02:32:33+00:00,Equivalence relations and $L^p$ distances between time series with application to the Black Summer Australian bushfires,"['Nick James', 'Max Menzies']","This paper introduces a new framework of algebraic equivalence relations
between time series and new distance metrics between them, then applies these
to investigate the Australian ``Black Summer'' bushfire season of 2019-2020.
First, we introduce a general framework for defining equivalence between time
series, heuristically intended to be equivalent if they differ only up to
noise. Our first specific implementation is based on using change point
algorithms and comparing statistical quantities such as mean or variance in
stationary segments. We thus derive the existence of such equivalence relations
on the space of time series, such that the quotient spaces can be equipped with
a metrizable topology. Next, we illustrate specifically how to define and
compute such distances among a collection of time series and perform clustering
and additional analysis thereon. Then, we apply these insights to analyze air
quality data across New South Wales, Australia, during the 2019-2020 bushfires.
There, we investigate structural similarity with respect to this data and
identify locations that were impacted anonymously by the fires relative to
their location. This may have implications regarding the appropriate management
of resources to avoid gaps in the defense against future fires.",http://arxiv.org/pdf/2002.02592v3,stat.ME
2020-02-01 14:03:01+00:00,Variable-lag Granger Causality and Transfer Entropy for Time Series Analysis,"['Chainarong Amornbunchornvej', 'Elena Zheleva', 'Tanya Berger-Wolf']","Granger causality is a fundamental technique for causal inference in time
series data, commonly used in the social and biological sciences. Typical
operationalizations of Granger causality make a strong assumption that every
time point of the effect time series is influenced by a combination of other
time series with a fixed time delay. The assumption of fixed time delay also
exists in Transfer Entropy, which is considered to be a non-linear version of
Granger causality. However, the assumption of the fixed time delay does not
hold in many applications, such as collective behavior, financial markets, and
many natural phenomena. To address this issue, we develop Variable-lag Granger
causality and Variable-lag Transfer Entropy, generalizations of both Granger
causality and Transfer Entropy that relax the assumption of the fixed time
delay and allow causes to influence effects with arbitrary time delays. In
addition, we propose methods for inferring both variable-lag Granger causality
and Transfer Entropy relations. In our approaches, we utilize an optimal
warping path of Dynamic Time Warping (DTW) to infer variable-lag causal
relations. We demonstrate our approaches on an application for studying
coordinated collective behavior and other real-world casual-inference datasets
and show that our proposed approaches perform better than several existing
methods in both simulated and real-world datasets. Our approaches can be
applied in any domain of time series analysis. The software of this work is
available in the R-CRAN package: VLTimeCausality.",http://arxiv.org/pdf/2002.00208v3,cs.LG
2020-01-31 16:13:02+00:00,Two-Sample Testing for Event Impacts in Time Series,"['Erik Scharwächter', 'Emmanuel Müller']","In many application domains, time series are monitored to detect extreme
events like technical faults, natural disasters, or disease outbreaks.
Unfortunately, it is often non-trivial to select both a time series that is
informative about events and a powerful detection algorithm: detection may fail
because the detection algorithm is not suitable, or because there is no shared
information between the time series and the events of interest. In this work,
we thus propose a non-parametric statistical test for shared information
between a time series and a series of observed events. Our test allows
identifying time series that carry information on event occurrences without
committing to a specific event detection methodology. In a nutshell, we test
for divergences of the value distributions of the time series at increasing
lags after event occurrences with a multiple two-sample testing approach. In
contrast to related tests, our approach is applicable for time series over
arbitrary domains, including multivariate numeric, strings or graphs. We
perform a large-scale simulation study to show that it outperforms or is on par
with related tests on our task for univariate time series. We also demonstrate
the real-world applicability of our approach on datasets from social media and
smart home environments.",http://arxiv.org/pdf/2001.11930v1,stat.ME
2020-01-27 21:35:15+00:00,Multi-label Prediction in Time Series Data using Deep Neural Networks,"['Wenyu Zhang', 'Devesh K. Jha', 'Emil Laftchiev', 'Daniel Nikovski']","This paper addresses a multi-label predictive fault classification problem
for multidimensional time-series data. While fault (event) detection problems
have been thoroughly studied in literature, most of the state-of-the-art
techniques can't reliably predict faults (events) over a desired future
horizon. In the most general setting of these types of problems, one or more
samples of data across multiple time series can be assigned several concurrent
fault labels from a finite, known set and the task is to predict the
possibility of fault occurrence over a desired time horizon. This type of
problem is usually accompanied by strong class imbalances where some classes
are represented by only a few samples. Importantly, in many applications of the
problem such as fault prediction and predictive maintenance, it is exactly
these rare classes that are of most interest. To address the problem, this
paper proposes a general approach that utilizes a multi-label recurrent neural
network with a new cost function that accentuates learning in the imbalanced
classes. The proposed algorithm is tested on two public benchmark datasets: an
industrial plant dataset from the PHM Society Data Challenge, and a human
activity recognition dataset. The results are compared with state-of-the-art
techniques for time-series classification and evaluation is performed using the
F1-score, precision and recall.",http://arxiv.org/pdf/2001.10098v1,cs.LG
2020-01-27 16:19:20+00:00,Bayesian nonparametric shared multi-sequence time series segmentation,"['Olga Mikheeva', 'Ieva Kazlauskaite', 'Hedvig Kjellström', 'Carl Henrik Ek']","In this paper, we introduce a method for segmenting time series data using
tools from Bayesian nonparametrics. We consider the task of temporal
segmentation of a set of time series data into representative stationary
segments. We use Gaussian process (GP) priors to impose our knowledge about the
characteristics of the underlying stationary segments, and use a nonparametric
distribution to partition the sequences into such segments, formulated in terms
of a prior distribution on segment length. Given the segmentation, the model
can be viewed as a variant of a Gaussian mixture model where the mixture
components are described using the covariance function of a GP. We demonstrate
the effectiveness of our model on synthetic data as well as on real time-series
data of heartbeats where the task is to segment the indicative types of beats
and to classify the heartbeat recordings into classes that correspond to
healthy and abnormal heart sounds.",http://arxiv.org/pdf/2001.09886v1,cs.LG
2020-01-27 00:31:37+00:00,A clustering approach to time series forecasting using neural networks: A comparative study on distance-based vs. feature-based clustering methods,"['Manie Tadayon', 'Yumi Iwashita']","Time series forecasting has gained lots of attention recently; this is
because many real-world phenomena can be modeled as time series. The massive
volume of data and recent advancements in the processing power of the computers
enable researchers to develop more sophisticated machine learning algorithms
such as neural networks to forecast the time series data. In this paper, we
propose various neural network architectures to forecast the time series data
using the dynamic measurements; moreover, we introduce various architectures on
how to combine static and dynamic measurements for forecasting. We also
investigate the importance of performing techniques such as anomaly detection
and clustering on forecasting accuracy. Our results indicate that clustering
can improve the overall prediction time as well as improve the forecasting
performance of the neural network. Furthermore, we show that feature-based
clustering can outperform the distance-based clustering in terms of speed and
efficiency. Finally, our results indicate that adding more predictors to
forecast the target variable will not necessarily improve the forecasting
accuracy.",http://arxiv.org/pdf/2001.09547v2,cs.LG
2020-01-24 09:13:33+00:00,RePAD: Real-time Proactive Anomaly Detection for Time Series,"['Ming-Chang Lee', 'Jia-Chun Lin', 'Ernst Gunnar Gran']","During the past decade, many anomaly detection approaches have been
introduced in different fields such as network monitoring, fraud detection, and
intrusion detection. However, they require understanding of data pattern and
often need a long off-line period to build a model or network for the target
data. Providing real-time and proactive anomaly detection for streaming time
series without human intervention and domain knowledge is highly valuable since
it greatly reduces human effort and enables appropriate countermeasures to be
undertaken before a disastrous damage, failure, or other harmful event occurs.
However, this issue has not been well studied yet. To address it, this paper
proposes RePAD, which is a Real-time Proactive Anomaly Detection algorithm for
streaming time series based on Long Short-Term Memory (LSTM). RePAD utilizes
short-term historic data points to predict and determine whether or not the
upcoming data point is a sign that an anomaly is likely to happen in the near
future. By dynamically adjusting the detection threshold over time, RePAD is
able to tolerate minor pattern change in time series and detect anomalies
either proactively or on time. Experiments based on two time series datasets
collected from the Numenta Anomaly Benchmark demonstrate that RePAD is able to
proactively detect anomalies and provide early warnings in real time without
human intervention and domain knowledge.",http://arxiv.org/pdf/2001.08922v8,cs.LG
2020-01-23 00:22:22+00:00,Deep Transformer Models for Time Series Forecasting: The Influenza Prevalence Case,"['Neo Wu', 'Bradley Green', 'Xue Ben', ""Shawn O'Banion""]","In this paper, we present a new approach to time series forecasting. Time
series data are prevalent in many scientific and engineering disciplines. Time
series forecasting is a crucial task in modeling time series data, and is an
important area of machine learning. In this work we developed a novel method
that employs Transformer-based machine learning models to forecast time series
data. This approach works by leveraging self-attention mechanisms to learn
complex patterns and dynamics from time series data. Moreover, it is a generic
framework and can be applied to univariate and multivariate time series data,
as well as time series embeddings. Using influenza-like illness (ILI)
forecasting as a case study, we show that the forecasting results produced by
our approach are favorably comparable to the state-of-the-art.",http://arxiv.org/pdf/2001.08317v1,cs.LG
2020-01-21 14:48:43+00:00,Motif Difference Field: A Simple and Effective Image Representation of Time Series for Classification,"['Yadong Zhang', 'Xin Chen']","Time series motifs play an important role in the time series analysis. The
motif-based time series clustering is used for the discovery of higher-order
patterns or structures in time series data. Inspired by the convolutional
neural network (CNN) classifier based on the image representations of time
series, motif difference field (MDF) is proposed. Compared to other image
representations of time series, MDF is simple and easy to construct. With the
Fully Convolution Network (FCN) as the classifier, MDF demonstrates the
superior performance on the UCR time series dataset in benchmark with other
time series classification methods. It is interesting to find that the triadic
time series motifs give the best result in the test. Due to the motif
clustering reflected in MDF, the significant motifs are detected with the help
of the Gradient-weighted Class Activation Mapping (Grad-CAM). The areas in MDF
with high weight in Grad-CAM have a high contribution from the significant
motifs with the desired ordinal patterns associated with the signature patterns
in time series. However, the signature patterns cannot be identified with the
neural network classifiers directly based on the time series.",http://arxiv.org/pdf/2001.07582v1,cs.LG
2020-01-20 04:22:59+00:00,Reconciling the Gaussian and Whittle Likelihood with an application to estimation in the frequency domain,"['Suhasini Subba Rao', 'Junho Yang']","In time series analysis there is an apparent dichotomy between time and
frequency domain methods. The aim of this paper is to draw connections between
frequency and time domain methods. Our focus will be on reconciling the
Gaussian likelihood and the Whittle likelihood. We derive an exact,
interpretable, bound between the Gaussian and Whittle likelihood of a second
order stationary time series. The derivation is based on obtaining the
transformation which is biorthogonal to the discrete Fourier transform of the
time series. Such a transformation yields a new decomposition for the inverse
of a Toeplitz matrix and enables the representation of the Gaussian likelihood
within the frequency domain. We show that the difference between the Gaussian
and Whittle likelihood is due to the omission of the best linear predictions
outside the domain of observation in the periodogram associated with the
Whittle likelihood. Based on this result, we obtain an approximation for the
difference between the Gaussian and Whittle likelihoods in terms of the best
fitting, finite order autoregressive parameters. These approximations are used
to define two new frequency domain quasi-likelihoods criteria. We show that
these new criteria can yield a better approximation of the spectral divergence
criterion, as compared to both the Gaussian and Whittle likelihoods. In
simulations, we show that the proposed estimators have satisfactory finite
sample properties.",http://arxiv.org/pdf/2001.06966v3,math.ST
2020-01-18 05:43:03+00:00,Insight into bias in time-stratified case-crossover studies,"['Xiaoming Wang', 'Sukun Wang']","The use of case-crossover designs has become widespread in epidemiological
and medical investigations of transient associations. However, the most popular
reference-select strategy, the time-stratified schema, is not a suitable
solution for controlling bias in case-crossover studies. To prove this, we
conducted a time series decomposition for daily ozone (O3) records; scrutinized
the ability of the time-stratified schema on controlling the yearly, monthly
and weekly time trends; and found it failed on controlling the weekly time
trend. Based on this finding, we proposed a new logistic regression approach in
which we did adjustment for the weekly time trend. A comparison between the
traditional model and the proposed method was done by simulation. An empirical
study was conducted to explore potential associations between air pollutants
and AMI hospitalizations. In summary, time-stratified schema provide effective
control on yearly and monthly time trends but not on weekly time trend.
Therefore, the estimation from the traditional logistical regression basically
reveals the effect of weekly time trend, instead of the transient effect. In
contrast, the proposed logistic regression with adjustment for weekly time
trend can effectively eliminate system bias in case-crossover studies.",http://arxiv.org/pdf/2001.06606v1,stat.ME
2020-01-18 02:05:54+00:00,Inference for Network Structure and Dynamics from Time Series Data via Graph Neural Network,"['Mengyuan Chen', 'Jiang Zhang', 'Zhang Zhang', 'Lun Du', 'Qiao Hu', 'Shuo Wang', 'Jiaqi Zhu']","Network structures in various backgrounds play important roles in social,
technological, and biological systems. However, the observable network
structures in real cases are often incomplete or unavailable due to measurement
errors or private protection issues. Therefore, inferring the complete network
structure is useful for understanding complex systems. The existing studies
have not fully solved the problem of inferring network structure with partial
or no information about connections or nodes. In this paper, we tackle the
problem by utilizing time series data generated by network dynamics. We regard
the network inference problem based on dynamical time series data as a problem
of minimizing errors for predicting future states and proposed a novel
data-driven deep learning model called Gumbel Graph Network (GGN) to solve the
two kinds of network inference problems: Network Reconstruction and Network
Completion. For the network reconstruction problem, the GGN framework includes
two modules: the dynamics learner and the network generator. For the network
completion problem, GGN adds a new module called the States Learner to infer
missing parts of the network. We carried out experiments on discrete and
continuous time series data. The experiments show that our method can
reconstruct up to 100% network structure on the network reconstruction task.
While the model can also infer the unknown parts of the structure with up to
90% accuracy when some nodes are missing. And the accuracy decays with the
increase of the fractions of missing nodes. Our framework may have wide
application areas where the network structure is hard to obtained and the time
series data is rich.",http://arxiv.org/pdf/2001.06576v1,cs.LG
2020-01-17 15:45:38+00:00,Generalization of Change-Point Detection in Time Series Data Based on Direct Density Ratio Estimation,"['Mikhail Hushchyn', 'Andrey Ustyuzhanin']","The goal of the change-point detection is to discover changes of time series
distribution. One of the state of the art approaches of the change-point
detection are based on direct density ratio estimation. In this work we show
how existing algorithms can be generalized using various binary classification
and regression models. In particular, we show that the Gradient Boosting over
Decision Trees and Neural Networks can be used for this purpose. The algorithms
are tested on several synthetic and real-world datasets. The results show that
the proposed methods outperform classical RuLSIF algorithm. Discussion of cases
where the proposed algorithms have advantages over existing methods are also
provided.",http://arxiv.org/pdf/2001.06386v1,cs.LG
2020-01-16 18:48:40+00:00,Inferring Individual Level Causal Models from Graph-based Relational Time Series,"['Ryan Rossi', 'Somdeb Sarkhel', 'Nesreen Ahmed']","In this work, we formalize the problem of causal inference over graph-based
relational time-series data where each node in the graph has one or more
time-series associated to it. We propose causal inference models for this
problem that leverage both the graph topology and time-series to accurately
estimate local causal effects of nodes. Furthermore, the relational time-series
causal inference models are able to estimate local effects for individual nodes
by exploiting local node-centric temporal dependencies and
topological/structural dependencies. We show that simpler causal models that do
not consider the graph topology are recovered as special cases of the proposed
relational time-series causal inference model. We describe the conditions under
which the resulting estimate can be used to estimate a causal effect, and
describe how the Durbin-Wu-Hausman test of specification can be used to test
for the consistency of the proposed estimator from data. Empirically, we
demonstrate the effectiveness of the causal inference models on both synthetic
data with known ground-truth and a large-scale observational relational
time-series data set collected from Wikipedia.",http://arxiv.org/pdf/2001.05993v3,cs.LG
2020-01-16 06:09:50+00:00,Human-like Time Series Summaries via Trend Utility Estimation,"['Pegah Jandaghi', 'Jay Pujara']","In many scenarios, humans prefer a text-based representation of quantitative
data over numerical, tabular, or graphical representations. The attractiveness
of textual summaries for complex data has inspired research on data-to-text
systems. While there are several data-to-text tools for time series, few of
them try to mimic how humans summarize for time series. In this paper, we
propose a model to create human-like text descriptions for time series. Our
system finds patterns in time series data and ranks these patterns based on
empirical observations of human behavior using utility estimation. Our proposed
utility estimation model is a Bayesian network capturing interdependencies
between different patterns. We describe the learning steps for this network and
introduce baselines along with their performance for each step. The output of
our system is a natural language description of time series that attempts to
match a human's summary of the same data.",http://arxiv.org/pdf/2001.05665v2,cs.LG
2020-01-15 11:15:48+00:00,High-Dimensional Changepoint Detection via a Geometrically Inspired Mapping,"['Thomas Grundy', 'Rebecca Killick', 'Gueorgui Mihaylov']","High-dimensional changepoint analysis is a growing area of research and has
applications in a wide range of fields. The aim is to accurately and
efficiently detect changepoints in time series data when both the number of
time points and dimensions grow large. Existing methods typically aggregate or
project the data to a smaller number of dimensions; usually one. We present a
high-dimensional changepoint detection method that takes inspiration from
geometry to map a high-dimensional time series to two dimensions. We show
theoretically and through simulation that if the input series is Gaussian then
the mappings preserve the Gaussianity of the data. Applying univariate
changepoint detection methods to both mapped series allows the detection of
changepoints that correspond to changes in the mean and variance of the
original time series. We demonstrate that this approach outperforms the current
state-of-the-art multivariate changepoint methods in terms of accuracy of
detected changepoints and computational efficiency. We conclude with
applications from genetics and finance.",http://arxiv.org/pdf/2001.05241v1,stat.ME
2020-01-14 08:17:33+00:00,Nonparametric Trend Estimation in Functional Time Series with Application to Annual Mortality Rates,"['Israel Martínez-Hernández', 'Marc G. Genton']","Here, we address the problem of trend estimation for functional time series.
Existing contributions either deal with detecting a functional trend or
assuming a simple model. They consider neither the estimation of a general
functional trend nor the analysis of functional time series with a functional
trend component. Similarly to univariate time series, we propose an alternative
methodology to analyze functional time series, taking into account a functional
trend component. We propose to estimate the functional trend by using a tensor
product surface that is easy to implement, to interpret, and allows to control
the smoothness properties of the estimator. Through a Monte Carlo study, we
simulate different scenarios of functional processes to show that our estimator
accurately identifies the functional trend component. We also show that the
dependency structure of the estimated stationary time series component is not
significantly affected by the error approximation of the functional trend
component. We apply our methodology to annual mortality rates in France.",http://arxiv.org/pdf/2001.04660v2,stat.ME
2020-01-14 03:06:53+00:00,For2For: Learning to forecast from forecasts,"['Shi Zhao', 'Ying Feng']","This paper presents a time series forecasting framework which combines
standard forecasting methods and a machine learning model. The inputs to the
machine learning model are not lagged values or regular time series features,
but instead forecasts produced by standard methods. The machine learning model
can be either a convolutional neural network model or a recurrent neural
network model. The intuition behind this approach is that forecasts of a time
series are themselves good features characterizing the series, especially when
the modelling purpose is forecasting. It can also be viewed as a weighted
ensemble method. Tested on the M4 competition dataset, this approach
outperforms all submissions for quarterly series, and is more accurate than all
but the winning algorithm for monthly series.",http://arxiv.org/pdf/2001.04601v1,stat.ML
2020-01-13 13:11:51+00:00,Robust Two-Step Wavelet-Based Inference for Time Series Models,"['Stéphane Guerrier', 'Roberto Molinari', 'Maria-Pia Victoria-Feser', 'Haotian Xu']","Complex time series models such as (the sum of) ARMA$(p,q)$ models with
additional noise, random walks, rounding errors and/or drifts are increasingly
used for data analysis in fields such as biology, ecology, engineering and
economics where the length of the observed signals can be extremely large.
Performing inference on and/or prediction from these models can be highly
challenging for several reasons: (i) the data may contain outliers that can
adversely affect the estimation procedure; (ii) the computational complexity
can become prohibitive when models include more than just a few parameters
and/or the time series are large; (iii) model building and/or selection adds
another layer of (computational) complexity to the previous task; and (iv)
solutions that address (i), (ii) and (iii) simultaneously do not exist in
practice. For this reason, this paper aims at jointly addressing these
challenges by proposing a general framework for robust two-step estimation
based on a bounded influence M-estimator of the wavelet variance. In this
perspective, we first develop the conditions for the joint asymptotic normality
of the latter estimator thereby providing the necessary tools to perform
(direct) inference for scale-based analysis of signals. Taking advantage of the
model-independent weights of this first-step estimator that are computed only
once, we then develop the asymptotic properties of two-step robust estimators
using the framework of the Generalized Method of Wavelet Moments (GMWM), hence
defining the Robust GMWM (RGMWM) that we then use for robust model estimation
and inference in a computationally efficient manner even for large time series.
Simulation studies illustrate the good finite sample performance of the RGMWM
estimator and applied examples highlight the practical relevance of the
proposed approach.",http://arxiv.org/pdf/2001.04214v1,stat.ME
2020-01-10 20:33:01+00:00,Forecasting multiple functional time series in a group structure: an application to mortality,"['Han Lin Shang', 'Steven Haberman']","When modeling sub-national mortality rates, we should consider three
features: (1) how to incorporate any possible correlation among sub-populations
to potentially improve forecast accuracy through multi-population joint
modeling; (2) how to reconcile sub-national mortality forecasts so that they
aggregate adequately across various levels of a group structure; (3) among the
forecast reconciliation methods, how to combine their forecasts to achieve
improved forecast accuracy. To address these issues, we introduce an extension
of grouped univariate functional time series method. We first consider a
multivariate functional time series method to jointly forecast multiple related
series. We then evaluate the impact and benefit of using forecast combinations
among the forecast reconciliation methods. Using the Japanese regional
age-specific mortality rates, we investigate one-step-ahead to 15-step-ahead
point and interval forecast accuracies of our proposed extension and make
recommendations.",http://arxiv.org/pdf/2001.03658v1,stat.ME
2020-01-08 15:39:18+00:00,Spectral estimation for non-linear long range dependent discrete time trawl processes,"['Paul Doukhan', 'François Roueff', 'Joseph Rynkiewicz']","Discrete time trawl processes constitute a large class of time series
parameterized by a trawl sequence (a j) j$\in$N and defined though a sequence
of independent and identically distributed (i.i.d.) copies of a continuous time
process ($\gamma$(t)) t$\in$R called the seed process. They provide a general
framework for modeling linear or non-linear long range dependent time series.
We investigate the spectral estimation, either pointwise or broadband, of long
range dependent discrete-time trawl processes. The difficulty arising from the
variety of seed processes and of trawl sequences is twofold. First, the
spectral density may take different forms, often including smooth additive
correction terms. Second, trawl processes with similar spectral densities may
exhibit very different statistical behaviors. We prove the consistency of our
estimators under very general conditions and we show that a wide class of trawl
processes satisfy them. This is done in particular by introducing a weighted
weak dependence index that can be of independent interest. The broadband
spectral estimator includes an estimator of the long memory parameter. We
complete this work with numerical experiments to evaluate the finite sample
size performance of this estimator for various integer valued discrete time
trawl processes.",http://arxiv.org/pdf/2001.02579v1,math.ST
2020-01-07 19:11:14+00:00,Vector Autoregressive Models with Spatially Structured Coefficients for Time Series on a Spatial Grid,"['Yuan Yan', 'Hsin-Cheng Huang', 'Marc G. Genton']","We propose a parsimonious spatiotemporal model for time series data on a
spatial grid. Our model is capable of dealing with high-dimensional time series
data that may be collected at hundreds of locations and capturing the spatial
non-stationarity. In essence, our model is a vector autoregressive model that
utilizes the spatial structure to achieve parsimony of autoregressive matrices
at two levels. The first level ensures the sparsity of the autoregressive
matrices using a lagged-neighborhood scheme. The second level performs a
spatial clustering of the non-zero autoregressive coefficients such that nearby
locations share similar coefficients. This model is interpretable and can be
used to identify geographical subregions, within each of which, the time series
share similar dynamical behavior with homogeneous autoregressive coefficients.
The model parameters are obtained using the penalized maximum likelihood with
an adaptive fused Lasso penalty. The estimation procedure is easy to implement
and can be tailored to the need of a modeler. We illustrate the performance of
the proposed estimation algorithm in a simulation study. We apply our model to
a wind speed time series dataset generated from a climate model over Saudi
Arabia to illustrate its usefulness. Limitations and possible extensions of our
method are also discussed.",http://arxiv.org/pdf/2001.02250v2,stat.ME
2020-01-07 07:28:21+00:00,Scalable Hybrid HMM with Gaussian Process Emission for Sequential Time-series Data Clustering,"['Yohan Jung', 'Jinkyoo Park']","Hidden Markov Model (HMM) combined with Gaussian Process (GP) emission can be
effectively used to estimate the hidden state with a sequence of complex
input-output relational observations. Especially when the spectral mixture (SM)
kernel is used for GP emission, we call this model as a hybrid HMM-GPSM. This
model can effectively model the sequence of time-series data. However, because
of a large number of parameters for the SM kernel, this model can not
effectively be trained with a large volume of data having (1) long sequence for
state transition and 2) a large number of time-series dataset in each sequence.
This paper proposes a scalable learning method for HMM-GPSM. To effectively
train the model with a long sequence, the proposed method employs a Stochastic
Variational Inference (SVI) approach. Also, to effectively process a large
number of data point each time-series data, we approximate the SM kernel using
Reparametrized Random Fourier Feature (R-RFF). The combination of these two
techniques significantly reduces the training time. We validate the proposed
learning method in terms of its hidden-sate estimation accuracy and computation
time using large-scale synthetic and real data sets with missing values.",http://arxiv.org/pdf/2001.01917v1,cs.LG
2020-01-07 04:28:00+00:00,Discovering Nonlinear Relations with Minimum Predictive Information Regularization,"['Tailin Wu', 'Thomas Breuel', 'Michael Skuhersky', 'Jan Kautz']","Identifying the underlying directional relations from observational time
series with nonlinear interactions and complex relational structures is key to
a wide range of applications, yet remains a hard problem. In this work, we
introduce a novel minimum predictive information regularization method to infer
directional relations from time series, allowing deep learning models to
discover nonlinear relations. Our method substantially outperforms other
methods for learning nonlinear relations in synthetic datasets, and discovers
the directional relations in a video game environment and a heart-rate vs.
breath-rate dataset.",http://arxiv.org/pdf/2001.01885v1,cs.LG
2020-01-05 11:25:53+00:00,Prediction of MRI Hardware Failures based on Image Features using Time Series Classification,"['Nadine Kuhnert', 'Lea Pflüger', 'Andreas Maier']","Already before systems malfunction one has to know if hardware components
will fail in near future in order to counteract in time. Thus, unplanned
downtime is ought to be avoided. In medical imaging, maximizing the system's
uptime is crucial for patients' health and healthcare provider's daily
business. We aim to predict failures of Head/Neck coils used in Magnetic
Resonance Imaging (MRI) by training a statistical model on sequential data
collected over time. As image features depend on the coil's condition, their
deviations from the normal range already hint to future failure. Thus, we used
image features and their variation over time to predict coil damage. After
comparison of different time series classification methods we found Long Short
Term Memorys (LSTMs) to achieve the highest F-score of 86.43% and to tell with
98.33% accuracy if hardware should be replaced.",http://arxiv.org/pdf/2001.02127v1,cs.LG
2020-01-04 08:31:34+00:00,Root Cause Detection Among Anomalous Time Series Using Temporal State Alignment,"['Sayan Chakraborty', 'Smit Shah', 'Kiumars Soltani', 'Anna Swigart']","The recent increase in the scale and complexity of software systems has
introduced new challenges to the time series monitoring and anomaly detection
process. A major drawback of existing anomaly detection methods is that they
lack contextual information to help stakeholders identify the cause of
anomalies. This problem, known as root cause detection, is particularly
challenging to undertake in today's complex distributed software systems since
the metrics under consideration generally have multiple internal and external
dependencies. Significant manual analysis and strong domain expertise is
required to isolate the correct cause of the problem. In this paper, we propose
a method that isolates the root cause of an anomaly by analyzing the patterns
in time series fluctuations. Our method considers the time series as
observations from an underlying process passing through a sequence of
discretized hidden states. The idea is to track the propagation of the effect
when a given problem causes unaligned but homogeneous shifts of the underlying
states. We evaluate our approach by finding the root cause of anomalies in
Zillows clickstream data by identifying causal patterns among a set of observed
fluctuations.",http://arxiv.org/pdf/2001.01056v1,cs.LG
2020-01-04 07:28:55+00:00,Temporal Tensor Transformation Network for Multivariate Time Series Prediction,"['Yuya Jeremy Ong', 'Mu Qiao', 'Divyesh Jadav']","Multivariate time series prediction has applications in a wide variety of
domains and is considered to be a very challenging task, especially when the
variables have correlations and exhibit complex temporal patterns, such as
seasonality and trend. Many existing methods suffer from strong statistical
assumptions, numerical issues with high dimensionality, manual feature
engineering efforts, and scalability. In this work, we present a novel deep
learning architecture, known as Temporal Tensor Transformation Network, which
transforms the original multivariate time series into a higher order of tensor
through the proposed Temporal-Slicing Stack Transformation. This yields a new
representation of the original multivariate time series, which enables the
convolution kernel to extract complex and non-linear features as well as
variable interactional signals from a relatively large temporal region.
Experimental results show that Temporal Tensor Transformation Network
outperforms several state-of-the-art methods on window-based predictions across
various tasks. The proposed architecture also demonstrates robust prediction
performance through an extensive sensitivity analysis.",http://arxiv.org/pdf/2001.01051v1,cs.LG
2020-01-02 18:48:29+00:00,A Deep Structural Model for Analyzing Correlated Multivariate Time Series,"['Changwei Hu', 'Yifan Hu', 'Sungyong Seo']","Multivariate time series are routinely encountered in real-world
applications, and in many cases, these time series are strongly correlated. In
this paper, we present a deep learning structural time series model which can
(i) handle correlated multivariate time series input, and (ii) forecast the
targeted temporal sequence by explicitly learning/extracting the trend,
seasonality, and event components. The trend is learned via a 1D and 2D
temporal CNN and LSTM hierarchical neural net. The CNN-LSTM architecture can
(i) seamlessly leverage the dependency among multiple correlated time series in
a natural way, (ii) extract the weighted differencing feature for better trend
learning, and (iii) memorize the long-term sequential pattern. The seasonality
component is approximated via a non-liner function of a set of Fourier terms,
and the event components are learned by a simple linear function of regressor
encoding the event dates. We compare our model with several state-of-the-art
methods through a comprehensive set of experiments on a variety of time series
data sets, such as forecasts of Amazon AWS Simple Storage Service (S3) and
Elastic Compute Cloud (EC2) billings, and the closing prices for corporate
stocks in the same category.",http://arxiv.org/pdf/2001.00559v1,stat.ML
2020-01-02 13:03:14+00:00,Prediction in locally stationary time series,"['Holger Dette', 'Weichi Wu']","We develop an estimator for the high-dimensional covariance matrix of a
locally stationary process with a smoothly varying trend and use this statistic
to derive consistent predictors in non-stationary time series. In contrast to
the currently available methods for this problem the predictor developed here
does not rely on fitting an autoregressive model and does not require a
vanishing trend. The finite sample properties of the new methodology are
illustrated by means of a simulation study and a financial indices study.",http://arxiv.org/pdf/2001.00419v2,stat.ME
2019-12-31 05:58:10+00:00,Model-free Bootstrap for a General Class of Stationary Time Series,"['Yiren Wang', 'Dimitris N. Politis']","A model-free bootstrap procedure for a general class of stationary time
series is introduced. The theoretical framework is established, showing
asymptotic validity of bootstrap confidence intervals for many statistics of
interest. In addition, asymptotic validity of one-step ahead bootstrap
prediction intervals is also demonstrated. Finite-sample experiments are
conducted to empirically confirm the performance of the new method, and to
compare with
  popular methods such as the block bootstrap and the autoregressive (AR)-sieve
bootstrap.",http://arxiv.org/pdf/1912.13185v1,math.ST
2019-12-30 14:25:29+00:00,Globally Optimal And Adaptive Short-Term Forecast of Locally Stationary Time Series And A Test for Its Stability,"['Xiucai Ding', 'Zhou Zhou']","Forecasting the evolution of complex systems is one of the grand challenges
of modern data science. The fundamental difficulty lies in understanding the
structure of the observed stochastic process. In this paper, we show that every
uniformly-positive-definite-in-covariance and sufficiently short-range
dependent non-stationary and nonlinear time series can be well approximated
globally by an auto-regressive process of slowly diverging order. When linear
prediction with ${\cal L}^2$ loss is concerned, the latter result facilitates a
unified globally-optimal short-term forecasting theory for a wide class of
locally stationary time series asymptotically. A nonparametric sieve method is
proposed to globally and adaptively estimate the optimal forecasting
coefficient functions and the associated mean squared error of forecast. An
adaptive stability test is proposed to check whether the optimal forecasting
coefficients are time-varying, a frequently-encountered question for
practitioners and researchers of time series. Furthermore, partial
auto-correlation functions (PACF) of general non-stationary time series are
studied and used as a visual tool to explore the linear dependence structure of
such series. We use extensive numerical simulations and two real data examples
to illustrate the usefulness of our results.",http://arxiv.org/pdf/1912.12937v1,math.ST
2019-12-27 04:33:11+00:00,Use Short Isometric Shapelets to Accelerate Binary Time Series Classification,"['Weibo Shu', 'Yaqiang Yao', 'Shengfei Lyu', 'Jinlong Li', 'Huanhuan Chen']","In the research area of time series classification, the ensemble shapelet
transform algorithm is one of state-of-the-art algorithms for classification.
However, its high time complexity is an issue to hinder its application since
its base classifier shapelet transform includes a high time complexity of a
distance calculation and shapelet selection. Therefore, in this paper we
introduce a novel algorithm, i.e. short isometric shapelet transform, which
contains two strategies to reduce the time complexity. The first strategy of
SIST fixes the length of shapelet based on a simplified distance calculation,
which largely reduces the number of shapelet candidates as well as speeds up
the distance calculation in the ensemble shapelet transform algorithm. The
second strategy is to train a single linear classifier in the feature space
instead of an ensemble classifier. The theoretical evidences of these two
strategies are presented to guarantee a near-lossless accuracy under some
preconditions while reducing the time complexity. Furthermore, empirical
experiments demonstrate the superior performance of the proposed algorithm.",http://arxiv.org/pdf/1912.11982v2,cs.LG
2019-12-20 02:24:41+00:00,Features or Shape? Tackling the False Dichotomy of Time Series Classification,"['Sara Alaee', 'Alireza Abdoli', 'Christian Shelton', 'Amy C. Murillo', 'Alec C. Gerry', 'Eamonn Keogh']","Time series classification is an important task in its own right, and it is
often a precursor to further downstream analytics. To date, virtually all works
in the literature have used either shape-based classification using a distance
measure or feature-based classification after finding some suitable features
for the domain. It seems to be underappreciated that in many datasets it is the
case that some classes are best discriminated with features, while others are
best discriminated with shape. Thus, making the shape vs. feature choice will
condemn us to poor results, at least for some classes. In this work, we propose
a new model for classifying time series that allows the use of both shape and
feature-based measures, when warranted. Our algorithm automatically decides
which approach is best for which class, and at query time chooses which
classifier to trust the most. We evaluate our idea on real world datasets and
demonstrate that our ideas produce statistically significant improvement in
classification accuracy.",http://arxiv.org/pdf/1912.09614v1,cs.LG
2019-12-19 16:45:40+00:00,Temporal Fusion Transformers for Interpretable Multi-horizon Time Series Forecasting,"['Bryan Lim', 'Sercan O. Arik', 'Nicolas Loeff', 'Tomas Pfister']","Multi-horizon forecasting problems often contain a complex mix of inputs --
including static (i.e. time-invariant) covariates, known future inputs, and
other exogenous time series that are only observed historically -- without any
prior information on how they interact with the target. While several deep
learning models have been proposed for multi-step prediction, they typically
comprise black-box models which do not account for the full range of inputs
present in common scenarios. In this paper, we introduce the Temporal Fusion
Transformer (TFT) -- a novel attention-based architecture which combines
high-performance multi-horizon forecasting with interpretable insights into
temporal dynamics. To learn temporal relationships at different scales, the TFT
utilizes recurrent layers for local processing and interpretable self-attention
layers for learning long-term dependencies. The TFT also uses specialized
components for the judicious selection of relevant features and a series of
gating layers to suppress unnecessary components, enabling high performance in
a wide range of regimes. On a variety of real-world datasets, we demonstrate
significant performance improvements over existing benchmarks, and showcase
three practical interpretability use-cases of TFT.",http://arxiv.org/pdf/1912.09363v3,stat.ML
2019-12-18 23:38:48+00:00,Variable-lag Granger Causality for Time Series Analysis,"['Chainarong Amornbunchornvej', 'Elena Zheleva', 'Tanya Y. Berger-Wolf']","Granger causality is a fundamental technique for causal inference in time
series data, commonly used in the social and biological sciences. Typical
operationalizations of Granger causality make a strong assumption that every
time point of the effect time series is influenced by a combination of other
time series with a fixed time delay. However, the assumption of the fixed time
delay does not hold in many applications, such as collective behavior,
financial markets, and many natural phenomena. To address this issue, we
develop variable-lag Granger causality, a generalization of Granger causality
that relaxes the assumption of the fixed time delay and allows causes to
influence effects with arbitrary time delays. In addition, we propose a method
for inferring variable-lag Granger causality relations. We demonstrate our
approach on an application for studying coordinated collective behavior and
show that it performs better than several existing methods in both simulated
and real-world datasets. Our approach can be applied in any domain of time
series analysis.",http://arxiv.org/pdf/1912.10829v1,cs.LG
2019-12-18 13:22:37+00:00,Method of moments estimators for the extremal index of a stationary time series,"['Axel Bücher', 'Tobias Jennessen']","The extremal index $\theta$, a number in the interval $[0,1]$, is known to be
a measure of primal importance for analyzing the extremes of a stationary time
series. New rank-based estimators for $\theta$ are proposed which rely on the
construction of approximate samples from the exponential distribution with
parameter $\theta$ that is then to be fitted via the method of moments. The new
estimators are analyzed both theoretically as well as empirically through a
large-scale simulation study. In specific scenarios, in particular for time
series models with $\theta \approx 1$, they are found to be superior to recent
competitors from the literature.",http://arxiv.org/pdf/1912.08584v2,math.ST
2019-12-18 05:51:42+00:00,Feature engineering workflow for activity recognition from synchronized inertial measurement units,"['Andreas W. Kempa-Liehr', 'Jonty Oram', 'Andrew Wong', 'Mark Finch', 'Thor Besier']","The ubiquitous availability of wearable sensors is responsible for driving
the Internet-of-Things but is also making an impact on sport sciences and
precision medicine. While human activity recognition from smartphone data or
other types of inertial measurement units (IMU) has evolved to one of the most
prominent daily life examples of machine learning, the underlying process of
time-series feature engineering still seems to be time-consuming. This lengthy
process inhibits the development of IMU-based machine learning applications in
sport science and precision medicine. This contribution discusses a feature
engineering workflow, which automates the extraction of time-series feature on
based on the FRESH algorithm (FeatuRe Extraction based on Scalable Hypothesis
tests) to identify statistically significant features from synchronized IMU
sensors (IMeasureU Ltd, NZ). The feature engineering workflow has five main
steps: time-series engineering, automated time-series feature extraction,
optimized feature extraction, fitting of a specialized classifier, and
deployment of optimized machine learning pipeline. The workflow is discussed
for the case of a user-specific running-walking classification, and the
generalization to a multi-user multi-activity classification is demonstrated.",http://arxiv.org/pdf/1912.08394v1,cs.LG
2019-12-16 06:14:03+00:00,A posteriori Trading-inspired Model-free Time Series Segmentation,['Mogens Graf Plessen'],"Within the context of multivariate time series segmentation this paper
proposes a method inspired by a posteriori optimal trading. After a
normalization step time series are treated channel-wise as surrogate stock
prices that can be traded optimally a posteriori in a virtual portfolio holding
either stock or cash. Linear transaction costs are interpreted as
hyperparameters for noise filtering. Resulting trading signals as well as
resulting trading signals obtained on the reversed time series are used for
unsupervised labeling, before a consensus over channels is reached that
determines segmentation time instants. The method is model-free such that no
model prescriptions for segments are made. Benefits of proposed approach
include simplicity, computational efficiency and adaptability to a wide range
of different shapes of time series. Performance is demonstrated on synthetic
and real-world data, including a large-scale dataset comprising a multivariate
time series of dimension 1000 and length 2709. Proposed method is compared to a
popular model-based bottom-up approach fitting piecewise affine models and to a
recent model-based top-down approach fitting Gaussian models, and found to be
consistently faster while producing more intuitive results.",http://arxiv.org/pdf/1912.06708v1,stat.ML
2019-12-11 19:08:07+00:00,Deteção de estruturas permanentes a partir de dados de séries temporais Sentinel 1 e 2,"['André Neves', 'Carlos Damásio', 'João Pires', 'Fernando Birra']","Mapping structures such as settlements, roads, individual houses and any
other types of artificial structures is of great importance for the analysis of
urban growth, masking, image alignment and, especially in the studied use case,
the definition of Fuel Management Networks (FGC), which protect buildings from
forest fires. Current cartography has a low generation frequency and their
resolution may not be suitable for extracting small structures such as small
settlements or roads, which may lack forest fire protection. In this paper, we
use time series data, extracted from Sentinel-1 and 2 constellations, over
Santar\'em, Ma\c{c}\~ao, to explore the detection of permanent structures at a
resolution of 10 by 10 meters. For this purpose, a XGBoost classification model
is trained with 133 attributes extracted from the time series from all the
bands, including normalized radiometric indices. The results show that the use
of time series data increases the accuracy of the extraction of permanent
structures when compared using only static data, using multitemporal data also
increases the number of detected roads. In general, the final result has a
permanent structure mapping with a higher resolution than state of the art
settlement maps, small structures and roads are also more accurately
represented. Regarding the use case, by using our final map for the creation of
FGC it is possible to simplify and accelerate the process of delimitation of
the official FGC.",http://arxiv.org/pdf/1912.10799v1,cs.LG
2019-12-11 18:17:12+00:00,The Wasserstein-Fourier Distance for Stationary Time Series,"['Elsa Cazelles', 'Arnaud Robert', 'Felipe Tobar']","We propose the Wasserstein-Fourier (WF) distance to measure the
(dis)similarity between time series by quantifying the displacement of their
energy across frequencies. The WF distance operates by calculating the
Wasserstein distance between the (normalised) power spectral densities (NPSD)
of time series. Yet this rationale has been considered in the past, we fill a
gap in the open literature providing a formal introduction of this distance,
together with its main properties from the joint perspective of Fourier
analysis and optimal transport. As the main aim of this work is to validate WF
as a general-purpose metric for time series, we illustrate its applicability on
three broad contexts. First, we rely on WF to implement a PCA-like
dimensionality reduction for NPSDs which allows for meaningful visualisation
and pattern recognition applications. Second, we show that the geometry induced
by WF on the space of NPSDs admits a geodesic interpolant between time series,
thus enabling data augmentation on the spectral domain, by averaging the
dynamic content of two signals. Third, we implement WF for time series
classification using parametric/non-parametric classifiers and compare it to
other classical metrics. Supported on theoretical results, as well as synthetic
illustrations and experiments on real-world data, this work establishes WF as a
meaningful and capable resource pertinent to general distance-based
applications of time series.",http://arxiv.org/pdf/1912.05509v2,stat.ML
2019-12-11 14:58:19+00:00,Classification des S{é}ries Temporelles Incertaines par Transformation Shapelet,"['Michael Mbouopda', 'Engelbert Mephu Nguifo']","Time serie classification is used in a diverse range of domain such as
meteorology, medicine and physics. It aims to classify chronological data. Many
accurate approaches have been built during the last decade and shapelet
transformation is one of them. However, none of these approaches does take data
uncertainty into account. Using uncertainty propagation techiniques, we propose
a new dissimilarity measure based on euclidean distance. We also show how to
use this new measure to adapt shapelet transformation to uncertain time series
classification. An experimental assessment of our contribution is done on some
state of the art datasets.",http://arxiv.org/pdf/1912.08919v1,cs.LG
2019-12-10 15:21:47+00:00,Generalised Network Autoregressive Processes and the GNAR package,"['Marina Knight', 'Kathryn Leeming', 'Guy Nason', 'Matthew Nunes']","This article introduces the GNAR package, which fits, predicts, and simulates
from a powerful new class of generalised network autoregressive processes. Such
processes consist of a multivariate time series along with a real, or inferred,
network that provides information about inter-variable relationships. The GNAR
model relates values of a time series for a given variable and time to earlier
values of the same variable and of neighbouring variables, with inclusion
controlled by the network structure. The GNAR package is designed to fit this
new model, while working with standard ts objects and the igraph package for
ease of use.",http://arxiv.org/pdf/1912.04758v1,stat.ME
2019-12-09 13:01:58+00:00,An empirical study of neural networks for trend detection in time series,"['Alexandre Miot', 'Gilles Drigout']","Detecting structure in noisy time series is a difficult task. One intuitive
feature is the notion of trend. From theoretical hints and using simulated time
series, we empirically investigate the efficiency of standard recurrent neural
networks (RNNs) to detect trends. We show the overall superiority and
versatility of certain standard RNNs structures over various other estimators.
These RNNs could be used as basic blocks to build more complex time series
trend estimators.",http://arxiv.org/pdf/1912.04009v2,cs.LG
2019-12-05 12:11:54+00:00,Warped Input Gaussian Processes for Time Series Forecasting,['David Tolpin'],"We introduce a Gaussian process-based model for handling of non-stationarity.
The warping is achieved non-parametrically, through imposing a prior on the
relative change of distance between subsequent observation inputs. The model
allows the use of general gradient optimization algorithms for training and
incurs only a small computational overhead on training and prediction. The
model finds its applications in forecasting in non-stationary time series with
either gradually varying volatility, presence of change points, or a
combination thereof. We evaluate the model on synthetic and real-world time
series data comparing against both baseline and known state-of-the-art
approaches and show that the model exhibits state-of-the-art forecasting
performance at a lower implementation and computation cost.",http://arxiv.org/pdf/1912.02527v1,stat.ML
2019-12-05 09:23:57+00:00,Advanced analysis of temporal data using Fisher-Shannon information: theoretical development and application in geosciences,"['Fabian Guignard', 'Mohamed Laib', 'Federico Amato', 'Mikhail Kanevski']","Complex non-linear time series are ubiquitous in geosciences. Quantifying
complexity and non-stationarity of these data is a challenging task, and
advanced complexity-based exploratory tool are required for understanding and
visualizing such data. This paper discusses the Fisher-Shannon method, from
which one can obtain a complexity measure and detect non-stationarity, as an
efficient data exploration tool. The state-of-the-art studies related to the
Fisher-Shannon measures are collected, and new analytical formulas for positive
unimodal skewed distributions are proposed. Case studies on both synthetic and
real data illustrate the usefulness of the Fisher-Shannon method, which can
find application in different domains including time series discrimination and
generation of times series features for clustering, modeling and forecasting.
The paper is accompanied with Python and R libraries for the non-parametric
estimation of the proposed measures.",http://arxiv.org/pdf/1912.02452v2,stat.ME
2019-12-05 06:22:04+00:00,Clustering Time-Series by a Novel Slope-Based Similarity Measure Considering Particle Swarm Optimization,"['Hossein Kamalzadeh', 'Abbas Ahmadi', 'Saeed Mansour']","Recently there has been an increase in the studies on time-series data mining
specifically time-series clustering due to the vast existence of time-series in
various domains. The large volume of data in the form of time-series makes it
necessary to employ various techniques such as clustering to understand the
data and to extract information and hidden patterns. In the field of clustering
specifically, time-series clustering, the most important aspects are the
similarity measure used and the algorithm employed to conduct the clustering.
In this paper, a new similarity measure for time-series clustering is developed
based on a combination of a simple representation of time-series, slope of each
segment of time-series, Euclidean distance and the so-called dynamic time
warping. It is proved in this paper that the proposed distance measure is
metric and thus indexing can be applied. For the task of clustering, the
Particle Swarm Optimization algorithm is employed. The proposed similarity
measure is compared to three existing measures in terms of various criteria
used for the evaluation of clustering algorithms. The results indicate that the
proposed similarity measure outperforms the rest in almost every dataset used
in this paper.",http://arxiv.org/pdf/1912.02405v1,cs.LG
2019-12-01 09:49:42+00:00,Machine learning applications in time series hierarchical forecasting,"['Mahdi Abolghasemi', 'Rob J Hyndman', 'Garth Tarr', 'Christoph Bergmeir']","Hierarchical forecasting (HF) is needed in many situations in the supply
chain (SC) because managers often need different levels of forecasts at
different levels of SC to make a decision. Top-Down (TD), Bottom-Up (BU) and
Optimal Combination (COM) are common HF models. These approaches are static and
often ignore the dynamics of the series while disaggregating them.
Consequently, they may fail to perform well if the investigated group of time
series are subject to large changes such as during the periods of promotional
sales. We address the HF problem of predicting real-world sales time series
that are highly impacted by promotion. We use three machine learning (ML)
models to capture sales variations over time. Artificial neural networks (ANN),
extreme gradient boosting (XGboost), and support vector regression (SVR)
algorithms are used to estimate the proportions of lower-level time series from
the upper level. We perform an in-depth analysis of 61 groups of time series
with different volatilities and show that ML models are competitive and
outperform some well-established models in the literature.",http://arxiv.org/pdf/1912.00370v1,cs.LG
2019-11-29 18:43:18+00:00,Financial Time Series Forecasting with Deep Learning : A Systematic Literature Review: 2005-2019,"['Omer Berat Sezer', 'Mehmet Ugur Gudelek', 'Ahmet Murat Ozbayoglu']","Financial time series forecasting is, without a doubt, the top choice of
computational intelligence for finance researchers from both academia and
financial industry due to its broad implementation areas and substantial
impact. Machine Learning (ML) researchers came up with various models and a
vast number of studies have been published accordingly. As such, a significant
amount of surveys exist covering ML for financial time series forecasting
studies. Lately, Deep Learning (DL) models started appearing within the field,
with results that significantly outperform traditional ML counterparts. Even
though there is a growing interest in developing models for financial time
series forecasting research, there is a lack of review papers that were solely
focused on DL for finance. Hence, our motivation in this paper is to provide a
comprehensive literature review on DL studies for financial time series
forecasting implementations. We not only categorized the studies according to
their intended forecasting implementation areas, such as index, forex,
commodity forecasting, but also grouped them based on their DL model choices,
such as Convolutional Neural Networks (CNNs), Deep Belief Networks (DBNs),
Long-Short Term Memory (LSTM). We also tried to envision the future for the
field by highlighting the possible setbacks and opportunities, so the
interested researchers can benefit.",http://arxiv.org/pdf/1911.13288v1,cs.LG
2019-11-28 00:04:21+00:00,Analysis of Hydrological and Suspended Sediment Events from Mad River Watershed using Multivariate Time Series Clustering,"['Ali Javed', 'Scott D. Hamshaw', 'Donna M. Rizzo', 'Byung Suk Lee']","Hydrological storm events are a primary driver for transporting water quality
constituents such as turbidity, suspended sediments and nutrients. Analyzing
the concentration (C) of these water quality constituents in response to
increased streamflow discharge (Q), particularly when monitored at high
temporal resolution during a hydrological event, helps to characterize the
dynamics and flux of such constituents. A conventional approach to storm event
analysis is to reduce the C-Q time series to two-dimensional (2-D) hysteresis
loops and analyze these 2-D patterns. While effective and informative to some
extent, this hysteresis loop approach has limitations because projecting the
C-Q time series onto a 2-D plane obscures detail (e.g., temporal variation)
associated with the C-Q relationships. In this paper, we address this issue
using a multivariate time series clustering approach. Clustering is applied to
sequences of river discharge and suspended sediment data (acquired through
turbidity-based monitoring) from six watersheds located in the Lake Champlain
Basin in the northeastern United States. While clusters of the hydrological
storm events using the multivariate time series approach were found to be
correlated to 2-D hysteresis loop classifications and watershed locations, the
clusters differed from the 2-D hysteresis classifications. Additionally, using
available meteorological data associated with storm events, we examine the
characteristics of computational clusters of storm events in the study
watersheds and identify the features driving the clustering approach.",http://arxiv.org/pdf/1911.12466v2,cs.LG
2019-11-27 21:47:59+00:00,AR-Net: A simple Auto-Regressive Neural Network for time-series,"['Oskar Triebe', 'Nikolay Laptev', 'Ram Rajagopal']","In this paper we present a new framework for time-series modeling that
combines the best of traditional statistical models and neural networks. We
focus on time-series with long-range dependencies, needed for monitoring fine
granularity data (e.g. minutes, seconds, milliseconds), prevalent in
operational use-cases.
  Traditional models, such as auto-regression fitted with least squares
(Classic-AR) can model time-series with a concise and interpretable model. When
dealing with long-range dependencies, Classic-AR models can become intractably
slow to fit for large data. Recently, sequence-to-sequence models, such as
Recurrent Neural Networks, which were originally intended for natural language
processing, have become popular for time-series. However, they can be overly
complex for typical time-series data and lack interpretability.
  A scalable and interpretable model is needed to bridge the statistical and
deep learning-based approaches. As a first step towards this goal, we propose
modelling AR-process dynamics using a feed-forward neural network approach,
termed AR-Net. We show that AR-Net is as interpretable as Classic-AR but also
scales to long-range dependencies.
  Our results lead to three major conclusions: First, AR-Net learns identical
AR-coefficients as Classic-AR, thus being equally interpretable. Second, the
computational complexity with respect to the order of the AR process, is linear
for AR-Net as compared to a quadratic for Classic-AR. This makes it possible to
model long-range dependencies within fine granularity data. Third, by
introducing regularization, AR-Net automatically selects and learns sparse
AR-coefficients. This eliminates the need to know the exact order of the
AR-process and allows to learn sparse weights for a model with long-range
dependencies.",http://arxiv.org/pdf/1911.12436v1,cs.LG
2019-11-27 17:57:12+00:00,LSAR: Efficient Leverage Score Sampling Algorithm for the Analysis of Big Time Series Data,"['Ali Eshragh', 'Fred Roosta', 'Asef Nazari', 'Michael W. Mahoney']","We apply methods from randomized numerical linear algebra (RandNLA) to
develop improved algorithms for the analysis of large-scale time series data.
We first develop a new fast algorithm to estimate the leverage scores of an
autoregressive (AR) model in big data regimes. We show that the accuracy of
approximations lies within $(1+\bigO{\varepsilon})$ of the true leverage scores
with high probability. These theoretical results are subsequently exploited to
develop an efficient algorithm, called LSAR, for fitting an appropriate AR
model to big time series data. Our proposed algorithm is guaranteed, with high
probability, to find the maximum likelihood estimates of the parameters of the
underlying true AR model and has a worst case running time that significantly
improves those of the state-of-the-art alternatives in big data regimes.
Empirical results on large-scale synthetic as well as real data highly support
the theoretical results and reveal the efficacy of this new approach.",http://arxiv.org/pdf/1911.12321v3,stat.ME
2019-11-27 08:05:48+00:00,"A tale of two toolkits, report the second: bake off redux. Chapter 1. dictionary based classifiers","['Anthony Bagnall', 'James Large', 'Matthew Middlehurst']","Time series classification (TSC) is the problem of learning labels from time
dependent data. One class of algorithms is derived from a bag of words
approach. A window is run along a series, the subseries is shortened and
discretised to form a word, then features are formed from the histogram of
frequency of occurrence of words. We call this type of approach to TSC
dictionary based classification. We compare four dictionary based algorithms in
the context of a wider project to update the great time series classification
bakeoff, a comparative study published in 2017. We experimentally characterise
the algorithms in terms of predictive performance, time complexity and space
complexity. We find that we can improve on the previous best in terms of
accuracy, but this comes at the cost of time and space. Alternatively, the same
performance can be achieved with far less cost. We review the relative merits
of the four algorithms before suggesting a path to possible improvement.",http://arxiv.org/pdf/1911.12008v1,cs.LG
2019-11-26 11:30:53+00:00,An Optimized and Energy-Efficient Parallel Implementation of Non-Iteratively Trained Recurrent Neural Networks,"['Julia El Zini', 'Yara Rizk', 'Mariette Awad']","Recurrent neural networks (RNN) have been successfully applied to various
sequential decision-making tasks, natural language processing applications, and
time-series predictions. Such networks are usually trained through
back-propagation through time (BPTT) which is prohibitively expensive,
especially when the length of the time dependencies and the number of hidden
neurons increase. To reduce the training time, extreme learning machines (ELMs)
have been recently applied to RNN training, reaching a 99\% speedup on some
applications. Due to its non-iterative nature, ELM training, when parallelized,
has the potential to reach higher speedups than BPTT.
  In this work, we present \opt, an optimized parallel RNN training algorithm
based on ELM that takes advantage of the GPU shared memory and of parallel QR
factorization algorithms to efficiently reach optimal solutions. The
theoretical analysis of the proposed algorithm is presented on six RNN
architectures, including LSTM and GRU, and its performance is empirically
tested on ten time-series prediction applications. \opt~is shown to reach up to
845 times speedup over its sequential counterpart and to require up to 20x less
time to train than parallel BPTT.",http://arxiv.org/pdf/1911.13252v1,cs.LG
2019-11-25 00:39:51+00:00,A Note on Mixing in High Dimensional Time Series,['Jiaqi Yin'],"Various mixing conditions have been imposed on high dimensional time series,
including the strong mixing ($\alpha$-mixing), maximal correlation coefficient
($\rho$-mixing), absolute regularity ($\beta$-mixing), and $\phi$-mixing.
$\alpha$-mixing condition is a routine assumption when studying autoregression
models. $\rho$-mixing can lead to $\alpha$-mixing. In this paper, we prove a
way to verify $\rho$-mixing under a high-dimensional triangular array time
series setting by using the Pearson's $\phi^2$, mean square contingency. Vector
autoregression model VAR(1) and vector autoregression moving average VARMA(1,1)
are proved satisfying $\rho$-mixing condition based on low rank setting.",http://arxiv.org/pdf/1911.10648v3,math.ST
2019-11-22 06:40:07+00:00,Economy Statistical Recurrent Units For Inferring Nonlinear Granger Causality,"['Saurabh Khanna', 'Vincent Y. F. Tan']","Granger causality is a widely-used criterion for analyzing interactions in
large-scale networks. As most physical interactions are inherently nonlinear,
we consider the problem of inferring the existence of pairwise Granger
causality between nonlinearly interacting stochastic processes from their time
series measurements. Our proposed approach relies on modeling the embedded
nonlinearities in the measurements using a component-wise time series
prediction model based on Statistical Recurrent Units (SRUs). We make a case
that the network topology of Granger causal relations is directly inferrable
from a structured sparse estimate of the internal parameters of the SRU
networks trained to predict the processes$'$ time series measurements. We
propose a variant of SRU, called economy-SRU, which, by design has considerably
fewer trainable parameters, and therefore less prone to overfitting. The
economy-SRU computes a low-dimensional sketch of its high-dimensional hidden
state in the form of random projections to generate the feedback for its
recurrent processing. Additionally, the internal weight parameters of the
economy-SRU are strategically regularized in a group-wise manner to facilitate
the proposed network in extracting meaningful predictive features that are
highly time-localized to mimic real-world causal events. Extensive experiments
are carried out to demonstrate that the proposed economy-SRU based time series
prediction model outperforms the MLP, LSTM and attention-gated CNN-based time
series models considered previously for inferring Granger causality.",http://arxiv.org/pdf/1911.09879v2,cs.LG
2019-11-21 18:35:12+00:00,"Bayesian forecasting of multivariate time series: Scalability, structure uncertainty and decisions",['Mike West'],"I overview recent research advances in Bayesian state-space modeling of
multivariate time series. A main focus is on the decouple/recouple concept that
enables application of state-space models to increasingly large-scale data,
applying to continuous or discrete time series outcomes. The scope includes
large-scale dynamic graphical models for forecasting and multivariate
volatility analysis in areas such as economics and finance, multi-scale
approaches for forecasting discrete/count time series in areas such as
commercial sales and demand forecasting, and dynamic network flow models for
areas including internet traffic monitoring. In applications, explicit
forecasting, monitoring and decision goals are paramount and should factor into
model assessment and comparison, a perspective that is highlighted.",http://arxiv.org/pdf/1911.09656v2,stat.ME
2019-11-21 09:32:20+00:00,Multi-Scale RCNN Model for Financial Time-series Classification,"['Liu Guang', 'Wang Xiaojie', 'Li Ruifan']","Financial time-series classification (FTC) is extremely valuable for
investment management. In past decades, it draws a lot of attention from a wide
extent of research areas, especially Artificial Intelligence (AI). Existing
researches majorly focused on exploring the effects of the Multi-Scale (MS)
property or the Temporal Dependency (TD) within financial time-series.
Unfortunately, most previous researches fail to combine these two properties
effectively and often fall short of accuracy and profitability. To effectively
combine and utilize both properties of financial time-series, we propose a
Multi-Scale Temporal Dependent Recurrent Convolutional Neural Network
(MSTD-RCNN) for FTC. In the proposed method, the MS features are simultaneously
extracted by convolutional units to precisely describe the state of the
financial market. Moreover, the TD and complementary across different scales
are captured through a Recurrent Neural Network. The proposed method is
evaluated on three financial time-series datasets which source from the Chinese
stock market. Extensive experimental results indicate that our model achieves
the state-of-the-art performance in trend classification and simulated trading,
compared with classical and advanced baseline models.",http://arxiv.org/pdf/1911.09359v1,cs.LG
2019-11-20 23:35:15+00:00,Discovering Subdimensional Motifs of Different Lengths in Large-Scale Multivariate Time Series,"['Yifeng Gao', 'Jessica Lin']","Detecting repeating patterns of different lengths in time series, also called
variable-length motifs, has received a great amount of attention by researchers
and practitioners. Despite the significant progress that has been made in
recent single dimensional variable-length motif discovery work, detecting
variable-length \textit{subdimensional motifs}---patterns that are
simultaneously occurring only in a subset of dimensions in multivariate time
series---remains a difficult task. The main challenge is scalability. On the
one hand, the brute-force enumeration solution, which searches for motifs of
all possible lengths, is very time consuming even in single dimensional time
series. On the other hand, previous work show that index-based fixed-length
approximate motif discovery algorithms such as random projection are not
suitable for detecting variable-length motifs due to memory requirement. In
this paper, we introduce an approximate variable-length subdimensional motif
discovery algorithm called \textbf{C}ollaborative \textbf{HI}erarchy based
\textbf{M}otif \textbf{E}numeration (CHIME) to efficiently detect
variable-length subdimensional motifs given a minimum motif length in
large-scale multivariate time series. We show that the memory cost of the
approach is significantly smaller than that of random projection. Moreover, the
speed of the proposed algorithm is significantly faster than that of the
state-of-the-art algorithms. We demonstrate that CHIME can efficiently detect
meaningful variable-length subdimensional motifs in large real world
multivariate time series datasets.",http://arxiv.org/pdf/1911.09218v1,cs.LG
2019-11-20 01:46:24+00:00,Equivariant online predictions of non-stationary time series,"['Kōsaku Takanashi', 'Kenichiro McAlinn']","We discuss the finite sample theoretical properties of online predictions in
non-stationary time series under model misspecification. To analyze the
theoretical predictive properties of statistical methods under this setting, we
first define the Kullback-Leibler risk, in order to place the problem within a
decision theoretic framework. Under this framework, we show that a specific
class of dynamic models -- random walk dynamic linear models -- produce exact
minimax predictive densities. We first show this result under Gaussian
assumptions, then relax this assumption using semi-martingale processes. This
result provides a theoretical baseline, under both non-stationary and
stationary time series data, for which other models can be compared against. We
extend the result to the synthesis of multiple predictive densities. Three
topical applications in epidemiology, climatology, and economics, confirm and
highlight our theoretical results.",http://arxiv.org/pdf/1911.08662v5,math.ST
2019-11-18 19:36:26+00:00,Temporal Knowledge Graph Embedding Model based on Additive Time Series Decomposition,"['Chengjin Xu', 'Mojtaba Nayyeri', 'Fouad Alkhoury', 'Hamed Shariat Yazdi', 'Jens Lehmann']","Knowledge Graph (KG) embedding has attracted more attention in recent years.
Most KG embedding models learn from time-unaware triples. However, the
inclusion of temporal information beside triples would further improve the
performance of a KGE model. In this regard, we propose ATiSE, a temporal KG
embedding model which incorporates time information into entity/relation
representations by using Additive Time Series decomposition. Moreover,
considering the temporal uncertainty during the evolution of entity/relation
representations over time, we map the representations of temporal KGs into the
space of multi-dimensional Gaussian distributions. The mean of each
entity/relation embedding at a time step shows the current expected position,
whereas its covariance (which is temporally stationary) represents its temporal
uncertainty. Experimental results show that ATiSE chieves the state-of-the-art
on link prediction over four temporal KGs.",http://arxiv.org/pdf/1911.07893v6,cs.LG
2019-11-18 12:20:47+00:00,Detecting structural breaks in eigensystems of functional time series,"['Holger Dette', 'Tim Kutta']","Detecting structural changes in functional data is a prominent topic in
statistical literature. However not all trends in the data are important in
applications, but only those of large enough influence. In this paper we
address the problem of identifying relevant changes in the eigenfunctions and
eigenvalues of covariance kernels of $L^2[0,1]$-valued time series. By
self-normalization techniques we derive pivotal, asymptotically consistent
tests for relevant changes in these characteristics of the second order
structure and investigate their finite sample properties in a simulation study.
The applicability of our approach is demonstrated analyzing German annual
temperature data.",http://arxiv.org/pdf/1911.07580v1,math.ST
2019-11-18 12:05:49+00:00,Bayesian Recurrent Framework for Missing Data Imputation and Prediction with Clinical Time Series,"['Yang Guo', 'Zhengyuan Liu', 'Pavitra Krishnswamy', 'Savitha Ramasamy']","Real-world clinical time series data sets exhibit a high prevalence of
missing values. Hence, there is an increasing interest in missing data
imputation. Traditional statistical approaches impose constraints on the
data-generating process and decouple imputation from prediction. Recent works
propose recurrent neural network based approaches for missing data imputation
and prediction with time series data. However, they generate deterministic
outputs and neglect the inherent uncertainty. In this work, we introduce a
unified Bayesian recurrent framework for simultaneous imputation and prediction
on time series data sets. We evaluate our approach on two real-world mortality
prediction tasks using the MIMIC-III and PhysioNet benchmark datasets. We
demonstrate strong performance gains over state-of-the-art (SOTA) methods, and
provide strategies to use the resulting probability distributions to better
assess reliability of the imputations and predictions.",http://arxiv.org/pdf/1911.07572v2,cs.LG
2019-11-16 21:45:38+00:00,RSM-GAN: A Convolutional Recurrent GAN for Anomaly Detection in Contaminated Seasonal Multivariate Time Series,"['Farzaneh Khoshnevisan', 'Zhewen Fan']","Robust anomaly detection is a requirement for monitoring complex modern
systems with applications such as cyber-security, fraud prevention, and
maintenance. These systems generate multiple correlated time series that are
highly seasonal and noisy. This paper presents a novel unsupervised deep
learning architecture for multivariate time series anomaly detection, called
Robust Seasonal Multivariate Generative Adversarial Network (RSM-GAN). It
extends recent advancements in GANs with adoption of convolutional-LSTM layers
and an attention mechanism to produce state-of-the-art performance. We conduct
extensive experiments to demonstrate the strength of our architecture in
adjusting for complex seasonality patterns and handling severe levels of
training data contamination. We also propose a novel anomaly score assignment
and causal inference framework. We compare RSM-GAN with existing classical and
deep-learning based anomaly detection models, and the results show that our
architecture is associated with the lowest false positive rate and improves
precision by 30% and 16% in real-world and synthetic data, respectively.
Furthermore, we report the superiority of RSM-GAN regarding accurate root cause
identification and NAB scores in all data settings.",http://arxiv.org/pdf/1911.07104v1,cs.LG
2019-11-14 23:11:19+00:00,Synthetic Event Time Series Health Data Generation,"['Saloni Dash', 'Ritik Dutta', 'Isabelle Guyon', 'Adrien Pavao', 'Andrew Yale', 'Kristin P. Bennett']","Synthetic medical data which preserves privacy while maintaining utility can
be used as an alternative to real medical data, which has privacy costs and
resource constraints associated with it. At present, most models focus on
generating cross-sectional health data which is not necessarily representative
of real data. In reality, medical data is longitudinal in nature, with a single
patient having multiple health events, non-uniformly distributed throughout
their lifetime. These events are influenced by patient covariates such as
comorbidities, age group, gender etc. as well as external temporal effects
(e.g. flu season). While there exist seminal methods to model time series data,
it becomes increasingly challenging to extend these methods to medical event
time series data. Due to the complexity of the real data, in which each patient
visit is an event, we transform the data by using summary statistics to
characterize the events for a fixed set of time intervals, to facilitate
analysis and interpretability. We then train a generative adversarial network
to generate synthetic data. We demonstrate this approach by generating human
sleep patterns, from a publicly available dataset. We empirically evaluate the
generated data and show close univariate resemblance between synthetic and real
data. However, we also demonstrate how stratification by covariates is required
to gain a deeper understanding of synthetic data quality.",http://arxiv.org/pdf/1911.06411v2,cs.LG
2019-11-14 21:11:42+00:00,Estimation of dynamic networks for high-dimensional nonstationary time series,"['Mengyu Xu', 'Xiaohui Chen', 'Wei Biao Wu']","This paper is concerned with the estimation of time-varying networks for
high-dimensional nonstationary time series. Two types of dynamic behaviors are
considered: structural breaks (i.e., abrupt change points) and smooth changes.
To simultaneously handle these two types of time-varying features, a two-step
approach is proposed: multiple change point locations are first identified
based on comparing the difference between the localized averages on sample
covariance matrices, and then graph supports are recovered based on a
kernelized time-varying constrained $L_1$-minimization for inverse matrix
estimation (CLIME) estimator on each segment. We derive the rates of
convergence for estimating the change points and precision matrices under mild
moment and dependence conditions. In particular, we show that this two-step
approach is consistent in estimating the change points and the piecewise smooth
precision matrix function, under certain high-dimensional scaling limit. The
method is applied to the analysis of network structure of the S\&P 500 index
between 2003 and 2008.",http://arxiv.org/pdf/1911.06385v4,math.ST
2019-11-14 10:07:41+00:00,Robust Parameter-Free Season Length Detection in Time Series,"['Maximilian Toller', 'Roman Kern']","The in-depth analysis of time series has gained a lot of research interest in
recent years, with the identification of periodic patterns being one important
aspect. Many of the methods for identifying periodic patterns require time
series' season length as input parameter. There exist only a few algorithms for
automatic season length approximation. Many of these rely on simplifications
such as data discretization and user defined parameters. This paper presents an
algorithm for season length detection that is designed to be sufficiently
reliable to be used in practical applications and does not require any input
other than the time series to be analyzed. The algorithm estimates a time
series' season length by interpolating, filtering and detrending the data. This
is followed by analyzing the distances between zeros in the directly
corresponding autocorrelation function. Our algorithm was tested against a
comparable algorithm and outperformed it by passing 122 out of 165 tests, while
the existing algorithm passed 83 tests. The robustness of our method can be
jointly attributed to both the algorithmic approach and also to design
decisions taken at the implementational level.",http://arxiv.org/pdf/1911.06015v1,cs.LG
2019-11-14 09:48:41+00:00,A Recurrent Probabilistic Neural Network with Dimensionality Reduction Based on Time-series Discriminant Component Analysis,"['Hideaki Hayashi', 'Taro Shibanoki', 'Keisuke Shima', 'Yuichi Kurita', 'Toshio Tsuji']","This paper proposes a probabilistic neural network developed on the basis of
time-series discriminant component analysis (TSDCA) that can be used to
classify high-dimensional time-series patterns. TSDCA involves the compression
of high-dimensional time series into a lower-dimensional space using a set of
orthogonal transformations and the calculation of posterior probabilities based
on a continuous-density hidden Markov model with a Gaussian mixture model
expressed in the reduced-dimensional space. The analysis can be incorporated
into a neural network, which is named a time-series discriminant component
network (TSDCN), so that parameters of dimensionality reduction and
classification can be obtained simultaneously as network coefficients according
to a backpropagation through time-based learning algorithm with the Lagrange
multiplier method. The TSDCN is considered to enable high-accuracy
classification of high-dimensional time-series patterns and to reduce the
computation time taken for network training. The validity of the TSDCN is
demonstrated for high-dimensional artificial data and EEG signals in the
experiments conducted during the study.",http://arxiv.org/pdf/1911.06009v1,cs.LG
2019-11-11 18:57:37+00:00,Making Good on LSTMs' Unfulfilled Promise,"['Daniel Philps', ""Artur d'Avila Garcez"", 'Tillman Weyde']","LSTMs promise much to financial time-series analysis, temporal and
cross-sectional inference, but we find that they do not deliver in a real-world
financial management task. We examine an alternative called Continual Learning
(CL), a memory-augmented approach, which can provide transparent explanations,
i.e. which memory did what and when. This work has implications for many
financial applications including credit, time-varying fairness in decision
making and more. We make three important new observations. Firstly, as well as
being more explainable, time-series CL approaches outperform LSTMs as well as a
simple sliding window learner using feed-forward neural networks (FFNN).
Secondly, we show that CL based on a sliding window learner (FFNN) is more
effective than CL based on a sequential learner (LSTM). Thirdly, we examine how
real-world, time-series noise impacts several similarity approaches used in CL
memory addressing. We provide these insights using an approach called Continual
Learning Augmentation (CLA) tested on a complex real-world problem, emerging
market equities investment decision making. CLA provides a test-bed as it can
be based on different types of time-series learners, allowing testing of LSTM
and FFNN learners side by side. CLA is also used to test several distance
approaches used in a memory recall-gate: Euclidean distance (ED), dynamic time
warping (DTW), auto-encoders (AE) and a novel hybrid approach, warp-AE. We find
that ED under-performs DTW and AE but warp-AE shows the best overall
performance in a real-world financial task.",http://arxiv.org/pdf/1911.04489v4,cs.LG
2019-11-11 08:55:55+00:00,Time2Graph: Revisiting Time Series Modeling with Dynamic Shapelets,"['Ziqiang Cheng', 'Yang Yang', 'Wei Wang', 'Wenjie Hu', 'Yueting Zhuang', 'Guojie Song']","Time series modeling has attracted extensive research efforts; however,
achieving both reliable efficiency and interpretability from a unified model
still remains a challenging problem. Among the literature, shapelets offer
interpretable and explanatory insights in the classification tasks, while most
existing works ignore the differing representative power at different time
slices, as well as (more importantly) the evolution pattern of shapelets. In
this paper, we propose to extract time-aware shapelets by designing a two-level
timing factor. Moreover, we define and construct the shapelet evolution graph,
which captures how shapelets evolve over time and can be incorporated into the
time series embeddings by graph embedding algorithms. To validate whether the
representations obtained in this way can be applied effectively in various
scenarios, we conduct experiments based on three public time series datasets,
and two real-world datasets from different domains. Experimental results
clearly show the improvements achieved by our approach compared with 17
state-of-the-art baselines.",http://arxiv.org/pdf/1911.04143v2,cs.LG
2019-11-04 02:28:50+00:00,Seasonally-Adjusted Auto-Regression of Vector Time Series,['Enzo Busseti'],"We present a simple algorithm to forecast vector time series, that is robust
against missing data, in both training and inference. It models seasonal
annual, weekly, and daily baselines, and a Gaussian process for the
seasonally-adjusted residuals. We develop a custom truncated eigendecomposition
to fit a low-rank plus block-diagonal Gaussian kernel. Inference is performed
with the Schur complement, using Tikhonov regularization to prevent overfit,
and the Woodbury formula to invert sub-matrices of the kernel efficiently.
Inference requires an amount of memory and computation linear in the dimension
of the time series, and so the model can scale to very large datasets. We also
propose a simple ""greedy"" grid search for automatic hyper-parameter tuning. The
paper is accompanied by tsar (i.e., time series auto-regressor), a Python
library that implements the algorithm.",http://arxiv.org/pdf/1911.01010v1,stat.ML
2019-11-04 00:04:30+00:00,Novel semi-metrics for multivariate change point analysis and anomaly detection,"['Nick James', 'Max Menzies', 'Lamiae Azizi', 'Jennifer Chan']","This paper proposes a new method for determining similarity and anomalies
between time series, most practically effective in large collections of (likely
related) time series, by measuring distances between structural breaks within
such a collection. We introduce a class of \emph{semi-metric} distance
measures, which we term \emph{MJ distances}. These semi-metrics provide an
advantage over existing options such as the Hausdorff and Wasserstein metrics.
We prove they have desirable properties, including better sensitivity to
outliers, while experiments on simulated data demonstrate that they uncover
similarity within collections of time series more effectively. Semi-metrics
carry a potential disadvantage: without the triangle inequality, they may not
satisfy a ""transitivity property of closeness."" We analyse this failure with
proof and introduce an computational method to investigate, in which we
demonstrate that our semi-metrics violate transitivity infrequently and mildly.
Finally, we apply our methods to cryptocurrency and measles data, introducing a
judicious application of eigenvalue analysis.",http://arxiv.org/pdf/1911.00995v3,cs.LG
2019-10-30 02:31:56+00:00,Spectral Subsampling MCMC for Stationary Time Series,"['Robert Salomone', 'Matias Quiroz', 'Robert Kohn', 'Mattias Villani', 'Minh-Ngoc Tran']","Bayesian inference using Markov Chain Monte Carlo (MCMC) on large datasets
has developed rapidly in recent years. However, the underlying methods are
generally limited to relatively simple settings where the data have specific
forms of independence. We propose a novel technique for speeding up MCMC for
time series data by efficient data subsampling in the frequency domain. For
several challenging time series models, we demonstrate a speedup of up to two
orders of magnitude while incurring negligible bias compared to MCMC on the
full dataset. We also propose alternative control variates for variance
reduction based on data grouping and coreset constructions.",http://arxiv.org/pdf/1910.13627v2,stat.ME
2019-10-29 02:48:56+00:00,ROCKET: Exceptionally fast and accurate time series classification using random convolutional kernels,"['Angus Dempster', 'François Petitjean', 'Geoffrey I. Webb']","Most methods for time series classification that attain state-of-the-art
accuracy have high computational complexity, requiring significant training
time even for smaller datasets, and are intractable for larger datasets.
Additionally, many existing methods focus on a single type of feature such as
shape or frequency. Building on the recent success of convolutional neural
networks for time series classification, we show that simple linear classifiers
using random convolutional kernels achieve state-of-the-art accuracy with a
fraction of the computational expense of existing methods.",http://arxiv.org/pdf/1910.13051v1,cs.LG
2019-10-26 19:59:45+00:00,Adaptive Bayesian Spectral Analysis of High-dimensional Nonstationary Time Series,"['Zeda Li', 'Ori Rosen', 'Fabio Ferrarelli', 'Robert T. Krafty']","This article introduces a nonparametric approach to spectral analysis of a
high-dimensional multivariate nonstationary time series. The procedure is based
on a novel frequency-domain factor model that provides a flexible yet
parsimonious representation of spectral matrices from a large number of
simultaneously observed time series. Real and imaginary parts of the factor
loading matrices are modeled independently using a prior that is formulated
from the tensor product of penalized splines and multiplicative gamma process
shrinkage priors, allowing for infinitely many factors with loadings
increasingly shrunk towards zero as the column index increases. Formulated in a
fully Bayesian framework, the time series is adaptively partitioned into
approximately stationary segments, where both the number and location of
partition points are assumed unknown. Stochastic approximation Monte Carlo
(SAMC) techniques are used to accommodate the unknown number of segments, and a
conditional Whittle likelihood-based Gibbs sampler is developed for efficient
sampling within segments. By averaging over the distribution of partitions, the
proposed method can approximate both abrupt and slowly varying changes in
spectral matrices. Performance of the proposed model is evaluated by extensive
simulations and demonstrated through the analysis of high-density
electroencephalography.",http://arxiv.org/pdf/1910.12126v1,stat.ME
2019-10-26 11:02:51+00:00,Shape-Preserving Prediction for Stationary Functional Time Series,"['Shuhao Jiao', 'Hernando Ombao']","This article presents a novel method for prediction of stationary functional
time series, in particular for trajectories that share a similar pattern but
display variable phases. The limitation of most of the existing prediction
methodologies for functional time series is that they only consider vertical
variation (amplitude, scale, or vertical shift). To overcome this limitation,
we develop a shape-preserving (SP) prediction method that incorporates both
vertical and horizontal variation. One major advantage of our proposed method
is the ability to preserve the shape of functions. Moreover, our proposed SP
method does not involve unnatural transformations and can be easily implemented
using existing software packages. The utility of the SP method is demonstrated
in the analysis of non-metanic hydrocarbons (NMHC) concentration. The analysis
demonstrates that the prediction by the SP method captures the common pattern
better than the existing prediction methods and also provides competitive
prediction accuracy.",http://arxiv.org/pdf/1910.12046v2,stat.ME
2019-10-25 02:16:15+00:00,Causal inference for climate change events from satellite image time series using computer vision and deep learning,['Vikas Ramachandra'],"We propose a method for causal inference using satellite image time series,
in order to determine the treatment effects of interventions which impact
climate change, such as deforestation. Simply put, the aim is to quantify the
'before versus after' effect of climate related human driven interventions,
such as urbanization; as well as natural disasters, such as hurricanes and
forest fires. As a concrete example, we focus on quantifying forest tree cover
change/ deforestation due to human led causes. The proposed method involves the
following steps. First, we uae computer vision and machine learning/deep
learning techniques to detect and quantify forest tree coverage levels over
time, at every time epoch. We then look at this time series to identify
changepoints. Next, we estimate the expected (forest tree cover) values using a
Bayesian structural causal model and projecting/forecasting the counterfactual.
This is compared to the values actually observed post intervention, and the
difference in the two values gives us the effect of the intervention (as
compared to the non intervention scenario, i.e. what would have possibly
happened without the intervention). As a specific use case, we analyze
deforestation levels before and after the hyperinflation event (intervention)
in Brazil (which ended in 1993-94), for the Amazon rainforest region, around
Rondonia, Brazil. For this deforestation use case, using our causal inference
framework can help causally attribute change/reduction in forest tree cover and
increasing deforestation rates due to human activities at various points in
time.",http://arxiv.org/pdf/1910.11492v1,cs.LG
2019-10-24 14:20:47+00:00,U-Time: A Fully Convolutional Network for Time Series Segmentation Applied to Sleep Staging,"['Mathias Perslev', 'Michael Hejselbak Jensen', 'Sune Darkner', 'Poul Jørgen Jennum', 'Christian Igel']","Neural networks are becoming more and more popular for the analysis of
physiological time-series. The most successful deep learning systems in this
domain combine convolutional and recurrent layers to extract useful features to
model temporal relations. Unfortunately, these recurrent models are difficult
to tune and optimize. In our experience, they often require task-specific
modifications, which makes them challenging to use for non-experts. We propose
U-Time, a fully feed-forward deep learning approach to physiological time
series segmentation developed for the analysis of sleep data. U-Time is a
temporal fully convolutional network based on the U-Net architecture that was
originally proposed for image segmentation. U-Time maps sequential inputs of
arbitrary length to sequences of class labels on a freely chosen temporal
scale. This is done by implicitly classifying every individual time-point of
the input signal and aggregating these classifications over fixed intervals to
form the final predictions. We evaluated U-Time for sleep stage classification
on a large collection of sleep electroencephalography (EEG) datasets. In all
cases, we found that U-Time reaches or outperforms current state-of-the-art
deep learning models while being much more robust in the training process and
without requiring architecture or hyperparameter adaptation across tasks.",http://arxiv.org/pdf/1910.11162v1,cs.LG
2019-10-23 05:48:33+00:00,MLAT: Metric Learning for kNN in Streaming Time Series,"['Dongmin Park', 'Susik Yoon', 'Hwanjun Song', 'Jae-Gil Lee']","Learning a good distance measure for distance-based classification in time
series leads to significant performance improvement in many tasks.
Specifically, it is critical to effectively deal with variations and temporal
dependencies in time series. However, existing metric learning approaches focus
on tackling variations mainly using a strict alignment of two sequences,
thereby being not able to capture temporal dependencies. To overcome this
limitation, we propose MLAT, which covers both alignment and temporal
dependencies at the same time. MLAT achieves the alignment effect as well as
preserves temporal dependencies by augmenting a given time series using a
sliding window. Furthermore, MLAT employs time-invariant metric learning to
derive the most appropriate distance measure from the augmented samples which
can also capture the temporal dependencies among them well. We show that MLAT
outperforms other existing algorithms in the extensive experiments on various
real-world data sets.",http://arxiv.org/pdf/1910.10368v1,cs.LG
2019-10-21 19:28:24+00:00,You May Not Need Order in Time Series Forecasting,"['Yunkai Zhang', 'Qiao Jiang', 'Shurui Li', 'Xiaoyong Jin', 'Xueying Ma', 'Xifeng Yan']","Time series forecasting with limited data is a challenging yet critical task.
While transformers have achieved outstanding performances in time series
forecasting, they often require many training samples due to the large number
of trainable parameters. In this paper, we propose a training technique for
transformers that prepares the training windows through random sampling. As
input time steps need not be consecutive, the number of distinct samples
increases from linearly to combinatorially many. By breaking the temporal
order, this technique also helps transformers to capture dependencies among
time steps in finer granularity. We achieve competitive results compared to the
state-of-the-art on real-world datasets.",http://arxiv.org/pdf/1910.09620v1,cs.LG
2019-10-21 14:16:05+00:00,Generalised learning of time-series: Ornstein-Uhlenbeck processes,"['Mehmet Süzen', 'Alper Yegenoglu']","In machine learning, statistics, econometrics and statistical physics,
cross-validation (CV) is used asa standard approach in quantifying the
generalisation performance of a statistical model. A directapplication of CV in
time-series leads to the loss of serial correlations, a requirement of
preserving anynon-stationarity and the prediction of the past data using the
future data. In this work, we proposea meta-algorithm called reconstructive
cross validation (rCV ) that avoids all these issues. At first,k folds are
formed with non-overlapping randomly selected subsets of the original
time-series. Then,we generate k new partial time-series by removing data points
from a given fold: every new partialtime-series have missing points at random
from a different entire fold. A suitable imputation or asmoothing technique is
used to reconstruct k time-series. We call these reconstructions
secondarymodels. Thereafter, we build the primary k time-series models using
new time-series coming fromthe secondary models. The performance of the primary
models are evaluated simultaneously bycomputing the deviations from the
originally removed data points and out-of-sample (OSS) data.Full
cross-validation in time-series models can be practiced with rCV along with
generating learning curves.",http://arxiv.org/pdf/1910.09394v3,stat.ML
2019-10-15 14:37:18+00:00,ODE guided Neural Data Augmentation Techniques for Time Series Data and its Benefits on Robustness,"['Anindya Sarkar', 'Anirudh Sunder Raj', 'Raghu Sesha Iyengar']","Exploring adversarial attack vectors and studying their effects on machine
learning algorithms has been of interest to researchers. Deep neural networks
working with time series data have received lesser interest compared to their
image counterparts in this context. In a recent finding, it has been revealed
that current state-of-the-art deep learning time series classifiers are
vulnerable to adversarial attacks. In this paper, we introduce two local
gradient based and one spectral density based time series data augmentation
techniques. We show that a model trained with data obtained using our
techniques obtains state-of-the-art classification accuracy on various time
series benchmarks. In addition, it improves the robustness of the model against
some of the most common corruption techniques,such as Fast Gradient Sign Method
(FGSM) and Basic Iterative Method (BIM).",http://arxiv.org/pdf/1910.06813v3,cs.LG
2019-10-14 21:46:03+00:00,Adaptive Transfer Learning of Multi-View Time Series Classification,"['Donglin Zhan', 'Shiyu Yi', 'Dongli Xu', 'Xiao Yu', 'Denglin Jiang', 'Siqi Yu', 'Haoting Zhang', 'Wenfang Shangguan', 'Weihua Zhang']","Time Series Classification (TSC) has been an important and challenging task
in data mining, especially on multivariate time series and multi-view time
series data sets. Meanwhile, transfer learning has been widely applied in
computer vision and natural language processing applications to improve deep
neural network's generalization capabilities. However, very few previous works
applied transfer learning framework to time series mining problems.
Particularly, the technique of measuring similarities between source domain and
target domain based on dynamic representation such as density estimation with
importance sampling has never been combined with transfer learning framework.
In this paper, we first proposed a general adaptive transfer learning framework
for multi-view time series data, which shows strong ability in storing
inter-view importance value in the process of knowledge transfer. Next, we
represented inter-view importance through some time series similarity
measurements and approximated the posterior distribution in latent space for
the importance sampling via density estimation techniques. We then computed the
matrix norm of sampled importance value, which controls the degree of knowledge
transfer in pre-training process. We further evaluated our work, applied it to
many other time series classification tasks, and observed that our architecture
maintained desirable generalization ability. Finally, we concluded that our
framework could be adapted with deep learning techniques to receive significant
model performance improvements.",http://arxiv.org/pdf/1910.07632v1,cs.LG
2019-10-14 18:21:33+00:00,Bayesian Temporal Factorization for Multidimensional Time Series Prediction,"['Xinyu Chen', 'Lijun Sun']","Large-scale and multidimensional spatiotemporal data sets are becoming
ubiquitous in many real-world applications such as monitoring urban traffic and
air quality. Making predictions on these time series has become a critical
challenge due to not only the large-scale and high-dimensional nature but also
the considerable amount of missing data. In this paper, we propose a Bayesian
temporal factorization (BTF) framework for modeling multidimensional time
series -- in particular spatiotemporal data -- in the presence of missing
values. By integrating low-rank matrix/tensor factorization and vector
autoregressive (VAR) process into a single probabilistic graphical model, this
framework can characterize both global and local consistencies in large-scale
time series data. The graphical model allows us to effectively perform
probabilistic predictions and produce uncertainty estimates without imputing
those missing values. We develop efficient Gibbs sampling algorithms for model
inference and model updating for real-time prediction and test the proposed BTF
framework on several real-world spatiotemporal data sets for both missing data
imputation and multi-step rolling prediction tasks. The numerical experiments
demonstrate the superiority of the proposed BTF approaches over existing
state-of-the-art methods.",http://arxiv.org/pdf/1910.06366v2,stat.ML
2019-10-13 08:30:31+00:00,Causal Mechanism Transfer Network for Time Series Domain Adaptation in Mechanical Systems,"['Zijian Li', 'Ruichu Cai', 'Kok Soon Chai', 'Hong Wei Ng', 'Hoang Dung Vu', 'Marianne Winslett', 'Tom Z. J. Fu', 'Boyan Xu', 'Xiaoyan Yang', 'Zhenjie Zhang']","Data-driven models are becoming essential parts in modern mechanical systems,
commonly used to capture the behavior of various equipment and varying
environmental characteristics. Despite the advantages of these data-driven
models on excellent adaptivity to high dynamics and aging equipment, they are
usually hungry to massive labels over historical data, mostly contributed by
human engineers at an extremely high cost. The label demand is now the major
limiting factor to modeling accuracy, hindering the fulfillment of visions for
applications. Fortunately, domain adaptation enhances the model generalization
by utilizing the labelled source data as well as the unlabelled target data and
then we can reuse the model on different domains. However, the mainstream
domain adaptation methods cannot achieve ideal performance on time series data,
because most of them focus on static samples and even the existing time series
domain adaptation methods ignore the properties of time series data, such as
temporal causal mechanism. In this paper, we assume that causal mechanism is
invariant and present our Causal Mechanism Transfer Network(CMTN) for time
series domain adaptation. By capturing and transferring the dynamic and
temporal causal mechanism of multivariate time series data and alleviating the
time lags and different value ranges among different machines, CMTN allows the
data-driven models to exploit existing data and labels from similar systems,
such that the resulting model on a new system is highly reliable even with very
limited data. We report our empirical results and lessons learned from two
real-world case studies, on chiller plant energy optimization and boiler fault
detection, which outperforms the existing state-of-the-art method.",http://arxiv.org/pdf/1910.06761v1,cs.LG
2019-10-10 16:49:18+00:00,Graph Spectral Embedding for Parsimonious Transmission of Multivariate Time Series,"['Lihan Yao', 'Paul Bendich']","We propose a graph spectral representation of time series data that 1) is
parsimoniously encoded to user-demanded resolution; 2) is unsupervised and
performant in data-constrained scenarios; 3) captures event and
event-transition structure within the time series; and 4) has near-linear
computational complexity in both signal length and ambient dimension. This
representation, which we call Laplacian Events Signal Segmentation (LESS), can
be computed on time series of arbitrary dimension and originating from sensors
of arbitrary type. Hence, time series originating from sensors of heterogeneous
type can be compressed to levels demanded by constrained-communication
environments, before being fused at a common center.
  Temporal dynamics of the data is summarized without explicit partitioning or
probabilistic modeling. As a proof-of-principle, we apply this technique on
high dimensional wavelet coefficients computed from the Free Spoken Digit
Dataset to generate a memory efficient representation that is interpretable.
Due to its unsupervised and non-parametric nature, LESS representations remain
performant in the digit classification task despite the absence of labels and
limited data.",http://arxiv.org/pdf/1910.04689v1,stat.ML
2019-10-10 02:53:28+00:00,Time series classification for varying length series,"['Chang Wei Tan', 'Francois Petitjean', 'Eamonn Keogh', 'Geoffrey I. Webb']","Research into time series classification has tended to focus on the case of
series of uniform length. However, it is common for real-world time series data
to have unequal lengths. Differing time series lengths may arise from a number
of fundamentally different mechanisms. In this work, we identify and evaluate
two classes of such mechanisms -- variations in sampling rate relative to the
relevant signal and variations between the start and end points of one time
series relative to one another. We investigate how time series generated by
each of these classes of mechanism are best addressed for time series
classification. We perform extensive experiments and provide practical
recommendations on how variations in length should be handled in time series
classification.",http://arxiv.org/pdf/1910.04341v1,cs.LG
2019-10-09 11:30:29+00:00,Probabilistic sequential matrix factorization,"['Ömer Deniz Akyildiz', 'Gerrit J. J. van den Burg', 'Theodoros Damoulas', 'Mark F. J. Steel']","We introduce the probabilistic sequential matrix factorization (PSMF) method
for factorizing time-varying and non-stationary datasets consisting of
high-dimensional time-series. In particular, we consider nonlinear Gaussian
state-space models where sequential approximate inference results in the
factorization of a data matrix into a dictionary and time-varying coefficients
with potentially nonlinear Markovian dependencies. The assumed Markovian
structure on the coefficients enables us to encode temporal dependencies into a
low-dimensional feature space. The proposed inference method is solely based on
an approximate extended Kalman filtering scheme, which makes the resulting
method particularly efficient. PSMF can account for temporal nonlinearities
and, more importantly, can be used to calibrate and estimate generic
differentiable nonlinear subspace models. We also introduce a robust version of
PSMF, called rPSMF, which uses Student-t filters to handle model
misspecification. We show that PSMF can be used in multiple contexts: modeling
time series with a periodic subspace, robustifying changepoint detection
methods, and imputing missing data in several high-dimensional time-series,
such as measurements of pollutants across London.",http://arxiv.org/pdf/1910.03906v3,stat.ML
2019-10-07 18:41:00+00:00,High-Dimensional Multivariate Forecasting with Low-Rank Gaussian Copula Processes,"['David Salinas', 'Michael Bohlke-Schneider', 'Laurent Callot', 'Roberto Medico', 'Jan Gasthaus']","Predicting the dependencies between observations from multiple time series is
critical for applications such as anomaly detection, financial risk management,
causal analysis, or demand forecasting. However, the computational and
numerical difficulties of estimating time-varying and high-dimensional
covariance matrices often limits existing methods to handling at most a few
hundred dimensions or requires making strong assumptions on the dependence
between series. We propose to combine an RNN-based time series model with a
Gaussian copula process output model with a low-rank covariance structure to
reduce the computational complexity and handle non-Gaussian marginal
distributions. This permits to drastically reduce the number of parameters and
consequently allows the modeling of time-varying correlations of thousands of
time series. We show on several real-world datasets that our method provides
significant accuracy improvements over state-of-the-art baselines and perform
an ablation study analyzing the contributions of the different components of
our model.",http://arxiv.org/pdf/1910.03002v2,cs.LG
2019-10-03 16:47:33+00:00,DPSOM: Deep Probabilistic Clustering with Self-Organizing Maps,"['Laura Manduchi', 'Matthias Hüser', 'Julia Vogt', 'Gunnar Rätsch', 'Vincent Fortuin']","Generating interpretable visualizations from complex data is a common problem
in many applications. Two key ingredients for tackling this issue are
clustering and representation learning. However, current methods do not yet
successfully combine the strengths of these two approaches. Existing
representation learning models which rely on latent topological structure such
as self-organising maps, exhibit markedly lower clustering performance compared
to recent deep clustering methods. To close this performance gap, we (a)
present a novel way to fit self-organizing maps with probabilistic cluster
assignments (PSOM), (b) propose a new deep architecture for probabilistic
clustering (DPSOM) using a VAE, and (c) extend our architecture for time-series
clustering (T-DPSOM), which also allows forecasting in the latent space using
LSTMs. We show that DPSOM achieves superior clustering performance compared to
current deep clustering methods on MNIST/Fashion-MNIST, while maintaining the
favourable visualization properties of SOMs. On medical time series, we show
that T-DPSOM outperforms baseline methods in time series clustering and time
series forecasting, while providing interpretable visualizations of patient
state trajectories and uncertainty estimation.",http://arxiv.org/pdf/1910.01590v3,cs.LG
2019-09-29 16:44:12+00:00,Machine Learning vs Statistical Methods for Time Series Forecasting: Size Matters,"['Vitor Cerqueira', 'Luis Torgo', 'Carlos Soares']","Time series forecasting is one of the most active research topics. Machine
learning methods have been increasingly adopted to solve these predictive
tasks. However, in a recent work, these were shown to systematically present a
lower predictive performance relative to simple statistical methods. In this
work, we counter these results. We show that these are only valid under an
extremely low sample size. Using a learning curve method, our results suggest
that machine learning methods improve their relative predictive performance as
the sample size grows. The code to reproduce the experiments is available at
https://github.com/vcerqueira/MLforForecasting.",http://arxiv.org/pdf/1909.13316v1,stat.ML
2019-09-26 16:42:13+00:00,Data Smashing 2.0: Sequence Likelihood (SL) Divergence For Fast Time Series Comparison,"['Yi Huang', 'Ishanu Chattopadhyay']","Recognizing subtle historical patterns is central to modeling and forecasting
problems in time series analysis. Here we introduce and develop a new approach
to quantify deviations in the underlying hidden generators of observed data
streams, resulting in a new efficiently computable universal metric for time
series. The proposed metric is in the sense that we can compare and contrast
data streams regardless of where and how they are generated and without any
feature engineering step. The approach proposed in this paper is conceptually
distinct from our previous work on data smashing, and vastly improves
discrimination performance and computing speed. The core idea here is the
generalization of the notion of KL divergence often used to compare probability
distributions to a notion of divergence in time series. We call this the
sequence likelihood (SL) divergence, which may be used to measure deviations
within a well-defined class of discrete-valued stochastic processes. We devise
efficient estimators of SL divergence from finite sample paths and subsequently
formulate a universal metric useful for computing distance between time series
produced by hidden stochastic generators.",http://arxiv.org/pdf/1909.12243v2,stat.ML
2019-09-26 12:52:43+00:00,Set Functions for Time Series,"['Max Horn', 'Michael Moor', 'Christian Bock', 'Bastian Rieck', 'Karsten Borgwardt']","Despite the eminent successes of deep neural networks, many architectures are
often hard to transfer to irregularly-sampled and asynchronous time series that
commonly occur in real-world datasets, especially in healthcare applications.
This paper proposes a novel approach for classifying irregularly-sampled time
series with unaligned measurements, focusing on high scalability and data
efficiency. Our method SeFT (Set Functions for Time Series) is based on recent
advances in differentiable set function learning, extremely parallelizable with
a beneficial memory footprint, thus scaling well to large datasets of long time
series and online monitoring scenarios. Furthermore, our approach permits
quantifying per-observation contributions to the classification outcome. We
extensively compare our method with existing algorithms on multiple healthcare
time series datasets and demonstrate that it performs competitively whilst
significantly reducing runtime.",http://arxiv.org/pdf/1909.12064v3,cs.LG
2019-09-25 10:36:30+00:00,Stationarity and Moment Properties of some Multivariate Count Autoregressions,"['Zinsou Max Debaly', 'Lionel Truquet']","We study stationarity and moments properties of some count time series models
from contraction and stability properties of iterated random maps. Both
univariate and multivariate processes are considered, including the recent
multivariate count time series models introduced recently by Doukhan et al.
(2017). We improve many existing results by providing optimal stationarity
conditions or conditions ensuring existence of some exponential moments.",http://arxiv.org/pdf/1909.11392v1,math.ST
2019-09-19 14:35:30+00:00,Shape and Time Distortion Loss for Training Deep Time Series Forecasting Models,"['Vincent Le Guen', 'Nicolas Thome']","This paper addresses the problem of time series forecasting for
non-stationary signals and multiple future steps prediction. To handle this
challenging task, we introduce DILATE (DIstortion Loss including shApe and
TimE), a new objective function for training deep neural networks. DILATE aims
at accurately predicting sudden changes, and explicitly incorporates two terms
supporting precise shape and temporal change detection. We introduce a
differentiable loss function suitable for training deep neural nets, and
provide a custom back-prop implementation for speeding up optimization. We also
introduce a variant of DILATE, which provides a smooth generalization of
temporally-constrained Dynamic Time Warping (DTW). Experiments carried out on
various non-stationary datasets reveal the very good behaviour of DILATE
compared to models trained with the standard Mean Squared Error (MSE) loss
function, and also to DTW and variants. DILATE is also agnostic to the choice
of the model, and we highlight its benefit for training fully connected
networks as well as specialized recurrent architectures, showing its capacity
to improve over state-of-the-art trajectory forecasting approaches.",http://arxiv.org/pdf/1909.09020v4,stat.ML
2019-09-19 08:37:54+00:00,Timage -- A Robust Time Series Classification Pipeline,"['Marc Wenninger', 'Sebastian P. Bayerl', 'Jochen Schmidt', 'Korbinian Riedhammer']","Time series are series of values ordered by time. This kind of data can be
found in many real world settings. Classifying time series is a difficult task
and an active area of research. This paper investigates the use of transfer
learning in Deep Neural Networks and a 2D representation of time series known
as Recurrence Plots. In order to utilize the research done in the area of image
classification, where Deep Neural Networks have achieved very good results, we
use a Residual Neural Networks architecture known as ResNet. As preprocessing
of time series is a major part of every time series classification pipeline,
the method proposed simplifies this step and requires only few parameters. For
the first time we propose a method for multi time series classification:
Training a single network to classify all datasets in the archive with one
network. We are among the first to evaluate the method on the latest 2018
release of the UCR archive, a well established time series classification
benchmarking dataset.",http://arxiv.org/pdf/1909.09149v1,cs.LG
2019-09-17 15:04:08+00:00,sktime: A Unified Interface for Machine Learning with Time Series,"['Markus Löning', 'Anthony Bagnall', 'Sajaysurya Ganesh', 'Viktor Kazakov', 'Jason Lines', 'Franz J. Király']","We present sktime -- a new scikit-learn compatible Python library with a
unified interface for machine learning with time series. Time series data gives
rise to various distinct but closely related learning tasks, such as
forecasting and time series classification, many of which can be solved by
reducing them to related simpler tasks. We discuss the main rationale for
creating a unified interface, including reduction, as well as the design of
sktime's core API, supported by a clear overview of common time series tasks
and reduction approaches.",http://arxiv.org/pdf/1909.07872v1,cs.LG
2019-09-17 00:16:31+00:00,Self-boosted Time-series Forecasting with Multi-task and Multi-view Learning,"['Long H. Nguyen', 'Zhenhe Pan', 'Opeyemi Openiyi', 'Hashim Abu-gellban', 'Mahdi Moghadasi', 'Fang Jin']","A robust model for time series forecasting is highly important in many
domains, including but not limited to financial forecast, air temperature and
electricity consumption. To improve forecasting performance, traditional
approaches usually require additional feature sets. However, adding more
feature sets from different sources of data is not always feasible due to its
accessibility limitation. In this paper, we propose a novel self-boosted
mechanism in which the original time series is decomposed into multiple time
series. These time series played the role of additional features in which the
closely related time series group is used to feed into multi-task learning
model, and the loosely related group is fed into multi-view learning part to
utilize its complementary information. We use three real-world datasets to
validate our model and show the superiority of our proposed method over
existing state-of-the-art baseline methods.",http://arxiv.org/pdf/1909.08181v1,cs.LG
2019-09-16 13:16:14+00:00,Estimating change points in nonparametric time series regression models,"['Maria Mohr', 'Leonie Selk']","In this paper we consider a regression model that allows for time series
covariates as well as heteroscedasticity with a regression function that is
modelled nonparametrically. We assume that the regression function changes at
some unknown time $\lfloor ns_0\rfloor$, $s_0\in(0,1)$, and our aim is to
estimate the (rescaled) change point $s_0$. The considered estimator is based
on a Kolmogorov-Smirnov functional of the marked empirical process of
residuals. We show consistency of the estimator and prove a rate of convergence
of $O_P(n^{-1})$ which in this case is clearly optimal as there are only $n$
points in the sequence. Additionally we investigate the case of lagged
dependent covariates, that is, autoregression models with a change in the
nonparametric (auto-) regression function and give a consistency result. The
method of proof also allows for different kinds of functionals such that
Cram\'er-von Mises type estimators can be considered similarly. The approach
extends existing literature by allowing nonparametric models, time series data
as well as heteroscedasticity. Finite sample simulations indicate the good
performance of our estimator in regression as well as autoregression models and
a real data example shows its applicability in practise.",http://arxiv.org/pdf/1909.07178v1,math.ST
2019-09-16 09:26:00+00:00,Towards a Rigorous Evaluation of XAI Methods on Time Series,"['Udo Schlegel', 'Hiba Arnout', 'Mennatallah El-Assady', 'Daniela Oelke', 'Daniel A. Keim']","Explainable Artificial Intelligence (XAI) methods are typically deployed to
explain and debug black-box machine learning models. However, most proposed XAI
methods are black-boxes themselves and designed for images. Thus, they rely on
visual interpretability to evaluate and prove explanations. In this work, we
apply XAI methods previously used in the image and text-domain on time series.
We present a methodology to test and evaluate various XAI methods on time
series by introducing new verification techniques to incorporate the temporal
dimension. We further conduct preliminary experiments to assess the quality of
selected XAI method explanations with various verification methods on a range
of datasets and inspecting quality metrics on it. We demonstrate that in our
initial experiments, SHAP works robust for all models, but others like
DeepLIFT, LRP, and Saliency Maps work better with specific architectures.",http://arxiv.org/pdf/1909.07082v2,cs.LG
2019-09-14 16:24:28+00:00,High-dimensional vector autoregressive time series modeling via tensor decomposition,"['Di Wang', 'Yao Zheng', 'Heng Lian', 'Guodong Li']","The classical vector autoregressive model is a fundamental tool for
multivariate time series analysis. However, it involves too many parameters
when the number of time series and lag order are even moderately large. This
paper proposes to rearrange the transition matrices of the model into a tensor
form such that the parameter space can be restricted along three directions
simultaneously via tensor decomposition. In contrast, the reduced-rank
regression method can restrict the parameter space in only one direction.
Besides achieving substantial dimension reduction, the proposed model is
interpretable from the factor modeling perspective. Moreover, to handle
high-dimensional time series, this paper considers imposing sparsity on factor
matrices to improve the model interpretability and estimation efficiency, which
leads to a sparsity-inducing estimator. For the low-dimensional case, we derive
asymptotic properties of the proposed least squares estimator and introduce an
alternating least squares algorithm. For the high-dimensional case, we
establish non-asymptotic properties of the sparsity-inducing estimator and
propose an ADMM algorithm for regularized estimation. Simulation experiments
and a real data example demonstrate the advantages of the proposed approach
over various existing methods.",http://arxiv.org/pdf/1909.06624v2,stat.ME
2019-09-13 21:18:06+00:00,Interpolation-Prediction Networks for Irregularly Sampled Time Series,"['Satya Narayan Shukla', 'Benjamin M. Marlin']","In this paper, we present a new deep learning architecture for addressing the
problem of supervised learning with sparse and irregularly sampled multivariate
time series. The architecture is based on the use of a semi-parametric
interpolation network followed by the application of a prediction network. The
interpolation network allows for information to be shared across multiple
dimensions of a multivariate time series during the interpolation stage, while
any standard deep learning model can be used for the prediction network. This
work is motivated by the analysis of physiological time series data in
electronic health records, which are sparse, irregularly sampled, and
multivariate. We investigate the performance of this architecture on both
classification and regression tasks, showing that our approach outperforms a
range of baseline and recently proposed models.",http://arxiv.org/pdf/1909.07782v1,cs.LG
2019-09-13 15:58:20+00:00,Multiscale Jump Testing and Estimation Under Complex Temporal Dynamics,"['Weichi Wu', 'Zhou Zhou']","We consider the problem of detecting jumps in an otherwise smoothly evolving
trend whilst the covariance and higher-order structures of the system can
experience both smooth and abrupt changes over time. The number of jump points
is allowed to diverge to infinity with the jump sizes possibly shrinking to
zero. The method is based on a multiscale application of an optimal jump-pass
filter to the time series, where the scales are dense between admissible lower
and upper bounds. For a wide class of non-stationary time series models and
trend functions, the proposed method is shown to be able to detect all jump
points within a nearly optimal range with a prescribed probability
asymptotically under mild conditions. For a time series of length $n$, the
computational complexity of the proposed method is $O(n)$ for each scale and
$O(n\log^{1+\epsilon} n)$ overall, where $\epsilon$ is an arbitrarily small
positive constant. Numerical studies show that the proposed jump testing and
estimation method performs robustly and accurately under complex temporal
dynamics.",http://arxiv.org/pdf/1909.06307v3,stat.ME
2019-09-13 09:17:07+00:00,Two-sample tests for relevant differences in the eigenfunctions of covariance operators,"['Alexander Aue', 'Holger Dette', 'Gregory Rice']","This paper deals with two-sample tests for functional time series data, which
have become widely available in conjunction with the advent of modern complex
observation systems. Here, particular interest is in evaluating whether two
sets of functional time series observations share the shape of their primary
modes of variation as encoded by the eigenfunctions of the respective
covariance operators. To this end, a novel testing approach is introduced that
connects with, and extends, existing literature in two main ways. First, tests
are set up in the relevant testing framework, where interest is not in testing
an exact null hypothesis but rather in detecting deviations deemed sufficiently
relevant, with relevance determined by the practitioner and perhaps guided by
domain experts. Second, the proposed test statistics rely on a
self-normalization principle that helps to avoid the notoriously difficult task
of estimating the long-run covariance structure of the underlying functional
time series. The main theoretical result of this paper is the derivation of the
large-sample behavior of the proposed test statistics. Empirical evidence,
indicating that the proposed procedures work well in finite samples and compare
favorably with competing methods, is provided through a simulation study, and
an application to annual temperature data.",http://arxiv.org/pdf/1909.06098v1,math.ST
2019-09-13 08:31:00+00:00,Functional Time Series Analysis Based on Records,"['Israel Martínez-Hernández', 'Marc G. Genton']","In many phenomena, data are collected on a large scale and of different
frequencies. In this context, functional data analysis (FDA) has become an
important statistical methodology for analyzing and modeling such data. The
approach of FDA is to assume that data are continuous functions and that each
continuous function is considered as a single observation. Thus, FDA deals with
large-scale and complex data. However, visualization and exploratory data
analysis, which is very important in practice, can be challenging due to the
complexity of the continuous functions. Here we propose some nonparametric
tools for functional data observed over time (functional time series). For
that, we propose to use the concept of record. We study the properties of the
trajectory of the number of record curves under different scenarios. Also, we
propose a unit root test based on the number of records. The trajectory of the
number of records over time and the unit root test can be used as visualization
and exploratory data analysis. We illustrate the advantages of our proposal
through a Monte Carlo simulation study. We also illustrate our method on two
different datasets: Annual mortality rates in France and daily wind speed
curves at Yanbu, Saudi Arabia. Overall, we can identify the type of functional
time series being studied based on the number of record curves observed.",http://arxiv.org/pdf/1909.06083v2,stat.ME
2019-09-12 15:01:30+00:00,"A tale of two toolkits, report the first: benchmarking time series classification algorithms for correctness and efficiency","['Anthony Bagnall', 'Franz Király', 'Markus Löning', 'Matthew Middlehurst', 'George Oastler']","sktime is an open source, Python based, sklearn compatible toolkit for time
series analysis developed by researchers at the University of East Anglia
(UEA), University College London and the Alan Turing Institute. A key initial
goal for sktime was to provide time series classification functionality
equivalent to that available in a related java package, tsml, also developed at
UEA. We describe the implementation of six such classifiers in sktime and
compare them to their tsml equivalents. We demonstrate correctness through
equivalence of accuracy on a range of standard test problems and compare the
build time of the different implementations. We find that there is significant
difference in accuracy on only one of the six algorithms we look at (Proximity
Forest). This difference is causing us some pain in debugging. We found a much
wider range of difference in efficiency. Again, this was not unexpected, but it
does highlight ways both toolkits could be improved.",http://arxiv.org/pdf/1909.05738v3,cs.LG
2019-09-11 09:32:40+00:00,InceptionTime: Finding AlexNet for Time Series Classification,"['Hassan Ismail Fawaz', 'Benjamin Lucas', 'Germain Forestier', 'Charlotte Pelletier', 'Daniel F. Schmidt', 'Jonathan Weber', 'Geoffrey I. Webb', 'Lhassane Idoumghar', 'Pierre-Alain Muller', 'François Petitjean']","This paper brings deep learning at the forefront of research into Time Series
Classification (TSC). TSC is the area of machine learning tasked with the
categorization (or labelling) of time series. The last few decades of work in
this area have led to significant progress in the accuracy of classifiers, with
the state of the art now represented by the HIVE-COTE algorithm. While
extremely accurate, HIVE-COTE cannot be applied to many real-world datasets
because of its high training time complexity in O(N2 * T4) for a dataset with N
time series of length T. For example, it takes HIVE-COTE more than 8 days to
learn from a small dataset with N = 1500 time series of short length T = 46.
Meanwhile deep learning has received enormous attention because of its high
accuracy and scalability. Recent approaches to deep learning for TSC have been
scalable, but less accurate than HIVE-COTE. We introduce InceptionTime - an
ensemble of deep Convolutional Neural Network (CNN) models, inspired by the
Inception-v4 architecture. Our experiments show that InceptionTime is on par
with HIVE-COTE in terms of accuracy while being much more scalable: not only
can it learn from 1,500 time series in one hour but it can also learn from 8M
time series in 13 hours, a quantity of data that is fully out of reach of
HIVE-COTE.",http://arxiv.org/pdf/1909.04939v3,cs.LG
2019-09-06 14:27:51+00:00,BNB autoregressions for modeling integer-valued time series with extreme observations,['Paolo Gorgi'],"This article introduces a general class of heavy-tailed autoregressions for
modeling integer-valued time series with outliers. The proposed specification
is based on a heavy-tailed mixture of negative binomial distributions that
features an observation-driven dynamic equation for the conditional
expectation. The existence of a unique stationary and ergodic solution for the
class of autoregressive processes is shown under a general contraction
condition. The estimation of the model can be easily performed by Maximum
Likelihood given the closed form of the likelihood function. The strong
consistency and the asymptotic normality of the estimator are formally derived.
Two examples of specifications illustrate the flexibility of the approach and
the relevance of the theoretical results. In particular, a linear dynamic
equation and a score-driven equation for the conditional expectation are
considered. The score-driven specification is shown to be particularly
appealing as it delivers a robust filtering method that attenuates the impact
of outliers. An empirical application to the time series of narcotics
trafficking reports in Sydney illustrates the effectiveness of the method in
handling extreme observations.",http://arxiv.org/pdf/1909.02929v1,math.ST
2019-08-31 14:14:33+00:00,Déjà vu: A data-centric forecasting approach through time series cross-similarity,"['Yanfei Kang', 'Evangelos Spiliotis', 'Fotios Petropoulos', 'Nikolaos Athiniotis', 'Feng Li', 'Vassilios Assimakopoulos']","Accurate forecasts are vital for supporting the decisions of modern
companies. Forecasters typically select the most appropriate statistical model
for each time series. However, statistical models usually presume some data
generation process while making strong assumptions about the errors. In this
paper, we present a novel data-centric approach -- `forecasting with
similarity', which tackles model uncertainty in a model-free manner. Existing
similarity-based methods focus on identifying similar patterns within the
series, i.e., `self-similarity'. In contrast, we propose searching for similar
patterns from a reference set, i.e., `cross-similarity'. Instead of
extrapolating, the future paths of the similar series are aggregated to obtain
the forecasts of the target series. Building on the cross-learning concept, our
approach allows the application of similarity-based forecasting on series with
limited lengths. We evaluate the approach using a rich collection of real data
and show that it yields competitive accuracy in both points forecasts and
prediction intervals.",http://arxiv.org/pdf/1909.00221v3,stat.ME
2019-08-29 22:13:27+00:00,A robust approach for testing parameter change in Poisson autoregressive models,"['Jiwon Kang', 'Junmo Song']","Parameter change test has been an important issue in time series analysis.
The problem has also been actively explored in the field of integer-valued time
series, but the testing in the presence of outliers has not yet been
extensively investigated. This study considers the problem of testing for
parameter change in Poisson autoregressive models particularly when
observations are contaminated by outliers. To lessen the impact of outliers on
testing procedure, we propose a test based on the density power divergence,
which is introduced by Basu et al. (Biometrika, 1998), and derive its limiting
null distribution. Monte Carlo simulation results demonstrate validity and
strong robustness of the proposed test.",http://arxiv.org/pdf/1908.11466v1,stat.ME
2019-08-27 13:36:08+00:00,Fourier-type monitoring procedures for strict stationarity,"['Sangyeol Lee', 'Simos G. Meintanis', 'Charl Pretorius']","We consider model-free monitoring procedures for strict stationarity of a
given time series. The new criteria are formulated as L2-type statistics
incorporating the empirical characteristic function. Asymptotic as well as
Monte Carlo results are presented. The new methods are also employed in order
to test for possible stationarity breaks in time-series data from the financial
sector.",http://arxiv.org/pdf/1908.10191v1,math.ST
2019-08-24 22:00:39+00:00,Heterogeneous Relational Kernel Learning,"['Andre T. Nguyen', 'Edward Raff']","Recent work has developed Bayesian methods for the automatic statistical
analysis and description of single time series as well as of homogeneous sets
of time series data. We extend prior work to create an interpretable kernel
embedding for heterogeneous time series. Our method adds practically no
computational cost compared to prior results by leveraging previously discarded
intermediate results. We show the practical utility of our method by leveraging
the learned embeddings for clustering, pattern discovery, and anomaly
detection. These applications are beyond the ability of prior relational kernel
learning approaches.",http://arxiv.org/pdf/1908.09219v1,cs.LG
2019-08-22 16:49:30+00:00,Time series model selection with a meta-learning approach; evidence from a pool of forecasting algorithms,"['Sasan Barak', 'Mahdi Nasiri', 'Mehrdad Rostamzadeh']","One of the challenging questions in time series forecasting is how to find
the best algorithm. In recent years, a recommender system scheme has been
developed for time series analysis using a meta-learning approach. This system
selects the best forecasting method with consideration of the time series
characteristics. In this paper, we propose a novel approach to focusing on some
of the unanswered questions resulting from the use of meta-learning in time
series forecasting. Therefore, three main gaps in previous works are addressed
including, analyzing various subsets of top forecasters as inputs for
meta-learners; evaluating the effect of forecasting error measures; and
assessing the role of the dimensionality of the feature space on the
forecasting errors of meta-learners. All of these objectives are achieved with
the help of a diverse state-of-the-art pool of forecasters and meta-learners.
For this purpose, first, a pool of forecasting algorithms is implemented on the
NN5 competition dataset and ranked based on the two error measures. Then, six
machine-learning classifiers known as meta-learners, are trained on the
extracted features of the time series in order to assign the most suitable
forecasting method for the various subsets of the pool of forecasters.
Furthermore, two-dimensionality reduction methods are implemented in order to
investigate the role of feature space dimension on the performance of
meta-learners. In general, it was found that meta-learners were able to defeat
all of the individual benchmark forecasters; this performance was improved even
after applying the feature selection method.",http://arxiv.org/pdf/1908.08489v1,stat.ML
2019-08-19 12:55:55+00:00,Bayesian approach to Lorenz curve using time series grouped data,"['Genya Kobayashi', 'Yuta Yamauchi', 'Kazuhiko Kakamu', 'Yuki Kawakubo', 'Shonosuke Sugasawa']","This study is concerned with estimating the inequality measures associated
with the underlying hypothetical income distribution from the times series
grouped data on the Lorenz curve. We adopt the Dirichlet pseudo likelihood
approach where the parameters of the Dirichlet likelihood are set to the
differences between the Lorenz curve of the hypothetical income distribution
for the consecutive income classes and propose a state space model which
combines the transformed parameters of the Lorenz curve through a time series
structure. Furthermore, the information on the sample size in each survey is
introduced into the originally nuisance Dirichlet precision parameter to take
into account the variability from the sampling. From the simulated data and
real data on the Japanese monthly income survey, it is confirmed that the
proposed model produces more efficient estimates on the inequality measures
than the existing models without time series structures.",http://arxiv.org/pdf/1908.06772v1,stat.ME
2019-08-19 07:27:15+00:00,AdaptSPEC-X: Covariate Dependent Spectral Modeling of Multiple Nonstationary Time Series,"['Michael Bertolacci', 'Ori Rosen', 'Edward Cripps', 'Sally Cripps']","We present a method for the joint analysis of a panel of possibly
nonstationary time series. The approach is Bayesian and uses a
covariate-dependent infinite mixture model to incorporate multiple time series,
with mixture components parameterized by a time varying mean and log spectrum.
The mixture components are based on AdaptSPEC, a nonparametric model which
adaptively divides the time series into an unknown number of segments and
estimates the local log spectra by smoothing splines. We extend AdaptSPEC to
handle missing values, a common feature of time series which can cause
difficulties for nonparametric spectral methods. A second extension is to allow
for a time varying mean. Covariates, assumed to be time-independent, are
incorporated via the mixture weights using the logistic stick breaking process.
The model can estimate time varying means and spectra at observed and
unobserved covariate values, allowing for predictive inference. Estimation is
performed by Markov chain Monte Carlo (MCMC) methods, combining data
augmentation, reversible jump, and Riemann manifold Hamiltonian Monte Carlo
techniques. We evaluate the methodology using simulated data, and describe
applications to Australian rainfall data and measles incidence in the US.
Software implementing the method proposed in this paper is available in the R
package BayesSpec.",http://arxiv.org/pdf/1908.06622v2,stat.ME
2019-08-18 17:19:16+00:00,Independence Testing for Multivariate Time Series,"['Ronak Mehta', 'Jaewon Chung', 'Cencheng Shen', 'Ting Xu', 'Joshua T. Vogelstein']","Complex data structures such as time series are increasingly present in
modern data science problems. A fundamental question is whether two such
time-series are statistically dependent. Many current approaches make
parametric assumptions on the random processes, only detect linear association,
require multiple tests, or forfeit power in high-dimensional, nonlinear
settings. Estimating the distribution of any test statistic under the null is
non-trivial, as the permutation test is invalid. This work juxtaposes distance
correlation (Dcorr) and multiscale graph correlation (MGC) from independence
testing literature and block permutation from time series analysis to address
these challenges. The proposed nonparametric procedure is valid and consistent,
building upon prior work by characterizing the geometry of the relationship,
estimating the time lag at which dependence is maximized, avoiding the need for
multiple testing, and exhibiting superior power in high-dimensional, low sample
size, nonlinear settings. Neural connectivity is analyzed via fMRI data,
revealing linear dependence of signals within the visual network and default
mode network, and nonlinear relationships in other networks. This work uncovers
a first-resort data analysis tool with open-source code available, directly
impacting a wide range of scientific disciplines.",http://arxiv.org/pdf/1908.06486v3,stat.ML
2019-08-17 08:49:42+00:00,Chaotic Time Series Prediction using Spatio-Temporal RBF Neural Networks,"['Alishba Sadiq', 'Muhammad Sohail Ibrahim', 'Muhammad Usman', 'Muhammad Zubair', 'Shujaat Khan']","Due to the dynamic nature, chaotic time series are difficult predict. In
conventional signal processing approaches signals are treated either in time or
in space domain only. Spatio-temporal analysis of signal provides more
advantages over conventional uni-dimensional approaches by harnessing the
information from both the temporal and spatial domains. Herein, we propose an
spatio-temporal extension of RBF neural networks for the prediction of chaotic
time series. The proposed algorithm utilizes the concept of time-space
orthogonality and separately deals with the temporal dynamics and spatial
non-linearity(complexity) of the chaotic series. The proposed RBF architecture
is explored for the prediction of Mackey-Glass time series and results are
compared with the standard RBF. The spatio-temporal RBF is shown to out perform
the standard RBFNN by achieving significantly reduced estimation error.",http://arxiv.org/pdf/1908.08389v1,stat.ML
2019-08-14 20:29:41+00:00,Mixed pooling of seasonality for time series forecasting: An application to pallet transport data,"['Hyunji Moon', 'Bomi Song', 'Hyeonseop Lee']","Multiple seasonal patterns play a key role in time series forecasting,
especially for business time series where seasonal effects are often dramatic.
Previous approaches including Fourier decomposition, exponential smoothing, and
seasonal autoregressive integrated moving average (SARIMA) models do not
reflect the distinct characteristics of each period in seasonal patterns. We
propose a mixed hierarchical seasonality (MHS) model. Intermediate parameters
for each seasonal period are first estimated, and a mixture of intermediate
parameters is taken. This results in a model that automatically learns the
relative importance of each seasonality and addresses the interactions between
them. The model is implemented with Stan, a probabilistic language, and was
compared with three existing models on a real-world dataset of pallet transport
from a logistic network. Our new model achieved considerable improvements in
terms of out of sample prediction error (MAPE) and predictive density (ELPD)
compared to complete pooling, Fourier decomposition, and SARIMA model.",http://arxiv.org/pdf/1908.05339v2,stat.ML
2019-08-13 19:46:26+00:00,Local Score Dependent Model Explanation for Time Dependent Covariates,"['Xochitl Watts', 'Freddy Lecue']","The use of deep neural networks to make high risk decisions creates a need
for global and local explanations so that users and experts have confidence in
the modeling algorithms. We introduce a novel technique to find global and
local explanations for time series data used in binary classification machine
learning systems. We identify the most salient of the original features used by
a black box model to distinguish between classes. The explanation can be made
on categorical, continuous, and time series data and can be generalized to any
binary classification model. The analysis is conducted on time series data to
train a long short-term memory deep neural network and uses the time dependent
structure of the underlying features in the explanation. The proposed technique
attributes weights to features to explain an observations risk of belonging to
a class as a multiplicative factor of a base hazard rate. We use a variation of
the Cox Proportional Hazards regression, a Generalized Additive Model, to
explain the effect of variables upon the probability of an in-class response
for a score output from the black box model. The covariates incorporate time
dependence structure in the features so the explanation is inclusive of the
underlying time series data structure.",http://arxiv.org/pdf/1908.04839v1,cs.LG
2019-08-10 13:58:54+00:00,Autoregressive-Model-Based Methods for Online Time Series Prediction with Missing Values: an Experimental Evaluation,"['Xi Chen', 'Hongzhi Wang', 'Yanjie Wei', 'Jianzhong Li', 'Hong Gao']","Time series prediction with missing values is an important problem of time
series analysis since complete data is usually hard to obtain in many
real-world applications. To model the generation of time series, autoregressive
(AR) model is a basic and widely used one, which assumes that each observation
in the time series is a noisy linear combination of some previous observations
along with a constant shift. To tackle the problem of prediction with missing
values, a number of methods were proposed based on various data models. For
real application scenarios, how do these methods perform over different types
of time series with different levels of data missing remains to be
investigated. In this paper, we focus on online methods for AR-model-based time
series prediction with missing values. We adapted five mainstream methods to
fit in such a scenario. We make detailed discussion on each of them by
introducing their core ideas about how to estimate the AR coefficients and
their different strategies to deal with missing values. We also present
algorithmic implementations for better understanding. In order to
comprehensively evaluate these methods and do the comparison, we conduct
experiments with various configurations of relative parameters over both
synthetic and real data. From the experimental results, we derived several
noteworthy conclusions and shows that imputation is a simple but reliable
strategy to handle missing values in online prediction tasks.",http://arxiv.org/pdf/1908.06729v2,stat.ML
2019-08-09 13:46:48+00:00,LSTM-based Flow Prediction,"['Hongzhi Wang', 'Yang Song', 'Shihan Tang']","In this paper, a method of prediction on continuous time series variables
from the production or flow -- an LSTM algorithm based on multivariate tuning
-- is proposed. The algorithm improves the traditional LSTM algorithm and
converts the time series data into supervised learning sequences regarding
industrial data's features. The main innovation of this paper consists in
introducing the concepts of periodic measurement and time window in the
industrial prediction problem, especially considering industrial data with time
series characteristics. Experiments using real-world datasets show that the
prediction accuracy is improved, 54.05% higher than that of traditional LSTM
algorithm.",http://arxiv.org/pdf/1908.03571v1,cs.LG
2019-08-09 10:49:07+00:00,TEASER: Early and Accurate Time Series Classification,"['P. Schäfer', 'U. Leser']","Early time series classification (eTSC) is the problem of classifying a time
series after as few measurements as possible with the highest possible
accuracy. The most critical issue of any eTSC method is to decide when enough
data of a time series has been seen to take a decision: Waiting for more data
points usually makes the classification problem easier but delays the time in
which a classification is made; in contrast, earlier classification has to cope
with less input data, often leading to inferior accuracy. The state-of-the-art
eTSC methods compute a fixed optimal decision time assuming that every times
series has the same defined start time (like turning on a machine). However, in
many real-life applications measurements start at arbitrary times (like
measuring heartbeats of a patient), implying that the best time for taking a
decision varies heavily between time series. We present TEASER, a novel
algorithm that models eTSC as a two two-tier classification problem: In the
first tier, a classifier periodically assesses the incoming time series to
compute class probabilities. However, these class probabilities are only used
as output label if a second-tier classifier decides that the predicted label is
reliable enough, which can happen after a different number of measurements. In
an evaluation using 45 benchmark datasets, TEASER is two to three times earlier
at predictions than its competitors while reaching the same or an even higher
classification accuracy. We further show TEASER's superior performance using
real-life use cases, namely energy monitoring, and gait detection.",http://arxiv.org/pdf/1908.03405v2,cs.LG
2019-08-08 14:27:00+00:00,Application of Levy Processes in Modelling (Geodetic) Time Series With Mixed Spectra,"['J. P. Montillet', 'X. He', 'K. Yu']","Recently, various models have been developed, including the fractional
Brownian motion (fBm), to analyse the stochastic properties of geodetic time
series, together with the extraction of geophysical signals. The noise spectrum
of these time series is generally modeled as a mixed spectrum, with a sum of
white and coloured noise. Here, we are interested in modelling the residual
time series, after deterministically subtracting geophysical signals from the
observations. This residual time series is then assumed to be a sum of three
random variables (r.v.), with the last r.v. belonging to the family of Levy
processes. This stochastic term models the remaining residual signals and other
correlated processes. Via simulations and real time series, we identify three
classes of Levy processes: Gaussian, fractional and stable. In the first case,
residuals are predominantly constituted of short-memory processes. Fractional
Levy process can be an alternative model to the fBm in the presence of
long-term correlations and self-similarity property. Stable process is
characterized by a large variance, which can be satisfied in the case of
heavy-tailed distributions. The application to geodetic time series imply
potential anxiety in the functional model selection where missing geophysical
information can generate such residual time series.",http://arxiv.org/pdf/1908.11736v1,stat.ME
2019-08-08 00:52:55+00:00,The uncertainty estimation of feature-based forecast combinations,"['Xiaoqian Wang', 'Yanfei Kang', 'Fotios Petropoulos', 'Feng Li']","Forecasting is an indispensable element of operational research (OR) and an
important aid to planning. The accurate estimation of the forecast uncertainty
facilitates several operations management activities, predominantly in
supporting decisions in inventory and supply chain management and effectively
setting safety stocks. In this paper, we introduce a feature-based framework,
which links the relationship between time series features and the interval
forecasting performance into providing reliable interval forecasts. We propose
an optimal threshold ratio searching algorithm and a new weight determination
mechanism for selecting an appropriate subset of models and assigning
combination weights for each time series tailored to the observed features. We
evaluate our approach using a large set of time series from the M4 competition.
Our experiments show that our approach significantly outperforms a wide range
of benchmark models, both in terms of point forecasts as well as prediction
intervals.",http://arxiv.org/pdf/1908.02891v3,stat.ME
2019-08-07 20:52:19+00:00,Self-Organizing Maps with Variable Input Length for Motif Discovery and Word Segmentation,"['Raphael C. Brito', 'Hansenclever F. Bassani']","Time Series Motif Discovery (TSMD) is defined as searching for patterns that
are previously unknown and appear with a given frequency in time series.
Another problem strongly related with TSMD is Word Segmentation. This problem
has received much attention from the community that studies early language
acquisition in babies and toddlers. The development of biologically plausible
models for word segmentation could greatly advance this field. Therefore, in
this article, we propose the Variable Input Length Map (VILMAP) for Motif
Discovery and Word Segmentation. The model is based on the Self-Organizing Maps
and can identify Motifs with different lengths in time series. In our
experiments, we show that VILMAP presents good results in finding Motifs in a
standard Motif discovery dataset and can avoid catastrophic forgetting when
trained with datasets with increasing values of input size. We also show that
VILMAP achieves results similar or superior to other methods in the literature
developed for the task of word segmentation.",http://arxiv.org/pdf/1908.02830v1,cs.LG
2019-08-03 10:38:22+00:00,Developing an Unsupervised Real-time Anomaly Detection Scheme for Time Series with Multi-seasonality,"['Wentai Wu', 'Ligang He', 'Weiwei Lin', 'Yi Su', 'Yuhua Cui', 'Carsten Maple', 'Stephen Jarvis']","On-line detection of anomalies in time series is a key technique used in
various event-sensitive scenarios such as robotic system monitoring, smart
sensor networks and data center security. However, the increasing diversity of
data sources and the variety of demands make this task more challenging than
ever. Firstly, the rapid increase in unlabeled data means supervised learning
is becoming less suitable in many cases. Secondly, a large portion of time
series data have complex seasonality features. Thirdly, on-line anomaly
detection needs to be fast and reliable. In light of this, we have developed a
prediction-driven, unsupervised anomaly detection scheme, which adopts a
backbone model combining the decomposition and the inference of time series
data. Further, we propose a novel metric, Local Trend Inconsistency (LTI), and
an efficient detection algorithm that computes LTI in a real-time manner and
scores each data point robustly in terms of its probability of being anomalous.
We have conducted extensive experimentation to evaluate our algorithm with
several datasets from both public repositories and production environments. The
experimental results show that our scheme outperforms existing representative
anomaly detection algorithms in terms of the commonly used metric, Area Under
Curve (AUC), while achieving the desired efficiency.",http://arxiv.org/pdf/1908.01146v3,cs.LG
2019-08-02 20:15:56+00:00,Linear Dynamics: Clustering without identification,"['Chloe Ching-Yun Hsu', 'Michaela Hardt', 'Moritz Hardt']","Linear dynamical systems are a fundamental and powerful parametric model
class. However, identifying the parameters of a linear dynamical system is a
venerable task, permitting provably efficient solutions only in special cases.
This work shows that the eigenspectrum of unknown linear dynamics can be
identified without full system identification. We analyze a computationally
efficient and provably convergent algorithm to estimate the eigenvalues of the
state-transition matrix in a linear dynamical system.
  When applied to time series clustering, our algorithm can efficiently cluster
multi-dimensional time series with temporal offsets and varying lengths, under
the assumption that the time series are generated from linear dynamical
systems. Evaluating our algorithm on both synthetic data and real
electrocardiogram (ECG) signals, we see improvements in clustering quality over
existing baselines.",http://arxiv.org/pdf/1908.01039v3,cs.LG
2019-08-02 09:00:14+00:00,Inferring linear and nonlinear Interaction networks using neighborhood support vector machines,"['Kamel Jebreen', 'Badih Ghattas']","In this paper, we consider modelling interaction between a set of variables
in the context of time series and high dimension. We suggest two approaches.
The first is similar to the neighborhood lasso when the lasso model is replaced
by a support vector machine (SVMs). The second is a restricted Bayesian network
adapted for time series. We show the efficiency of our approaches by
simulations using linear, nonlinear data set and a mixture of both.",http://arxiv.org/pdf/1908.00762v1,stat.ML
2019-08-01 11:29:29+00:00,Forecasting functional time series using weighted likelihood methodology,"['Ufuk Beyaztas', 'Han Lin Shang']","Functional time series whose sample elements are recorded sequentially over
time are frequently encountered with increasing technology. Recent studies have
shown that analyzing and forecasting of functional time series can be performed
easily using functional principal component analysis and existing
univariate/multivariate time series models. However, the forecasting
performance of such functional time series models may be affected by the
presence of outlying observations which are very common in many scientific
fields. Outliers may distort the functional time series model structure, and
thus, the underlying model may produce high forecast errors. We introduce a
robust forecasting technique based on weighted likelihood methodology to obtain
point and interval forecasts in functional time series in the presence of
outliers. The finite sample performance of the proposed method is illustrated
by Monte Carlo simulations and four real-data examples. Numerical results
reveal that the proposed method exhibits superior performance compared with the
existing method(s).",http://arxiv.org/pdf/1908.00336v1,stat.ME
2019-07-31 14:43:27+00:00,Coupling and perturbation techniques for categorical time series,['Lionel Truquet'],"We present a general approach for studying autoregressive categorical time
series models with dependence of infinite order and defined conditional on an
exogenous covariate process. To this end, we adapt a coupling approach,
developed in the literature for bounding the relaxation speed of a chain with
complete connection and from which we derive a perturbation result for
non-homogenous versions of such chains. We then study stationarity, ergodicity
and dependence properties of some chains with complete connections and
exogenous covariates. As a consequence, we obtain a general framework for
studying some observation-driven time series models used both in statistics and
econometrics but without theoretical support.",http://arxiv.org/pdf/1907.13533v1,math.ST
2019-07-26 23:13:46+00:00,Scalable Dictionary Classifiers for Time Series Classification,"['Matthew Middlehurst', 'William Vickers', 'Anthony Bagnall']","Dictionary based classifiers are a family of algorithms for time series
classification (TSC), that focus on capturing the frequency of pattern
occurrences in a time series. The ensemble based Bag of Symbolic Fourier
Approximation Symbols (BOSS) was found to be a top performing TSC algorithm in
a recent evaluation, as well as the best performing dictionary based
classifier. A recent addition to the category, the Word Extraction for Time
Series Classification (WEASEL), claims an improvement on this performance. Both
of these algorithms however have non-trivial scalability issues, taking a
considerable amount of build time and space on larger datasets. We evaluate
changes to the way BOSS chooses classifiers for its ensemble, replacing its
parameter search with random selection. This change allows for the easy
implementation of contracting, setting a build time limit for the classifier
and check-pointing, saving progress during the classifiers build. To
differentiate between the two BOSS ensemble methods we refer to our randomised
version as RBOSS. Additionally we test the application of common ensembling
techniques to help retain accuracy from the loss of the BOSS parameter search.
We achieve a significant reduction in build time without a significant change
in accuracy on average when compared to BOSS by creating a size $n$ weighted
ensemble selecting the best performers from $k$ randomly chosen parameter sets.
Our experiments are conducted on datasets from the recently expanded UCR time
series archive. We demonstrate the usability improvements to RBOSS with a case
study using a large whale acoustics dataset for which BOSS proved infeasible.",http://arxiv.org/pdf/1907.11815v1,cs.LG
2019-07-24 20:11:41+00:00,Deep Generative Quantile-Copula Models for Probabilistic Forecasting,"['Ruofeng Wen', 'Kari Torkkola']","We introduce a new category of multivariate conditional generative models and
demonstrate its performance and versatility in probabilistic time series
forecasting and simulation. Specifically, the output of quantile regression
networks is expanded from a set of fixed quantiles to the whole Quantile
Function by a univariate mapping from a latent uniform distribution to the
target distribution. Then the multivariate case is solved by learning such
quantile functions for each dimension's marginal distribution, followed by
estimating a conditional Copula to associate these latent uniform random
variables. The quantile functions and copula, together defining the joint
predictive distribution, can be parameterized by a single implicit generative
Deep Neural Network.",http://arxiv.org/pdf/1907.10697v1,stat.ML
2019-07-24 06:54:04+00:00,Interpretable Classification of Time-Series Data using Efficient Enumerative Techniques,"['Sara Mohammadinejad', 'Jyotirmoy V. Deshmukh', 'Aniruddh G. Puranic', 'Marcell Vazquez-Chanlatte', 'Alexandre Donzé']","Cyber-physical system applications such as autonomous vehicles, wearable
devices, and avionic systems generate a large volume of time-series data.
Designers often look for tools to help classify and categorize the data.
Traditional machine learning techniques for time-series data offer several
solutions to solve these problems; however, the artifacts trained by these
algorithms often lack interpretability. On the other hand, temporal logics,
such as Signal Temporal Logic (STL) have been successfully used in the formal
methods community as specifications of time-series behaviors. In this work, we
propose a new technique to automatically learn temporal logic formulae that are
able to cluster and classify real-valued time-series data. Previous work on
learning STL formulas from data either assumes a formula-template to be given
by the user, or assumes some special fragment of STL that enables exploring the
formula structure in a systematic fashion. In our technique, we relax these
assumptions, and provide a way to systematically explore the space of all STL
formulas. As the space of all STL formulas is very large, and contains many
semantically equivalent formulas, we suggest a technique to heuristically prune
the space of formulas considered. Finally, we illustrate our technique on
various case studies from the automotive, transportation and healthcare domain.",http://arxiv.org/pdf/1907.10265v1,cs.LG
2019-07-22 18:43:16+00:00,Factor Analysis for High-Dimensional Time Series with Change Point,"['Xialu Liu', 'Ting Zhang']","We consider change-point latent factor models for high-dimensional time
series, where a structural break may exist in the underlying factor structure.
In particular, we propose consistent estimators for factor loading spaces
before and after the change point, and the problem of estimating the
change-point location is also considered. Compared with existing results on
change-point factor analysis of high-dimensional time series, a distinguished
feature of the current paper is that our results allow strong cross-sectional
dependence in the noise process. To accommodate the unknown degree of
cross-sectional dependence strength, we propose to use self-normalization to
pivotalize the change-point test statistic. Numerical experiments including a
Monte Carlo simulation study and a real data application are presented to
illustrate the proposed methods.",http://arxiv.org/pdf/1907.09522v1,stat.ME
2019-07-20 01:20:19+00:00,Efficient Bayesian PARCOR Approaches for Dynamic Modeling of Multivariate Time Series,"['Wenjie Zhao', 'Raquel Prado']","A Bayesian lattice filtering and smoothing approach is proposed for fast and
accurate modeling and inference in multivariate non-stationary time series.
This approach offers computational feasibility and interpretable time-frequency
analysis in the multivariate context. The proposed framework allows us to
obtain posterior estimates of the time-varying spectral densities of individual
time series components, as well as posterior measurements of the time-frequency
relationships across multiple components, such as time-varying coherence and
partial coherence.
  The proposed formulation considers multivariate dynamic linear models (MDLMs)
on the forward and backward time-varying partial autocorrelation coefficients
(TV-VPARCOR). Computationally expensive schemes for posterior inference on the
multivariate dynamic PARCOR model are avoided using approximations in the MDLM
context. Approximate inference on the corresponding time-varying vector
autoregressive (TV-VAR) coefficients is obtained via Whittle's algorithm. A key
aspect of the proposed TV-VPARCOR representations is that they are of lower
dimension, and therefore more efficient, than TV-VAR representations. The
performance of the TV-VPARCOR models is illustrated in simulation studies and
in the analysis of multivariate non-stationary temporal data arising in
neuroscience and environmental applications. Model performance is evaluated
using goodness-of-fit measurements in the time-frequency domain and also by
assessing the quality of short-term forecasting.",http://arxiv.org/pdf/1907.08733v1,stat.ME
2019-07-18 02:19:20+00:00,An Adaptive Approach for Anomaly Detector Selection and Fine-Tuning in Time Series,"['Hui Ye', 'Xiaopeng Ma', 'Qingfeng Pan', 'Huaqiang Fang', 'Hang Xiang', 'Tongzhen Shao']","The anomaly detection of time series is a hotspot of time series data mining.
The own characteristics of different anomaly detectors determine the abnormal
data that they are good at. There is no detector can be optimizing in all types
of anomalies. Moreover, it still has difficulties in industrial production due
to problems such as a single detector can't be optimized at different time
windows of the same time series. This paper proposes an adaptive model based on
time series characteristics and selecting appropriate detector and run-time
parameters for anomaly detection, which is called ATSDLN(Adaptive Time Series
Detector Learning Network). We take the time series as the input of the model,
and learn the time series representation through FCN. In order to realize the
adaptive selection of detectors and run-time parameters according to the input
time series, the outputs of FCN are the inputs of two sub-networks: the
detector selection network and the run-time parameters selection network. In
addition, the way that the variable layer width design of the parameter
selection sub-network and the introduction of transfer learning make the model
be with more expandability. Through experiments, it is found that ATSDLN can
select appropriate anomaly detector and run-time parameters, and have strong
expandability, which can quickly transfer. We investigate the performance of
ATSDLN in public data sets, our methods outperform other methods in most cases
with higher effect and better adaptation. We also show experimental results on
public data sets to demonstrate how model structure and transfer learning
affect the effectiveness.",http://arxiv.org/pdf/1907.07843v1,stat.ML
2019-07-17 16:05:37+00:00,Clustering Activity-Travel Behavior Time Series using Topological Data Analysis,"['Renjie Chen', 'Jingyue Zhang', 'Nalini Ravishanker', 'Karthik Konduri']","Over the last few years, traffic data has been exploding and the
transportation discipline has entered the era of big data. It brings out new
opportunities for doing data-driven analysis, but it also challenges
traditional analytic methods. This paper proposes a new Divide and Combine
based approach to do K means clustering on activity-travel behavior time series
using features that are derived using tools in Time Series Analysis and
Topological Data Analysis. Clustering data from five waves of the National
Household Travel Survey ranging from 1990 to 2017 suggests that activity-travel
patterns of individuals over the last three decades can be grouped into three
clusters. Results also provide evidence in support of recent claims about
differences in activity-travel patterns of different survey cohorts. The
proposed method is generally applicable and is not limited only to
activity-travel behavior analysis in transportation studies. Driving behavior,
travel mode choice, household vehicle ownership, when being characterized as
categorical time series, can all be analyzed using the proposed method.",http://arxiv.org/pdf/1907.07603v1,stat.ML
2019-07-15 16:36:06+00:00,Probability inequalities for high dimensional time series under a triangular array framework,"['Fang Han', 'Weibiao Wu']","Study of time series data often involves measuring the strength of temporal
dependence, on which statistical properties like consistency and central limit
theorem are built. Historically, various dependence measures have been
proposed. In this note, we first survey some of the most well-used dependence
measures as well as various probability and moment inequalities built upon them
under a high-dimensional triangular array time series setting. We then argue
that this triangular array setting will pose substantially new challenges to
the verification of some dependence conditions. In particular, ``textbook
results"" could now be misleading, and hence are recommended to be used with
caution.",http://arxiv.org/pdf/1907.06577v1,math.ST
2019-07-09 13:34:49+00:00,GP-VAE: Deep Probabilistic Time Series Imputation,"['Vincent Fortuin', 'Dmitry Baranchuk', 'Gunnar Rätsch', 'Stephan Mandt']","Multivariate time series with missing values are common in areas such as
healthcare and finance, and have grown in number and complexity over the years.
This raises the question whether deep learning methodologies can outperform
classical data imputation methods in this domain. However, naive applications
of deep learning fall short in giving reliable confidence estimates and lack
interpretability. We propose a new deep sequential latent variable model for
dimensionality reduction and data imputation. Our modeling assumption is simple
and interpretable: the high dimensional time series has a lower-dimensional
representation which evolves smoothly in time according to a Gaussian process.
The non-linear dimensionality reduction in the presence of missing data is
achieved using a VAE approach with a novel structured variational
approximation. We demonstrate that our approach outperforms several classical
and deep learning-based data imputation methods on high-dimensional data from
the domains of computer vision and healthcare, while additionally improving the
smoothness of the imputations and providing interpretable uncertainty
estimates.",http://arxiv.org/pdf/1907.04155v5,stat.ML
2019-07-08 23:21:32+00:00,Latent ODEs for Irregularly-Sampled Time Series,"['Yulia Rubanova', 'Ricky T. Q. Chen', 'David Duvenaud']","Time series with non-uniform intervals occur in many applications, and are
difficult to model using standard recurrent neural networks (RNNs). We
generalize RNNs to have continuous-time hidden dynamics defined by ordinary
differential equations (ODEs), a model we call ODE-RNNs. Furthermore, we use
ODE-RNNs to replace the recognition network of the recently-proposed Latent ODE
model. Both ODE-RNNs and Latent ODEs can naturally handle arbitrary time gaps
between observations, and can explicitly model the probability of observation
times using Poisson processes. We show experimentally that these ODE-based
models outperform their RNN-based counterparts on irregularly-sampled data.",http://arxiv.org/pdf/1907.03907v1,cs.LG
2019-07-08 14:10:01+00:00,Routine Modeling with Time Series Metric Learning,"['Paul Compagnon', 'Grégoire Lefebvre', 'Stefan Duffner', 'Christophe Garcia']","Traditionally, the automatic recognition of human activities is performed
with supervised learning algorithms on limited sets of specific activities.
This work proposes to recognize recurrent activity patterns, called routines,
instead of precisely defined activities. The modeling of routines is defined as
a metric learning problem, and an architecture, called SS2S, based on
sequence-to-sequence models is proposed to learn a distance between time
series. This approach only relies on inertial data and is thus non intrusive
and preserves privacy. Experimental results show that a clustering algorithm
provided with the learned distance is able to recover daily routines.",http://arxiv.org/pdf/1907.04666v1,cs.LG
2019-07-07 18:23:17+00:00,Fast ES-RNN: A GPU Implementation of the ES-RNN Algorithm,"['Andrew Redd', 'Kaung Khin', 'Aldo Marini']","Due to their prevalence, time series forecasting is crucial in multiple
domains. We seek to make state-of-the-art forecasting fast, accessible, and
generalizable. ES-RNN is a hybrid between classical state space forecasting
models and modern RNNs that achieved a 9.4% sMAPE improvement in the M4
competition. Crucially, ES-RNN implementation requires per-time series
parameters. By vectorizing the original implementation and porting the
algorithm to a GPU, we achieve up to 322x training speedup depending on batch
size with similar results as those reported in the original submission. Our
code can be found at: https://github.com/damitkwr/ESRNN-GPU",http://arxiv.org/pdf/1907.03329v1,cs.LG
2019-07-06 17:03:48+00:00,Learning a latent pattern of heterogeneity in the innovation rates of a time series of counts,"['Helton Graziadei', 'Hedibert F. Lopes', 'Paulo C. Marques F']","We develop a Bayesian hierarchical semiparametric model for phenomena related
to time series of counts. The main feature of the model is its capability to
learn a latent pattern of heterogeneity in the distribution of the process
innovation rates, which are softly clustered through time with the help of a
Dirichlet process placed at the top of the model hierarchy. The probabilistic
forecasting capabilities of the model are put to test in the analysis of crime
data in Pittsburgh, with favorable results.",http://arxiv.org/pdf/1907.03155v1,stat.ME
2019-07-04 20:28:52+00:00,Particularities and commonalities of singular spectrum analysis as a method of time series analysis and signal processing,['Nina Golyandina'],"Singular spectrum analysis (SSA), starting from the second half of the XX
century, has been a rapidly developing method of time series analysis. Since it
can be called principal component analysis for time series, SSA will definitely
be a standard method in time series analysis and signal processing in the
future. Moreover, the problems solved by SSA are considerably wider than that
for principal component analysis. In particular, the problems of frequency
estimation, forecasting and missing values imputation can be solved within the
framework of SSA. The idea of SSA came from different scientific communities,
such as that of researchers in time series analysis (Karhunen-Loeve
decomposition), signal processing (low-rank approximation and frequency
estimation) and multivariate data analysis (principal component analysis).
Also, depending on the area of applications, different viewpoints on the same
algorithms, choice of parameters, and methodology as a whole are considered.
Thus, the aim of the paper is to describe and compare different viewpoints on
SSA and its modifications and extensions to give people from different
scientific communities the possibility to be aware of potentially new aspects
of the method.",http://arxiv.org/pdf/1907.02579v2,stat.ME
2019-07-03 02:00:52+00:00,VELC: A New Variational AutoEncoder Based Model for Time Series Anomaly Detection,"['Chunkai Zhang', 'Shaocong Li', 'Hongye Zhang', 'Yingyang Chen']","Anomaly detection is a classical but worthwhile problem, and many deep
learning-based anomaly detection algorithms have been proposed, which can
usually achieve better detection results than traditional methods. In view of
reconstruct ability of the model and the calculation of anomaly score, this
paper proposes a time series anomaly detection method based on Variational
AutoEncoder model(VAE) with re-Encoder and Latent Constraint network(VELC). In
order to modify reconstruct ability of the model to prevent it from
reconstructing abnormal samples well, we add a constraint network in the latent
space of the VAE to force it generate new latent variables that are similar
with that of training samples. To be able to calculate anomaly score in two
feature spaces, we train a re-encoder to transform the generated data to a new
latent space. For better handling the time series, we use the LSTM as the
encoder and decoder part of the VAE framework. Experimental results of several
benchmarks show that our method outperforms state-of-the-art anomaly detection
methods.",http://arxiv.org/pdf/1907.01702v2,cs.LG
2019-07-01 23:22:45+00:00,Predicting Treatment Initiation from Clinical Time Series Data via Graph-Augmented Time-Sensitive Model,"['Fan Zhang', 'Tong Wu', 'Yunlong Wang', 'Yong Cai', 'Cao Xiao', 'Emily Zhao', 'Lucas Glass', 'Jimeng Sun']","Many computational models were proposed to extract temporal patterns from
clinical time series for each patient and among patient group for predictive
healthcare. However, the common relations among patients (e.g., share the same
doctor) were rarely considered. In this paper, we represent patients and
clinicians relations by bipartite graphs addressing for example from whom a
patient get a diagnosis. We then solve for the top eigenvectors of the graph
Laplacian, and include the eigenvectors as latent representations of the
similarity between patient-clinician pairs into a time-sensitive prediction
model. We conducted experiments using real-world data to predict the initiation
of first-line treatment for Chronic Lymphocytic Leukemia (CLL) patients.
Results show that relational similarity can improve prediction over multiple
baselines, for example a 5% incremental over long-short term memory baseline in
terms of area under precision-recall curve.",http://arxiv.org/pdf/1907.01099v1,cs.LG
2019-06-29 16:36:04+00:00,Enhancing the Locality and Breaking the Memory Bottleneck of Transformer on Time Series Forecasting,"['Shiyang Li', 'Xiaoyong Jin', 'Yao Xuan', 'Xiyou Zhou', 'Wenhu Chen', 'Yu-Xiang Wang', 'Xifeng Yan']","Time series forecasting is an important problem across many domains,
including predictions of solar plant energy output, electricity consumption,
and traffic jam situation. In this paper, we propose to tackle such forecasting
problem with Transformer [1]. Although impressed by its performance in our
preliminary study, we found its two major weaknesses: (1) locality-agnostics:
the point-wise dot-product self-attention in canonical Transformer architecture
is insensitive to local context, which can make the model prone to anomalies in
time series; (2) memory bottleneck: space complexity of canonical Transformer
grows quadratically with sequence length $L$, making directly modeling long
time series infeasible. In order to solve these two issues, we first propose
convolutional self-attention by producing queries and keys with causal
convolution so that local context can be better incorporated into attention
mechanism. Then, we propose LogSparse Transformer with only $O(L(\log L)^{2})$
memory cost, improving forecasting accuracy for time series with fine
granularity and strong long-term dependencies under constrained memory budget.
Our experiments on both synthetic data and real-world datasets show that it
compares favorably to the state-of-the-art.",http://arxiv.org/pdf/1907.00235v3,cs.LG
2019-06-28 07:06:32+00:00,Anomaly Subsequence Detection with Dynamic Local Density for Time Series,"['Chunkai Zhang', 'Yingyang Chen', 'Ao Yin']","Anomaly subsequence detection is to detect inconsistent data, which always
contains important information, among time series. Due to the high
dimensionality of the time series, traditional anomaly detection often requires
a large time overhead; furthermore, even if the dimensionality reduction
techniques can improve the efficiency, they will lose some information and
suffer from time drift and parameter tuning. In this paper, we propose a new
anomaly subsequence detection with Dynamic Local Density Estimation (DLDE) to
improve the detection effect without losing the trend information by
dynamically dividing the time series using Time Split Tree. In order to avoid
the impact of the hash function and the randomness of dynamic time segments,
ensemble learning is used. Experimental results on different types of data sets
verify that the proposed model outperforms the state-of-art methods, and the
accuracy has big improvement.",http://arxiv.org/pdf/1907.00701v1,cs.LG
2019-06-28 06:45:07+00:00,An Improvement of PAA on Trend-Based Approximation for Time Series,"['Chunkai Zhang', 'Yingyang Chen', 'Ao Yin', 'Zhen Qin', 'Xing Zhang', 'Keli Zhang', 'Zoe L. Jiang']","Piecewise Aggregate Approximation (PAA) is a competitive basic dimension
reduction method for high-dimensional time series mining. When deployed,
however, the limitations are obvious that some important information will be
missed, especially the trend. In this paper, we propose two new approaches for
time series that utilize approximate trend feature information. Our first
method is based on relative mean value of each segment to record the trend,
which divide each segment into two parts and use the numerical average
respectively to represent the trend. We proved that this method satisfies lower
bound which guarantee no false dismissals. Our second method uses a binary
string to record the trend which is also relative to mean in each segment. Our
methods are applied on similarity measurement in classification and anomaly
detection, the experimental results show the improvement of accuracy and
effectiveness by extracting the trend feature suitably.",http://arxiv.org/pdf/1907.00700v1,cs.LG
2019-06-25 15:05:25+00:00,A Self-supervised Approach to Hierarchical Forecasting with Applications to Groupwise Synthetic Controls,"['Konstantin Mishchenko', 'Mallory Montgomery', 'Federico Vaggi']","When forecasting time series with a hierarchical structure, the existing
state of the art is to forecast each time series independently, and, in a
post-treatment step, to reconcile the time series in a way that respects the
hierarchy (Hyndman et al., 2011; Wickramasuriya et al., 2018). We propose a new
loss function that can be incorporated into any maximum likelihood objective
with hierarchical data, resulting in reconciled estimates with confidence
intervals that correctly account for additional uncertainty due to imperfect
reconciliation. We evaluate our method using a non-linear model and synthetic
data on a counterfactual forecasting problem, where we have access to the
ground truth and contemporaneous covariates, and show that we largely improve
over the existing state-of-the-art method.",http://arxiv.org/pdf/1906.10586v1,stat.ML
2019-06-25 08:18:58+00:00,Dynamic time series clustering via volatility change-points,['Nick Whiteley'],"This note outlines a method for clustering time series based on a statistical
model in which volatility shifts at unobserved change-points. The model
accommodates some classical stylized features of returns and its relation to
GARCH is discussed. Clustering is performed using a probability metric
evaluated between posterior distributions of the most recent change-point
associated with each series. This implies series are grouped together at a
given time if there is evidence the most recent shifts in their respective
volatilities were coincident or closely timed. The clustering method is
dynamic, in that groupings may be updated in an online manner as data arrive.
Numerical results are given analyzing daily returns of constituents of the S&P
500.",http://arxiv.org/pdf/1906.10372v1,stat.ME
2019-06-25 05:41:16+00:00,TS-CHIEF: A Scalable and Accurate Forest Algorithm for Time Series Classification,"['Ahmed Shifaz', 'Charlotte Pelletier', 'Francois Petitjean', 'Geoffrey I. Webb']","Time Series Classification (TSC) has seen enormous progress over the last two
decades. HIVE-COTE (Hierarchical Vote Collective of Transformation-based
Ensembles) is the current state of the art in terms of classification accuracy.
HIVE-COTE recognizes that time series data are a specific data type for which
the traditional attribute-value representation, used predominantly in machine
learning, fails to provide a relevant representation. HIVE-COTE combines
multiple types of classifiers: each extracting information about a specific
aspect of a time series, be it in the time domain, frequency domain or
summarization of intervals within the series. However, HIVE-COTE (and its
predecessor, FLAT-COTE) is often infeasible to run on even modest amounts of
data. For instance, training HIVE-COTE on a dataset with only 1,500 time series
can require 8 days of CPU time. It has polynomial runtime with respect to the
training set size, so this problem compounds as data quantity increases. We
propose a novel TSC algorithm, TS-CHIEF (Time Series Combination of
Heterogeneous and Integrated Embedding Forest), which rivals HIVE-COTE in
accuracy but requires only a fraction of the runtime. TS-CHIEF constructs an
ensemble classifier that integrates the most effective embeddings of time
series that research has developed in the last decade. It uses tree-structured
classifiers to do so efficiently. We assess TS-CHIEF on 85 datasets of the
University of California Riverside (UCR) archive, where it achieves
state-of-the-art accuracy with scalability and efficiency. We demonstrate that
TS-CHIEF can be trained on 130k time series in 2 days, a data quantity that is
beyond the reach of any TSC algorithm with comparable accuracy.",http://arxiv.org/pdf/1906.10329v2,cs.LG
2019-06-24 13:15:02+00:00,Streaming Adaptation of Deep Forecasting Models using Adaptive Recurrent Units,"['Prathamesh Deshpande', 'Sunita Sarawagi']","We present ARU, an Adaptive Recurrent Unit for streaming adaptation of deep
globally trained time-series forecasting models. The ARU combines the
advantages of learning complex data transformations across multiple time series
from deep global models, with per-series localization offered by closed-form
linear models. Unlike existing methods of adaptation that are either
memory-intensive or non-responsive after training, ARUs require only fixed
sized state and adapt to streaming data via an easy RNN-like update operation.
The core principle driving ARU is simple --- maintain sufficient statistics of
conditional Gaussian distributions and use them to compute local parameters in
closed form. Our contribution is in embedding such local linear models in
globally trained deep models while allowing end-to-end training on the one
hand, and easy RNN-like updates on the other. Across several datasets we show
that ARU is more effective than recently proposed local adaptation methods that
tax the global network to compute local parameters.",http://arxiv.org/pdf/1906.09926v2,cs.LG
2019-06-13 20:12:55+00:00,Recurrent Neural Processes,"['Timon Willi', 'Jonathan Masci', 'Jürgen Schmidhuber', 'Christian Osendorfer']","We extend Neural Processes (NPs) to sequential data through Recurrent NPs or
RNPs, a family of conditional state space models. RNPs model the state space
with Neural Processes. Given time series observed on fast real-world time
scales but containing slow long-term variabilities, RNPs may derive appropriate
slow latent time scales. They do so in an efficient manner by establishing
conditional independence among subsequences of the time series. Our
theoretically grounded framework for stochastic processes expands the
applicability of NPs while retaining their benefits of flexibility, uncertainty
estimation, and favorable runtime with respect to Gaussian Processes (GPs). We
demonstrate that state spaces learned by RNPs benefit predictive performance on
real-world time-series data and nonlinear system identification, even in the
case of limited data availability.",http://arxiv.org/pdf/1906.05915v2,cs.LG
2019-06-12 17:44:53+00:00,GluonTS: Probabilistic Time Series Models in Python,"['Alexander Alexandrov', 'Konstantinos Benidis', 'Michael Bohlke-Schneider', 'Valentin Flunkert', 'Jan Gasthaus', 'Tim Januschowski', 'Danielle C. Maddix', 'Syama Rangapuram', 'David Salinas', 'Jasper Schulz', 'Lorenzo Stella', 'Ali Caner Türkmen', 'Yuyang Wang']","We introduce Gluon Time Series (GluonTS, available at
https://gluon-ts.mxnet.io), a library for deep-learning-based time series
modeling. GluonTS simplifies the development of and experimentation with time
series models for common tasks such as forecasting or anomaly detection. It
provides all necessary components and tools that scientists need for quickly
building new models, for efficiently running and analyzing experiments and for
evaluating model accuracy.",http://arxiv.org/pdf/1906.05264v2,cs.LG
2019-06-12 15:20:52+00:00,Warping Resilient Scalable Anomaly Detection in Time Series,"['Abilasha S', 'Sahely Bhadra', 'Deepak P', 'Anish Mathew']","Time series data is ubiquitous in the real-world problems across various
domains including healthcare, social media, and crime surveillance. Detecting
anomalies, or irregular and rare events, in time series data, can enable us to
find abnormal events in any natural phenomena, which may require special
treatment. Moreover, labeled instances of anomaly are hard to get in time
series data. On the other hand, time series data, due to its nature, often
exhibits localized expansions and compressions in the time dimension which is
called warping. These two challenges make it hard to detect anomalies in time
series as often such warpings could get detected as anomalies erroneously. Our
objective is to build an anomaly detection model that is robust to such warping
variations. In this paper, we propose a novel unsupervised time series anomaly
detection method, WaRTEm-AD, that operates in two stages. Within the key stage
of representation learning, we employ data augmentation through bespoke time
series operators which are passed through a twin autoencoder architecture to
learn warping-robust representations for time series data. Second, adaptations
of state-of-the-art anomaly detection methods are employed on the learnt
representations to identify anomalies. We will illustrate that WaRTEm-AD is
designed to detect two types of time series anomalies: point and sequence
anomalies. We compare WaRTEm-AD with the state-of-the-art baselines and
establish the effectiveness of our method both in terms of anomaly detection
performance and computational efficiency.",http://arxiv.org/pdf/1906.05205v2,cs.LG
2019-06-11 16:24:45+00:00,Efficient Kernel-based Subsequence Search for User Identification from Walking Activity,"['Antonio Candelieri', 'Stanislav Fedorov', 'Enza Messina']","This paper presents an efficient approach for subsequence search in data
streams. The problem consists in identifying coherent repetitions of a given
reference time-series, eventually multi-variate, within a longer data stream.
Dynamic Time Warping (DTW) is the metric most widely used to implement pattern
query, but its computational complexity is a well-known issue. In this paper we
present an approach aimed at learning a kernel able to approximate DTW to be
used for efficiently analyse streaming data collected from wearable sensors,
reducing the burden of computation. Contrary to kernel, DTW allows for
comparing time series with different length. Thus, to use a kernel, a feature
embedding is used to represent a time-series as a fixed length vector. Each
vector component is the DTW between the given time-series and a set of 'basis'
series, usually randomly chosen. The vector size is the number of basis series
used for the feature embedding. Searching for the portion of the data stream
minimizing the DTW with the reference subsequence leads to a global
optimization problem. The proposed approach has been validated on a benchmark
dataset related to the identification of users depending on their walking
activity. A comparison with a traditional DTW implementation is also provided.",http://arxiv.org/pdf/1906.04680v2,cs.LG
2019-06-10 07:31:40+00:00,Time-Series Anomaly Detection Service at Microsoft,"['Hansheng Ren', 'Bixiong Xu', 'Yujing Wang', 'Chao Yi', 'Congrui Huang', 'Xiaoyu Kou', 'Tony Xing', 'Mao Yang', 'Jie Tong', 'Qi Zhang']","Large companies need to monitor various metrics (for example, Page Views and
Revenue) of their applications and services in real time. At Microsoft, we
develop a time-series anomaly detection service which helps customers to
monitor the time-series continuously and alert for potential incidents on time.
In this paper, we introduce the pipeline and algorithm of our anomaly detection
service, which is designed to be accurate, efficient and general. The pipeline
consists of three major modules, including data ingestion, experimentation
platform and online compute. To tackle the problem of time-series anomaly
detection, we propose a novel algorithm based on Spectral Residual (SR) and
Convolutional Neural Network (CNN). Our work is the first attempt to borrow the
SR model from visual saliency detection domain to time-series anomaly
detection. Moreover, we innovatively combine SR and CNN together to improve the
performance of SR model. Our approach achieves superior experimental results
compared with state-of-the-art baselines on both public datasets and Microsoft
production data.",http://arxiv.org/pdf/1906.03821v1,cs.LG
2019-06-10 01:00:36+00:00,RobustTrend: A Huber Loss with a Combined First and Second Order Difference Regularization for Time Series Trend Filtering,"['Qingsong Wen', 'Jingkun Gao', 'Xiaomin Song', 'Liang Sun', 'Jian Tan']","Extracting the underlying trend signal is a crucial step to facilitate time
series analysis like forecasting and anomaly detection. Besides noise signal,
time series can contain not only outliers but also abrupt trend changes in
real-world scenarios. To deal with these challenges, we propose a robust trend
filtering algorithm based on robust statistics and sparse learning.
Specifically, we adopt the Huber loss to suppress outliers, and utilize a
combination of the first order and second order difference on the trend
component as regularization to capture both slow and abrupt trend changes.
Furthermore, an efficient method is designed to solve the proposed robust trend
filtering based on majorization minimization (MM) and alternative direction
method of multipliers (ADMM). We compared our proposed robust trend filter with
other nine state-of-the-art trend filtering algorithms on both synthetic and
real-world datasets. The experiments demonstrate that our algorithm outperforms
existing methods.",http://arxiv.org/pdf/1906.03751v2,cs.LG
2019-06-03 16:38:20+00:00,Learning Interpretable Shapelets for Time Series Classification through Adversarial Regularization,"['Yichang Wang', 'Rémi Emonet', 'Elisa Fromont', 'Simon Malinowski', 'Etienne Menager', 'Loïc Mosser', 'Romain Tavenard']","Times series classification can be successfully tackled by jointly learning a
shapelet-based representation of the series in the dataset and classifying the
series according to this representation. However, although the learned
shapelets are discriminative, they are not always similar to pieces of a real
series in the dataset. This makes it difficult to interpret the decision, i.e.
difficult to analyze if there are particular behaviors in a series that
triggered the decision. In this paper, we make use of a simple convolutional
network to tackle the time series classification task and we introduce an
adversarial regularization to constrain the model to learn more interpretable
shapelets. Our classification results on all the usual time series benchmarks
are comparable with the results obtained by similar state-of-the-art algorithms
but our adversarially regularized method learns shapelets that are, by design,
interpretable.",http://arxiv.org/pdf/1906.00917v2,cs.LG
2019-06-03 01:00:47+00:00,A Fast-Optimal Guaranteed Algorithm For Learning Sub-Interval Relationships in Time Series,"['Saurabh Agrawal', 'Saurabh Verma', 'Anuj Karpatne', 'Stefan Liess', 'Snigdhansu Chatterjee', 'Vipin Kumar']","Traditional approaches focus on finding relationships between two entire time
series, however, many interesting relationships exist in small sub-intervals of
time and remain feeble during other sub-intervals. We define the notion of a
sub-interval relationship (SIR) to capture such interactions that are prominent
only in certain sub-intervals of time. To that end, we propose a fast-optimal
guaranteed algorithm to find most interesting SIR relationship in a pair of
time series. Lastly, we demonstrate the utility of our method in climate
science domain based on a real-world dataset along with its scalability scope
and obtain useful domain insights.",http://arxiv.org/pdf/1906.01450v1,cs.LG
2019-06-01 16:29:50+00:00,Super-resolution of Time-series Labels for Bootstrapped Event Detection,"['Ivan Kiskin', 'Udeepa Meepegama', 'Steven Roberts']","Solving real-world problems, particularly with deep learning, relies on the
availability of abundant, quality data. In this paper we develop a novel
framework that maximises the utility of time-series datasets that contain only
small quantities of expertly-labelled data, larger quantities of weakly (or
coarsely) labelled data and a large volume of unlabelled data. This represents
scenarios commonly encountered in the real world, such as in crowd-sourcing
applications. In our work, we use a nested loop using a Kernel Density
Estimator (KDE) to super-resolve the abundant low-quality data labels, thereby
enabling effective training of a Convolutional Neural Network (CNN). We
demonstrate two key results: a) The KDE is able to super-resolve labels more
accurately, and with better calibrated probabilities, than well-established
classifiers acting as baselines; b) Our CNN, trained on super-resolved labels
from the KDE, achieves an improvement in F1 score of 22.1% over the next best
baseline system in our candidate problem domain.",http://arxiv.org/pdf/1906.00254v1,cs.LG
2019-05-31 14:12:13+00:00,Time Series Anomaly Detection Using Convolutional Neural Networks and Transfer Learning,"['Tailai Wen', 'Roy Keyes']","Time series anomaly detection plays a critical role in automated monitoring
systems. Most previous deep learning efforts related to time series anomaly
detection were based on recurrent neural networks (RNN). In this paper, we
propose a time series segmentation approach based on convolutional neural
networks (CNN) for anomaly detection. Moreover, we propose a transfer learning
framework that pretrains a model on a large-scale synthetic univariate time
series data set and then fine-tunes its weights on small-scale, univariate or
multivariate data sets with previously unseen classes of anomalies. For the
multivariate case, we introduce a novel network architecture. The approach was
tested on multiple synthetic and real data sets successfully.",http://arxiv.org/pdf/1905.13628v1,cs.LG
2019-05-31 13:40:15+00:00,A multi-series framework for demand forecasts in E-commerce,"['Rémy Garnier', 'Arnaud Belletoile']","Sales forecasts are crucial for the E-commerce business. State-of-the-art
techniques typically apply only univariate methods to make prediction for each
series independently. However, due to the short nature of sales times series in
E-commerce, univariate methods don't apply well. In this article, we propose a
global model which outperforms state-of-the-art models on real dataset. It is
achieved by using Tree Boosting Methods that exploit non-linearity and
cross-series information. We also proposed a preprocessing framework to
overcome the inherent difficulties in the E-commerce data. In particular, we
use different schemes to limit the impact of the volatility of the data.",http://arxiv.org/pdf/1905.13614v1,stat.ML
2019-05-30 12:33:59+00:00,A novel hybrid model based on multi-objective Harris hawks optimization algorithm for daily PM2.5 and PM10 forecasting,"['Pei Du', 'Jianzhou Wang', 'Yan Hao', 'Tong Niu', 'Wendong Yang']","High levels of air pollution may seriously affect people's living environment
and even endanger their lives. In order to reduce air pollution concentrations,
and warn the public before the occurrence of hazardous air pollutants, it is
urgent to design an accurate and reliable air pollutant forecasting model.
However, most previous research have many deficiencies, such as ignoring the
importance of predictive stability, and poor initial parameters and so on,
which have significantly effect on the performance of air pollution prediction.
Therefore, to address these issues, a novel hybrid model is proposed in this
study. Specifically, a powerful data preprocessing techniques is applied to
decompose the original time series into different modes from low- frequency to
high- frequency. Next, a new multi-objective algorithm called MOHHO is first
developed in this study, which are introduced to tune the parameters of ELM
model with high forecasting accuracy and stability for air pollution series
prediction, simultaneously. And the optimized ELM model is used to perform the
time series prediction. Finally, a scientific and robust evaluation system
including several error criteria, benchmark models, and several experiments
using six air pollutant concentrations time series from three cities in China
is designed to perform a compressive assessment for the presented hybrid
forecasting model. Experimental results indicate that the proposed hybrid model
can guarantee a more stable and higher predictive performance compared to
others, whose superior prediction ability may help to develop effective plans
for air pollutant emissions and prevent health problems caused by air
pollution.",http://arxiv.org/pdf/1905.13550v1,cs.LG
2019-05-30 10:20:32+00:00,Factorized Inference in Deep Markov Models for Incomplete Multimodal Time Series,"['Tan Zhi-Xuan', 'Harold Soh', 'Desmond C. Ong']","Integrating deep learning with latent state space models has the potential to
yield temporal models that are powerful, yet tractable and interpretable.
Unfortunately, current models are not designed to handle missing data or
multiple data modalities, which are both prevalent in real-world data. In this
work, we introduce a factorized inference method for Multimodal Deep Markov
Models (MDMMs), allowing us to filter and smooth in the presence of missing
data, while also performing uncertainty-aware multimodal fusion. We derive this
method by factorizing the posterior p(z|x) for non-linear state space models,
and develop a variational backward-forward algorithm for inference. Because our
method handles incompleteness over both time and modalities, it is capable of
interpolation, extrapolation, conditional generation, label prediction, and
weakly supervised learning of multimodal time series. We demonstrate these
capabilities on both synthetic and real-world multimodal data under high levels
of data deletion. Our method performs well even with more than 50% missing
data, and outperforms existing deep approaches to inference in latent time
series.",http://arxiv.org/pdf/1905.13570v3,cs.LG
2019-05-29 07:55:55+00:00,Learning Temporal Causal Sequence Relationships from Real-Time Time-Series,"['Antonio Anastasio Bruto da Costa', 'Pallab Dasgupta']","We aim to mine temporal causal sequences that explain observed events
(consequents) in time-series traces. Causal explanations of key events in a
time-series has applications in design debugging, anomaly detection, planning,
root-cause analysis and many more. We make use of decision trees and interval
arithmetic to mine sequences that explain defining events in the time-series.
We propose modified decision tree construction metrics to handle the
non-determinism introduced by the temporal dimension. The mined sequences are
expressed in a readable temporal logic language that is easy to interpret. The
application of the proposed methodology is illustrated through various
examples.",http://arxiv.org/pdf/1905.12262v6,cs.LG
2019-05-28 16:27:52+00:00,Deep Factors for Forecasting,"['Yuyang Wang', 'Alex Smola', 'Danielle C. Maddix', 'Jan Gasthaus', 'Dean Foster', 'Tim Januschowski']","Producing probabilistic forecasts for large collections of similar and/or
dependent time series is a practically relevant and challenging task. Classical
time series models fail to capture complex patterns in the data, and
multivariate techniques struggle to scale to large problem sizes. Their
reliance on strong structural assumptions makes them data-efficient, and allows
them to provide uncertainty estimates. The converse is true for models based on
deep neural networks, which can learn complex patterns and dependencies given
enough data. In this paper, we propose a hybrid model that incorporates the
benefits of both approaches. Our new method is data-driven and scalable via a
latent, global, deep component. It also handles uncertainty through a local
classical model. We provide both theoretical and empirical evidence for the
soundness of our approach through a necessary and sufficient decomposition of
exchangeable time series into a global and a local part. Our experiments
demonstrate the advantages of our model both in term of data efficiency,
accuracy and computational complexity.",http://arxiv.org/pdf/1905.12417v1,stat.ML
2019-05-28 15:40:18+00:00,BreizhCrops: A Time Series Dataset for Crop Type Mapping,"['Marc Rußwurm', 'Charlotte Pelletier', 'Maximilian Zollner', 'Sébastien Lefèvre', 'Marco Körner']","We present Breizhcrops, a novel benchmark dataset for the supervised
classification of field crops from satellite time series. We aggregated label
data and Sentinel-2 top-of-atmosphere as well as bottom-of-atmosphere time
series in the region of Brittany (Breizh in local language), north-east France.
We compare seven recently proposed deep neural networks along with a Random
Forest baseline. The dataset, model (re-)implementations and pre-trained model
weights are available at the associated GitHub repository
(https://github.com/dl4sits/BreizhCrops) that has been designed with
applicability for practitioners in mind. We plan to maintain the repository
with additional data and welcome contributions of novel methods to build a
state-of-the-art benchmark on methods for crop type mapping.",http://arxiv.org/pdf/1905.11893v2,cs.LG
2019-05-28 11:16:20+00:00,Evaluating time series forecasting models: An empirical study on performance estimation methods,"['Vitor Cerqueira', 'Luis Torgo', 'Igor Mozetic']","Performance estimation aims at estimating the loss that a predictive model
will incur on unseen data. These procedures are part of the pipeline in every
machine learning project and are used for assessing the overall generalisation
ability of predictive models. In this paper we address the application of these
methods to time series forecasting tasks. For independent and identically
distributed data the most common approach is cross-validation. However, the
dependency among observations in time series raises some caveats about the most
appropriate way to estimate performance in this type of data and currently
there is no settled way to do so. We compare different variants of
cross-validation and of out-of-sample approaches using two case studies: One
with 62 real-world time series and another with three synthetic time series.
Results show noticeable differences in the performance estimation methods in
the two scenarios. In particular, empirical experiments suggest that
cross-validation approaches can be applied to stationary time series. However,
in real-world scenarios, when different sources of non-stationary variation are
at play, the most accurate estimates are produced by out-of-sample methods that
preserve the temporal order of observations.",http://arxiv.org/pdf/1905.11744v1,cs.LG
2019-05-26 03:09:10+00:00,Topological Data Analysis of Time Series Data for B2B Customer Relationship Management,"['Rodrigo Rivera-Castro', 'Polina Pilyugina', 'Alexander Pletnev', 'Ivan Maksimov', 'Wanyi Wyz', 'Evgeny Burnaev']","Topological Data Analysis (TDA) is a recent approach to analyze data sets
from the perspective of their topological structure. Its use for time series
data has been limited to the field of financial time series primarily and as a
method for feature generation in machine learning applications. In this work,
TDA is presented as a technique to gain additional understanding of the
customers' loyalty for business-to-business customer relationship management.
Increasing loyalty and strengthening relationships with key accounts remain an
active topic of discussion both for researchers and managers. Using two public
and two proprietary data sets of commercial data, this research shows that the
technique enables analysts to better understand their customer base and
identify prospective opportunities. In addition, the approach can be used as a
clustering method to increase the accuracy of a predictive model for loyalty
scoring. This work thus seeks to introduce TDA as a viable tool for data
analysis to the quantitate marketing practitioner.",http://arxiv.org/pdf/1906.03956v2,cs.LG
2019-05-24 20:28:57+00:00,N-BEATS: Neural basis expansion analysis for interpretable time series forecasting,"['Boris N. Oreshkin', 'Dmitri Carpov', 'Nicolas Chapados', 'Yoshua Bengio']","We focus on solving the univariate times series point forecasting problem
using deep learning. We propose a deep neural architecture based on backward
and forward residual links and a very deep stack of fully-connected layers. The
architecture has a number of desirable properties, being interpretable,
applicable without modification to a wide array of target domains, and fast to
train. We test the proposed architecture on several well-known datasets,
including M3, M4 and TOURISM competition datasets containing time series from
diverse domains. We demonstrate state-of-the-art performance for two
configurations of N-BEATS for all the datasets, improving forecast accuracy by
11% over a statistical benchmark and by 3% over last year's winner of the M4
competition, a domain-adjusted hand-crafted hybrid between neural network and
statistical time series models. The first configuration of our model does not
employ any time-series-specific components and its performance on heterogeneous
datasets strongly suggests that, contrarily to received wisdom, deep learning
primitives such as residual blocks are by themselves sufficient to solve a wide
range of forecasting problems. Finally, we demonstrate how the proposed
architecture can be augmented to provide outputs that are interpretable without
considerable loss in accuracy.",http://arxiv.org/pdf/1905.10437v4,cs.LG
2019-05-24 16:33:14+00:00,Factor Models for High-Dimensional Functional Time Series,"['Shahin Tavakoli', 'Gilles Nisol', 'Marc Hallin']","In this paper, we set up the theoretical foundations for a high-dimensional
functional factor model approach in the analysis of large cross-sections
(panels) of functional time series (FTS). We first establish a representation
result stating that, under mild assumptions on the covariance operator of the
cross-section, we can represent each FTS as the sum of a common component
driven by scalar factors loaded via functional loadings, and a mildly
cross-correlated idiosyncratic component. Our model and theory are developed in
a general Hilbert space setting that allows for mixed panels of functional and
scalar time series. We then turn to the identification of the number of
factors, and the estimation of the factors, their loadings, and the common
components. We provide a family of information criteria for identifying the
number of factors, and prove their consistency. We provide average error bounds
for the estimators of the factors, loadings, and common component; our results
encompass the scalar case, for which they reproduce and extend, under weaker
conditions, well-established similar results. Under slightly stronger
assumptions, we also provide uniform bounds for the estimators of factors,
loadings, and common component, thus extending existing scalar results. Our
consistency results in the asymptotic regime where the number $N$ of series and
the number $T$ of time observations diverge thus extend to the functional
context the ""blessing of dimensionality"" that explains the success of factor
models in the analysis of high-dimensional (scalar) time series. We provide
numerical illustrations that corroborate the convergence rates predicted by the
theory, and provide finer understanding of the interplay between $N$ and $T$
for estimation purposes. We conclude with an application to forecasting
mortality curves, where we demonstrate that our approach outperforms existing
methods.",http://arxiv.org/pdf/1905.10325v4,math.ST
2019-05-24 11:46:56+00:00,Generative adversarial network based on chaotic time series,"['Makoto Naruse', 'Takashi Matsubara', 'Nicolas Chauvet', 'Kazutaka Kanno', 'Tianyu Yang', 'Atsushi Uchida']","Generative adversarial network (GAN) is gaining increased importance in
artificially constructing natural images and related functionalities wherein
two networks called generator and discriminator are evolving through
adversarial mechanisms. Using deep convolutional neural networks and related
techniques, high-resolution, highly realistic scenes, human faces, among others
have been generated. While GAN in general needs a large amount of genuine
training data sets, it is noteworthy that vast amounts of pseudorandom numbers
are required. Here we utilize chaotic time series generated experimentally by
semiconductor lasers for the latent variables of GAN whereby the inherent
nature of chaos can be reflected or transformed into the generated output data.
We show that the similarity in proximity, which is a degree of robustness of
the generated images with respects to a minute change in the input latent
variables, is enhanced while the versatility as a whole is not severely
degraded. Furthermore, we demonstrate that the surrogate chaos time series
eliminates the signature of generated images that is originally observed
corresponding to the negative autocorrelation inherent in the chaos sequence.
We also discuss the impact of utilizing chaotic time series in retrieving
images from the trained generator.",http://arxiv.org/pdf/1905.10163v1,cs.LG
2019-05-23 20:13:12+00:00,"CDSA: Cross-Dimensional Self-Attention for Multivariate, Geo-tagged Time Series Imputation","['Jiawei Ma', 'Zheng Shou', 'Alireza Zareian', 'Hassan Mansour', 'Anthony Vetro', 'Shih-Fu Chang']","Many real-world applications involve multivariate, geo-tagged time series
data: at each location, multiple sensors record corresponding measurements. For
example, air quality monitoring system records PM2.5, CO, etc. The resulting
time-series data often has missing values due to device outages or
communication errors. In order to impute the missing values, state-of-the-art
methods are built on Recurrent Neural Networks (RNN), which process each time
stamp sequentially, prohibiting the direct modeling of the relationship between
distant time stamps. Recently, the self-attention mechanism has been proposed
for sequence modeling tasks such as machine translation, significantly
outperforming RNN because the relationship between each two time stamps can be
modeled explicitly. In this paper, we are the first to adapt the self-attention
mechanism for multivariate, geo-tagged time series data. In order to jointly
capture the self-attention across multiple dimensions, including time, location
and the sensor measurements, while maintain low computational complexity, we
propose a novel approach called Cross-Dimensional Self-Attention (CDSA) to
process each dimension sequentially, yet in an order-independent manner. Our
extensive experiments on four real-world datasets, including three standard
benchmarks and our newly collected NYC-traffic dataset, demonstrate that our
approach outperforms the state-of-the-art imputation and forecasting methods. A
detailed systematic analysis confirms the effectiveness of our design choices.",http://arxiv.org/pdf/1905.09904v2,cs.LG
2019-05-23 14:55:28+00:00,Population-based Global Optimisation Methods for Learning Long-term Dependencies with RNNs,"['Bryan Lim', 'Stefan Zohren', 'Stephen Roberts']","Despite recent innovations in network architectures and loss functions,
training RNNs to learn long-term dependencies remains difficult due to
challenges with gradient-based optimisation methods. Inspired by the success of
Deep Neuroevolution in reinforcement learning (Such et al. 2017), we explore
the use of gradient-free population-based global optimisation (PBO) techniques
-- training RNNs to capture long-term dependencies in time-series data. Testing
evolution strategies (ES) and particle swarm optimisation (PSO) on an
application in volatility forecasting, we demonstrate that PBO methods lead to
performance improvements in general, with ES exhibiting the most consistent
results across a variety of architectures.",http://arxiv.org/pdf/1905.09691v1,stat.ML
2019-05-19 16:46:55+00:00,Estimating variances in time series linear regression models using empirical BLUPs and convex optimization,"['Martina Hančová', 'Gabriela Vozáriková', 'Andrej Gajdoš', 'Jozef Hanč']","We propose a two-stage estimation method of variance components in time
series models known as FDSLRMs, whose observations can be described by a linear
mixed model (LMM). We based estimating variances, fundamental quantities in a
time series forecasting approach called kriging, on the empirical (plug-in)
best linear unbiased predictions of unobservable random components in FDSLRM.
  The method, providing invariant non-negative quadratic estimators, can be
used for any absolutely continuous probability distribution of time series
data. As a result of applying the convex optimization and the LMM methodology,
we resolved two problems $-$ theoretical existence and equivalence between
least squares estimators, non-negative (M)DOOLSE, and maximum likelihood
estimators, (RE)MLE, as possible starting points of our method and a practical
lack of computational implementation for FDSLRM. As for computing (RE)MLE in
the case of $ n $ observed time series values, we also discovered a new
algorithm of order $\mathcal{O}(n)$, which at the default precision is $10^7$
times more accurate and $n^2$ times faster than the best current Python(or
R)-based computational packages, namely CVXPY, CVXR, nlme, sommer and mixed.
  We illustrate our results on three real data sets $-$ electricity
consumption, tourism and cyber security $-$ which are easily available,
reproducible, sharable and modifiable in the form of interactive Jupyter
notebooks.",http://arxiv.org/pdf/1905.07771v1,stat.ME
2019-05-18 23:45:32+00:00,On Selecting Stable Predictors in Time Series Models,['Avleen S. Bijral'],"We extend the feature selection methodology to dependent data and propose a
novel time series predictor selection scheme that accommodates statistical
dependence in a more typical i.i.d sub-sampling based framework. Furthermore,
the machinery of mixing stationary processes allows us to quantify the
improvements of our approach over any base predictor selection method (such as
lasso) even in a finite sample setting. Using the lasso as a base procedure we
demonstrate the applicability of our methods to simulated and several real time
series datasets.",http://arxiv.org/pdf/1905.07659v1,stat.ME
2019-05-18 03:40:48+00:00,Factor Models for High-Dimensional Tensor Time Series,"['Rong Chen', 'Dan Yang', 'Cun-hui Zhang']","Large tensor (multi-dimensional array) data are now routinely collected in a
wide range of applications, due to modern data collection capabilities. Often
such observations are taken over time, forming tensor time series. In this
paper we present a factor model approach for analyzing high-dimensional dynamic
tensor time series and multi-category dynamic transport networks. Two
estimation procedures along with their theoretical properties and simulation
results are presented. Two applications are used to illustrate the model and
its interpretations.",http://arxiv.org/pdf/1905.07530v2,stat.ME
2019-05-17 11:59:23+00:00,Functional Lagged Regression with Sparse Noisy Observations,"['Tomáš Rubín', 'Victor M. Panaretos']","A functional (lagged) time series regression model involves the regression of
scalar response time series on a time series of regressors that consists of a
sequence of random functions. In practice, the underlying regressor curve time
series are not always directly accessible, but are latent processes observed
(sampled) only at discrete measurement locations. In this paper, we consider
the so-called sparse observation scenario where only a relatively small number
of measurement locations have been observed, possibly different for each curve.
The measurements can be further contaminated by additive measurement error. A
spectral approach to the estimation of the model dynamics is considered. The
spectral density of the regressor time series and the cross-spectral density
between the regressors and response time series are estimated by kernel
smoothing methods from the sparse observations. The impulse response regression
coefficients of the lagged regression model are then estimated by means of
ridge regression (Tikhonov regularisation) or PCA regression (spectral
truncation). The latent functional time series are then recovered by means of
prediction, conditioning on all the observed observed data. The performance and
implementation of our methods are illustrated by means of a simulation study
and the analysis of meteorological data.",http://arxiv.org/pdf/1905.07218v2,stat.ME
2019-05-15 14:14:12+00:00,Robust change point tests by bounded transformations,"['Alexander Dürre', 'Roland Fried']","Classical moment based change point tests like the cusum test are very
powerful in case of Gaussian time series with one change point but behave
poorly under heavy tailed distributions and corrupted data. A new class of
robust change point tests based on cusum statistics of robustly transformed
observations is proposed. This framework is quite flexible, depending on the
used transformation one can detect for instance changes in the mean, scale or
dependence of a possibly multivariate time series. Simulations indicate that
this approach is very powerful in detecting changes in the marginal variance of
ARCH processes and outperforms existing proposals for detecting structural
breaks in the dependence structure of heavy tailed multivariate time series.",http://arxiv.org/pdf/1905.06201v1,math.ST
2019-05-14 14:42:58+00:00,Online Anomaly Detection with Sparse Gaussian Processes,"['Jingjing Fei', 'Shiliang Sun']","Online anomaly detection of time-series data is an important and challenging
task in machine learning. Gaussian processes (GPs) are powerful and flexible
models for modeling time-series data. However, the high time complexity of GPs
limits their applications in online anomaly detection. Attributed to some
internal or external changes, concept drift usually occurs in time-series data,
where the characteristics of data and meanings of abnormal behaviors alter over
time. Online anomaly detection methods should have the ability to adapt to
concept drift. Motivated by the above facts, this paper proposes the method of
sparse Gaussian processes with Q-function (SGP-Q). The SGP-Q employs sparse
Gaussian processes (SGPs) whose time complexity is lower than that of GPs, thus
significantly speeding up online anomaly detection. By using Q-function
properly, the SGP-Q can adapt to concept drift well. Moreover, the SGP-Q makes
use of few abnormal data in the training data by its strategy of updating
training data, resulting in more accurate sparse Gaussian process regression
models and better anomaly detection results. We evaluate the SGP-Q on various
artificial and real-world datasets. Experimental results validate the
effectiveness of the SGP-Q.",http://arxiv.org/pdf/1905.05761v1,cs.LG
2019-05-14 12:09:04+00:00,A self-organising eigenspace map for time series clustering,"['Donya Rahmani', 'Damien Fay', 'Jacek Brodzki']","This paper presents a novel time series clustering method, the
self-organising eigenspace map (SOEM), based on a generalisation of the
well-known self-organising feature map (SOFM). The SOEM operates on the
eigenspaces of the embedded covariance structures of time series which are
related directly to modes in those time series. Approximate joint
diagonalisation acts as a pseudo-metric across these spaces allowing us to
generalise the SOFM to a neural network with matrix input. The technique is
empirically validated against three sets of experiments; univariate and
multivariate time series clustering, and application to (clustered)
multi-variate time series forecasting. Results indicate that the technique
performs a valid topologically ordered clustering of the time series. The
clustering is superior in comparison to standard benchmarks when the data is
non-aligned, gives the best clustering stage for when used in forecasting, and
can be used with partial/non-overlapping time series, multivariate clustering
and produces a topological representation of the time series objects.",http://arxiv.org/pdf/1905.05540v1,stat.ML
2019-05-10 11:09:34+00:00,Capturing Evolution Genes for Time Series Data,"['Wenjie Hu', 'Jianping Huang', 'Liang Wu', 'Yang Yang', 'Zongtao Liu', 'Zhanlin Sun', 'Bingshen Yao', 'Ke Chen']","The modeling of time series is becoming increasingly critical in a wide
variety of applications. Overall, data evolves by following different patterns,
which are generally caused by different user behaviors. Given a time series, we
define the evolution gene to capture the latent user behaviors and to describe
how the behaviors lead to the generation of time series. In particular, we
propose a uniform framework that recognizes different evolution genes of
segments by learning a classifier, and adopt an adversarial generator to
implement the evolution gene by estimating the segments' distribution.
Experimental results based on a synthetic dataset and five real-world datasets
show that our approach can not only achieve a good prediction results (e.g.,
averagely +10.56% in terms of F1), but is also able to provide explanations of
the results.",http://arxiv.org/pdf/1905.05004v2,cs.LG
2019-05-10 07:11:17+00:00,Time-Series Event Prediction with Evolutionary State Graph,"['Wenjie Hu', 'Yang Yang', 'Ziqiang Cheng', 'Carl Yang', 'Xiang Ren']","The accurate and interpretable prediction of future events in time-series
data often requires the capturing of representative patterns (or referred to as
states) underpinning the observed data. To this end, most existing studies
focus on the representation and recognition of states, but ignore the changing
transitional relations among them. In this paper, we present evolutionary state
graph, a dynamic graph structure designed to systematically represent the
evolving relations (edges) among states (nodes) along time. We conduct analysis
on the dynamic graphs constructed from the time-series data and show that
changes on the graph structures (e.g., edges connecting certain state nodes)
can inform the occurrences of events (i.e., time-series fluctuation). Inspired
by this, we propose a novel graph neural network model, Evolutionary State
Graph Network (EvoNet), to encode the evolutionary state graph for accurate and
interpretable time-series event prediction. Specifically, Evolutionary State
Graph Network models both the node-level (state-to-state) and graph-level
(segment-to-segment) propagation, and captures the node-graph
(state-to-segment) interactions over time. Experimental results based on five
real-world datasets show that our approach not only achieves clear improvements
compared with 11 baselines, but also provides more insights towards explaining
the results of event predictions.",http://arxiv.org/pdf/1905.05006v4,cs.LG
2019-05-09 18:24:34+00:00,"Think Globally, Act Locally: A Deep Neural Network Approach to High-Dimensional Time Series Forecasting","['Rajat Sen', 'Hsiang-Fu Yu', 'Inderjit Dhillon']","Forecasting high-dimensional time series plays a crucial role in many
applications such as demand forecasting and financial predictions. Modern
datasets can have millions of correlated time-series that evolve together, i.e
they are extremely high dimensional (one dimension for each individual
time-series). There is a need for exploiting global patterns and coupling them
with local calibration for better prediction. However, most recent deep
learning approaches in the literature are one-dimensional, i.e, even though
they are trained on the whole dataset, during prediction, the future forecast
for a single dimension mainly depends on past values from the same dimension.
In this paper, we seek to correct this deficiency and propose DeepGLO, a deep
forecasting model which thinks globally and acts locally. In particular,
DeepGLO is a hybrid model that combines a global matrix factorization model
regularized by a temporal convolution network, along with another temporal
network that can capture local properties of each time-series and associated
covariates. Our model can be trained effectively on high-dimensional but
diverse time series, where different time series can have vastly different
scales, without a priori normalization or rescaling. Empirical results
demonstrate that DeepGLO can outperform state-of-the-art approaches; for
example, we see more than 25% improvement in WAPE over other methods on a
public dataset that contains more than 100K-dimensional time series.",http://arxiv.org/pdf/1905.03806v2,stat.ML
2019-05-05 14:59:22+00:00,Multivariate Time Series Classification using Dilated Convolutional Neural Network,"['Omolbanin Yazdanbakhsh', 'Scott Dick']","Multivariate time series classification is a high value and well-known
problem in machine learning community. Feature extraction is a main step in
classification tasks. Traditional approaches employ hand-crafted features for
classification while convolutional neural networks (CNN) are able to extract
features automatically. In this paper, we use dilated convolutional neural
network for multivariate time series classification. To deploy dilated CNN, a
multivariate time series is transformed into an image-like style and stacks of
dilated and strided convolutions are applied to extract in and between features
of variates in time series simultaneously. We evaluate our model on two human
activity recognition time series, finding that the automatic features extracted
for the time series can be as effective as hand-crafted features.",http://arxiv.org/pdf/1905.01697v1,cs.LG
2019-05-03 22:39:53+00:00,Temporal Graph Convolutional Networks for Automatic Seizure Detection,"['Ian Covert', 'Balu Krishnan', 'Imad Najm', 'Jiening Zhan', 'Matthew Shore', 'John Hixson', 'Ming Jack Po']","Seizure detection from EEGs is a challenging and time consuming clinical
problem that would benefit from the development of automated algorithms. EEGs
can be viewed as structural time series, because they are multivariate time
series where the placement of leads on a patient's scalp provides prior
information about the structure of interactions. Commonly used deep learning
models for time series don't offer a way to leverage structural information,
but this would be desirable in a model for structural time series. To address
this challenge, we propose the temporal graph convolutional network (TGCN), a
model that leverages structural information and has relatively few parameters.
TGCNs apply feature extraction operations that are localized and shared over
both time and space, thereby providing a useful inductive bias in tasks where
one expects similar features to be discriminative across the different
sequences. In our experiments we focus on metrics that are most important to
seizure detection, and demonstrate that TGCN matches the performance of related
models that have been shown to be state of the art in other tasks.
Additionally, we investigate interpretability advantages of TGCN by exploring
approaches for helping clinicians determine when precisely seizures occur, and
the parts of the brain that are most involved.",http://arxiv.org/pdf/1905.01375v1,cs.LG
2019-05-01 16:03:51+00:00,A Novel Trend Symbolic Aggregate Approximation for Time Series,"['Yufeng Yu', 'Yuelong Zhu', 'Dingsheng Wan', 'Qun Zhao', 'Huan Liu']","Symbolic Aggregate approximation (SAX) is a classical symbolic approach in
many time series data mining applications. However, SAX only reflects the
segment mean value feature and misses important information in a segment,
namely the trend of the value change in the segment. Such a miss may cause a
wrong classification in some cases, since the SAX representation cannot
distinguish different time series with similar average values but different
trends. In this paper, we present Trend Feature Symbolic Aggregate
approximation (TFSAX) to solve this problem. First, we utilize Piecewise
Aggregate Approximation (PAA) approach to reduce dimensionality and discretize
the mean value of each segment by SAX. Second, extract trend feature in each
segment by using trend distance factor and trend shape factor. Then, design
multi-resolution symbolic mapping rules to discretize trend information into
symbols. We also propose a modified distance measure by integrating the SAX
distance with a weighted trend distance. We show that our distance measure has
a tighter lower bound to the Euclidean distance than that of the original SAX.
The experimental results on diverse time series data sets demonstrate that our
proposed representation significantly outperforms the original SAX
representation and an improved SAX representation for classification.",http://arxiv.org/pdf/1905.00421v1,cs.LG
2019-05-01 10:39:21+00:00,Surface Type Classification for Autonomous Robot Indoor Navigation,"['Francesco Lomio', 'Erjon Skenderi', 'Damoon Mohamadi', 'Jussi Collin', 'Reza Ghabcheloo', 'Heikki Huttunen']","In this work we describe the preparation of a time series dataset of inertial
measurements for determining the surface type under a wheeled robot. The data
consists of over 7600 labeled time series samples, with the corresponding
surface type annotation. This data was used in two public competitions with
over 1500 participant in total. Additionally, we describe the performance of
state-of-art deep learning models for time series classification, as well as
propose a baseline model based on an ensemble of machine learning methods. The
baseline achieves an accuracy of over 68% with our nine-category dataset.",http://arxiv.org/pdf/1905.00252v1,cs.LG
2019-04-29 10:12:17+00:00,ConvTimeNet: A Pre-trained Deep Convolutional Neural Network for Time Series Classification,"['Kathan Kashiparekh', 'Jyoti Narwariya', 'Pankaj Malhotra', 'Lovekesh Vig', 'Gautam Shroff']","Training deep neural networks often requires careful hyper-parameter tuning
and significant computational resources. In this paper, we propose ConvTimeNet
(CTN): an off-the-shelf deep convolutional neural network (CNN) trained on
diverse univariate time series classification (TSC) source tasks. Once trained,
CTN can be easily adapted to new TSC target tasks via a small amount of
fine-tuning using labeled instances from the target tasks. We note that the
length of convolutional filters is a key aspect when building a pre-trained
model that can generalize to time series of different lengths across datasets.
To achieve this, we incorporate filters of multiple lengths in all
convolutional layers of CTN to capture temporal features at multiple time
scales. We consider all 65 datasets with time series of lengths up to 512
points from the UCR TSC Benchmark for training and testing transferability of
CTN: We train CTN on a randomly chosen subset of 24 datasets using a multi-head
approach with a different softmax layer for each training dataset, and study
generalizability and transferability of the learned filters on the remaining 41
TSC datasets. We observe significant gains in classification accuracy as well
as computational efficiency when using pre-trained CTN as a starting point for
subsequent task-specific fine-tuning compared to existing state-of-the-art TSC
approaches. We also provide qualitative insights into the working of CTN by: i)
analyzing the activations and filters of first convolution layer suggesting the
filters in CTN are generically useful, ii) analyzing the impact of the design
decision to incorporate multiple length decisions, and iii) finding regions of
time series that affect the final classification decision via occlusion
sensitivity analysis.",http://arxiv.org/pdf/1904.12546v2,cs.LG
2019-04-29 09:06:00+00:00,The Hyvärinen scoring rule in Gaussian linear time series models,"['Silvia Columbu', 'Valentina Mameli', 'Monica Musio', 'A. Philip Dawid']","Likelihood-based estimation methods involve the normalising constant of the
model distributions, expressed as a function of the parameter. However in many
problems this function is not easily available, and then less efficient but
more easily computed estimators may be attractive. In this work we study
stationary time-series models, and construct and analyse ""score-matching''
estimators, that do not involve the normalising constant. We consider two
scenarios: a single series of increasing length, and an increasing number of
independent series of fixed length. In the latter case there are two variants,
one based on the full data, and another based on a sufficient statistic. We
study the empirical performance of these estimators in three special cases,
autoregressive (\AR), moving average (MA) and fractionally differenced white
noise (\ARFIMA) models, and make comparisons with full and pairwise likelihood
estimators. The results are somewhat model-dependent, with the new estimators
doing well for $\MA$ and \ARFIMA\ models, but less so for $\AR$ models.",http://arxiv.org/pdf/1904.12513v1,stat.ME
2019-04-27 20:30:26+00:00,Temporal-Clustering Invariance in Irregular Healthcare Time Series,"['Mohammad Taha Bahadori', 'Zachary Chase Lipton']","Electronic records contain sequences of events, some of which take place all
at once in a single visit, and others that are dispersed over multiple visits,
each with a different timestamp. We postulate that fine temporal detail, e.g.,
whether a series of blood tests are completed at once or in rapid succession
should not alter predictions based on this data. Motivated by this intuition,
we propose models for analyzing sequences of multivariate clinical time series
data that are invariant to this temporal clustering. We propose an efficient
data augmentation technique that exploits the postulated temporal-clustering
invariance to regularize deep neural networks optimized for several clinical
prediction tasks. We introduce two techniques to temporally coarsen
(downsample) irregular time series: (i) grouping the data points based on
regularly-spaced timestamps; and (ii) clustering them, yielding
irregularly-paced timestamps. Moreover, we propose a MultiResolution Ensemble
(MRE) model, improving predictive accuracy by ensembling predictions based on
inputs sequences transformed by different coarsening operators. Our experiments
show that MRE improves the mAP on the benchmark mortality prediction task from
51.53% to 53.92%.",http://arxiv.org/pdf/1904.12206v1,cs.LG
2019-04-25 16:09:02+00:00,Bracketing in the Comparative Interrupted Time-Series Design to Address Concerns about History Interacting with Group: Evaluating Missouri Handgun Purchaser Law,"['Raiden B. Hasegawa', 'Dylan S. Small', 'Daniel W Webster']","In the comparative interrupted time series design (also called the method of
difference-in-differences), the change in outcome in a group exposed to
treatment in the periods before and after the exposure is compared to the
change in outcome in a control group not exposed to treatment in either period.
The standard difference-in-difference estimator for a comparative interrupted
time series design will be biased for estimating the causal effect of the
treatment if there is an interaction between history in the after period and
the groups; for example, there is a historical event besides the start of the
treatment in the after period that benefits the treated group more than the
control group. We present a bracketing method for bounding the effect of an
interaction between history and the groups that arises from a time-invariant
unmeasured confounder having a different effect in the after period than the
before period. The method is applied to a study of the effect of the repeal of
Missouri's permit-to-purchase handgun law on its firearm homicide rate. We
estimate that the effect of the permit-to-purchase repeal on Missouri's firearm
homicide rate is bracketed between 0.9 and 1.3 homicides per 100,000 people,
corresponding to a percentage increase of 17% to 27% (95% confidence interval:
[0.6,1.7] or [11%,35%]). A placebo study provides additional support for the
hypothesis that the repeal has a causal effect of increasing the rate of
state-wide firearm homicides.",http://arxiv.org/pdf/1904.11430v1,stat.ME
2019-04-25 15:49:23+00:00,Time Series Simulation by Conditional Generative Adversarial Net,"['Rao Fu', 'Jie Chen', 'Shutian Zeng', 'Yiping Zhuang', 'Agus Sudjianto']","Generative Adversarial Net (GAN) has been proven to be a powerful machine
learning tool in image data analysis and generation. In this paper, we propose
to use Conditional Generative Adversarial Net (CGAN) to learn and simulate time
series data. The conditions can be both categorical and continuous variables
containing different kinds of auxiliary information. Our simulation studies
show that CGAN is able to learn different kinds of normal and heavy tail
distributions, as well as dependent structures of different time series and it
can further generate conditional predictive distributions consistent with the
training data distributions. We also provide an in-depth discussion on the
rationale of GAN and the neural network as hierarchical splines to draw a clear
connection with the existing statistical method for distribution generation. In
practice, CGAN has a wide range of applications in the market risk and
counterparty risk analysis: it can be applied to learn the historical data and
generate scenarios for the calculation of Value-at-Risk (VaR) and Expected
Shortfall (ES) and predict the movement of the market risk factors. We present
a real data analysis including a backtesting to demonstrate CGAN is able to
outperform the Historic Simulation, a popular method in market risk analysis
for the calculation of VaR. CGAN can also be applied in the economic time
series modeling and forecasting, and an example of hypothetical shock analysis
for economic models and the generation of potential CCAR scenarios by CGAN is
given at the end of the paper.",http://arxiv.org/pdf/1904.11419v1,stat.ML
2019-04-24 21:31:12+00:00,State-domain Change Point Detection for Nonlinear Time Series Regression,"['Yan Cui', 'Jun Yang', 'Zhou Zhou']","Change point detection in time series has attracted substantial interest, but
most of the existing results have been focused on detecting change points in
the time domain. This paper considers the situation where nonlinear time series
have potential change points in the state domain. We apply a density-weighted
anti-symmetric kernel function to the state domain and therefore propose a
nonparametric procedure to test the existence of change points. When the
existence of change points is affirmative, we further introduce an algorithm to
estimate the number of change points together with their locations. Theoretical
results of the proposed detection and estimation procedures are given and a
real dataset is used to illustrate our methods.",http://arxiv.org/pdf/1904.11075v4,stat.ME
2019-04-18 07:14:45+00:00,Explaining Deep Classification of Time-Series Data with Learned Prototypes,"['Alan H. Gee', 'Diego Garcia-Olano', 'Joydeep Ghosh', 'David Paydarfar']","The emergence of deep learning networks raises a need for explainable AI so
that users and domain experts can be confident applying them to high-risk
decisions. In this paper, we leverage data from the latent space induced by
deep learning models to learn stereotypical representations or ""prototypes""
during training to elucidate the algorithmic decision-making process. We study
how leveraging prototypes effect classification decisions of two dimensional
time-series data in a few different settings: (1) electrocardiogram (ECG)
waveforms to detect clinical bradycardia, a slowing of heart rate, in preterm
infants, (2) respiration waveforms to detect apnea of prematurity, and (3)
audio waveforms to classify spoken digits. We improve upon existing models by
optimizing for increased prototype diversity and robustness, visualize how
these prototypes in the latent space are used by the model to distinguish
classes, and show that prototypes are capable of learning features on two
dimensional time-series data to produce explainable insights during
classification tasks. We show that the prototypes are capable of learning
real-world features - bradycardia in ECG, apnea in respiration, and
articulation in speech - as well as features within sub-classes. Our novel work
leverages learned prototypical framework on two dimensional time-series data to
produce explainable insights during classification tasks.",http://arxiv.org/pdf/1904.08935v3,cs.LG
2019-04-17 13:59:14+00:00,Indirect Inference for Time Series Using the Empirical Characteristic Function and Control Variates,"['Richard A. Davis', 'Thiago do Rêgo Sousa', 'Claudia Klüppelberg']","We estimate the parameter of a stationary time series process by minimizing
the integrated weighted mean squared error between the empirical and simulated
characteristic function, when the true characteristic functions cannot be
explicitly computed. Motivated by Indirect Inference, we use a Monte Carlo
approximation of the characteristic function based on iid simulated blocks. As
a classical variance reduction technique, we propose the use of control
variates for reducing the variance of this Monte Carlo approximation. These two
approximations yield two new estimators that are applicable to a large class of
time series processes. We show consistency and asymptotic normality of the
parameter estimators under strong mixing, moment conditions, and smoothness of
the simulated blocks with respect to its parameter. In a simulation study we
show the good performance of these new simulation based estimators, and the
superiority of the control variates based estimator for Poisson driven time
series of counts.",http://arxiv.org/pdf/1904.08276v3,math.ST
2019-04-17 03:18:45+00:00,Forecasting with time series imaging,"['Xixi Li', 'Yanfei Kang', 'Feng Li']","Feature-based time series representations have attracted substantial
attention in a wide range of time series analysis methods. Recently, the use of
time series features for forecast model averaging has been an emerging research
focus in the forecasting community. Nonetheless, most of the existing
approaches depend on the manual choice of an appropriate set of features.
Exploiting machine learning methods to extract features from time series
automatically becomes crucial in state-of-the-art time series analysis. In this
paper, we introduce an automated approach to extract time series features based
on time series imaging. We first transform time series into recurrence plots,
from which local features can be extracted using computer vision algorithms.
The extracted features are used for forecast model averaging. Our experiments
show that forecasting based on automatically extracted features, with less
human intervention and a more comprehensive view of the raw time series data,
yields highly comparable performances with the best methods in the largest
forecasting competition dataset (M4) and outperforms the top methods in the
Tourism forecasting competition dataset.",http://arxiv.org/pdf/1904.08064v3,stat.ML
2019-04-16 11:41:34+00:00,Forecasting Weakly Correlated Time Series in Tasks of Electronic Commerce,"['Lyudmyla Kirichenko', 'Tamara Radivilova', 'Illya Zinkevich']","Forecasting of weakly correlated time series of conversion rate by methods of
exponential smoothing, neural network and decision tree on the example of
conversion percent series for an electronic store is considered in the paper.
The advantages and disadvantages of each method are considered.",http://arxiv.org/pdf/1904.10927v1,cs.LG
2019-04-16 05:03:45+00:00,DSTP-RNN: a dual-stage two-phase attention-based recurrent neural networks for long-term and multivariate time series prediction,"['Yeqi Liu', 'Chuanyang Gong', 'Ling Yang', 'Yingyi Chen']","Long-term prediction of multivariate time series is still an important but
challenging problem. The key to solve this problem is to capture the spatial
correlations at the same time, the spatio-temporal relationships at different
times and the long-term dependence of the temporal relationships between
different series. Attention-based recurrent neural networks (RNN) can
effectively represent the dynamic spatio-temporal relationships between
exogenous series and target series, but it only performs well in one-step time
prediction and short-term time prediction. In this paper, inspired by human
attention mechanism including the dual-stage two-phase (DSTP) model and the
influence mechanism of target information and non-target information, we
propose DSTP-based RNN (DSTP-RNN) and DSTP-RNN-2 respectively for long-term
time series prediction. Specifically, we first propose the DSTP-based structure
to enhance the spatial correlations between exogenous series. The first phase
produces violent but decentralized response weight, while the second phase
leads to stationary and concentrated response weight. Secondly, we employ
multiple attentions on target series to boost the long-term dependence.
Finally, we study the performance of deep spatial attention mechanism and
provide experiment and interpretation. Our methods outperform nine baseline
methods on four datasets in the fields of energy, finance, environment and
medicine, respectively.",http://arxiv.org/pdf/1904.07464v1,cs.LG
2019-04-14 16:39:16+00:00,Bootstrapping Covariance Operators of Functional Time Series,"['Olimjon Sh. Sharipov', 'Martin Wendler']","For testing hypothesis on the covariance operator of functional time series,
we suggest to use the full functional information and to avoid dimension
reduction techniques. The limit distribution follows from the central limit
theorem of the weak convergence of the partial sum process in general Hilbert
space applied to the product space. In order to obtain critical values for
tests, we generalize bootstrap results from the independent to the dependent
case. This results can be applied to covariance operators, autocovariance
operators and cross covariance operators. We discuss one sample and changepoint
tests and give some simulation results.",http://arxiv.org/pdf/1904.06721v3,math.ST
2019-04-12 22:48:49+00:00,Remaining Useful Life Estimation Using Functional Data Analysis,"['Qiyao Wang', 'Shuai Zheng', 'Ahmed Farahat', 'Susumu Serita', 'Chetan Gupta']","Remaining Useful Life (RUL) of an equipment or one of its components is
defined as the time left until the equipment or component reaches its end of
useful life. Accurate RUL estimation is exceptionally beneficial to Predictive
Maintenance, and Prognostics and Health Management (PHM). Data driven
approaches which leverage the power of algorithms for RUL estimation using
sensor and operational time series data are gaining popularity. Existing
algorithms, such as linear regression, Convolutional Neural Network (CNN),
Hidden Markov Models (HMMs), and Long Short-Term Memory (LSTM), have their own
limitations for the RUL estimation task. In this work, we propose a novel
Functional Data Analysis (FDA) method called functional Multilayer Perceptron
(functional MLP) for RUL estimation. Functional MLP treats time series data
from multiple equipment as a sample of random continuous processes over time.
FDA explicitly incorporates both the correlations within the same equipment and
the random variations across different equipment's sensor time series into the
model. FDA also has the benefit of allowing the relationship between RUL and
sensor variables to vary over time. We implement functional MLP on the
benchmark NASA C-MAPSS data and evaluate the performance using two
popularly-used metrics. Results show the superiority of our algorithm over all
the other state-of-the-art methods.",http://arxiv.org/pdf/1904.06442v1,cs.LG
2019-04-10 03:47:49+00:00,Discovering patterns of online popularity from time series,"['Mert Ozer', 'Anna Sapienza', 'Andrés Abeliuk', 'Goran Muric', 'Emilio Ferrara']","How is popularity gained online? Is being successful strictly related to
rapidly becoming viral in an online platform or is it possible to acquire
popularity in a steady and disciplined fashion? What are other temporal
characteristics that can unveil the popularity of online content? To answer
these questions, we leverage a multi-faceted temporal analysis of the evolution
of popular online contents. Here, we present dipm-SC: a multi-dimensional
shape-based time-series clustering algorithm with a heuristic to find the
optimal number of clusters. First, we validate the accuracy of our algorithm on
synthetic datasets generated from benchmark time series models. Second, we show
that dipm-SC can uncover meaningful clusters of popularity behaviors in a
real-world Twitter dataset. By clustering the multidimensional time-series of
the popularity of contents coupled with other domain-specific dimensions, we
uncover two main patterns of popularity: bursty and steady temporal behaviors.
Moreover, we find that the way popularity is gained over time has no
significant impact on the final cumulative popularity.",http://arxiv.org/pdf/1904.04994v1,cs.LG
2019-04-09 21:06:55+00:00,Enhancing Time Series Momentum Strategies Using Deep Neural Networks,"['Bryan Lim', 'Stefan Zohren', 'Stephen Roberts']","While time series momentum is a well-studied phenomenon in finance, common
strategies require the explicit definition of both a trend estimator and a
position sizing rule. In this paper, we introduce Deep Momentum Networks -- a
hybrid approach which injects deep learning based trading rules into the
volatility scaling framework of time series momentum. The model also
simultaneously learns both trend estimation and position sizing in a
data-driven manner, with networks directly trained by optimising the Sharpe
ratio of the signal. Backtesting on a portfolio of 88 continuous futures
contracts, we demonstrate that the Sharpe-optimised LSTM improved traditional
methods by more than two times in the absence of transactions costs, and
continue outperforming when considering transaction costs up to 2-3 basis
points. To account for more illiquid assets, we also propose a turnover
regularisation term which trains the network to factor in costs at run-time.",http://arxiv.org/pdf/1904.04912v3,stat.ML
2019-04-09 16:51:01+00:00,Time-Series Analysis via Low-Rank Matrix Factorization Applied to Infant-Sleep Data,"['Sheng Liu', 'Mark Cheng', 'Hayley Brooks', 'Wayne Mackey', 'David J. Heeger', 'Esteban G. Tabak', 'Carlos Fernandez-Granda']","We propose a nonparametric model for time series with missing data based on
low-rank matrix factorization. The model expresses each instance in a set of
time series as a linear combination of a small number of shared basis
functions. Constraining the functions and the corresponding coefficients to be
nonnegative yields an interpretable low-dimensional representation of the data.
A time-smoothing regularization term ensures that the model captures meaningful
trends in the data, instead of overfitting short-term fluctuations. The
low-dimensional representation makes it possible to detect outliers and cluster
the time series according to the interpretable features extracted by the model,
and also to perform forecasting via kernel regression. We apply our methodology
to a large real-world dataset of infant-sleep data gathered by caregivers with
a mobile-phone app. Our analysis automatically extracts daily-sleep patterns
consistent with the existing literature. This allows us to compute
sleep-development trends for the cohort, which characterize the emergence of
circadian sleep and different napping habits. We apply our methodology to
detect anomalous individuals, to cluster the cohort into groups with different
sleeping tendencies, and to obtain improved predictions of future sleep
behavior.",http://arxiv.org/pdf/1904.04780v3,stat.ML
2019-04-03 19:46:56+00:00,Decomposing Temperature Time Series with Non-Negative Matrix Factorization,"['Peter Weiderer', 'Ana Maria Tomé', 'Elmar Wolfgang Lang']","During the fabrication of casting parts sensor data is typically
automatically recorded and accumulated for process monitoring and defect
diagnosis. As casting is a thermal process with many interacting process
parameters, root cause analysis tends to be tedious and ineffective. We show
how a decomposition based on non-negative matrix factorization (NMF), which is
guided by a knowledge-based initialization strategy, is able to extract
physical meaningful sources from temperature time series collected during a
thermal manufacturing process. The approach assumes the time series to be
generated by a superposition of several simultaneously acting component
processes. NMF is able to reverse the superposition and to identify the hidden
component processes. The latter can be linked to ongoing physical phenomena and
process variables, which cannot be monitored directly. Our approach provides
new insights into the underlying physics and offers a tool, which can assist in
diagnosing defect causes. We demonstrate our method by applying it to real
world data, collected in a foundry during the series production of casting
parts for the automobile industry.",http://arxiv.org/pdf/1904.02217v1,cs.LG
2019-03-28 01:14:31+00:00,Medical Time Series Classification with Hierarchical Attention-based Temporal Convolutional Networks: A Case Study of Myotonic Dystrophy Diagnosis,"['Lei Lin', 'Beilei Xu', 'Wencheng Wu', 'Trevor Richardson', 'Edgar A. Bernal']","Myotonia, which refers to delayed muscle relaxation after contraction, is the
main symptom of myotonic dystrophy patients. We propose a hierarchical
attention-based temporal convolutional network (HA-TCN) for myotonic dystrohpy
diagnosis from handgrip time series data, and introduce mechanisms that enable
model explainability. We compare the performance of the HA-TCN model against
that of benchmark TCN models, LSTM models with and without attention
mechanisms, and SVM approaches with handcrafted features. In terms of
classification accuracy and F1 score, we found all deep learning models have
similar levels of performance, and they all outperform SVM. Further, the HA-TCN
model outperforms its TCN counterpart with regards to computational efficiency
regardless of network depth, and in terms of performance particularly when the
number of hidden layers is small. Lastly, HA-TCN models can consistently
identify relevant time series segments in the relaxation phase of the handgrip
time series, and exhibit increased robustness to noise when compared to
attention-based LSTM models.",http://arxiv.org/pdf/1903.11748v1,cs.LG
2019-03-27 09:39:38+00:00,Introduction to Dynamic Linear Models for Time Series Analysis,['Marko Laine'],"Dynamic linear models (DLM) offer a very generic framework to analyse time
series data. Many classical time series models can be formulated as DLMs,
including ARMA models and standard multiple linear regression models. The
models can be seen as general regression models where the coefficients can vary
in time. In addition, they allow for a state space representation and a
formulation as hierarchical statistical models, which in turn is the key for
efficient estimation by Kalman formulas and by Markov chain Monte Carlo (MCMC)
methods. A dynamic linear model can handle non-stationary processes, missing
values and non-uniform sampling as well as observations with varying
accuracies. This chapter gives an introduction to DLM and shows how to build
various useful models for analysing trends and other sources of variability in
geodetic time series.",http://arxiv.org/pdf/1903.11309v2,stat.ME
2019-03-22 23:39:53+00:00,Time Series Imputation,"['Samuel Arcadinho', 'Paulo Mateus']","Multivariate time series is a very active topic in the research community and
many machine learning tasks are being used in order to extract information from
this type of data. However, in real-world problems data has missing values,
which may difficult the application of machine learning techniques to extract
information. In this paper we focus on the task of imputation of time series.
Many imputation methods for time series are based on regression methods.
Unfortunately, these methods perform poorly when the variables are categorical.
To address this case, we propose a new imputation method based on Expectation
Maximization over dynamic Bayesian networks. The approach is assessed with
synthetic and real data, and it outperforms several state-of-the art methods.",http://arxiv.org/pdf/1903.09732v1,cs.LG
2019-03-22 12:53:23+00:00,Optimal Combination Forecasts on Retail Multi-Dimensional Sales Data,"['Luis Roque', 'Cristina A. C. Fernandes', 'Tony Silva']","Time series data in the retail world are particularly rich in terms of
dimensionality, and these dimensions can be aggregated in groups or
hierarchies. Valuable information is nested in these complex structures, which
helps to predict the aggregated time series data. From a portfolio of brands
under HUUB's monitoring, we selected two to explore their sales behaviour,
leveraging the grouping properties of their product structure. Using
statistical models, namely SARIMA, to forecast each level of the hierarchy, an
optimal combination approach was used to generate more consistent forecasts in
the higher levels. Our results show that the proposed methods can indeed
capture nested information in the more granular series, helping to improve the
forecast accuracy of the aggregated series. The Weighted Least Squares (WLS)
method surpasses all other methods proposed in the study, including the Minimum
Trace (MinT) reconciliation.",http://arxiv.org/pdf/1903.09478v1,stat.ML
2019-03-21 21:42:19+00:00,Trainable Time Warping: Aligning Time-Series in the Continuous-Time Domain,"['Soheil Khorram', 'Melvin G McInnis', 'Emily Mower Provost']","DTW calculates the similarity or alignment between two signals, subject to
temporal warping. However, its computational complexity grows exponentially
with the number of time-series. Although there have been algorithms developed
that are linear in the number of time-series, they are generally quadratic in
time-series length. The exception is generalized time warping (GTW), which has
linear computational cost. Yet, it can only identify simple time warping
functions. There is a need for a new fast, high-quality multisequence alignment
algorithm. We introduce trainable time warping (TTW), whose complexity is
linear in both the number and the length of time-series. TTW performs alignment
in the continuous-time domain using a sinc convolutional kernel and a
gradient-based optimization technique. We compare TTW and GTW on 85 UCR
datasets in time-series averaging and classification. TTW outperforms GTW on
67.1% of the datasets for the averaging tasks, and 61.2% of the datasets for
the classification tasks.",http://arxiv.org/pdf/1903.09245v1,cs.LG
2019-03-21 13:03:55+00:00,Multi-Task Time Series Analysis applied to Drug Response Modelling,"['Alex Bird', 'Christopher K. I. Williams', 'Christopher Hawthorne']","Time series models such as dynamical systems are frequently fitted to a
cohort of data, ignoring variation between individual entities such as
patients. In this paper we show how these models can be personalised to an
individual level while retaining statistical power, via use of multi-task
learning (MTL). To our knowledge this is a novel development of MTL which
applies to time series both with and without control inputs. The modelling
framework is demonstrated on a physiological drug response problem which
results in improved predictive accuracy and uncertainty estimation over
existing state-of-the-art models.",http://arxiv.org/pdf/1903.08970v1,cs.LG
2019-03-17 10:04:23+00:00,Adversarial Attacks on Deep Neural Networks for Time Series Classification,"['Hassan Ismail Fawaz', 'Germain Forestier', 'Jonathan Weber', 'Lhassane Idoumghar', 'Pierre-Alain Muller']","Time Series Classification (TSC) problems are encountered in many real life
data mining tasks ranging from medicine and security to human activity
recognition and food safety. With the recent success of deep neural networks in
various domains such as computer vision and natural language processing,
researchers started adopting these techniques for solving time series data
mining problems. However, to the best of our knowledge, no previous work has
considered the vulnerability of deep learning models to adversarial time series
examples, which could potentially make them unreliable in situations where the
decision taken by the classifier is crucial such as in medicine and security.
For computer vision problems, such attacks have been shown to be very easy to
perform by altering the image and adding an imperceptible amount of noise to
trick the network into wrongly classifying the input image. Following this line
of work, we propose to leverage existing adversarial attack mechanisms to add a
special noise to the input time series in order to decrease the network's
confidence when classifying instances at test time. Our results reveal that
current state-of-the-art deep learning time series classifiers are vulnerable
to adversarial attacks which can have major consequences in multiple domains
such as food safety and quality assurance.",http://arxiv.org/pdf/1903.07054v2,cs.LG
2019-03-17 00:06:18+00:00,Change Point Detection in the Mean of High-Dimensional Time Series Data under Dependence,"['Jun Li', 'Minya Xu', 'Ping-Shou Zhong', 'Lingjun Li']","High-dimensional time series are characterized by a large number of
measurements and complex dependence, and often involve abrupt change points. We
propose a new procedure to detect change points in the mean of high-dimensional
time series data. The proposed procedure incorporates spatial and temporal
dependence of data and is able to test and estimate the change point occurred
on the boundary of time series. We study its asymptotic properties under mild
conditions. Simulation studies demonstrate its robust performance through the
comparison with other existing methods. Our procedure is applied to an fMRI
dataset.",http://arxiv.org/pdf/1903.07006v1,stat.ME
2019-03-15 15:32:43+00:00,Deep Neural Network Ensembles for Time Series Classification,"['Hassan Ismail Fawaz', 'Germain Forestier', 'Jonathan Weber', 'Lhassane Idoumghar', 'Pierre-Alain Muller']","Deep neural networks have revolutionized many fields such as computer vision
and natural language processing. Inspired by this recent success, deep learning
started to show promising results for Time Series Classification (TSC).
However, neural networks are still behind the state-of-the-art TSC algorithms,
that are currently composed of ensembles of 37 non deep learning based
classifiers. We attribute this gap in performance due to the lack of neural
network ensembles for TSC. Therefore in this paper, we show how an ensemble of
60 deep learning models can significantly improve upon the current
state-of-the-art performance of neural networks for TSC, when evaluated over
the UCR/UEA archive: the largest publicly available benchmark for time series
analysis. Finally, we show how our proposed Neural Network Ensemble (NNE) is
the first time series classifier to outperform COTE while reaching similar
performance to the current state-of-the-art ensemble HIVE-COTE.",http://arxiv.org/pdf/1903.06602v2,cs.LG
2019-03-14 07:42:19+00:00,Detecting causality in multivariate time series via non-uniform embedding,"['Ziyu Jia', 'Youfang Lin', 'Zehui Jiao', 'Yan Ma', 'Jing Wang']","Causal analysis based on non-uniform embedding schemes is an important way to
detect the underlying interactions between dynamic systems. However, there are
still some obstacles to estimate high-dimensional conditional mutual
information and form optimal mixed embedding vector in traditional non-uniform
embedding schemes. In this study, we present a new non-uniform embedding method
framed in information theory to detect causality for multivariate time series,
named LM-PMIME, which integrates the low-dimensional approximation of
conditional mutual information and the mixed search strategy for the
construction of the mixed embedding vector. We apply the proposed method to
simulations of linear stochastic, nonlinear stochastic, and chaotic systems,
demonstrating its superiority over partial conditional mutual information from
mixed embedding (PMIME) method. Moreover, the proposed method works well for
multivariate time series with weak coupling strengths, especially for chaotic
systems. In the actual application, we show its applicability to epilepsy
multichannel electrocorticographic recordings.",http://arxiv.org/pdf/1903.05842v3,stat.ME
2019-03-13 16:40:23+00:00,Matrix factorization for multivariate time series analysis,"['Pierre Alquier', 'Nicolas Marie']","Matrix factorization is a powerful data analysis tool. It has been used in
multivariate time series analysis, leading to the decomposition of the series
in a small set of latent factors. However, little is known on the statistical
performances of matrix factorization for time series. In this paper, we extend
the results known for matrix estimation in the i.i.d setting to time series.
Moreover, we prove that when the series exhibit some additional structure like
periodicity or smoothness, it is possible to improve on the classical rates of
convergence.",http://arxiv.org/pdf/1903.05589v2,math.ST
2019-03-11 21:17:20+00:00,Financial Trading Model with Stock Bar Chart Image Time Series with Deep Convolutional Neural Networks,"['Omer Berat Sezer', 'Ahmet Murat Ozbayoglu']","Even though computational intelligence techniques have been extensively
utilized in financial trading systems, almost all developed models use the time
series data for price prediction or identifying buy-sell points. However, in
this study we decided to use 2-D stock bar chart images directly without
introducing any additional time series associated with the underlying stock. We
propose a novel algorithmic trading model CNN-BI (Convolutional Neural Network
with Bar Images) using a 2-D Convolutional Neural Network. We generated 2-D
images of sliding windows of 30-day bar charts for Dow 30 stocks and trained a
deep Convolutional Neural Network (CNN) model for our algorithmic trading
model. We tested our model separately between 2007-2012 and 2012-2017 for
representing different market conditions. The results indicate that the model
was able to outperform Buy and Hold strategy, especially in trendless or bear
markets. Since this is a preliminary study and probably one of the first
attempts using such an unconventional approach, there is always potential for
improvement. Overall, the results are promising and the model might be
integrated as part of an ensemble trading model combined with different
strategies.",http://arxiv.org/pdf/1903.04610v1,cs.LG
2019-03-08 06:26:59+00:00,Should we Reload Time Series Classification Performance Evaluation ? (a position paper),"['Dominique Gay', 'Vincent Lemaire']","Since the introduction and the public availability of the \textsc{ucr} time
series benchmark data sets, numerous Time Series Classification (TSC) methods
has been designed, evaluated and compared to each others. We suggest a critical
view of TSC performance evaluation protocols put in place in recent TSC
literature. The main goal of this `position' paper is to stimulate discussion
and reflexion about performance evaluation in TSC literature.",http://arxiv.org/pdf/1903.03300v1,stat.ML
2019-03-07 09:29:31+00:00,GRATIS: GeneRAting TIme Series with diverse and controllable characteristics,"['Yanfei Kang', 'Rob J Hyndman', 'Feng Li']","The explosion of time series data in recent years has brought a flourish of
new time series analysis methods, for forecasting, clustering, classification
and other tasks. The evaluation of these new methods requires either collecting
or simulating a diverse set of time series benchmarking data to enable reliable
comparisons against alternative approaches. We propose GeneRAting TIme Series
with diverse and controllable characteristics, named GRATIS, with the use of
mixture autoregressive (MAR) models. We simulate sets of time series using MAR
models and investigate the diversity and coverage of the generated time series
in a time series feature space. By tuning the parameters of the MAR models,
GRATIS is also able to efficiently generate new time series with controllable
features. In general, as a costless surrogate to the traditional data
collection approach, GRATIS can be used as an evaluation tool for tasks such as
time series forecasting and classification. We illustrate the usefulness of our
time series generation process through a time series forecasting application.",http://arxiv.org/pdf/1903.02787v2,stat.ML
2019-03-05 11:32:26+00:00,Data-driven Neural Architecture Learning For Financial Time-series Forecasting,"['Dat Thanh Tran', 'Juho Kanniainen', 'Moncef Gabbouj', 'Alexandros Iosifidis']","Forecasting based on financial time-series is a challenging task since most
real-world data exhibits nonstationary property and nonlinear dependencies. In
addition, different data modalities often embed different nonlinear
relationships which are difficult to capture by human-designed models. To
tackle the supervised learning task in financial time-series prediction, we
propose the application of a recently formulated algorithm that adaptively
learns a mapping function, realized by a heterogeneous neural architecture
composing of Generalized Operational Perceptron, given a set of labeled data.
With a modified objective function, the proposed algorithm can accommodate the
frequently observed imbalanced data distribution problem. Experiments on a
large-scale Limit Order Book dataset demonstrate that the proposed algorithm
outperforms related algorithms, including tensor-based methods which have
access to a broader set of input information.",http://arxiv.org/pdf/1903.06751v1,cs.LG
2019-03-04 15:37:14+00:00,Time Series Source Separation using Dynamic Mode Decomposition,"['Arvind Prasadan', 'Raj Rao Nadakuditi']","The Dynamic Mode Decomposition (DMD) extracted dynamic modes are the
non-orthogonal eigenvectors of the matrix that best approximates the one-step
temporal evolution of the multivariate samples. In the context of dynamical
system analysis, the extracted dynamic modes are a generalization of global
stability modes. We apply DMD to a data matrix whose rows are linearly
independent, additive mixtures of latent time series. We show that when the
latent time series are uncorrelated at a lag of one time-step then, in the
large sample limit, the recovered dynamic modes will approximate, up to a
column-wise normalization, the columns of the mixing matrix. Thus, DMD is a
time series blind source separation algorithm in disguise, but is different
from closely related second order algorithms such as the Second-Order Blind
Identification (SOBI) method and the Algorithm for Multiple Unknown Signals
Extraction (AMUSE). All can unmix mixed stationary, ergodic Gaussian time
series in a way that kurtosis-based Independent Components Analysis (ICA)
fundamentally cannot. We use our insights on single lag DMD to develop a
higher-lag extension, analyze the finite sample performance with and without
randomly missing data, and identify settings where the higher lag variant can
outperform the conventional single lag variant. We validate our results with
numerical simulations, and highlight how DMD can be used in change point
detection.",http://arxiv.org/pdf/1903.01310v4,math.ST
2019-03-04 14:34:53+00:00,Multiscale clustering of nonparametric regression curves,"['Michael Vogt', 'Oliver Linton']","In a wide range of modern applications, we observe a large number of time
series rather than only a single one. It is often natural to suppose that there
is some group structure in the observed time series. When each time series is
modelled by a nonparametric regression equation, one may in particular assume
that the observed time series can be partitioned into a small number of groups
whose members share the same nonparametric regression function. We develop a
bandwidth-free clustering method to estimate the unknown group structure from
the data. More precisely speaking, we construct multiscale estimators of the
unknown groups and their unknown number which are free of classical bandwidth
or smoothing parameters. In the theoretical part of the paper, we analyze the
statistical properties of our estimators. Our theoretical results are derived
under general conditions which allow the data to be dependent both in time
series direction and across different time series. The technical analysis of
the paper is complemented by a simulation study and a real-data application.",http://arxiv.org/pdf/1903.01459v1,math.ST
2019-03-04 14:13:16+00:00,Multiscale inference and long-run variance estimation in nonparametric regression with time series errors,"['Marina Khismatullina', 'Michael Vogt']","In this paper, we develop new multiscale methods to test qualitative
hypotheses about the regression function m in a nonparametric regression model
with fixed design points and time series errors. In time series applications, m
represents a nonparametric time trend. Practitioners are often interested in
whether the trend m has certain shape properties. For example, they would like
to know whether m is constant or whether it is increasing/decreasing in certain
time regions. Our multiscale methods allow to test for such shape properties of
the trend m. In order to perform the methods, we require an estimator of the
long-run variance of the error process. We propose a new difference-based
estimator of the long-run error variance for the case that the error terms form
an AR(p) process. In the technical part of the paper, we derive asymptotic
theory for the proposed multiscale test and the estimator of the long-run error
variance. The theory is complemented by a simulation study and an empirical
application to climate data.",http://arxiv.org/pdf/1903.01253v1,math.ST
2019-03-02 14:25:46+00:00,Goodness-of-Fit Testing for Time Series Models via Distance Covariance,"['Phyllis Wan', 'Richard A. Davis']","In many statistical modeling frameworks, goodness-of-fit tests are typically
administered to the estimated residuals. In the time series setting, whiteness
of the residuals is assessed using the sample autocorrelation function. For
many time series models, especially those used for financial time series, the
key assumption on the residuals is that they are in fact independent and not
just uncorrelated. In this paper, we apply the auto-distance covariance
function (ADCV) to evaluate the serial dependence of the estimated residuals.
Distance covariance can discriminate between dependence and independence of two
random vectors. The limit behavior of the test statistic based on the ADCV is
derived for a general class of time series models. One of the key aspects in
this theory is adjusting for the dependence that arises due to parameter
estimation. This adjustment has essentially the same form regardless of the
model specification. We illustrate the results in simulated examples.",http://arxiv.org/pdf/1903.00708v1,math.ST
2019-02-28 03:09:25+00:00,Financial series prediction using Attention LSTM,"['Sangyeon Kim', 'Myungjoo Kang']","Financial time series prediction, especially with machine learning
techniques, is an extensive field of study. In recent times, deep learning
methods (especially time series analysis) have performed outstandingly for
various industrial problems, with better prediction than machine learning
methods. Moreover, many researchers have used deep learning methods to predict
financial time series with various models in recent years. In this paper, we
will compare various deep learning models, such as multilayer perceptron (MLP),
one-dimensional convolutional neural networks (1D CNN), stacked long short-term
memory (stacked LSTM), attention networks, and weighted attention networks for
financial time series prediction. In particular, attention LSTM is not only
used for prediction, but also for visualizing intermediate outputs to analyze
the reason of prediction; therefore, we will show an example for understanding
the model prediction intuitively with attention vectors. In addition, we focus
on time and factors, which lead to an easy understanding of why certain trends
are predicted when accessing a given time series table. We also modify the loss
functions of the attention models with weighted categorical cross entropy; our
proposed model produces a 0.76 hit ratio, which is superior to those of other
methods for predicting the trends of the KOSPI 200.",http://arxiv.org/pdf/1902.10877v1,cs.LG
2019-02-27 19:55:54+00:00,Insights into LSTM Fully Convolutional Networks for Time Series Classification,"['Fazle Karim', 'Somshubra Majumdar', 'Houshang Darabi']","Long Short Term Memory Fully Convolutional Neural Networks (LSTM-FCN) and
Attention LSTM-FCN (ALSTM-FCN) have shown to achieve state-of-the-art
performance on the task of classifying time series signals on the old
University of California-Riverside (UCR) time series repository. However, there
has been no study on why LSTM-FCN and ALSTM-FCN perform well. In this paper, we
perform a series of ablation tests (3627 experiments) on LSTM-FCN and ALSTM-FCN
to provide a better understanding of the model and each of its sub-module.
Results from the ablation tests on ALSTM-FCN and LSTM-FCN show that the LSTM
and the FCN blocks perform better when applied in a conjoined manner. Two
z-normalizing techniques, z-normalizing each sample independently and
z-normalizing the whole dataset, are compared using a Wilcoxson signed-rank
test to show a statistical difference in performance. In addition, we provide
an understanding of the impact dimension shuffle has on LSTM-FCN by comparing
its performance with LSTM-FCN when no dimension shuffle is applied. Finally, we
demonstrate the performance of the LSTM-FCN when the LSTM block is replaced by
a GRU, basic RNN, and Dense Block.",http://arxiv.org/pdf/1902.10756v3,cs.LG
2019-02-27 19:55:44+00:00,Adversarial Attacks on Time Series,"['Fazle Karim', 'Somshubra Majumdar', 'Houshang Darabi']","Time series classification models have been garnering significant importance
in the research community. However, not much research has been done on
generating adversarial samples for these models. These adversarial samples can
become a security concern. In this paper, we propose utilizing an adversarial
transformation network (ATN) on a distilled model to attack various time series
classification models. The proposed attack on the classification model utilizes
a distilled model as a surrogate that mimics the behavior of the attacked
classical time series classification models. Our proposed methodology is
applied onto 1-Nearest Neighbor Dynamic Time Warping (1-NN ) DTW, a Fully
Connected Network and a Fully Convolutional Network (FCN), all of which are
trained on 42 University of California Riverside (UCR) datasets. In this paper,
we show both models were susceptible to attacks on all 42 datasets. To the best
of our knowledge, such an attack on time series classification models has never
been done before. Finally, we recommend future researchers that develop time
series classification models to incorporating adversarial data samples into
their training data sets to improve resilience on adversarial samples and to
consider model robustness as an evaluative metric.",http://arxiv.org/pdf/1902.10755v2,cs.LG
2019-02-18 00:34:58+00:00,A One-Class Support Vector Machine Calibration Method for Time Series Change Point Detection,"['Baihong Jin', 'Yuxin Chen', 'Dan Li', 'Kameshwar Poolla', 'Alberto Sangiovanni-Vincentelli']","It is important to identify the change point of a system's health status,
which usually signifies an incipient fault under development. The One-Class
Support Vector Machine (OC-SVM) is a popular machine learning model for anomaly
detection and hence could be used for identifying change points; however, it is
sometimes difficult to obtain a good OC-SVM model that can be used on sensor
measurement time series to identify the change points in system health status.
In this paper, we propose a novel approach for calibrating OC-SVM models. The
approach uses a heuristic search method to find a good set of input data and
hyperparameters that yield a well-performing model. Our results on the C-MAPSS
dataset demonstrate that OC-SVM can also achieve satisfactory accuracy in
detecting change point in time series with fewer training data, compared to
state-of-the-art deep learning approaches. In our case study, the OC-SVM
calibrated by the proposed model is shown to be useful especially in scenarios
with limited amount of training data.",http://arxiv.org/pdf/1902.06361v1,cs.LG
2019-02-17 15:57:30+00:00,Approximate leave-future-out cross-validation for Bayesian time series models,"['Paul-Christian Bürkner', 'Jonah Gabry', 'Aki Vehtari']","One of the common goals of time series analysis is to use the observed series
to inform predictions for future observations. In the absence of any actual new
data to predict, cross-validation can be used to estimate a model's future
predictive accuracy, for instance, for the purpose of model comparison or
selection. Exact cross-validation for Bayesian models is often computationally
expensive, but approximate cross-validation methods have been developed, most
notably methods for leave-one-out cross-validation (LOO-CV). If the actual
prediction task is to predict the future given the past, LOO-CV provides an
overly optimistic estimate because the information from future observations is
available to influence predictions of the past. To properly account for the
time series structure, we can use leave-future-out cross-validation (LFO-CV).
Like exact LOO-CV, exact LFO-CV requires refitting the model many times to
different subsets of the data. Using Pareto smoothed importance sampling, we
propose a method for approximating exact LFO-CV that drastically reduces the
computational costs while also providing informative diagnostics about the
quality of the approximation.",http://arxiv.org/pdf/1902.06281v5,stat.ME
2019-02-14 22:14:45+00:00,Quick and Easy Time Series Generation with Established Image-based GANs,"['Eoin Brophy', 'Zhengwei Wang', 'Tomas E. Ward']","In the recent years Generative Adversarial Networks (GANs) have demonstrated
significant progress in generating authentic looking data. In this work we
introduce our simple method to exploit the advancements in well established
image-based GANs to synthesise single channel time series data. We implement
Wasserstein GANs (WGANs) with gradient penalty due to their stability in
training to synthesise three different types of data; sinusoidal data,
photoplethysmograph (PPG) data and electrocardiograph (ECG) data. The length of
the returned time series data is limited only by the image resolution, we use
an image size of 64x64 pixels which yields 4096 data points. We present both
visual and quantitative evidence that our novel method can successfully
generate time series data using image-based GANs.",http://arxiv.org/pdf/1902.05624v3,cs.LG
2019-02-14 11:44:01+00:00,Generalisation in fully-connected neural networks for time series forecasting,"['Anastasia Borovykh', 'Cornelis W. Oosterlee', 'Sander M. Bohte']","In this paper we study the generalization capabilities of fully-connected
neural networks trained in the context of time series forecasting. Time series
do not satisfy the typical assumption in statistical learning theory of the
data being i.i.d. samples from some data-generating distribution. We use the
input and weight Hessians, that is the smoothness of the learned function with
respect to the input and the width of the minimum in weight space, to quantify
a network's ability to generalize to unseen data. While such generalization
metrics have been studied extensively in the i.i.d. setting of for example
image recognition, here we empirically validate their use in the task of time
series forecasting. Furthermore we discuss how one can control the
generalization capability of the network by means of the training process using
the learning rate, batch size and the number of training iterations as
controls. Using these hyperparameters one can efficiently control the
complexity of the output function without imposing explicit constraints.",http://arxiv.org/pdf/1902.05312v2,stat.ML
2019-02-12 21:36:31+00:00,Weighted Tensor Completion for Time-Series Causal Inference,"['Debmalya Mandal', 'David Parkes']","Marginal Structural Models (MSM) are the most popular models for causal
inference from time-series observational data. However, they have two main
drawbacks: (a) they do not capture subject heterogeneity, and (b) they only
consider fixed time intervals and do not scale gracefully with longer
intervals. In this work, we propose a new family of MSMs to address these two
concerns. We model the potential outcomes as a three-dimensional tensor of low
rank, where the three dimensions correspond to the agents, time periods and the
set of possible histories. Unlike the traditional MSM, we allow the dimensions
of the tensor to increase with the number of agents and time periods. We set up
a weighted tensor completion problem as our estimation procedure, and show that
the solution to this problem converges to the true model in an appropriate
sense. Then we show how to solve the estimation problem, providing conditions
under which we can approximately and efficiently solve the estimation problem.
Finally we propose an algorithm based on projected gradient descent, which is
easy to implement, and evaluate its performance on a simulated dataset.",http://arxiv.org/pdf/1902.04646v3,cs.LG
2019-02-12 20:54:37+00:00,Machine Learning of Time Series Using Time-delay Embedding and Precision Annealing,"['Alexander J. A. Ty', 'Zheng Fang', 'Rivver A. Gonzalez', 'Paul J. Rozdeba', 'Henry D. I. Abarbanel']","Tasking machine learning to predict segments of a time series requires
estimating the parameters of a ML model with input/output pairs from the time
series. Using the equivalence between statistical data assimilation and
supervised machine learning, we revisit this task. The training method for the
machine utilizes a precision annealing approach to identifying the global
minimum of the action (-log[P]). In this way we are able to identify the number
of training pairs required to produce good generalizations (predictions) for
the time series. We proceed from a scalar time series $s(t_n); t_n = t_0 + n
\Delta t$ and using methods of nonlinear time series analysis show how to
produce a $D_E > 1$ dimensional time delay embedding space in which the time
series has no false neighbors as does the observed $s(t_n)$ time series. In
that $D_E$-dimensional space we explore the use of feed forward multi-layer
perceptrons as network models operating on $D_E$-dimensional input and
producing $D_E$-dimensional outputs.",http://arxiv.org/pdf/1902.05062v2,cs.LG
2019-02-09 14:09:32+00:00,Low-pass filtering as Bayesian inference,"['Cristobal Valenzuela', 'Felipe Tobar']","We propose a Bayesian nonparametric method for low-pass filtering that can
naturally handle unevenly-sampled and noise-corrupted observations. The
proposed model is constructed as a latent-factor model for time series, where
the latent factors are Gaussian processes with non-overlapping spectra. With
this construction, the low-pass version of the time series can be identified as
the low-frequency latent component, and therefore it can be found by means of
Bayesian inference. We show that the model admits exact training and can be
implemented with minimal numerical approximations. Finally, the proposed model
is validated against standard linear filters on synthetic and real-world time
series.",http://arxiv.org/pdf/1902.03427v1,stat.ML
2019-02-04 15:07:37+00:00,Ordinal Patterns in Clusters of Subsequent Extremes of Regularly Varying Time Series,"['Marco Oesting', 'Alexander Schnurr']","In this paper, we investigate temporal clusters of extremes defined as
subsequent exceedances of high thresholds in a stationary time series. Two
meaningful features of these clusters are the probability distribution of the
cluster size and the ordinal patterns within a cluster. Since these patterns
take only the ordinal structure of consecutive data points into account the
method is robust under monotone transformations and measurement errors. We
verify the existence of the corresponding limit distributions in the framework
of regularly varying time series, develop non-parametric estimators and show
their asymptotic normality under appropriate mixing conditions. The performance
of the estimators is demonstrated in a simulated example and a real data
application to discharge data of the river Rhine.",http://arxiv.org/pdf/1902.01237v2,math.ST
2019-02-02 03:28:34+00:00,A Spatial-Temporal Decomposition Based Deep Neural Network for Time Series Forecasting,"['Reza Asadi', 'Amelia Regan']","Spatial time series forecasting problems arise in a broad range of
applications, such as environmental and transportation problems. These problems
are challenging because of the existence of specific spatial, short-term and
long-term patterns, and the curse of dimensionality. In this paper, we propose
a deep neural network framework for large-scale spatial time series forecasting
problems. We explicitly designed the neural network architecture for capturing
various types of patterns. In preprocessing, a time series decomposition method
is applied to separately feed short-term, long-term and spatial patterns into
different components of a neural network. A fuzzy clustering method finds
cluster of neighboring time series based on similarity of time series
residuals; as they can be meaningful short-term patterns for spatial time
series. In neural network architecture, each kernel of a multi-kernel
convolution layer is applied to a cluster of time series to extract short-term
features in neighboring areas. The output of convolution layer is concatenated
by trends and followed by convolution-LSTM layer to capture long-term patterns
in larger regional areas. To make a robust prediction when faced with missing
data, an unsupervised pretrained denoising autoencoder reconstructs the output
of the model in a fine-tuning step. The experimental results illustrate the
model outperforms baseline and state of the art models in a traffic flow
prediction dataset.",http://arxiv.org/pdf/1902.00636v1,cs.LG
2019-02-01 16:49:51+00:00,Time Series Deconfounder: Estimating Treatment Effects over Time in the Presence of Hidden Confounders,"['Ioana Bica', 'Ahmed M. Alaa', 'Mihaela van der Schaar']","The estimation of treatment effects is a pervasive problem in medicine.
Existing methods for estimating treatment effects from longitudinal
observational data assume that there are no hidden confounders, an assumption
that is not testable in practice and, if it does not hold, leads to biased
estimates. In this paper, we develop the Time Series Deconfounder, a method
that leverages the assignment of multiple treatments over time to enable the
estimation of treatment effects in the presence of multi-cause hidden
confounders. The Time Series Deconfounder uses a novel recurrent neural network
architecture with multitask output to build a factor model over time and infer
latent variables that render the assigned treatments conditionally independent;
then, it performs causal inference using these latent variables that act as
substitutes for the multi-cause unobserved confounders. We provide a
theoretical analysis for obtaining unbiased causal effects of time-varying
exposures using the Time Series Deconfounder. Using both simulated and real
data we show the effectiveness of our method in deconfounding the estimation of
treatment responses over time.",http://arxiv.org/pdf/1902.00450v4,cs.LG
2019-01-30 10:07:45+00:00,Unsupervised Scalable Representation Learning for Multivariate Time Series,"['Jean-Yves Franceschi', 'Aymeric Dieuleveut', 'Martin Jaggi']","Time series constitute a challenging data type for machine learning
algorithms, due to their highly variable lengths and sparse labeling in
practice. In this paper, we tackle this challenge by proposing an unsupervised
method to learn universal embeddings of time series. Unlike previous works, it
is scalable with respect to their length and we demonstrate the quality,
transferability and practicability of the learned representations with thorough
experiments and comparisons. To this end, we combine an encoder based on causal
dilated convolutions with a novel triplet loss employing time-based negative
sampling, obtaining general-purpose representations for variable length and
multivariate time series.",http://arxiv.org/pdf/1901.10738v4,cs.LG
2019-01-30 05:51:41+00:00,End-to-End Learned Early Classification of Time Series for In-Season Crop Type Mapping,"['Marc Rußwurm', 'Nicolas Courty', 'Rémi Emonet', 'Sébastien Lefèvre', 'Devis Tuia', 'Romain Tavenard']","Remote sensing satellites capture the cyclic dynamics of our Planet in
regular time intervals recorded in satellite time series data. End-to-end
trained deep learning models use this time series data to make predictions at a
large scale, for instance, to produce up-to-date crop cover maps. Most time
series classification approaches focus on the accuracy of predictions. However,
the earliness of the prediction is also of great importance since coming to an
early decision can make a crucial difference in time-sensitive applications. In
this work, we present an End-to-End Learned Early Classification of Time Series
(ELECTS) model that estimates a classification score and a probability of
whether sufficient data has been observed to come to an early and still
accurate decision. ELECTS is modular: any deep time series classification model
can adopt the ELECTS conceptual idea by adding a second prediction head that
outputs a probability of stopping the classification. The ELECTS loss function
then optimizes the overall model on a balanced objective of earliness and
accuracy. Our experiments on four crop classification datasets from Europe and
Africa show that ELECTS allows reaching state-of-the-art accuracy while
reducing the quantity of data massively to be downloaded, stored, and
processed. The source code is available at https://github.com/marccoru/elects.",http://arxiv.org/pdf/1901.10681v2,cs.LG
2019-01-29 21:39:56+00:00,Stochastic Gradient MCMC for Nonlinear State Space Models,"['Christopher Aicher', 'Srshti Putcha', 'Christopher Nemeth', 'Paul Fearnhead', 'Emily B. Fox']","State space models (SSMs) provide a flexible framework for modeling complex
time series via a latent stochastic process. Inference for nonlinear,
non-Gaussian SSMs is often tackled with particle methods that do not scale well
to long time series. The challenge is two-fold: not only do computations scale
linearly with time, as in the linear case, but particle filters additionally
suffer from increasing particle degeneracy with longer series. Stochastic
gradient MCMC methods have been developed to scale Bayesian inference for
finite-state hidden Markov models and linear SSMs using buffered stochastic
gradient estimates to account for temporal dependencies. We extend these
stochastic gradient estimators to nonlinear SSMs using particle methods. We
present error bounds that account for both buffering error and particle error
in the case of nonlinear SSMs that are log-concave in the latent process. We
evaluate our proposed particle buffered stochastic gradient using stochastic
gradient MCMC for inference on both long sequential synthetic and
minute-resolution financial returns data, demonstrating the importance of this
class of methods.",http://arxiv.org/pdf/1901.10568v3,stat.ML
2019-01-26 17:36:51+00:00,Clustering Discrete-Valued Time Series,"['Tyler Roick', 'Dimitris Karlis', 'Paul D. McNicholas']","There is a need for the development of models that are able to account for
discreteness in data, along with its time series properties and correlation.
Our focus falls on INteger-valued AutoRegressive (INAR) type models. The INAR
type models can be used in conjunction with existing model-based clustering
techniques to cluster discrete-valued time series data. With the use of a
finite mixture model, several existing techniques such as the selection of the
number of clusters, estimation using expectation-maximization and model
selection are applicable. The proposed model is then demonstrated on real data
to illustrate its clustering applications.",http://arxiv.org/pdf/1901.09249v2,stat.ME
2019-01-26 09:47:31+00:00,Discovery of Important Subsequences in Electrocardiogram Beats Using the Nearest Neighbour Algorithm,"['Ricards Marcinkevics', 'Steven Kelk', 'Carlo Galuzzi', 'Berthold Stegemann']","The classification of time series data is a well-studied problem with
numerous practical applications, such as medical diagnosis and speech
recognition. A popular and effective approach is to classify new time series in
the same way as their nearest neighbours, whereby proximity is defined using
Dynamic Time Warping (DTW) distance, a measure analogous to sequence alignment
in bioinformatics. However, practitioners are not only interested in accurate
classification, they are also interested in why a time series is classified a
certain way. To this end, we introduce here the problem of finding a minimum
length subsequence of a time series, the removal of which changes the outcome
of the classification under the nearest neighbour algorithm with DTW distance.
Informally, such a subsequence is expected to be relevant for the
classification and can be helpful for practitioners in interpreting the
outcome. We describe a simple but optimized implementation for detecting these
subsequences and define an accompanying measure to quantify the relevance of
every time point in the time series for the classification. In tests on
electrocardiogram data we show that the algorithm allows discovery of important
subsequences and can be helpful in detecting abnormalities in cardiac rhythms
distinguishing sick from healthy patients.",http://arxiv.org/pdf/1901.09187v1,cs.LG
2019-01-24 17:55:15+00:00,Testing Equality of Autocovariance Operators for Functional Time Series,"['Dimitrios Pilavakis', 'Efstathios Paparoditis', 'Theofanis Sapatinas']","We consider strictly stationary stochastic processes of Hilbert space-valued
random variables and focus on fully functional tests for the equality of the
lag-zero autocovariance operators of several independent functional time
series. A moving block bootstrap-based testing procedure is proposed which
generates pseudo random elements that satisfy the null hypothesis of interest.
It is based on directly bootstrapping the time series of tensor products which
overcomes some common difficulties associated with applications of the
bootstrap to related testing problems. The suggested methodology can be
potentially applied to a broad range of test statistics of the hypotheses of
interest. As an example, we establish validity for approximating the
distribution under the null of a test statistic based on the Hilbert-Schmidt
distance of the corresponding sample lag-zero autocovariance operators, and
show consistency under the alternative. As a prerequisite, we prove a central
limit theorem for the moving block bootstrap procedure applied to the sample
autocovariance operator which is of interest on its own. The finite sample size
and power performance of the suggested moving block bootstrap-based testing
procedure is illustrated through simulations and an application to a real-life
dataset is discussed.",http://arxiv.org/pdf/1901.08535v3,math.ST
2019-01-24 08:30:16+00:00,Temporal Logistic Neural Bag-of-Features for Financial Time series Forecasting leveraging Limit Order Book Data,"['Nikolaos Passalis', 'Anastasios Tefas', 'Juho Kanniainen', 'Moncef Gabbouj', 'Alexandros Iosifidis']","Time series forecasting is a crucial component of many important
applications, ranging from forecasting the stock markets to energy load
prediction. The high-dimensionality, velocity and variety of the data collected
in these applications pose significant and unique challenges that must be
carefully addressed for each of them. In this work, a novel Temporal Logistic
Neural Bag-of-Features approach, that can be used to tackle these challenges,
is proposed. The proposed method can be effectively combined with deep neural
networks, leading to powerful deep learning models for time series analysis.
However, combining existing BoF formulations with deep feature extractors pose
significant challenges: the distribution of the input features is not
stationary, tuning the hyper-parameters of the model can be especially
difficult and the normalizations involved in the BoF model can cause
significant instabilities during the training process. The proposed method is
capable of overcoming these limitations by a employing a novel adaptive scaling
mechanism and replacing the classical Gaussian-based density estimation
involved in the regular BoF model with a logistic kernel. The effectiveness of
the proposed approach is demonstrated using extensive experiments on a
large-scale financial time series dataset that consists of more than 4 million
limit orders.",http://arxiv.org/pdf/1901.08280v1,cs.LG
2019-01-23 19:43:06+00:00,Recurrent Neural Filters: Learning Independent Bayesian Filtering Steps for Time Series Prediction,"['Bryan Lim', 'Stefan Zohren', 'Stephen Roberts']","Despite the recent popularity of deep generative state space models, few
comparisons have been made between network architectures and the inference
steps of the Bayesian filtering framework -- with most models simultaneously
approximating both state transition and update steps with a single recurrent
neural network (RNN). In this paper, we introduce the Recurrent Neural Filter
(RNF), a novel recurrent autoencoder architecture that learns distinct
representations for each Bayesian filtering step, captured by a series of
encoders and decoders. Testing this on three real-world time series datasets,
we demonstrate that the decoupled representations learnt not only improve the
accuracy of one-step-ahead forecasts while providing realistic uncertainty
estimates, but also facilitate multistep prediction through the separation of
encoder stages.",http://arxiv.org/pdf/1901.08096v6,stat.ML
2019-01-20 18:48:48+00:00,Explainable Failure Predictions with RNN Classifiers based on Time Series Data,"['Ioana Giurgiu', 'Anika Schumann']","Given key performance indicators collected with fine granularity as time
series, our aim is to predict and explain failures in storage environments.
Although explainable predictive modeling based on spiky telemetry data is key
in many domains, current approaches cannot tackle this problem. Deep learning
methods suitable for sequence modeling and learning temporal dependencies, such
as RNNs, are effective, but opaque from an explainability perspective. Our
approach first extracts the anomalous spikes from time series as events and
then builds an RNN classifier with attention mechanisms to embed the
irregularity and frequency of these events. A preliminary evaluation on real
world storage environments shows that our approach can predict failures within
a 3-day prediction window with comparable accuracy as traditional RNN-based
classifiers. At the same time it can explain the predictions by returning the
key anomalous events which led to those failure predictions.",http://arxiv.org/pdf/1901.08554v1,cs.LG
2019-01-17 23:16:34+00:00,A robust functional time series forecasting method,['Han Lin Shang'],"Univariate time series often take the form of a collection of curves observed
sequentially over time. Examples of these include hourly ground-level ozone
concentration curves. These curves can be viewed as a time series of functions
observed at equally spaced intervals over a dense grid. Since functional time
series may contain various types of outliers, we introduce a robust functional
time series forecasting method to down-weigh the influence of outliers in
forecasting. Through a robust principal component analysis based on projection
pursuit, a time series of functions can be decomposed into a set of robust
dynamic functional principal components and their associated scores.
Conditioning on the estimated functional principal components, the crux of the
curve-forecasting problem lies in modeling and forecasting principal component
scores, through a robust vector autoregressive forecasting method. Via a
simulation study and an empirical study on forecasting ground-level ozone
concentration, the robust method demonstrates the superior forecast accuracy
that dynamic functional principal component regression entails. The robust
method also shows the superior estimation accuracy of the parameters in the
vector autoregressive models for modeling and forecasting principal component
scores, and thus improves curve forecast accuracy.",http://arxiv.org/pdf/1901.06030v1,stat.ME
2019-01-17 17:08:59+00:00,Applying SVGD to Bayesian Neural Networks for Cyclical Time-Series Prediction and Inference,"['Xinyu Hu', 'Paul Szerlip', 'Theofanis Karaletsos', 'Rohit Singh']","A regression-based BNN model is proposed to predict spatiotemporal quantities
like hourly rider demand with calibrated uncertainties. The main contributions
of this paper are (i) A feed-forward deterministic neural network (DetNN)
architecture that predicts cyclical time series data with sensitivity to
anomalous forecasting events; (ii) A Bayesian framework applying SVGD to train
large neural networks for such tasks, capable of producing time series
predictions as well as measures of uncertainty surrounding the predictions.
Experiments show that the proposed BNN reduces average estimation error by 10%
across 8 U.S. cities compared to a fine-tuned multilayer perceptron (MLP), and
4% better than the same network architecture trained without SVGD.",http://arxiv.org/pdf/1901.05906v1,cs.LG
2019-01-13 17:52:06+00:00,Sales Demand Forecast in E-commerce using a Long Short-Term Memory Neural Network Methodology,"['Kasun Bandara', 'Peibei Shi', 'Christoph Bergmeir', 'Hansika Hewamalage', 'Quoc Tran', 'Brian Seaman']","Generating accurate and reliable sales forecasts is crucial in the E-commerce
business. The current state-of-the-art techniques are typically univariate
methods, which produce forecasts considering only the historical sales data of
a single product. However, in a situation where large quantities of related
time series are available, conditioning the forecast of an individual time
series on past behaviour of similar, related time series can be beneficial.
Since the product assortment hierarchy in an E-commerce platform contains large
numbers of related products, in which the sales demand patterns can be
correlated, our attempt is to incorporate this cross-series information in a
unified model. We achieve this by globally training a Long Short-Term Memory
network (LSTM) that exploits the non-linear demand relationships available in
an E-commerce product assortment hierarchy. Aside from the forecasting
framework, we also propose a systematic pre-processing framework to overcome
the challenges in the E-commerce business. We also introduce several product
grouping strategies to supplement the LSTM learning schemes, in situations
where sales patterns in a product portfolio are disparate. We empirically
evaluate the proposed forecasting framework on a real-world online marketplace
dataset from Walmart.com. Our method achieves competitive results on category
level and super-departmental level datasets, outperforming state-of-the-art
techniques.",http://arxiv.org/pdf/1901.04028v2,cs.LG
2019-01-10 17:05:55+00:00,Penalized estimation of flexible hidden Markov models for time series of counts,"['Timo Adam', 'Roland Langrock', 'Christian H. Weiß']","Hidden Markov models are versatile tools for modeling sequential
observations, where it is assumed that a hidden state process selects which of
finitely many distributions generates any given observation. Specifically for
time series of counts, the Poisson family often provides a natural choice for
the state-dependent distributions, though more flexible distributions such as
the negative binomial or distributions with a bounded range can also be used.
However, in practice, choosing an adequate class of (parametric) distributions
is often anything but straightforward, and an inadequate choice can have severe
negative consequences on the model's predictive performance, on state
classification, and generally on inference related to the system considered. To
address this issue, we propose an effectively nonparametric approach to fitting
hidden Markov models to time series of counts, where the state-dependent
distributions are estimated in a completely data-driven way without the need to
select a distributional family. To avoid overfitting, we add a roughness
penalty based on higher-order differences between adjacent count probabilities
to the likelihood, which is demonstrated to produce smooth probability mass
functions of the state-dependent distributions. The feasibility of the
suggested approach is assessed in a simulation experiment, and illustrated in
two real-data applications, where we model the distribution of i) major
earthquake counts and ii) acceleration counts of an oceanic whitetip shark
(Carcharhinus longimanus) over time.",http://arxiv.org/pdf/1901.03275v1,stat.ME
2019-01-10 06:48:43+00:00,Nonparametric Multiple Change Point Detection for Non-Stationary Times Series,"['Zixiang Guan', 'Gemai Chen']","This article considers a nonparametric method for detecting change points in
non-stationary time series. The proposed method will divide the time series
into several segments so that between two adjacent segments, the normalized
spectral density functions are different. The theory is based on the assumption
that within each segment, time series is a linear process, which means that our
method works not only for classic time series models, e.g., causal and
invertible ARMA process, but also preserves good performance for non-invertible
moving average process. We show that our estimations for change points are
consistent. Also, a Bayesian information criterion is applied to estimate the
member of change points consistently. Simulation results as well as empirical
results will be presented.",http://arxiv.org/pdf/1901.03036v3,math.ST
2019-01-08 17:43:38+00:00,Dynamic tail inference with log-Laplace volatility,['Gordon V. Chavez'],"We propose a family of models that enable predictive estimation of
time-varying extreme event probabilities in heavy-tailed and nonlinearly
dependent time series. The models are a white noise process with conditionally
log-Laplace stochastic volatility. In contrast to other, similar stochastic
volatility formalisms, this process has analytic expressions for its
conditional probabilistic structure that enable straightforward estimation of
dynamically changing extreme event probabilities. The process and volatility
are conditionally Pareto-tailed, with tail exponent given by the reciprocal of
the log-volatility's mean absolute innovation. This formalism can accommodate a
wide variety of nonlinear dependence, as well as conditional power law-tail
behavior ranging from weakly non-Gaussian to Cauchy-like tails. We provide a
computationally straightforward estimation procedure that uses an asymptotic
approximation of the process' dynamic large deviation probabilities. We
demonstrate the estimator's utility with a simulation study. We then show the
method's predictive capabilities on a simulated nonlinear time series where the
volatility is driven by the chaotic Lorenz system. Lastly we provide an
empirical application, which shows that this simple modeling method can be
effectively used for dynamic and predictive tail inference in financial time
series.",http://arxiv.org/pdf/1901.02419v5,stat.ME
2019-01-01 00:52:01+00:00,Recurrent Neural Networks for Time Series Forecasting,['Gábor Petneházi'],"Time series forecasting is difficult. It is difficult even for recurrent
neural networks with their inherent ability to learn sequentiality. This
article presents a recurrent neural network based time series forecasting
framework covering feature engineering, feature importances, point and interval
predictions, and forecast evaluation. The description of the method is followed
by an empirical study using both LSTM and GRU networks.",http://arxiv.org/pdf/1901.00069v1,cs.LG
2018-12-30 13:13:16+00:00,Comparison between DeepESNs and gated RNNs on multivariate time-series prediction,"['Claudio Gallicchio', 'Alessio Micheli', 'Luca Pedrelli']","We propose an experimental comparison between Deep Echo State Networks
(DeepESNs) and gated Recurrent Neural Networks (RNNs) on multivariate
time-series prediction tasks. In particular, we compare reservoir and
fully-trained RNNs able to represent signals featured by multiple time-scales
dynamics. The analysis is performed in terms of efficiency and prediction
accuracy on 4 polyphonic music tasks. Our results show that DeepESN is able to
outperform ESN in terms of prediction accuracy and efficiency. Whereas, between
fully-trained approaches, Gated Recurrent Units (GRU) outperforms Long
Short-Term Memory (LSTM) and simple RNN models in most cases. Overall, DeepESN
turned out to be extremely more efficient than others RNN approaches and the
best solution in terms of prediction accuracy on 3 out of 4 tasks.",http://arxiv.org/pdf/1812.11527v2,cs.LG
2018-12-30 13:07:07+00:00,Improving forecasting accuracy of time series data using a new ARIMA-ANN hybrid method and empirical mode decomposition,"['Ümit Çavuş Büyükşahin', 'Şeyda Ertekin']","Many applications in different domains produce large amount of time series
data. Making accurate forecasting is critical for many decision makers. Various
time series forecasting methods exist which use linear and nonlinear models
separately or combination of both. Studies show that combining of linear and
nonlinear models can be effective to improve forecasting performance. However,
some assumptions that those existing methods make, might restrict their
performance in certain situations. We provide a new Autoregressive Integrated
Moving Average (ARIMA)-Artificial Neural Network(ANN) hybrid method that work
in a more general framework. Experimental results show that strategies for
decomposing the original data and for combining linear and nonlinear models
throughout the hybridization process are key factors in the forecasting
performance of the methods. By using appropriate strategies, our hybrid method
can be an effective way to improve forecasting accuracy obtained by traditional
hybrid methods and also either of the individual methods used separately.",http://arxiv.org/pdf/1812.11526v1,cs.LG
2018-12-21 02:39:02+00:00,Autoregressive Models for Matrix-Valued Time Series,"['Rong Chen', 'Han Xiao', 'Dan Yang']","In finance, economics and many other fields, observations in a matrix form
are often generated over time. For example, a set of key economic indicators
are regularly reported in different countries every quarter. The observations
at each quarter neatly form a matrix and are observed over many consecutive
quarters. Dynamic transport networks with observations generated on the edges
can be formed as a matrix observed over time. Although it is natural to turn
the matrix observations into a long vector, and then use the standard vector
time series models for analysis, it is often the case that the columns and rows
of the matrix represent different types of structures that are closely
interplayed. In this paper we follow the autoregressive structure for modeling
time series and propose a novel matrix autoregressive model in a bilinear form
that maintains and utilizes the matrix structure to achieve a greater
dimensional reduction, as well as more interpretable results. Probabilistic
properties of the models are investigated. Estimation procedures with their
theoretical properties are presented and demonstrated with simulated and real
examples.",http://arxiv.org/pdf/1812.08916v2,stat.ME
2018-12-20 07:11:11+00:00,Feedforward Neural Network for Time Series Anomaly Detection,"['Zhang Rong', 'Dong Shandong', 'Nie Xin', 'Xiao Shiguang']","Time series anomaly detection is usually formulated as finding outlier data
points relative to some usual data, which is also an important problem in
industry and academia. To ensure systems working stably, internet companies,
banks and other companies need to monitor time series, which is called KPI (Key
Performance Indicators), such as CPU used, number of orders, number of online
users and so on. However, millions of time series have several shapes (e.g.
seasonal KPIs, KPIs of timed tasks and KPIs of CPU used), so that it is very
difficult to use a simple statistical model to detect anomaly for all kinds of
time series. Although some anomaly detectors have developed many years and some
supervised models are also available in this field, we find many methods have
their own disadvantages. In this paper, we present our system, which is based
on deep feedforward neural network and detect anomaly points of time series.
The main difference between our system and other systems based on supervised
models is that we do not need feature engineering of time series to train deep
feedforward neural network in our system, which is essentially an end-to-end
system.",http://arxiv.org/pdf/1812.08389v2,cs.LG
2018-12-20 01:26:08+00:00,NeuralWarp: Time-Series Similarity with Warping Networks,"['Josif Grabocka', 'Lars Schmidt-Thieme']","Research on time-series similarity measures has emphasized the need for
elastic methods which align the indices of pairs of time series and a plethora
of non-parametric have been proposed for the task. On the other hand, deep
learning approaches are dominant in closely related domains, such as learning
image and text sentence similarity. In this paper, we propose
\textit{NeuralWarp}, a novel measure that models the alignment of time-series
indices in a deep representation space, by modeling a warping function as an
upper level neural network between deeply-encoded time series values.
Experimental results demonstrate that \textit{NeuralWarp} outperforms both
non-parametric and un-warped deep models on a range of diverse real-life
datasets.",http://arxiv.org/pdf/1812.08306v1,cs.LG
2018-12-18 23:43:48+00:00,A Comparison of LSTMs and Attention Mechanisms for Forecasting Financial Time Series,"['Thomas Hollis', 'Antoine Viscardi', 'Seung Eun Yi']","While LSTMs show increasingly promising results for forecasting Financial
Time Series (FTS), this paper seeks to assess if attention mechanisms can
further improve performance. The hypothesis is that attention can help prevent
long-term dependencies experienced by LSTM models. To test this hypothesis, the
main contribution of this paper is the implementation of an LSTM with
attention. Both the benchmark LSTM and the LSTM with attention were compared
and both achieved reasonable performances of up to 60% on five stocks from
Kaggle's Two Sigma dataset. This comparative analysis demonstrates that an LSTM
with attention can indeed outperform standalone LSTMs but further investigation
is required as issues do arise with such model architectures.",http://arxiv.org/pdf/1812.07699v1,cs.LG
2018-12-18 22:57:46+00:00,Deep Gated Recurrent and Convolutional Network Hybrid Model for Univariate Time Series Classification,"['Nelly Elsayed', 'Anthony S. Maida', 'Magdy Bayoumi']","Hybrid LSTM-fully convolutional networks (LSTM-FCN) for time series
classification have produced state-of-the-art classification results on
univariate time series. We show that replacing the LSTM with a gated recurrent
unit (GRU) to create a GRU-fully convolutional network hybrid model (GRU-FCN)
can offer even better performance on many time series datasets. The proposed
GRU-FCN model outperforms state-of-the-art classification performance in many
univariate and multivariate time series datasets. In addition, since the GRU
uses a simpler architecture than the LSTM, it has fewer training parameters,
less training time, and a simpler hardware implementation, compared to the
LSTM-based models.",http://arxiv.org/pdf/1812.07683v3,cs.LG
2018-12-18 11:03:11+00:00,A new time-varying model for forecasting long-memory series,"['Luisa Bisaglia', 'Matteo Grigoletto']","In this work we propose a new class of long-memory models with time-varying
fractional parameter. In particular, the dynamics of the long-memory
coefficient, $d$, is specified through a stochastic recurrence equation driven
by the score of the predictive likelihood, as suggested by Creal et al. (2013)
and Harvey (2013). We demonstrate the validity of the proposed model by a Monte
Carlo experiment and an application to two real time series.",http://arxiv.org/pdf/1812.07295v1,stat.ME
2018-12-13 16:54:49+00:00,Impact of Data Normalization on Deep Neural Network for Time Series Forecasting,"['Samit Bhanja', 'Abhishek Das']","For the last few years it has been observed that the Deep Neural Networks
(DNNs) has achieved an excellent success in image classification, speech
recognition. But DNNs are suffer great deal of challenges for time series
forecasting because most of the time series data are nonlinear in nature and
highly dynamic in behaviour. The time series forecasting has a great impact on
our socio-economic environment. Hence, to deal with these challenges its need
to be redefined the DNN model and keeping this in mind, data pre-processing,
network architecture and network parameters are need to be consider before
feeding the data into DNN models. Data normalization is the basic data
pre-processing technique form which learning is to be done. The effectiveness
of time series forecasting is heavily depend on the data normalization
technique. In this paper, different normalization methods are used on time
series data before feeding the data into the DNN model and we try to find out
the impact of each normalization technique on DNN to forecast the time series.
Here the Deep Recurrent Neural Network (DRNN) is used to predict the closing
index of Bombay Stock Exchange (BSE) and New York Stock Exchange (NYSE) by
using BSE and NYSE time series data.",http://arxiv.org/pdf/1812.05519v2,cs.LG
2018-12-12 02:38:29+00:00,Deep Air Quality Forecasting Using Hybrid Deep Learning Framework,"['Shengdong Du', 'Tianrui Li', 'Yan Yang', 'Shi-Jinn Horng']","Air quality forecasting has been regarded as the key problem of air pollution
early warning and control management. In this paper, we propose a novel deep
learning model for air quality (mainly PM2.5) forecasting, which learns the
spatial-temporal correlation features and interdependence of multivariate air
quality related time series data by hybrid deep learning architecture. Due to
the nonlinear and dynamic characteristics of multivariate air quality time
series data, the base modules of our model include one-dimensional
Convolutional Neural Networks (1D-CNNs) and Bi-directional Long Short-term
Memory networks (Bi-LSTM). The former is to extract the local trend features
and spatial correlation features, and the latter is to learn spatial-temporal
dependencies. Then we design a jointly hybrid deep learning framework based on
one-dimensional CNNs and Bi-LSTM for shared representation features learning of
multivariate air quality related time series data. We conduct extensive
experimental evaluations using two real-world datasets, and the results show
that our model is capable of dealing with PM2.5 air pollution forecasting with
satisfied accuracy.",http://arxiv.org/pdf/1812.04783v3,cs.LG
2018-12-10 20:04:05+00:00,Estimating heterogeneous treatment effects in nonstationary time series with state-space models,"['Shu Li', 'Peter Bühlmann']","Randomized trials and observational studies, more often than not, run over a
certain period of time. The treatment effect evolves during this period which
provides crucial insights into the treatment response and the long-term
effects. Many conventional methods for estimating treatment effects are limited
to the i.i.d. setting and are not suited for inferring the time dynamics of the
treatment effect. The time series encountered in these settings are highly
informative but often nonstationary due to the changing effects of treatment.
This increases the difficulty, since stationarity, a common assumption in time
series analysis, cannot be reasonably assumed. Another challenge is the
heterogeneity of the treatment effect when the treatment affects units
differently. The task of estimating heterogeneous treatment effects from
nonstationary and, in particular, interventional time series is highly relevant
but has remained unexplored yet. We propose Causal Transfer, a method which
combines regression to adjust for confounding with time series modelling to
learn the effect of the treatment and how it evolves over time. Causal Transfer
does not assume the data to be stationary and can be applied to randomized
trials and observational studies in which treatment is confounded. Causal
Transfer adjusts the effect for possible confounders and transfers the learned
effect to other time series and, thereby, estimates various forms of treatment
effects, such as the average treatment effect (ATE) or the conditional average
treatment effect (CATE). By learning the time dynamics of the effect, Causal
Transfer can also predict the treatment effect for unobserved future time
points and determine the long-term consequences of treatment.",http://arxiv.org/pdf/1812.04063v3,stat.ME
2018-12-10 07:43:35+00:00,Testing for high-dimensional network parameters in auto-regressive models,"['Lili Zheng', 'Garvesh Raskutti']","High-dimensional auto-regressive models provide a natural way to model
influence between $M$ actors given multi-variate time series data for $T$ time
intervals. While there has been considerable work on network estimation, there
is limited work in the context of inference and hypothesis testing. In
particular, prior work on hypothesis testing in time series has been restricted
to linear Gaussian auto-regressive models. From a practical perspective, it is
important to determine suitable statistical tests for connections between
actors that go beyond the Gaussian assumption. In the context of
\emph{high-dimensional} time series models, confidence intervals present
additional estimators since most estimators such as the Lasso and Dantzig
selectors are biased which has led to \emph{de-biased} estimators. In this
paper we address these challenges and provide convergence in distribution
results and confidence intervals for the multi-variate AR(p) model with
sub-Gaussian noise, a generalization of Gaussian noise that broadens
applicability and presents numerous technical challenges. The main technical
challenge lies in the fact that unlike Gaussian random vectors, for
sub-Gaussian vectors zero correlation does not imply independence. The proof
relies on using an intricate truncation argument to develop novel concentration
bounds for quadratic forms of dependent sub-Gaussian random variables. Our
convergence in distribution results hold provided $T = \Omega((s \vee \rho)^2
\log^2 M)$, where $s$ and $\rho$ refer to sparsity parameters which matches
existed results for hypothesis testing with i.i.d. samples. We validate our
theoretical results with simulation results for both block-structured and
chain-structured networks.",http://arxiv.org/pdf/1812.03659v2,math.ST
2018-12-07 21:20:42+00:00,seq2graph: Discovering Dynamic Dependencies from Multivariate Time Series with Multi-level Attention,"['Xuan-Hong Dang', 'Syed Yousaf Shah', 'Petros Zerfos']","Discovering temporal lagged and inter-dependencies in multivariate time
series data is an important task. However, in many real-world applications,
such as commercial cloud management, manufacturing predictive maintenance, and
portfolios performance analysis, such dependencies can be non-linear and
time-variant, which makes it more challenging to extract such dependencies
through traditional methods such as Granger causality or clustering. In this
work, we present a novel deep learning model that uses multiple layers of
customized gated recurrent units (GRUs) for discovering both time lagged
behaviors as well as inter-timeseries dependencies in the form of directed
weighted graphs. We introduce a key component of Dual-purpose recurrent neural
network that decodes information in the temporal domain to discover lagged
dependencies within each time series, and encodes them into a set of vectors
which, collected from all component time series, form the informative inputs to
discover inter-dependencies. Though the discovery of two types of dependencies
are separated at different hierarchical levels, they are tightly connected and
jointly trained in an end-to-end manner. With this joint training, learning of
one type of dependency immediately impacts the learning of the other one,
leading to overall accurate dependencies discovery. We empirically test our
model on synthetic time series data in which the exact form of (non-linear)
dependencies is known. We also evaluate its performance on two real-world
applications, (i) performance monitoring data from a commercial cloud provider,
which exhibit highly dynamic, non-linear, and volatile behavior and, (ii)
sensor data from a manufacturing plant. We further show how our approach is
able to capture these dependency behaviors via intuitive and interpretable
dependency graphs and use them to generate highly accurate forecasts.",http://arxiv.org/pdf/1812.04448v1,cs.LG
2018-12-06 08:14:57+00:00,Time-Discounting Convolution for Event Sequences with Ambiguous Timestamps,"['Takayuki Katsuki', 'Takayuki Osogami', 'Akira Koseki', 'Masaki Ono', 'Michiharu Kudo', 'Masaki Makino', 'Atsushi Suzuki']","This paper proposes a method for modeling event sequences with ambiguous
timestamps, a time-discounting convolution. Unlike in ordinary time series,
time intervals are not constant, small time-shifts have no significant effect,
and inputting timestamps or time durations into a model is not effective. The
criteria that we require for the modeling are providing robustness against
time-shifts or timestamps uncertainty as well as maintaining the essential
capabilities of time-series models, i.e., forgetting meaningless past
information and handling infinite sequences. The proposed method handles them
with a convolutional mechanism across time with specific parameterizations,
which efficiently represents the event dependencies in a time-shift invariant
manner while discounting the effect of past events, and a dynamic pooling
mechanism, which provides robustness against the uncertainty in timestamps and
enhances the time-discounting capability by dynamically changing the pooling
window size. In our learning algorithm, the decaying and dynamic pooling
mechanisms play critical roles in handling infinite and variable length
sequences. Numerical experiments on real-world event sequences with ambiguous
timestamps and ordinary time series demonstrated the advantages of our method.",http://arxiv.org/pdf/1812.02395v1,cs.LG
2018-12-05 01:01:52+00:00,RobustSTL: A Robust Seasonal-Trend Decomposition Algorithm for Long Time Series,"['Qingsong Wen', 'Jingkun Gao', 'Xiaomin Song', 'Liang Sun', 'Huan Xu', 'Shenghuo Zhu']","Decomposing complex time series into trend, seasonality, and remainder
components is an important task to facilitate time series anomaly detection and
forecasting. Although numerous methods have been proposed, there are still many
time series characteristics exhibiting in real-world data which are not
addressed properly, including 1) ability to handle seasonality fluctuation and
shift, and abrupt change in trend and reminder; 2) robustness on data with
anomalies; 3) applicability on time series with long seasonality period. In the
paper, we propose a novel and generic time series decomposition algorithm to
address these challenges. Specifically, we extract the trend component robustly
by solving a regression problem using the least absolute deviations loss with
sparse regularization. Based on the extracted trend, we apply the the non-local
seasonal filtering to extract the seasonality component. This process is
repeated until accurate decomposition is obtained. Experiments on different
synthetic and real-world time series datasets demonstrate that our method
outperforms existing solutions.",http://arxiv.org/pdf/1812.01767v1,cs.LG
2018-12-03 04:58:56+00:00,Modeling Treatment Delays for Patients using Feature Label Pairs in a Time Series,"['Weiyu Huang', 'Yunlong Wang', 'Li Zhou', 'Emily Zhao', 'Yilian Yuan', 'Alejandro Ribero']","Pharmaceutical targeting is one of key inputs for making sales and marketing
strategy planning. Targeting list is built on predicting physician's sales
potential of certain type of patient. In this paper, we present a
time-sensitive targeting framework leveraging time series model to predict
patient's disease and treatment progression. We create time features by
extracting service history within a certain period, and record whether the
event happens in a look-forward period. Such feature-label pairs are examined
across all time periods and all patients to train a model. It keeps the
inherent order of services and evaluates features associated to the imminent
future, which contribute to improved accuracy.",http://arxiv.org/pdf/1812.00554v1,cs.LG
2018-12-03 03:04:08+00:00,Large Spectral Density Matrix Estimation by Thresholding,"['Yiming Sun', 'Yige Li', 'Amy Kuceyeski', 'Sumanta Basu']","Spectral density matrix estimation of multivariate time series is a classical
problem in time series and signal processing. In modern neuroscience, spectral
density based metrics are commonly used for analyzing functional connectivity
among brain regions. In this paper, we develop a non-asymptotic theory for
regularized estimation of high-dimensional spectral density matrices of
Gaussian and linear processes using thresholded versions of averaged
periodograms. Our theoretical analysis ensures that consistent estimation of
spectral density matrix of a $p$-dimensional time series using $n$ samples is
possible under high-dimensional regime $\log p / n \rightarrow 0$ as long as
the true spectral density is approximately sparse. A key technical component of
our analysis is a new concentration inequality of average periodogram around
its expectation, which is of independent interest. Our estimation consistency
results complement existing results for shrinkage based estimators of
multivariate spectral density, which require no assumption on sparsity but only
ensure consistent estimation in a regime $p^2/n \rightarrow 0$. In addition,
our proposed thresholding based estimators perform consistent and automatic
edge selection when learning coherence networks among the components of a
multivariate time series. We demonstrate the advantage of our estimators using
simulation studies and a real data application on functional connectivity
analysis with fMRI data.",http://arxiv.org/pdf/1812.00532v1,stat.ME
2018-12-02 23:59:36+00:00,Improving Clinical Predictions through Unsupervised Time Series Representation Learning,"['Xinrui Lyu', 'Matthias Hueser', 'Stephanie L. Hyland', 'George Zerveas', 'Gunnar Raetsch']","In this work, we investigate unsupervised representation learning on medical
time series, which bears the promise of leveraging copious amounts of existing
unlabeled data in order to eventually assist clinical decision making. By
evaluating on the prediction of clinically relevant outcomes, we show that in a
practical setting, unsupervised representation learning can offer clear
performance benefits over end-to-end supervised architectures. We experiment
with using sequence-to-sequence (Seq2Seq) models in two different ways, as an
autoencoder and as a forecaster, and show that the best performance is achieved
by a forecasting Seq2Seq model with an integrated attention mechanism, proposed
here for the first time in the setting of unsupervised learning for medical
time series.",http://arxiv.org/pdf/1812.00490v1,cs.LG
2018-11-30 23:42:53+00:00,Deep Factors with Gaussian Processes for Forecasting,"['Danielle C. Maddix', 'Yuyang Wang', 'Alex Smola']","A large collection of time series poses significant challenges for classical
and neural forecasting approaches. Classical time series models fail to fit
data well and to scale to large problems, but succeed at providing uncertainty
estimates. The converse is true for deep neural networks. In this paper, we
propose a hybrid model that incorporates the benefits of both approaches. Our
new method is data-driven and scalable via a latent, global, deep component. It
also handles uncertainty through a local classical Gaussian Process model. Our
experiments demonstrate that our method obtains higher accuracy than
state-of-the-art methods.",http://arxiv.org/pdf/1812.00098v1,stat.ML
2018-11-30 06:27:44+00:00,ADSaS: Comprehensive Real-time Anomaly Detection System,"['Sooyeon Lee', 'Huy Kang Kim']","Since with massive data growth, the need for autonomous and generic anomaly
detection system is increased. However, developing one stand-alone generic
anomaly detection system that is accurate and fast is still a challenge. In
this paper, we propose conventional time-series analysis approaches, the
Seasonal Autoregressive Integrated Moving Average (SARIMA) model and Seasonal
Trend decomposition using Loess (STL), to detect complex and various anomalies.
Usually, SARIMA and STL are used only for stationary and periodic time-series,
but by combining, we show they can detect anomalies with high accuracy for data
that is even noisy and non-periodic. We compared the algorithm to Long Short
Term Memory (LSTM), a deep-learning-based algorithm used for anomaly detection
system. We used a total of seven real-world datasets and four artificial
datasets with different time-series properties to verify the performance of the
proposed algorithm.",http://arxiv.org/pdf/1811.12634v1,cs.LG
2018-11-29 10:23:01+00:00,Recurrent Deep Divergence-based Clustering for simultaneous feature learning and clustering of variable length time series,"['Daniel J. Trosten', 'Andreas S. Strauman', 'Michael Kampffmeyer', 'Robert Jenssen']","The task of clustering unlabeled time series and sequences entails a
particular set of challenges, namely to adequately model temporal relations and
variable sequence lengths. If these challenges are not properly handled, the
resulting clusters might be of suboptimal quality. As a key solution, we
present a joint clustering and feature learning framework for time series based
on deep learning. For a given set of time series, we train a recurrent network
to represent, or embed, each time series in a vector space such that a
divergence-based clustering loss function can discover the underlying cluster
structure in an end-to-end manner. Unlike previous approaches, our model
inherently handles multivariate time series of variable lengths and does not
require specification of a distance-measure in the input space. On a diverse
set of benchmark datasets we illustrate that our proposed Recurrent Deep
Divergence-based Clustering approach outperforms, or performs comparable to,
previous approaches.",http://arxiv.org/pdf/1811.12050v2,stat.ML
2018-11-28 15:19:45+00:00,Multi-step Time Series Forecasting Using Ridge Polynomial Neural Network with Error-Output Feedbacks,"['Waddah Waheeb', 'Rozaida Ghazali']","Time series forecasting gets much attention due to its impact on many
practical applications. Higher-order neural network with recurrent feedback is
a powerful technique which used successfully for forecasting. It maintains fast
learning and the ability to learn the dynamics of the series over time. For
that, in this paper, we propose a novel model which is called Ridge Polynomial
Neural Network with Error-Output Feedbacks (RPNN-EOFs) that combines the
properties of higher order and error-output feedbacks. The well-known
Mackey-Glass time series is used to test the forecasting capability of
RPNN-EOFS. Simulation results showed that the proposed RPNN-EOFs provides
better understanding for the Mackey-Glass time series with root mean square
error equal to 0.00416. This result is smaller than other models in the
literature. Therefore, we can conclude that the RPNN-EOFs can be applied
successfully for time series forecasting.",http://arxiv.org/pdf/1811.11620v1,cs.LG
2018-11-27 13:22:32+00:00,Extracting conditionally heteroscedastic components using ICA,"['Jari Miettinen', 'Markus Matilainen', 'Klaus Nordhausen', 'Sara Taskinen']","In the independent component model, the multivariate data is assumed to be a
mixture of mutually independent latent components, and in independent component
analysis (ICA) the aim is to estimate these latent components. In this paper we
study an ICA method which combines the use of linear and quadratic
autocorrelations in order to enable efficient estimation of various kinds of
stationary time series. Statistical properties of the estimator are studied by
finding its limiting distribution under general conditions, and the asymptotic
variances are derived in the case of ARMA-GARCH model. We use the asymptotic
results and a finite sample simulation study to compare different choices of a
weight coefficient. As it is often of interest to identify all those components
which exhibit stochastic volatility features we also suggest a test statistic
for this problem. We also show that a slightly modified version of principal
volatility components (PVC) can be seen as an ICA method. Finally, we apply the
estimators in analyzing a data set which consists of time series of exchange
rates of seven currencies to US dollar. Supplementary material including proofs
of the theorems is available online.",http://arxiv.org/pdf/1811.10963v1,math.ST
2018-11-26 11:14:43+00:00,Bayesian Nonparametric Analysis of Multivariate Time Series: A Matrix Gamma Process Approach,"['Alexander Meier', 'Claudia Kirch', 'Renate Meyer']","While there is an increasing amount of literature about Bayesian time series
analysis, only a few Bayesian nonparametric approaches to multivariate time
series exist. Most methods rely on Whittle's Likelihood, involving the second
order structure of a stationary time series by means of its spectral density
matrix. This is often modeled in terms of the Cholesky decomposition to ensure
positive definiteness. However, asymptotic properties such as posterior
consistency or posterior contraction rates are not known. A different idea is
to model the spectral density matrix by means of random measures. This is in
line with existing approaches for the univariate case, where the normalized
spectral density is modeled similar to a probability density, e.g. with a
Dirichlet process mixture of Beta densities. In this work, we present a related
approach for multivariate time series, with matrix-valued mixture weights
induced by a Hermitian positive definite Gamma process. The proposed procedure
is shown to perform well for both simulated and real data. Posterior
consistency and contraction rates are also established.",http://arxiv.org/pdf/1811.10292v1,stat.ME
2018-11-26 08:09:02+00:00,Wavelet-based and Fourier-based multivariate Whittle estimation: multiwave,"['Sophie Achard', 'Irène Gannaz']","Multivariate time series with long-dependence are observed in many
applications such as finance , geophysics or neuroscience. Many packages
provide estimation tools for univariate settings but few are addressing the
problem of long-dependence estimation for multivariate settings. The package
multiwave is providing efficient estimation procedures for multivariate time
series. Two semi-parametric estimation methods of the long-memory exponents and
long-run covariance matrix of time series are implemented. The first one is the
Fourier-based estimation proposed by [18] and the second one is a wavelet-based
estimation described in [4]. The objective of this paper is to provide an
overview of the R package multiwave with its practical application
perspectives.",http://arxiv.org/pdf/1811.10224v1,math.ST
2018-11-20 14:54:24+00:00,T-CGAN: Conditional Generative Adversarial Network for Data Augmentation in Noisy Time Series with Irregular Sampling,"['Giorgia Ramponi', 'Pavlos Protopapas', 'Marco Brambilla', 'Ryan Janssen']","In this paper we propose a data augmentation method for time series with
irregular sampling, Time-Conditional Generative Adversarial Network (T-CGAN).
Our approach is based on Conditional Generative Adversarial Networks (CGAN),
where the generative step is implemented by a deconvolutional NN and the
discriminative step by a convolutional NN. Both the generator and the
discriminator are conditioned on the sampling timestamps, to learn the hidden
relationship between data and timestamps, and consequently to generate new time
series. We evaluate our model with synthetic and real-world datasets. For the
synthetic data, we compare the performance of a classifier trained with
T-CGAN-generated data, against the performance of the same classifier trained
on the original data. Results show that classifiers trained on T-CGAN-generated
data perform the same as classifiers trained on real data, even with very short
time series and small training sets. For the real world datasets, we compare
our method with other techniques of data augmentation for time series, such as
time slicing and time warping, over a classification problem with unbalanced
datasets. Results show that our method always outperforms the other approaches,
both in case of regularly sampled and irregularly sampled time series. We
achieve particularly good performance in case with a small training set and
short, noisy, irregularly-sampled time series.",http://arxiv.org/pdf/1811.08295v2,cs.LG
2018-11-20 03:36:45+00:00,A Deep Neural Network for Unsupervised Anomaly Detection and Diagnosis in Multivariate Time Series Data,"['Chuxu Zhang', 'Dongjin Song', 'Yuncong Chen', 'Xinyang Feng', 'Cristian Lumezanu', 'Wei Cheng', 'Jingchao Ni', 'Bo Zong', 'Haifeng Chen', 'Nitesh V. Chawla']","Nowadays, multivariate time series data are increasingly collected in various
real world systems, e.g., power plants, wearable devices, etc. Anomaly
detection and diagnosis in multivariate time series refer to identifying
abnormal status in certain time steps and pinpointing the root causes. Building
such a system, however, is challenging since it not only requires to capture
the temporal dependency in each time series, but also need encode the
inter-correlations between different pairs of time series. In addition, the
system should be robust to noise and provide operators with different levels of
anomaly scores based upon the severity of different incidents. Despite the fact
that a number of unsupervised anomaly detection algorithms have been developed,
few of them can jointly address these challenges. In this paper, we propose a
Multi-Scale Convolutional Recurrent Encoder-Decoder (MSCRED), to perform
anomaly detection and diagnosis in multivariate time series data. Specifically,
MSCRED first constructs multi-scale (resolution) signature matrices to
characterize multiple levels of the system statuses in different time steps.
Subsequently, given the signature matrices, a convolutional encoder is employed
to encode the inter-sensor (time series) correlations and an attention based
Convolutional Long-Short Term Memory (ConvLSTM) network is developed to capture
the temporal patterns. Finally, based upon the feature maps which encode the
inter-sensor correlations and temporal information, a convolutional decoder is
used to reconstruct the input signature matrices and the residual signature
matrices are further utilized to detect and diagnose anomalies. Extensive
empirical studies based on a synthetic dataset and a real power plant dataset
demonstrate that MSCRED can outperform state-of-the-art baseline methods.",http://arxiv.org/pdf/1811.08055v1,cs.LG
2018-11-19 11:34:27+00:00,Joint reconstruction and prediction of random dynamical systems under borrowing of strength,"['Spyridon J. Hatjispyros', 'Christos Merkatas']","We propose a Bayesian nonparametric model based on Markov Chain Monte Carlo
(MCMC) methods for the joint reconstruction and prediction of discrete time
stochastic dynamical systems, based on $m$-multiple time-series data, perturbed
by additive dynamical noise. We introduce the Pairwise Dependent Geometric
Stick-Breaking Reconstruction (PD-GSBR) model, which relies on the construction
of a $m$-variate nonparametric prior over the space of densities supported over
$\mathbb{R}^m$. We are focusing in the case where at least one of the
time-series has a sufficiently large sample size representation for an
independent and accurate Geometric Stick-Breaking estimation, as defined in
Merkatas et al. (2017). Our contention, is that whenever the dynamical error
processes perturbing the underlying dynamical systems share common
characteristics, underrepresented data sets can benefit in terms of model
estimation accuracy. The PD-GSBR estimation and prediction procedure is
demonstrated specifically in the case of maps with polynomial nonlinearities of
an arbitrary degree. Simulations based on synthetic time-series are presented.",http://arxiv.org/pdf/1811.07625v2,stat.ME
2018-11-15 13:33:59+00:00,Sparsely Observed Functional Time Series: Estimation and Prediction,"['Tomáš Rubín', 'Victor M. Panaretos']","Functional time series analysis, whether based on time of frequency domain
methodology, has traditionally been carried out under the assumption of
complete observation of the constituent series of curves, assumed stationary.
Nevertheless, as is often the case with independent functional data, it may
well happen that the data available to the analyst are not the actual sequence
of curves, but relatively few and noisy measurements per curve, potentially at
different locations in each curve's domain. Under this sparse sampling regime,
neither the established estimators of the time series' dynamics, nor their
corresponding theoretical analysis will apply. The subject of this paper is to
tackle the problem of estimating the dynamics and of recovering the latent
process of smooth curves in the sparse regime. Assuming smoothness of the
latent curves, we construct a consistent nonparametric estimator of the series'
spectral density operator and use it develop a frequency-domain recovery
approach, that predicts the latent curve at a given time by borrowing strength
from the (estimated) dynamic correlations in the series across time. Further to
predicting the latent curves from their noisy point samples, the method fills
in gaps in the sequence (curves nowhere sampled), denoises the data, and serves
as a basis for forecasting. Means of providing corresponding confidence bands
are also investigated. A simulation study interestingly suggests that sparse
observation for a longer time period, may be provide better performance than
dense observation for a shorter period, in the presence of smoothness. The
methodology is further illustrated by application to an environmental data set
on fair-weather atmospheric electricity, which naturally leads to a sparse
functional time-series.",http://arxiv.org/pdf/1811.06340v2,stat.ME
2018-11-15 04:47:12+00:00,The autoregression bootstrap for kernel estimates of smooth nonlinear functional time series,"['Johannes T. N. Krebs', 'Jürgen E. Franke']","Functional times series have become an integral part of both functional data
and time series analysis. This paper deals with the functional autoregressive
model of order 1 and the autoregression bootstrap for smooth functions. The
regression operator is estimated in the framework developed by Ferraty and Vieu
[2004] and Ferraty et al. [2007] which is here extended to the double
functional case under an assumption of stationary ergodic data which dates back
to Laib and Louani [2010]. The main result of this article is the
characterization of the asymptotic consistency of the bootstrapped regression
operator.",http://arxiv.org/pdf/1811.06172v1,math.ST
2018-11-14 21:33:24+00:00,Adversarial Unsupervised Representation Learning for Activity Time-Series,"['Karan Aggarwal', 'Shafiq Joty', 'Luis Fernandez-Luque', 'Jaideep Srivastava']","Sufficient physical activity and restful sleep play a major role in the
prevention and cure of many chronic conditions. Being able to proactively
screen and monitor such chronic conditions would be a big step forward for
overall health. The rapid increase in the popularity of wearable devices
provides a significant new source, making it possible to track the user's
lifestyle real-time. In this paper, we propose a novel unsupervised
representation learning technique called activity2vec that learns and
""summarizes"" the discrete-valued activity time-series. It learns the
representations with three components: (i) the co-occurrence and magnitude of
the activity levels in a time-segment, (ii) neighboring context of the
time-segment, and (iii) promoting subject-invariance with adversarial training.
We evaluate our method on four disorder prediction tasks using linear
classifiers. Empirical evaluation demonstrates that our proposed method scales
and performs better than many strong baselines. The adversarial regime helps
improve the generalizability of our representations by promoting subject
invariant features. We also show that using the representations at the level of
a day works the best since human activity is structured in terms of daily
routines",http://arxiv.org/pdf/1811.06847v1,cs.LG
2018-11-09 03:42:36+00:00,EA-LSTM: Evolutionary Attention-based LSTM for Time Series Prediction,"['Youru Li', 'Zhenfeng Zhu', 'Deqiang Kong', 'Hua Han', 'Yao Zhao']","Time series prediction with deep learning methods, especially long short-term
memory neural networks (LSTMs), have scored significant achievements in recent
years. Despite the fact that the LSTMs can help to capture long-term
dependencies, its ability to pay different degree of attention on sub-window
feature within multiple time-steps is insufficient. To address this issue, an
evolutionary attention-based LSTM training with competitive random search is
proposed for multivariate time series prediction. By transferring shared
parameters, an evolutionary attention learning approach is introduced to the
LSTMs model. Thus, like that for biological evolution, the pattern for
importance-based attention sampling can be confirmed during temporal
relationship mining. To refrain from being trapped into partial optimization
like traditional gradient-based methods, an evolutionary computation inspired
competitive random search method is proposed, which can well configure the
parameters in the attention layer. Experimental results have illustrated that
the proposed model can achieve competetive prediction performance compared with
other baseline methods.",http://arxiv.org/pdf/1811.03760v1,cs.LG
2018-11-05 09:21:33+00:00,Towards a Near Universal Time Series Data Mining Tool: Introducing the Matrix Profile,['Chin-Chia Michael Yeh'],"The last decade has seen a flurry of research on all-pairs-similarity-search
(or, self-join) for text, DNA, and a handful of other datatypes, and these
systems have been applied to many diverse data mining problems. Surprisingly,
however, little progress has been made on addressing this problem for time
series subsequences. In this thesis, we have introduced a near universal time
series data mining tool called matrix profile which solves the
all-pairs-similarity-search problem and caches the output in an easy-to-access
fashion. The proposed algorithm is not only parameter-free, exact and scalable,
but also applicable for both single and multidimensional time series. By
building time series data mining methods on top of matrix profile, many time
series data mining tasks (e.g., motif discovery, discord discovery, shapelet
discovery, semantic segmentation, and clustering) can be efficiently solved.
Because the same matrix profile can be shared by a diverse set of time series
data mining methods, matrix profile is versatile and
computed-once-use-many-times data structure. We demonstrate the utility of
matrix profile for many time series data mining problems, including motif
discovery, discord discovery, weakly labeled time series classification, and
representation learning on domains as diverse as seismology, entomology, music
processing, bioinformatics, human activity monitoring, electrical power-demand
monitoring, and medicine. We hope the matrix profile is not the end but the
beginning of many more time series data mining projects.",http://arxiv.org/pdf/1811.03064v2,cs.LG
2018-11-01 12:41:24+00:00,Can automated smoothing significantly improve benchmark time series classification algorithms?,"['James Large', 'Paul Southam', 'Anthony Bagnall']","tl;dr: no, it cannot, at least not on average on the standard archive
problems. We assess whether using six smoothing algorithms (moving average,
exponential smoothing, Gaussian filter, Savitzky-Golay filter, Fourier
approximation and a recursive median sieve) could be automatically applied to
time series classification problems as a preprocessing step to improve the
performance of three benchmark classifiers (1-Nearest Neighbour with Euclidean
and Dynamic Time Warping distances, and Rotation Forest). We found no
significant improvement over unsmoothed data even when we set the smoothing
parameter through cross validation. We are not claiming smoothing has no worth.
It has an important role in exploratory analysis and helps with specific
classification problems where domain knowledge can be exploited. What we
observe is that the automatic application does not help and that we cannot
explain the improvement of other time series classification algorithms over the
baseline classifiers simply as a function of the absence of smoothing.",http://arxiv.org/pdf/1811.00894v1,cs.LG
2018-11-01 03:19:10+00:00,Latent Gaussian Count Time Series,"['Yisu Jia', 'Stefanos Kechagias', 'James Livsey', 'Robert Lund', 'Vladas Pipiras']","This paper develops the theory and methods for modeling a stationary count
time series via Gaussian transformations. The techniques use a latent Gaussian
process and a distributional transformation to construct stationary series with
very flexible correlation features that can have any pre-specified marginal
distribution, including the classical Poisson, generalized Poisson, negative
binomial, and binomial structures. Gaussian pseudo-likelihood and implied
Yule-Walker estimation paradigms, based on the autocovariance function of the
count series, are developed via a new Hermite expansion. Particle filtering and
sequential Monte Carlo methods are used to conduct likelihood estimation.
Connections to state space models are made. Our estimation approaches are
evaluated in a simulation study and the methods are used to analyze a count
series of weekly retail sales.",http://arxiv.org/pdf/1811.00203v3,stat.ME
2018-10-31 19:24:20+00:00,"The UEA multivariate time series classification archive, 2018","['Anthony Bagnall', 'Hoang Anh Dau', 'Jason Lines', 'Michael Flynn', 'James Large', 'Aaron Bostrom', 'Paul Southam', 'Eamonn Keogh']","In 2002, the UCR time series classification archive was first released with
sixteen datasets. It gradually expanded, until 2015 when it increased in size
from 45 datasets to 85 datasets. In October 2018 more datasets were added,
bringing the total to 128. The new archive contains a wide range of problems,
including variable length series, but it still only contains univariate time
series classification problems. One of the motivations for introducing the
archive was to encourage researchers to perform a more rigorous evaluation of
newly proposed time series classification (TSC) algorithms. It has worked: most
recent research into TSC uses all 85 datasets to evaluate algorithmic advances.
Research into multivariate time series classification, where more than one
series are associated with each class label, is in a position where univariate
TSC research was a decade ago. Algorithms are evaluated using very few datasets
and claims of improvement are not based on statistical comparisons. We aim to
address this problem by forming the first iteration of the MTSC archive, to be
hosted at the website www.timeseriesclassification.com. Like the univariate
archive, this formulation was a collaborative effort between researchers at the
University of East Anglia (UEA) and the University of California, Riverside
(UCR). The 2018 vintage consists of 30 datasets with a wide range of cases,
dimensions and series lengths. For this first iteration of the archive we
format all data to be of equal length, include no series with missing data and
provide train/test splits.",http://arxiv.org/pdf/1811.00075v1,cs.LG
2018-10-31 14:50:01+00:00,Contrastive Multivariate Singular Spectrum Analysis,"['Abdi-Hakin Dirie', 'Abubakar Abid', 'James Zou']","We introduce Contrastive Multivariate Singular Spectrum Analysis, a novel
unsupervised method for dimensionality reduction and signal decomposition of
time series data. By utilizing an appropriate background dataset, the method
transforms a target time series dataset in a way that evinces the sub-signals
that are enhanced in the target dataset, as opposed to only those that account
for the greatest variance. This shifts the goal from finding signals that
explain the most variance to signals that matter the most to the analyst. We
demonstrate our method on an illustrative synthetic example, as well as show
the utility of our method in the downstream clustering of electrocardiogram
signals from the public MHEALTH dataset.",http://arxiv.org/pdf/1810.13317v1,stat.ML
2018-10-28 01:57:31+00:00,On buffered double autoregressive time series models,['Zhao Liu'],"A buffered double autoregressive (BDAR) time series model is proposed in this
paper to depict the buffering phenomenon of conditional mean and conditional
variance in time series. To build this model, a novel flexible regime switching
mechanism is introduced to modify the classical threshold time series model by
capturing the stickiness of signal. Besides, considering the inadequacy of
traditional models under the lack of information, a signal retrospection is run
in this model to provide a more accurate judgment. Moreover, formal proofs
suggest strict stationarity and geometric ergodicity of BDAR model under
several sufficient conditions. A Gaussian quasi-maximum likelihood estimation
(QMLE) is employed and the asymptotic distributions of its estimators are
derived. It has been demonstrated that the estimated thresholds of the BDAR
model are $n$-consistent, each of which converges weakly to a functional of a
two-sided compound Poisson process. The remaining parameters are
$\sqrt{n}$-consistent and asymptotically normal. Furthermore, a model selection
criteria and its asymptotic property have been established. Simulation studies
are constructed to evaluate the finite sample performance of QMLE and model
selection criteria. Finally, an empirical analysis of Hang Seng Index (HSI)
using BDAR model reveals the asymmetry of investors' preference over losses and
gains as well as the asymmetry of volatility structure.",http://arxiv.org/pdf/1810.11746v1,stat.ME
2018-10-27 10:01:46+00:00,Time series clustering based on the characterisation of segment typologies,"['David Guijo-Rubio', 'Antonio Manuel Durán-Rosal', 'Pedro Antonio Gutiérrez', 'Alicia Troncoso', 'César Hervás-Martínez']","Time series clustering is the process of grouping time series with respect to
their similarity or characteristics. Previous approaches usually combine a
specific distance measure for time series and a standard clustering method.
However, these approaches do not take the similarity of the different
subsequences of each time series into account, which can be used to better
compare the time series objects of the dataset. In this paper, we propose a
novel technique of time series clustering based on two clustering stages. In a
first step, a least squares polynomial segmentation procedure is applied to
each time series, which is based on a growing window technique that returns
different-length segments. Then, all the segments are projected into same
dimensional space, based on the coefficients of the model that approximates the
segment and a set of statistical features. After mapping, a first hierarchical
clustering phase is applied to all mapped segments, returning groups of
segments for each time series. These clusters are used to represent all time
series in the same dimensional space, after defining another specific mapping
process. In a second and final clustering stage, all the time series objects
are grouped. We consider internal clustering quality to automatically adjust
the main parameter of the algorithm, which is an error threshold for the
segmenta- tion. The results obtained on 84 datasets from the UCR Time Series
Classification Archive have been compared against two state-of-the-art methods,
showing that the performance of this methodology is very promising.",http://arxiv.org/pdf/1810.11624v1,cs.LG
2018-10-26 08:23:22+00:00,Spectral Analysis of High-dimensional Time Series,"['Mark Fiecas', 'Chenlei Leng', 'Weidong Liu', 'Yi Yu']","A useful approach for analysing multiple time series is via characterising
their spectral density matrix as the frequency domain analog of the covariance
matrix. When the dimension of the time series is large compared to their
length, regularisation based methods can overcome the curse of dimensionality,
but the existing ones lack theoretical justification. This paper develops the
first non-asymptotic result for characterising the difference between the
sample and population versions of the spectral density matrix, allowing one to
justify a range of high-dimensional models for analysing time series. As a
concrete example, we apply this result to establish the convergence of the
smoothed periodogram estimators and sparse estimators of the inverse of
spectral density matrices, namely precision matrices. These results, novel in
the frequency domain time series analysis, are corroborated by simulations and
an analysis of the Google Flu Trends data.",http://arxiv.org/pdf/1810.11223v1,math.ST
2018-10-23 17:56:37+00:00,Bayesian Model Search for Nonstationary Periodic Time Series,"['Beniamino Hadj-Amar', 'Bärbel Finkenstädt', 'Mark Fiecas', 'Francis Levi', 'Robert Huckstepp']","We propose a novel Bayesian methodology for analyzing nonstationary time
series that exhibit oscillatory behaviour. We approximate the time series using
a piecewise oscillatory model with unknown periodicities, where our goal is to
estimate the change-points while simultaneously identifying the potentially
changing periodicities in the data. Our proposed methodology is based on a
trans-dimensional Markov chain Monte Carlo (MCMC) algorithm that simultaneously
updates the change-points and the periodicities relevant to any segment between
them. We show that the proposed methodology successfully identifies time
changing oscillatory behaviour in two applications which are relevant to
e-Health and sleep research, namely the occurrence of ultradian oscillations in
human skin temperature during the time of night rest, and the detection of
instances of sleep apnea in plethysmographic respiratory traces.",http://arxiv.org/pdf/1810.09996v3,stat.ME
2018-10-23 15:40:25+00:00,Clustering Time Series with Nonlinear Dynamics: A Bayesian Non-Parametric and Particle-Based Approach,"['Alexander Lin', 'Yingzhuo Zhang', 'Jeremy Heng', 'Stephen A. Allsop', 'Kay M. Tye', 'Pierre E. Jacob', 'Demba Ba']","We propose a general statistical framework for clustering multiple time
series that exhibit nonlinear dynamics into an a-priori-unknown number of
sub-groups. Our motivation comes from neuroscience, where an important problem
is to identify, within a large assembly of neurons, subsets that respond
similarly to a stimulus or contingency. Upon modeling the multiple time series
as the output of a Dirichlet process mixture of nonlinear state-space models,
we derive a Metropolis-within-Gibbs algorithm for full Bayesian inference that
alternates between sampling cluster assignments and sampling parameter values
that form the basis of the clustering. The Metropolis step employs recent
innovations in particle-based methods. We apply the framework to clustering
time series acquired from the prefrontal cortex of mice in an experiment
designed to characterize the neural underpinnings of fear.",http://arxiv.org/pdf/1810.09920v4,stat.ML
2018-10-22 05:53:22+00:00,Stochastic Gradient MCMC for State Space Models,"['Christopher Aicher', 'Yi-An Ma', 'Nicholas J. Foti', 'Emily B. Fox']","State space models (SSMs) are a flexible approach to modeling complex time
series. However, inference in SSMs is often computationally prohibitive for
long time series. Stochastic gradient MCMC (SGMCMC) is a popular method for
scalable Bayesian inference for large independent data. Unfortunately when
applied to dependent data, such as in SSMs, SGMCMC's stochastic gradient
estimates are biased as they break crucial temporal dependencies. To alleviate
this, we propose stochastic gradient estimators that control this bias by
performing additional computation in a `buffer' to reduce breaking
dependencies. Furthermore, we derive error bounds for this bias and show a
geometric decay under mild conditions. Using these estimators, we develop novel
SGMCMC samplers for discrete, continuous and mixed-type SSMs with analytic
message passing. Our experiments on real and synthetic data demonstrate the
effectiveness of our SGMCMC algorithms compared to batch MCMC, allowing us to
scale inference to long time series with millions of time points.",http://arxiv.org/pdf/1810.09098v2,stat.ML
2018-10-21 13:27:55+00:00,Training Dynamic Exponential Family Models with Causal and Lateral Dependencies for Generalized Neuromorphic Computing,"['Hyeryung Jang', 'Osvaldo Simeone']","Neuromorphic hardware platforms, such as Intel's Loihi chip, support the
implementation of Spiking Neural Networks (SNNs) as an energy-efficient
alternative to Artificial Neural Networks (ANNs). SNNs are networks of neurons
with internal analogue dynamics that communicate by means of binary time
series. In this work, a probabilistic model is introduced for a generalized
set-up in which the synaptic time series can take values in an arbitrary
alphabet and are characterized by both causal and instantaneous statistical
dependencies. The model, which can be considered as an extension of exponential
family harmoniums to time series, is introduced by means of a hybrid
directed-undirected graphical representation. Furthermore, distributed learning
rules are derived for Maximum Likelihood and Bayesian criteria under the
assumption of fully observed time series in the training set.",http://arxiv.org/pdf/1810.08940v3,cs.LG
2018-10-18 22:23:49+00:00,A similarity measure for second order properties of non-stationary functional time series with applications to clustering and testing,"['Anne van Delft', 'Holger Dette']","Due to the surge of data storage techniques, the need for the development of
appropriate techniques to identify patterns and to extract knowledge from the
resulting enormous data sets, which can be viewed as collections of dependent
functional data, is of increasing interest in many scientific areas. We develop
a similarity measure for spectral density operators of a collection of
functional time series, which is based on the aggregation of Hilbert-Schmidt
differences of the individual time-varying spectral density operators. Under
fairly general conditions, the asymptotic properties of the corresponding
estimator are derived and asymptotic normality is established. The introduced
statistic lends itself naturally to quantify (dis)-similarity between
functional time series, which we subsequently exploit in order to build a
spectral clustering algorithm. Our algorithm is the first of its kind in the
analysis of non-stationary (functional) time series and enables to discover
particular patterns by grouping together `similar' series into clusters,
thereby reducing the complexity of the analysis considerably. The algorithm is
simple to implement and computationally feasible. As a further application we
provide a simple test for the hypothesis that the second order properties of
two non-stationary functional time series coincide.",http://arxiv.org/pdf/1810.08292v2,stat.ME
2018-10-17 20:26:49+00:00,A Periodicity-based Parallel Time Series Prediction Algorithm in Cloud Computing Environments,"['Jianguo Chen', 'Kenli Li', 'Huigui Rong', 'Kashif Bilal', 'Keqin Li', 'Philip S. Yu']","In the era of big data, practical applications in various domains continually
generate large-scale time-series data. Among them, some data show significant
or potential periodicity characteristics, such as meteorological and financial
data. It is critical to efficiently identify the potential periodic patterns
from massive time-series data and provide accurate predictions. In this paper,
a Periodicity-based Parallel Time Series Prediction (PPTSP) algorithm for
large-scale time-series data is proposed and implemented in the Apache Spark
cloud computing environment. To effectively handle the massive historical
datasets, a Time Series Data Compression and Abstraction (TSDCA) algorithm is
presented, which can reduce the data scale as well as accurately extracting the
characteristics. Based on this, we propose a Multi-layer Time Series Periodic
Pattern Recognition (MTSPPR) algorithm using the Fourier Spectrum Analysis
(FSA) method. In addition, a Periodicity-based Time Series Prediction (PTSP)
algorithm is proposed. Data in the subsequent period are predicted based on all
previous period models, in which a time attenuation factor is introduced to
control the impact of different periods on the prediction results. Moreover, to
improve the performance of the proposed algorithms, we propose a parallel
solution on the Apache Spark platform, using the Streaming real-time computing
module. To efficiently process the large-scale time-series datasets in
distributed computing environments, Distributed Streams (DStreams) and
Resilient Distributed Datasets (RDDs) are used to store and calculate these
datasets. Extensive experimental results show that our PPTSP algorithm has
significant advantages compared with other algorithms in terms of prediction
accuracy and performance.",http://arxiv.org/pdf/1810.07776v1,cs.LG
2018-10-17 20:00:40+00:00,The UCR Time Series Archive,"['Hoang Anh Dau', 'Anthony Bagnall', 'Kaveh Kamgar', 'Chin-Chia Michael Yeh', 'Yan Zhu', 'Shaghayegh Gharghabi', 'Chotirat Ann Ratanamahatana', 'Eamonn Keogh']","The UCR Time Series Archive - introduced in 2002, has become an important
resource in the time series data mining community, with at least one thousand
published papers making use of at least one data set from the archive. The
original incarnation of the archive had sixteen data sets but since that time,
it has gone through periodic expansions. The last expansion took place in the
summer of 2015 when the archive grew from 45 to 85 data sets. This paper
introduces and will focus on the new data expansion from 85 to 128 data sets.
Beyond expanding this valuable resource, this paper offers pragmatic advice to
anyone who may wish to evaluate a new algorithm on the archive. Finally, this
paper makes a novel and yet actionable claim: of the hundreds of papers that
show an improvement over the standard baseline (1-nearest neighbor
classification), a large fraction may be mis-attributing the reasons for their
improvement. Moreover, they may have been able to achieve the same improvement
with a much simpler modification, requiring just a single line of code.",http://arxiv.org/pdf/1810.07758v2,cs.LG
2018-10-06 17:08:47+00:00,Discretizing Logged Interaction Data Biases Learning for Decision-Making,"['Peter Schulam', 'Suchi Saria']","Time series data that are not measured at regular intervals are commonly
discretized as a preprocessing step. For example, data about customer arrival
times might be simplified by summing the number of arrivals within hourly
intervals, which produces a discrete-time time series that is easier to model.
In this abstract, we show that discretization introduces a bias that affects
models trained for decision-making. We refer to this phenomenon as
discretization bias, and show that we can avoid it by using continuous-time
models instead.",http://arxiv.org/pdf/1810.03025v1,stat.ML
2018-10-06 07:46:03+00:00,Mining Novel Multivariate Relationships in Time Series Data Using Correlation Networks,"['Saurabh Agrawal', 'Michael Steinbach', 'Daniel Boley', 'Snigdhansu Chatterjee', 'Gowtham Atluri', 'Anh The Dang', 'Stefan Liess', 'Vipin Kumar']","In many domains, there is significant interest in capturing novel
relationships between time series that represent activities recorded at
different nodes of a highly complex system. In this paper, we introduce
multipoles, a novel class of linear relationships between more than two time
series. A multipole is a set of time series that have strong linear dependence
among themselves, with the requirement that each time series makes a
significant contribution to the linear dependence. We demonstrate that most
interesting multipoles can be identified as cliques of negative correlations in
a correlation network. Such cliques are typically rare in a real-world
correlation network, which allows us to find almost all multipoles efficiently
using a clique-enumeration approach. Using our proposed framework, we
demonstrate the utility of multipoles in discovering new physical phenomena in
two scientific domains: climate science and neuroscience. In particular, we
discovered several multipole relationships that are reproducible in multiple
other independent datasets and lead to novel domain insights.",http://arxiv.org/pdf/1810.02950v2,cs.LG
2018-10-05 16:32:12+00:00,Sliced Average Variance Estimation for Multivariate Time Series,"['Markus Matilainen', 'Christophe Croux', 'Klaus Nordhausen', 'Hannu Oja']","Supervised dimension reduction for time series is challenging as there may be
temporal dependence between the response $y$ and the predictors $\boldsymbol
x$. Recently a time series version of sliced inverse regression, TSIR, was
suggested, which applies approximate joint diagonalization of several
supervised lagged covariance matrices to consider the temporal nature of the
data. In this paper we develop this concept further and propose a time series
version of sliced average variance estimation, TSAVE. As both TSIR and TSAVE
have their own advantages and disadvantages, we consider furthermore a hybrid
version of TSIR and TSAVE. Based on examples and simulations we demonstrate and
evaluate the differences between the three methods and show also that they are
superior to apply their iid counterparts to when also using lagged values of
the explaining variables as predictors.",http://arxiv.org/pdf/1810.02782v1,stat.ME
2018-10-02 12:11:23+00:00,High-dimensional functional time series forecasting: An application to age-specific mortality rates,"['Yuan Gao', 'Han Lin Shang', 'Yanrong Yang']","We address the problem of forecasting high-dimensional functional time series
through a two-fold dimension reduction procedure. The difficulty of forecasting
high-dimensional functional time series lies in the curse of dimensionality. In
this paper, we propose a novel method to solve this problem. Dynamic functional
principal component analysis is first applied to reduce each functional time
series to a vector. We then use the factor model as a further dimension
reduction technique so that only a small number of latent factors are
preserved. Classic time series models can be used to forecast the factors and
conditional forecasts of the functions can be constructed. Asymptotic
properties of the approximated functions are established, including both
estimation error and forecast error. The proposed method is easy to implement
especially when the dimension of the functional time series is large. We show
the superiority of our approach by both simulation studies and an application
to Japanese age-specific mortality rates.",http://arxiv.org/pdf/1810.01195v1,stat.ME
2018-09-27 18:38:45+00:00,Dataset: Rare Event Classification in Multivariate Time Series,"['Chitta Ranjan', 'Mahendranath Reddy', 'Markku Mustonen', 'Kamran Paynabar', 'Karim Pourak']","A real-world dataset is provided from a pulp-and-paper manufacturing
industry. The dataset comes from a multivariate time series process. The data
contains a rare event of paper break that commonly occurs in the industry. The
data contains sensor readings at regular time-intervals (x's) and the event
label (y). The primary purpose of the data is thought to be building a
classification model for early prediction of the rare event. However, it can
also be used for multivariate time series data exploration and building other
supervised and unsupervised models.",http://arxiv.org/pdf/1809.10717v4,stat.ML
2018-09-27 03:35:00+00:00,Using Autoencoders To Learn Interesting Features For Detecting Surveillance Aircraft,['Teresa Nicole Brooks'],"This paper explores using a Long short-term memory (LSTM) based sequence
autoencoder to learn interesting features for detecting surveillance aircraft
using ADS-B flight data. An aircraft periodically broadcasts ADS-B (Automatic
Dependent Surveillance - Broadcast) data to ground receivers. The ability of
LSTM networks to model varying length time series data and remember
dependencies that span across events makes it an ideal candidate for
implementing a sequence autoencoder for ADS-B data because of its possible
variable length time series, irregular sampling and dependencies that span
across events.",http://arxiv.org/pdf/1809.10333v1,cs.LG
2018-09-24 01:37:26+00:00,Unified recurrent neural network for many feature types,"['Alexander Stec', 'Diego Klabjan', 'Jean Utke']","There are time series that are amenable to recurrent neural network (RNN)
solutions when treated as sequences, but some series, e.g. asynchronous time
series, provide a richer variation of feature types than current RNN cells take
into account. In order to address such situations, we introduce a unified RNN
that handles five different feature types, each in a different manner. Our RNN
framework separates sequential features into two groups dependent on their
frequency, which we call sparse and dense features, and which affect cell
updates differently. Further, we also incorporate time features at the
sequential level that relate to the time between specified events in the
sequence and are used to modify the cell's memory state. We also include two
types of static (whole sequence level) features, one related to time and one
not, which are combined with the encoder output. The experiments show that the
modeling framework proposed does increase performance compared to standard
cells.",http://arxiv.org/pdf/1809.08717v1,stat.ML
2018-09-17 09:27:04+00:00,Testing relevant hypotheses in functional time series via self-normalization,"['Holger Dette', 'Kevin Kokot', 'Stanislav Volgushev']","In this paper we develop methodology for testing relevant hypotheses about
functional time series in a tuning-free way. Instead of testing for exact
equality, for example for the equality of two mean functions from two
independent time series, we propose to test the null hypothesis of no relevant
deviation. In the two sample problem this means that an $L^2$-distance between
the two mean functions is smaller than a pre-specified threshold. For such
hypotheses self-normalization, which was introduced by Shao (2010) and Shao and
Zhang (2010) and is commonly used to avoid the estimation of nuisance
parameters, is not directly applicable. We develop new self-normalized
procedures for testing relevant hypotheses in the one sample, two sample and
change point problem and investigate their asymptotic properties. Finite sample
properties of the proposed tests are illustrated by means of a simulation study
and data examples. Our main focus is on functional time series, but extensions
to other settings are also briefly discussed.",http://arxiv.org/pdf/1809.06092v3,stat.ME
2018-09-14 05:19:51+00:00,Random Warping Series: A Random Features Method for Time-Series Embedding,"['Lingfei Wu', 'Ian En-Hsu Yen', 'Jinfeng Yi', 'Fangli Xu', 'Qi Lei', 'Michael Witbrock']","Time series data analytics has been a problem of substantial interests for
decades, and Dynamic Time Warping (DTW) has been the most widely adopted
technique to measure dissimilarity between time series. A number of
global-alignment kernels have since been proposed in the spirit of DTW to
extend its use to kernel-based estimation method such as support vector
machine. However, those kernels suffer from diagonal dominance of the Gram
matrix and a quadratic complexity w.r.t. the sample size. In this work, we
study a family of alignment-aware positive definite (p.d.) kernels, with its
feature embedding given by a distribution of \emph{Random Warping Series
(RWS)}. The proposed kernel does not suffer from the issue of diagonal
dominance while naturally enjoys a \emph{Random Features} (RF) approximation,
which reduces the computational complexity of existing DTW-based techniques
from quadratic to linear in terms of both the number and the length of
time-series. We also study the convergence of the RF approximation for the
domain of time series of unbounded length. Our extensive experiments on 16
benchmark datasets demonstrate that RWS outperforms or matches state-of-the-art
classification and clustering methods in both accuracy and computational time.
Our code and data is available at {
\url{https://github.com/IBM/RandomWarpingSeries}}.",http://arxiv.org/pdf/1809.05259v1,cs.LG
2018-09-13 21:35:04+00:00,Explainable time series tweaking via irreversible and reversible temporal transformations,"['Isak Karlsson', 'Jonathan Rebane', 'Panagiotis Papapetrou', 'Aristides Gionis']","Time series classification has received great attention over the past decade
with a wide range of methods focusing on predictive performance by exploiting
various types of temporal features. Nonetheless, little emphasis has been
placed on interpretability and explainability. In this paper, we formulate the
novel problem of explainable time series tweaking, where, given a time series
and an opaque classifier that provides a particular classification decision for
the time series, we want to find the minimum number of changes to be performed
to the given time series so that the classifier changes its decision to another
class. We show that the problem is NP-hard, and focus on two instantiations of
the problem, which we refer to as reversible and irreversible time series
tweaking. The classifier under investigation is the random shapelet forest
classifier. Moreover, we propose two algorithmic solutions for the two problems
along with simple optimizations, as well as a baseline solution using the
nearest neighbor classifier. An extensive experimental evaluation on a variety
of real datasets demonstrates the usefulness and effectiveness of our problem
formulation and solutions.",http://arxiv.org/pdf/1809.05183v1,cs.LG
2018-09-12 10:55:33+00:00,Deep learning for time series classification: a review,"['Hassan Ismail Fawaz', 'Germain Forestier', 'Jonathan Weber', 'Lhassane Idoumghar', 'Pierre-Alain Muller']","Time Series Classification (TSC) is an important and challenging problem in
data mining. With the increase of time series data availability, hundreds of
TSC algorithms have been proposed. Among these methods, only a few have
considered Deep Neural Networks (DNNs) to perform this task. This is surprising
as deep learning has seen very successful applications in the last years. DNNs
have indeed revolutionized the field of computer vision especially with the
advent of novel deeper architectures such as Residual and Convolutional Neural
Networks. Apart from images, sequential data such as text and audio can also be
processed with DNNs to reach state-of-the-art performance for document
classification and speech recognition. In this article, we study the current
state-of-the-art performance of deep learning algorithms for TSC by presenting
an empirical study of the most recent DNN architectures for TSC. We give an
overview of the most successful deep learning applications in various time
series domains under a unified taxonomy of DNNs for TSC. We also provide an
open source deep learning framework to the TSC community where we implemented
each of the compared approaches and evaluated them on a univariate TSC
benchmark (the UCR/UEA archive) and 12 multivariate time series datasets. By
training 8,730 deep learning models on 97 time series datasets, we propose the
most exhaustive study of DNNs for TSC to date.",http://arxiv.org/pdf/1809.04356v4,cs.LG
2018-09-12 00:40:40+00:00,Temporal Pattern Attention for Multivariate Time Series Forecasting,"['Shun-Yao Shih', 'Fan-Keng Sun', 'Hung-yi Lee']","Forecasting multivariate time series data, such as prediction of electricity
consumption, solar power production, and polyphonic piano pieces, has numerous
valuable applications. However, complex and non-linear interdependencies
between time steps and series complicate the task. To obtain accurate
prediction, it is crucial to model long-term dependency in time series data,
which can be achieved to some good extent by recurrent neural network (RNN)
with attention mechanism. Typical attention mechanism reviews the information
at each previous time step and selects the relevant information to help
generate the outputs, but it fails to capture the temporal patterns across
multiple time steps. In this paper, we propose to use a set of filters to
extract time-invariant temporal patterns, which is similar to transforming time
series data into its ""frequency domain"". Then we proposed a novel attention
mechanism to select relevant time series, and use its ""frequency domain""
information for forecasting. We applied the proposed model on several
real-world tasks and achieved state-of-the-art performance in all of them with
only one exception.",http://arxiv.org/pdf/1809.04206v3,cs.LG
2018-09-11 00:49:30+00:00,Threshold factor models for high-dimensional time series,"['Xialu Liu', 'Rong Chen']","We consider a threshold factor model for high-dimensional time series in
which the dynamics of the time series is assumed to switch between different
regimes according to the value of a threshold variable. This is an extension of
threshold modeling to a high-dimensional time series setting under a factor
structure. Specifically, within each threshold regime, the time series is
assumed to follow a factor model. The regime switching mechanism creates
structural change in the factor loading matrices. It provides flexibility in
dealing with situations that the underlying states may be changing over time,
as often observed in economic time series and other applications. We develop
the procedures for the estimation of the loading spaces, the number of factors
and the threshold value, as well as the identification of the threshold
variable, which governs the regime change mechanism. The theoretical properties
are investigated. Simulated and real data examples are presented to illustrate
the performance of the proposed method.",http://arxiv.org/pdf/1809.03643v2,stat.ME
2018-09-06 17:29:10+00:00,A Memory-Network Based Solution for Multivariate Time-Series Forecasting,"['Yen-Yu Chang', 'Fan-Yun Sun', 'Yueh-Hua Wu', 'Shou-De Lin']","Multivariate time series forecasting is extensively studied throughout the
years with ubiquitous applications in areas such as finance, traffic,
environment, etc. Still, concerns have been raised on traditional methods for
incapable of modeling complex patterns or dependencies lying in real word data.
To address such concerns, various deep learning models, mainly Recurrent Neural
Network (RNN) based methods, are proposed. Nevertheless, capturing extremely
long-term patterns while effectively incorporating information from other
variables remains a challenge for time-series forecasting. Furthermore,
lack-of-explainability remains one serious drawback for deep neural network
models. Inspired by Memory Network proposed for solving the question-answering
task, we propose a deep learning based model named Memory Time-series network
(MTNet) for time series forecasting. MTNet consists of a large memory
component, three separate encoders, and an autoregressive component to train
jointly. Additionally, the attention mechanism designed enable MTNet to be
highly interpretable. We can easily tell which part of the historic data is
referenced the most.",http://arxiv.org/pdf/1809.02105v1,cs.LG
2018-09-06 04:50:08+00:00,MASA: Motif-Aware State Assignment in Noisy Time Series Data,"['Saachi Jain', 'David Hallac', 'Rok Sosic', 'Jure Leskovec']","Complex systems, such as airplanes, cars, or financial markets, produce
multivariate time series data consisting of a large number of system
measurements over a period of time. Such data can be interpreted as a sequence
of states, where each state represents a prototype of system behavior. An
important problem in this domain is to identify repeated sequences of states,
known as motifs. Such motifs correspond to complex behaviors that capture
common sequences of state transitions. For example, in automotive data, a motif
of ""making a turn"" might manifest as a sequence of states: slowing down,
turning the wheel, and then speeding back up. However, discovering these motifs
is challenging, because the individual states and state assignments are
unknown, have different durations, and need to be jointly learned from the
noisy time series. Here we develop motif-aware state assignment (MASA), a
method to discover common motifs in noisy time series data and leverage those
motifs to more robustly assign states to measurements. We formulate the problem
of motif discovery as a large optimization problem, which we solve using an
expectation-maximization type approach. MASA performs well in the presence of
noise in the input data and is scalable to very large datasets. Experiments on
synthetic data show that MASA outperforms state-of-the-art baselines by up to
38.2%, and two case studies demonstrate how our approach discovers insightful
motifs in the presence of noise in real-world time series data.",http://arxiv.org/pdf/1809.01819v2,cs.LG
2018-09-03 22:02:11+00:00,Robust Estimation of Data-Dependent Causal Effects based on Observing a Single Time-Series,"['Mark J. van der Laan', 'Ivana Malenica']","Consider the case that one observes a single time-series, where at each time
t one observes a data record O(t) involving treatment nodes A(t), possible
covariates L(t) and an outcome node Y(t). The data record at time t carries
information for an (potentially causal) effect of the treatment A(t) on the
outcome Y(t), in the context defined by a fixed dimensional summary measure
Co(t). We are concerned with defining causal effects that can be consistently
estimated, with valid inference, for sequentially randomized experiments
without further assumptions. More generally, we consider the case when the
(possibly causal) effects can be estimated in a double robust manner, analogue
to double robust estimation of effects in the i.i.d. causal inference
literature. We propose a general class of averages of conditional
(context-specific) causal parameters that can be estimated in a double robust
manner, therefore fully utilizing the sequential randomization. We propose a
targeted maximum likelihood estimator (TMLE) of these causal parameters, and
present a general theorem establishing the asymptotic consistency and normality
of the TMLE. We extend our general framework to a number of typically studied
causal target parameters, including a sequentially adaptive design within a
single unit that learns the optimal treatment rule for the unit over time. Our
work opens up robust statistical inference for causal questions based on
observing a single time-series on a particular unit.",http://arxiv.org/pdf/1809.00734v1,math.ST
2018-08-31 04:17:44+00:00,Proximity Forest: An effective and scalable distance-based classifier for time series,"['Benjamin Lucas', 'Ahmed Shifaz', 'Charlotte Pelletier', ""Lachlan O'Neill"", 'Nayyar Zaidi', 'Bart Goethals', 'Francois Petitjean', 'Geoffrey I. Webb']","Research into the classification of time series has made enormous progress in
the last decade. The UCR time series archive has played a significant role in
challenging and guiding the development of new learners for time series
classification. The largest dataset in the UCR archive holds 10 thousand time
series only; which may explain why the primary research focus has been in
creating algorithms that have high accuracy on relatively small datasets.
  This paper introduces Proximity Forest, an algorithm that learns accurate
models from datasets with millions of time series, and classifies a time series
in milliseconds. The models are ensembles of highly randomized Proximity Trees.
Whereas conventional decision trees branch on attribute values (and usually
perform poorly on time series), Proximity Trees branch on the proximity of time
series to one exemplar time series or another; allowing us to leverage the
decades of work into developing relevant measures for time series. Proximity
Forest gains both efficiency and accuracy by stochastic selection of both
exemplars and similarity measures.
  Our work is motivated by recent time series applications that provide orders
of magnitude more time series than the UCR benchmarks. Our experiments
demonstrate that Proximity Forest is highly competitive on the UCR archive: it
ranks among the most accurate classifiers while being significantly faster. We
demonstrate on a 1M time series Earth observation dataset that Proximity Forest
retains this accuracy on datasets that are many orders of magnitude greater
than those in the UCR repository, while learning its models at least 100,000
times faster than current state of the art models Elastic Ensemble and COTE.",http://arxiv.org/pdf/1808.10594v2,cs.LG
2018-08-29 13:25:11+00:00,Correlated Time Series Forecasting using Deep Neural Networks: A Summary of Results,"['Razvan-Gabriel Cirstea', 'Darius-Valer Micu', 'Gabriel-Marcel Muresan', 'Chenjuan Guo', 'Bin Yang']","Cyber-physical systems often consist of entities that interact with each
other over time. Meanwhile, as part of the continued digitization of industrial
processes, various sensor technologies are deployed that enable us to record
time-varying attributes (a.k.a., time series) of such entities, thus producing
correlated time series. To enable accurate forecasting on such correlated time
series, this paper proposes two models that combine convolutional neural
networks (CNNs) and recurrent neural networks (RNNs). The first model employs a
CNN on each individual time series, combines the convoluted features, and then
applies an RNN on top of the convoluted features in the end to enable
forecasting. The second model adds additional auto-encoders into the individual
CNNs, making the second model a multi-task learning model, which provides
accurate and robust forecasting. Experiments on two real-world correlated time
series data set suggest that the proposed two models are effective and
outperform baselines in most settings.
  This report extends the paper ""Correlated Time Series Forecasting using
Multi-Task Deep Neural Networks,"" to appear in ACM CIKM 2018, by providing
additional experimental results.",http://arxiv.org/pdf/1808.09794v2,cs.LG
2018-08-29 03:22:47+00:00,Elastic bands across the path: A new framework and methods to lower bound DTW,"['Chang Wei Tan', 'Francois Petitjean', 'Geoffrey I. Webb']","There has been renewed recent interest in developing effective lower bounds
for Dynamic Time Warping (DTW) distance between time series. These have many
applications in time series indexing, clustering, forecasting, regression and
classification. One of the key time series classification algorithms, the
nearest neighbor algorithm with DTW distance (NN-DTW) is very expensive to
compute, due to the quadratic complexity of DTW. Lower bound search can speed
up NN-DTW substantially. An effective and tight lower bound quickly prunes off
unpromising nearest neighbor candidates from the search space and minimises the
number of the costly DTW computations. The speed up provided by lower bound
search becomes increasingly critical as training set size increases. Different
lower bounds provide different trade-offs between computation time and
tightness. Most existing lower bounds interact with DTW warping window sizes.
They are very tight and effective at smaller warping window sizes, but become
looser as the warping window increases, thus reducing the pruning effectiveness
for NN-DTW. In this work, we present a new class of lower bounds that are
tighter than the popular Keogh lower bound, while requiring similar computation
time. Our new lower bounds take advantage of the DTW boundary condition,
monotonicity and continuity constraints to create a tighter lower bound. Of
particular significance, they remain relatively tight even for large windows. A
single parameter to these new lower bounds controls the speed-tightness
trade-off. We demonstrate that these new lower bounds provide an exceptional
balance between computation time and tightness for the NN-DTW time series
classification task, resulting in greatly improved efficiency for NN-DTW lower
bound search.",http://arxiv.org/pdf/1808.09617v3,cs.LG
2018-08-27 12:15:14+00:00,Exponential inequalities for nonstationary Markov Chains,"['Pierre Alquier', 'Paul Doukhan', 'Xiequan Fan']","Exponential inequalities are main tools in machine learning theory. To prove
exponential inequalities for non i.i.d random variables allows to extend many
learning techniques to these variables. Indeed, much work has been done both on
inequalities and learning theory for time series, in the past 15 years.
However, for the non independent case, almost all the results concern
stationary time series. This excludes many important applications: for example
any series with a periodic behavior is non-stationary. In this paper, we extend
the basic tools of Dedecker and Fan (2015) to nonstationary Markov chains. As
an application, we provide a Bernstein-type inequality, and we deduce risk
bounds for the prediction of periodic autoregressive processes with an unknown
period.",http://arxiv.org/pdf/1808.08811v3,stat.ML
2018-08-23 20:24:36+00:00,Modeling High-Dimensional Time Series: A Factor Model with Dynamically Dependent Factors and Diverging Eigenvalues,"['Zhaoxing Gao', 'Ruey S. Tsay']","This article proposes a new approach to modeling high-dimensional time series
by treating a $p$-dimensional time series as a nonsingular linear
transformation of certain common factors and idiosyncratic components. Unlike
the approximate factor models, we assume that the factors capture all the
non-trivial dynamics of the data, but the cross-sectional dependence may be
explained by both the factors and the idiosyncratic components. Under the
proposed model, (a) the factor process is dynamically dependent and the
idiosyncratic component is a white noise process, and (b) the largest
eigenvalues of the covariance matrix of the idiosyncratic components may
diverge to infinity as the dimension $p$ increases. We propose a white noise
testing procedure for high-dimensional time series to determine the number of
white noise components and, hence, the number of common factors, and introduce
a projected Principal Component Analysis (PCA) to eliminate the diverging
effect of the idiosyncratic noises. Asymptotic properties of the proposed
method are established for both fixed $p$ and diverging $p$ as the sample size
$n$ increases to infinity. We use both simulated data and real examples to
assess the performance of the proposed method. We also compare our method with
two commonly used methods in the literature concerning the forecastability of
the extracted factors and find that the proposed approach not only provides
interpretable results, but also performs well in out-of-sample forecasting.
Supplementary materials of the article are available online.",http://arxiv.org/pdf/1808.07932v3,stat.ME
2018-08-21 00:13:12+00:00,Learning to Exploit Invariances in Clinical Time-Series Data using Sequence Transformer Networks,"['Jeeheh Oh', 'Jiaxuan Wang', 'Jenna Wiens']","Recently, researchers have started applying convolutional neural networks
(CNNs) with one-dimensional convolutions to clinical tasks involving
time-series data. This is due, in part, to their computational efficiency,
relative to recurrent neural networks and their ability to efficiently exploit
certain temporal invariances, (e.g., phase invariance). However, it is
well-established that clinical data may exhibit many other types of invariances
(e.g., scaling). While preprocessing techniques, (e.g., dynamic time warping)
may successfully transform and align inputs, their use often requires one to
identify the types of invariances in advance. In contrast, we propose the use
of Sequence Transformer Networks, an end-to-end trainable architecture that
learns to identify and account for invariances in clinical time-series data.
Applied to the task of predicting in-hospital mortality, our proposed approach
achieves an improvement in the area under the receiver operating characteristic
curve (AUROC) relative to a baseline CNN (AUROC=0.851 vs. AUROC=0.838). Our
results suggest that a variety of valuable invariances can be learned directly
from the data.",http://arxiv.org/pdf/1808.06725v1,cs.LG
2018-08-20 15:39:00+00:00,A Structural-Factor Approach to Modeling High-Dimensional Time Series and Space-Time Data,"['Zhaoxing Gao', 'Ruey S Tsay']","This paper considers a structural-factor approach to modeling
high-dimensional time series and space-time data by decomposing individual
series into trend, seasonal, and irregular components. For ease in analyzing
many time series, we employ a time polynomial for the trend, a linear
combination of trigonometric series for the seasonal component, and a new
factor model for the irregular components. The new factor model can simplify
the modeling process and achieve parsimony in parameterization. We propose a
Bayesian Information Criterion (BIC) to consistently determine the order of the
polynomial trend and the number of trigonometric functions. A test statistic is
used to determine the number of common factors. The convergence rates for the
estimators of the trend and seasonal components and the limiting distribution
of the test statistic are established under the setting that the number of time
series tends to infinity with the sample size, but at a slower rate. We use
simulation to study the performance of the proposed analysis in finite samples
and apply the proposed approach to two real examples. The first example
considers modeling weekly PM$_{2.5}$ data of 15 monitoring stations in the
southern region of Taiwan and the second example consists of monthly
value-weighted returns of 12 industrial portfolios.",http://arxiv.org/pdf/1808.06518v2,stat.ME
2018-08-16 15:19:34+00:00,Combining time-series and textual data for taxi demand prediction in event areas: a deep learning approach,"['Filipe Rodrigues', 'Ioulia Markou', 'Francisco Pereira']","Accurate time-series forecasting is vital for numerous areas of application
such as transportation, energy, finance, economics, etc. However, while modern
techniques are able to explore large sets of temporal data to build forecasting
models, they typically neglect valuable information that is often available
under the form of unstructured text. Although this data is in a radically
different format, it often contains contextual explanations for many of the
patterns that are observed in the temporal data. In this paper, we propose two
deep learning architectures that leverage word embeddings, convolutional layers
and attention mechanisms for combining text information with time-series data.
We apply these approaches for the problem of taxi demand forecasting in event
areas. Using publicly available taxi data from New York, we empirically show
that by fusing these two complementary cross-modal sources of information, the
proposed models are able to significantly reduce the error in the forecasts.",http://arxiv.org/pdf/1808.05535v1,stat.ML
2018-08-12 23:47:10+00:00,Interpretable Time Series Classification using All-Subsequence Learning and Symbolic Representations in Time and Frequency Domains,"['Thach Le Nguyen', 'Severin Gsponer', 'Iulia Ilie', 'Georgiana Ifrim']","The time series classification literature has expanded rapidly over the last
decade, with many new classification approaches published each year. The
research focus has mostly been on improving the accuracy and efficiency of
classifiers, while their interpretability has been somewhat neglected.
Classifier interpretability has become a critical constraint for many
application domains and the introduction of the 'right to explanation' GDPR EU
legislation in May 2018 is likely to further emphasize the importance of
explainable learning algorithms. In this work we analyse the state-of-the-art
for time series classification, and propose new algorithms that aim to maintain
the classifier accuracy and efficiency, but keep interpretability as a key
design constraint. We present new time series classification algorithms that
advance the state-of-the-art by implementing the following three key ideas: (1)
Multiple resolutions of symbolic approximations: we combine symbolic
representations obtained using different parameters; (2) Multiple domain
representations: we combine symbolic approximations in time (e.g., SAX) and
frequency (e.g., SFA) domains; (3) Efficient navigation of a huge
symbolic-words space: we adapt a symbolic sequence classifier named SEQL, to
make it work with multiple domain representations (e.g., SAX-SEQL, SFA-SEQL),
and use its greedy feature selection strategy to effectively filter the best
features for each representation. We show that a multi-resolution multi-domain
linear classifier, SAX-SFA-SEQL, achieves a similar accuracy to the
state-of-the-art COTE ensemble, and to a recent deep learning method (FCN), but
uses a fraction of the time required by either COTE or FCN. We discuss the
accuracy, efficiency and interpretability of our proposed algorithms. To
further analyse the interpretability aspect of our classifiers, we present a
case study on an ecology benchmark.",http://arxiv.org/pdf/1808.04022v1,cs.LG
2018-08-11 22:28:11+00:00,A Consistent Method for Learning OOMs from Asymptotically Stationary Time Series Data Containing Missing Values,['Tianlin Liu'],"In the traditional framework of spectral learning of stochastic time series
models, model parameters are estimated based on trajectories of fully recorded
observations. However, real-world time series data often contain missing
values, and worse, the distributions of missingness events over time are often
not independent of the visible process. Recently, a spectral OOM learning
algorithm for time series with missing data was introduced and proved to be
consistent, albeit under quite strong conditions. Here we refine the algorithm
and prove that the original strong conditions can be very much relaxed. We
validate our theoretical findings by numerical experiments, showing that the
algorithm can consistently handle missingness patterns whose dynamic interacts
with the visible process.",http://arxiv.org/pdf/1808.03873v2,cs.LG
2018-08-06 13:48:03+00:00,Nuisance Parameters Free Changepoint Detection in Non-stationary Series,"['Michal Pešta', 'Martin Wendler']","Detecting abrupt changes in the mean of a time series, so-called
changepoints, is important for many applications. However, many procedures rely
on the estimation of nuisance parameters (like long-run variance). Under the
alternative (a change in mean), estimators might be biased and data-adaptive
rules for the choice of tuning parameters might not work as expected. If the
data is not stationary, but heteroscedastic, this becomes more challenging. The
aim of this paper is to present and investigate two changepoint tests, which
involve neither nuisance nor tuning parameters. This is achieved by combing
self-normalization and wild bootstrap. We study the asymptotic behavior and
show the consistency of the bootstrap under the hypothesis as well as under the
alternative, assuming mild conditions on the weak dependence of the time series
and allowing the variance to change over time. As a by-product of the proposed
tests, a changepoint estimator is introduced and its consistency is proved. The
results are illustrated through a simulation study, which demonstrates
computational efficiency of the developed methods. The new tests will also be
applied to real data examples from finance and hydrology.",http://arxiv.org/pdf/1808.01905v2,math.ST
2018-07-20 11:35:35+00:00,The Sliding Window Discrete Fourier Transform,"['Lee F. Richardson', 'William F. Eddy']","This paper introduces a new tool for time-series analysis: the Sliding Window
Discrete Fourier Transform (SWDFT). The SWDFT is especially useful for
time-series with local- in-time periodic components. We define a 5-parameter
model for noiseless local periodic signals, then study the SWDFT of this model.
Our study illustrates several key concepts crucial to analyzing time-series
with the SWDFT, in particular Aliasing, Leakage, and Ringing. We also show how
these ideas extend to R > 1 local periodic components, using the linearity
property of the Fourier transform. Next, we propose a simple procedure for
estimating the 5 parameters of our local periodic signal model using the SWDFT.
Our estimation procedure speeds up computation by using a trigonometric
identity that linearizes estimation of 2 of the 5 parameters. We conclude with
a very small Monte Carlo simulation study of our estimation procedure under
different levels of noise.",http://arxiv.org/pdf/1807.07797v1,stat.ME
2018-07-19 20:13:03+00:00,Rapid Time Series Prediction with a Hardware-Based Reservoir Computer,"['Daniel Canaday', 'Aaron Griffith', 'Daniel Gauthier']","Reservoir computing is a neural network approach for processing
time-dependent signals that has seen rapid development in recent years.
Physical implementations of the technique using optical reservoirs have
demonstrated remarkable accuracy and processing speed at benchmark tasks.
However, these approaches require an electronic output layer to maintain high
performance, which limits their use in tasks such as time-series prediction,
where the output is fed back into the reservoir. We present here a reservoir
computing scheme that has rapid processing speed both by the reservoir and the
output layer. The reservoir is realized by an autonomous, time-delay, Boolean
network configured on a field-programmable gate array. We investigate the
dynamical properties of the network and observe the fading memory property that
is critical for successful reservoir computing. We demonstrate the utility of
the technique by training a reservoir to learn the short- and long-term
behavior of a chaotic system. We find accuracy comparable to state-of-the-art
software approaches of similar network size, but with a superior real-time
prediction rate up to 160 MHz.",http://arxiv.org/pdf/1807.07627v2,cs.LG
2018-07-16 03:27:18+00:00,Scene Learning: Deep Convolutional Networks For Wind Power Prediction by Embedding Turbines into Grid Space,"['Ruiguo Yu', 'Zhiqiang Liu', 'Xuewei Li', 'Wenhuan Lu', 'Mei Yu', 'Jianrong Wang', 'Bin Li']","Wind power prediction is of vital importance in wind power utilization. There
have been a lot of researches based on the time series of the wind power or
speed, but In fact, these time series cannot express the temporal and spatial
changes of wind, which fundamentally hinders the advance of wind power
prediction. In this paper, a new kind of feature that can describe the process
of temporal and spatial variation is proposed, namely, Spatio-Temporal
Features. We first map the data collected at each moment from the wind turbine
to the plane to form the state map, namely, the scene, according to the
relative positions. The scene time series over a period of time is a
multi-channel image, i.e. the Spatio-Temporal Features. Based on the
Spatio-Temporal Features, the deep convolutional network is applied to predict
the wind power, achieving a far better accuracy than the existing methods.
Compared with the starge-of-the-art method, the mean-square error (MSE) in our
method is reduced by 49.83%, and the average time cost for training models can
be shortened by a factor of more than 150.",http://arxiv.org/pdf/1807.05666v2,cs.LG
2018-07-11 13:31:35+00:00,Exploiting statistical dependencies of time series with hierarchical correlation reconstruction,['Jarek Duda'],"While we are usually focused on forecasting future values of time series, it
is often valuable to additionally predict their entire probability
distributions, e.g. to evaluate risk, Monte Carlo simulations. On example of
time series of $\approx$ 30000 Dow Jones Industrial Averages, there will be
presented application of hierarchical correlation reconstruction for this
purpose: MSE estimating polynomial as joint density for (current value,
context), where context is for example a few previous values. Then substituting
the currently observed context and normalizing density to 1, we get predicted
probability distribution for the current value. In contrast to standard machine
learning approaches like neural networks, optimal polynomial coefficients here
have inexpensive direct formula, have controllable accuracy, are unique and
independently calculated, each has a specific cumulant-like interpretation, and
such approximation can asymptotically approach complete description of any real
joint distribution - providing universal tool to quantitatively describe and
exploit statistical dependencies in time series, systematically enhancing
ARMA/ARCH-like approaches, also based on different distributions than Gaussian
which turns out improper for daily log returns. There is also discussed
application for non-stationary time series like calculating linear time trend,
or adapting coefficients to local statistical behavior.",http://arxiv.org/pdf/1807.04119v5,cs.LG
2018-07-10 15:26:33+00:00,Recurrent Auto-Encoder Model for Large-Scale Industrial Sensor Signal Analysis,"['Timothy Wong', 'Zhiyuan Luo']","Recurrent auto-encoder model summarises sequential data through an encoder
structure into a fixed-length vector and then reconstructs the original
sequence through the decoder structure. The summarised vector can be used to
represent time series features. In this paper, we propose relaxing the
dimensionality of the decoder output so that it performs partial
reconstruction. The fixed-length vector therefore represents features in the
selected dimensions only. In addition, we propose using rolling fixed window
approach to generate training samples from unbounded time series data. The
change of time series features over time can be summarised as a smooth
trajectory path. The fixed-length vectors are further analysed using additional
visualisation and unsupervised clustering techniques. The proposed method can
be applied in large-scale industrial processes for sensors signal analysis
purpose, where clusters of the vector representations can reflect the operating
states of the industrial system.",http://arxiv.org/pdf/1807.03710v1,cs.LG
2018-07-03 12:57:56+00:00,Time Series Modeling on Dynamic Networks,['Jonas Krampe'],"This paper focuses on modeling the dynamic attributes of a dynamic network
with a fixed number of vertices. These attributes are considered as time series
which dependency structure is influenced by the underlying network. They are
modeled by a multivariate doubly stochastic time series framework, that is we
assume linear processes for which the coefficient matrices are stochastic
processes themselves. We explicitly allow for dependence in the dynamics of the
coefficient matrices as well as between these two stochastic processes. This
framework allows for a separate modeling of the attributes and the underlying
network. In this setting, we define network autoregressive models and discuss
their stationarity conditions. Furthermore, an estimation approach is discussed
in a low- and high-dimensional setting and how this can be applied to
forecasting. The finite sample behavior of the forecast approach is
investigated. This approach is applied to real data whereby the goal is to
forecast the GDP of 33 economies.",http://arxiv.org/pdf/1807.01133v2,stat.ME
2018-06-28 16:57:55+00:00,Bootstrap Based Inference for Sparse High-Dimensional Time Series Models,"['J. Krampe', 'J-P. Kreiss', 'E. Paparoditis']","Fitting sparse models to high-dimensional time series is an important area of
statistical inference. In this paper we consider sparse vector autoregressive
models and develop appropriate bootstrap methods to infer properties of such
processes. Our bootstrap methodology generates pseudo time series using a
model-based bootstrap procedure which involves an estimated, sparsified version
of the underlying vector autoregressive model. Inference is performed using
so-called de-sparsified or de-biased estimators of the autoregressive model
parameters. We derive the asymptotic distribution of such estimators in the
time series context and establish asymptotic validity of the bootstrap
procedure proposed for estimation and, appropriately modified, for testing
purposes. In particular we focus on testing that large groups of autoregressive
coefficients equal zero. Our theoretical results are complemented by
simulations which investigate the finite sample performance of the bootstrap
methodology proposed. A real-life data application is also presented.",http://arxiv.org/pdf/1806.11083v3,stat.ME
2018-06-28 15:22:43+00:00,A depth-based method for functional time series forecasting,"['Antonio Elías', 'Raúl Jiménez']","An approach is presented for making predictions about functional time series.
The method is applied to data coming from periodically correlated processes and
electricity demand, obtaining accurate point forecasts and narrow prediction
bands that cover high proportions of the forecasted functional datum, for a
given confidence level. The method is computationally efficient and
substantially different to other functional time series methods, offering a new
insight for the analysis of these data structures.",http://arxiv.org/pdf/1806.11032v1,stat.ME
2018-06-26 12:47:17+00:00,The ARMA Point Process and its Estimation,"['Spencer Wheatley', 'Michael Schatz', 'Didier Sornette']","We introduce the ARMA (autoregressive-moving-average) point process, which is
a Hawkes process driven by a Neyman-Scott process with Poisson immigration. It
contains both the Hawkes and Neyman-Scott process as special cases and
naturally combines self-exciting and shot-noise cluster mechanisms, useful in a
variety of applications. The name ARMA is used because the ARMA point process
is an appropriate analogue of the ARMA time series model for integer-valued
series. As such, the ARMA point process framework accommodates a flexible
family of models sharing methodological and mathematical similarities with ARMA
time series. We derive an estimation procedure for ARMA point processes, as
well as the integer ARMA models, based on an MCEM (Monte Carlo Expectation
Maximization) algorithm. This powerful framework for estimation accommodates
trends in immigration, multiple parametric specifications of excitement
functions, as well as cases where marks and immigrants are not observed.",http://arxiv.org/pdf/1806.09948v1,math.ST
2018-06-25 07:31:55+00:00,Data-driven pattern identification and outlier detection in time series,"['Abdolrahman Khoshrou', 'Eric J. Pauwels']","We address the problem of data-driven pattern identification and outlier
detection in time series. To this end, we use singular value decomposition
(SVD) which is a well-known technique to compute a low-rank approximation for
an arbitrary matrix. By recasting the time series as a matrix it becomes
possible to use SVD to highlight the underlying patterns and periodicities.
This is done without the need for specifying user-defined parameters. From a
data mining perspective, this opens up new ways of analyzing time series in a
data-driven, bottom-up fashion. However, in order to get correct results, it is
important to understand how the SVD-spectrum of a time series is influenced by
various characteristics of the underlying signal and noise. In this paper, we
have extended the work in earlier papers by initiating a more systematic
analysis of these effects. We then illustrate our findings on some real-life
data.",http://arxiv.org/pdf/1807.03386v1,stat.ME
2018-06-23 21:54:10+00:00,A breakpoint detection in the mean model with heterogeneous variance on fixed time-intervals,"['Olivier Bock', 'Xavier Collilieux', 'François Guillamon', 'Emilie Lebarbier', 'Claire Pascal']","This work is motivated by an application for the homogeneization of
GNSS-derived IWV (Integrated Water Vapour) series. Indeed, these GPS series are
affected by abrupt changes due to equipment changes or environemental effects.
The detection and correction of the series from these changes is a crucial step
before any use for climate studies. In addition to these abrupt changes, it has
been observed in the series a non-stationary of the variability. We propose in
this paper a new segmentation model that is a breakpoint detection in the mean
model of a Gaussian process with heterogeneous variance on known
time-intervals. In this segmentation case, the dynamic programming (DP)
algorithm used classically to infer the breakpoints can not be applied anymore.
We propose a procedure in two steps: we first estimate robustly the variances
and then apply the classical inference by plugging these estimators. The
performance of our proposed procedure is assessed through simulation
experiments. An application to real GNSS data is presented.",http://arxiv.org/pdf/1806.09043v1,stat.ME
2018-06-23 11:12:12+00:00,Multilevel Wavelet Decomposition Network for Interpretable Time Series Analysis,"['Jingyuan Wang', 'Ze Wang', 'Jianfeng Li', 'Junjie Wu']","Recent years have witnessed the unprecedented rising of time series from
almost all kindes of academic and industrial fields. Various types of deep
neural network models have been introduced to time series analysis, but the
important frequency information is yet lack of effective modeling. In light of
this, in this paper we propose a wavelet-based neural network structure called
multilevel Wavelet Decomposition Network (mWDN) for building frequency-aware
deep learning models for time series analysis. mWDN preserves the advantage of
multilevel discrete wavelet decomposition in frequency learning while enables
the fine-tuning of all parameters under a deep neural network framework. Based
on mWDN, we further propose two deep learning models called Residual
Classification Flow (RCF) and multi-frequecy Long Short-Term Memory (mLSTM) for
time series classification and forecasting, respectively. The two models take
all or partial mWDN decomposed sub-series in different frequencies as input,
and resort to the back propagation algorithm to learn all the parameters
globally, which enables seamless embedding of wavelet-based frequency analysis
into deep learning frameworks. Extensive experiments on 40 UCR datasets and a
real-world user volume dataset demonstrate the excellent performance of our
time series models based on mWDN. In particular, we propose an importance
analysis method to mWDN based models, which successfully identifies those
time-series elements and mWDN layers that are crucially important to time
series analysis. This indeed indicates the interpretability advantage of mWDN,
and can be viewed as an indepth exploration to interpretable deep learning.",http://arxiv.org/pdf/1806.08946v1,cs.LG
2018-06-18 07:24:59+00:00,A Frequency Domain Bootstrap for General Stationary Processes,"['Marco Meyer', 'Efstathios Paparoditis', 'Jens-Peter Kreiss']","Existing frequency domain methods for bootstrapping time series have a
limited range. Consider for instance the class of spectral mean statistics
(also called integrated periodograms) which includes many important statistics
in time series analysis, such as sample autocovariances and autocorrelations
among other things. Essentially, such frequency domain bootstrap procedures
cover the case of linear time series with independent innovations, and some
even require the time series to be Gaussian. In this paper we propose a new,
frequency domain bootstrap method which is consistent for a much wider range of
stationary processes and can be applied to a large class of periodogram-based
statistics. It introduces a new concept of convolved periodograms of smaller
samples which uses pseudo periodograms of subsamples generated in a way that
correctly imitates the weak dependence structure of the periodogram. %The new
bootstrap procedure %corrects for those aspects of the distribution of spectral
means that cannot be mimicked by existing procedures. We show consistency for
this procedure for a general class of stationary time series, ranging clearly
beyond linear processes, and for general spectral means and ratio statistics.
Furthermore, and for the class of spectral means, we also show, how, using this
new approach, existing bootstrap methods, which replicate appropriately only
the dominant part of the distribution of interest, can be corrected. The finite
sample performance of the new bootstrap procedure is illustrated via
simulations.",http://arxiv.org/pdf/1806.06523v1,stat.ME
2018-06-13 08:33:43+00:00,PoARX Modelling for Multivariate Count Time Series,"['Jamie Halliday', 'Georgi N. Boshnakov']","This paper introduces multivariate Poisson autoregressive models with
exogenous covariates (PoARX) for modelling multivariate time series of counts.
We obtain conditions for the PoARX process to be stationary and ergodic before
proposing a computationally efficient procedure for estimation of parameters by
the method of inference functions (IFM) and obtaining asymptotic normality of
these estimators. Lastly, we demonstrate an application to count data for the
number of people entering and exiting a building, and show how the different
aspects of the model combine to produce a strong predictive model. We conclude
by suggesting some further areas of application and by listing directions for
future work.",http://arxiv.org/pdf/1806.04892v1,stat.ME
2018-06-12 13:40:30+00:00,A review on distance based time series classification,"['Amaia Abanda', 'Usue Mori', 'Jose A. Lozano']","Time series classification is an increasing research topic due to the vast
amount of time series data that are being created over a wide variety of
fields. The particularity of the data makes it a challenging task and different
approaches have been taken, including the distance based approach. 1-NN has
been a widely used method within distance based time series classification due
to it simplicity but still good performance. However, its supremacy may be
attributed to being able to use specific distances for time series within the
classification process and not to the classifier itself. With the aim of
exploiting these distances within more complex classifiers, new approaches have
arisen in the past few years that are competitive or which outperform the 1-NN
based approaches. In some cases, these new methods use the distance measure to
transform the series into feature vectors, bridging the gap between time series
and traditional classifiers. In other cases, the distances are employed to
obtain a time series kernel and enable the use of kernel methods for time
series classification. One of the main challenges is that a kernel function
must be positive semi-definite, a matter that is also addressed within this
review. The presented review includes a taxonomy of all those methods that aim
to classify time series using a distance based approach, as well as a
discussion of the strengths and weaknesses of each method.",http://arxiv.org/pdf/1806.04509v1,stat.ML
2018-06-06 14:11:30+00:00,SOM-VAE: Interpretable Discrete Representation Learning on Time Series,"['Vincent Fortuin', 'Matthias Hüser', 'Francesco Locatello', 'Heiko Strathmann', 'Gunnar Rätsch']","High-dimensional time series are common in many domains. Since human
cognition is not optimized to work well in high-dimensional spaces, these areas
could benefit from interpretable low-dimensional representations. However, most
representation learning algorithms for time series data are difficult to
interpret. This is due to non-intuitive mappings from data features to salient
properties of the representation and non-smoothness over time. To address this
problem, we propose a new representation learning framework building on ideas
from interpretable discrete dimensionality reduction and deep generative
modeling. This framework allows us to learn discrete representations of time
series, which give rise to smooth and interpretable embeddings with superior
clustering performance. We introduce a new way to overcome the
non-differentiability in discrete representation learning and present a
gradient-based version of the traditional self-organizing map algorithm that is
more performant than the original. Furthermore, to allow for a probabilistic
interpretation of our method, we integrate a Markov model in the representation
space. This model uncovers the temporal transition structure, improves
clustering performance even further and provides additional explanatory
insights as well as a natural representation of uncertainty. We evaluate our
model in terms of clustering performance and interpretability on static
(Fashion-)MNIST data, a time series of linearly interpolated (Fashion-)MNIST
images, a chaotic Lorenz attractor system with two macro states, as well as on
a challenging real world medical time series application on the eICU data set.
Our learned representations compare favorably with competitor methods and
facilitate downstream tasks on the real world data.",http://arxiv.org/pdf/1806.02199v7,cs.LG
2018-06-05 08:26:53+00:00,Deep Mixed Effect Model using Gaussian Processes: A Personalized and Reliable Prediction for Healthcare,"['Ingyo Chung', 'Saehoon Kim', 'Juho Lee', 'Kwang Joon Kim', 'Sung Ju Hwang', 'Eunho Yang']","We present a personalized and reliable prediction model for healthcare, which
can provide individually tailored medical services such as diagnosis, disease
treatment, and prevention. Our proposed framework targets at making
personalized and reliable predictions from time-series data, such as Electronic
Health Records (EHR), by modeling two complementary components: i) a shared
component that captures global trend across diverse patients and ii) a
patient-specific component that models idiosyncratic variability for each
patient. To this end, we propose a composite model of a deep neural network to
learn complex global trends from the large number of patients, and Gaussian
Processes (GP) to probabilistically model individual time-series given
relatively small number of visits per patient. We evaluate our model on diverse
and heterogeneous tasks from EHR datasets and show practical advantages over
standard time-series deep models such as pure Recurrent Neural Network (RNN).",http://arxiv.org/pdf/1806.01551v3,stat.ML
2018-06-05 01:49:02+00:00,Dynamic Function-on-Scalars Regression,['Daniel R. Kowal'],"We develop a modeling framework for dynamic function-on-scalars regression,
in which a time series of functional data is regressed on a time series of
scalar predictors. The regression coefficient function for each predictor is
allowed to be dynamic, which is essential for applications where the
association between predictors and a (functional) response is time-varying. For
greater modeling flexibility, we design a nonparametric reduced-rank functional
data model with an unknown functional basis expansion, which is data-adaptive
and, unlike most existing methods, modeled as unknown for appropriate
uncertainty quantification. Within a Bayesian framework, we introduce shrinkage
priors that simultaneously (i) regularize time-varying regression coefficient
functions to be locally static, (ii) effectively remove unimportant predictor
variables from the model, and (iii) reduce sensitivity to the dimension of the
functional basis. A simulation analysis confirms the importance of these
shrinkage priors, with notable improvements over existing alternatives. We
develop a novel projection-based Gibbs sampling algorithm, which offers
unrivaled computational scalability for fully Bayesian functional regression.
We apply the proposed methodology (i) to analyze the time-varying impact of
macroeconomic variables on the U.S. yield curve and (ii) to characterize the
effects of socioeconomic and demographic predictors on age-specific fertility
rates in South and Southeast Asia.",http://arxiv.org/pdf/1806.01460v2,stat.ME
2018-06-05 01:31:01+00:00,EigenNetworks,"['Jonathan Mei', 'José M. F. Moura']","Many applications donot have the benefit of the laws of physics to derive
succinct descriptive models for observed data. In alternative,
interdependencies among $N$ time series $\{ x_{nk}, k>0 \}_{n=1}^{N}$ are
nowadays often captured by a graph or network $G$ that in practice may be very
large. The network itself may change over time as well (i.e., as $G_k$).
Tracking brute force the changes of time varying networks presents major
challenges, including the associated computational problems. Further, a large
set of networks may not lend itself to useful analysis. This paper approximates
the time varying networks $\left\{G_k\right\}$ as weighted linear combinations
of eigennetworks. The eigennetworks are fixed building blocks that are
estimated by first learning the time series of graphs $G_k$ from the data $\{
x_{nk}, k>0 \}_{n=1}^{N}$, followed by a Principal Network Analysis procedure.
The weights of the eigennetwork representation are eigenfeatures and the time
varying networks $\left\{G_k\right\}$ describe a trajectory in eigennetwork
space. These eigentrajectories should be smooth since the networks $G_k$ vary
at a much slower rate than the data $x_{nk}$, except when structural network
shifts occur reflecting potentially an abrupt change in the underlying
application and sources of the data. Algorithms for learning the time series of
graphs $\left\{G_k\right\}$, deriving the eigennetworks, eigenfeatures and
eigentrajectories, and detecting changepoints are presented. Experiments on
simulated data and with two real time series data (a voting record of the US
senate and genetic expression data for the \textit{Drosophila Melanogaster} as
it goes through its life cycle) demonstrate the performance of the learning and
provide interesting interpretations of the eigennetworks.",http://arxiv.org/pdf/1806.01455v2,stat.ML
2018-06-02 18:46:50+00:00,Hierarchical Attention-Based Recurrent Highway Networks for Time Series Prediction,"['Yunzhe Tao', 'Lin Ma', 'Weizhong Zhang', 'Jian Liu', 'Wei Liu', 'Qiang Du']","Time series prediction has been studied in a variety of domains. However, it
is still challenging to predict future series given historical observations and
past exogenous data. Existing methods either fail to consider the interactions
among different components of exogenous variables which may affect the
prediction accuracy, or cannot model the correlations between exogenous data
and target data. Besides, the inherent temporal dynamics of exogenous data are
also related to the target series prediction, and thus should be considered as
well. To address these issues, we propose an end-to-end deep learning model,
i.e., Hierarchical attention-based Recurrent Highway Network (HRHN), which
incorporates spatio-temporal feature extraction of exogenous variables and
temporal dynamics modeling of target variables into a single framework.
Moreover, by introducing the hierarchical attention mechanism, HRHN can
adaptively select the relevant exogenous features in different semantic levels.
We carry out comprehensive empirical evaluations with various methods over
several datasets, and show that HRHN outperforms the state of the arts in time
series prediction, especially in capturing sudden changes and sudden
oscillations of time series.",http://arxiv.org/pdf/1806.00685v1,cs.LG
2018-05-27 02:42:34+00:00,BRITS: Bidirectional Recurrent Imputation for Time Series,"['Wei Cao', 'Dong Wang', 'Jian Li', 'Hao Zhou', 'Lei Li', 'Yitan Li']","Time series are widely used as signals in many classification/regression
tasks. It is ubiquitous that time series contains many missing values. Given
multiple correlated time series data, how to fill in missing values and to
predict their class labels? Existing imputation methods often impose strong
assumptions of the underlying data generating process, such as linear dynamics
in the state space. In this paper, we propose BRITS, a novel method based on
recurrent neural networks for missing value imputation in time series data. Our
proposed method directly learns the missing values in a bidirectional recurrent
dynamical system, without any specific assumption. The imputed values are
treated as variables of RNN graph and can be effectively updated during the
backpropagation.BRITS has three advantages: (a) it can handle multiple
correlated missing values in time series; (b) it generalizes to time series
with nonlinear dynamics underlying; (c) it provides a data-driven imputation
procedure and applies to general settings with missing data.We evaluate our
model on three real-world datasets, including an air quality dataset, a
health-care data, and a localization data for human activity. Experiments show
that our model outperforms the state-of-the-art methods in both imputation and
classification/regression accuracies.",http://arxiv.org/pdf/1805.10572v1,cs.LG
2018-05-24 21:34:17+00:00,Structure Learning from Time Series with False Discovery Control,"['Bernat Guillen Pegueroles', 'Bhanukiran Vinzamuri', 'Karthikeyan Shanmugam', 'Steve Hedden', 'Jonathan D. Moyer', 'Kush R. Varshney']","We consider the Granger causal structure learning problem from time series
data. Granger causal algorithms predict a 'Granger causal effect' between two
variables by testing if prediction error of one decreases significantly in the
absence of the other variable among the predictor covariates. Almost all
existing Granger causal algorithms condition on a large number of variables
(all but two variables) to test for effects between a pair of variables. We
propose a new structure learning algorithm called MMPC-p inspired by the well
known MMHC algorithm for non-time series data. We show that under some
assumptions, the algorithm provides false discovery rate control. The algorithm
is sound and complete when given access to perfect directed information testing
oracles. We also outline a novel tester for the linear Gaussian case. We show
through our extensive experiments that the MMPC-p algorithm scales to larger
problems and has improved statistical power compared to existing state of the
art for large sparse graphs. We also apply our algorithm on a global
development dataset and validate our findings with subject matter experts.",http://arxiv.org/pdf/1805.09909v1,stat.ML
2018-05-24 18:12:10+00:00,Dynamic Chain Graph Models for Ordinal Time Series Data,"['Pariya Behrouzi', 'Fentaw Abegaz', 'Ernst C. Wit']","This paper introduces sparse dynamic chain graph models for network inference
in high dimensional non-Gaussian time series data. The proposed method
parametrized by a precision matrix that encodes the intra time-slice
conditional independence among variables at a fixed time point, and an
autoregressive coefficient that contains dynamic conditional independences
interactions among time series components across consecutive time steps. The
proposed model is a Gaussian copula vector autoregressive model, which is used
to model sparse interactions in a high-dimensional setting. Estimation is
achieved via a penalized EM algorithm. In this paper, we use an efficient
coordinate descent algorithm to optimize the penalized log-likelihood with the
smoothly clipped absolute deviation penalty. We demonstrate our approach on
simulated and genomic datasets. The method is implemented in an R package
tsnetwork.",http://arxiv.org/pdf/1805.09840v1,stat.ME
2018-05-16 10:13:36+00:00,Analyzing high-dimensional time-series data using kernel transfer operator eigenfunctions,"['Stefan Klus', 'Sebastian Peitz', 'Ingmar Schuster']","Kernel transfer operators, which can be regarded as approximations of
transfer operators such as the Perron-Frobenius or Koopman operator in
reproducing kernel Hilbert spaces, are defined in terms of covariance and
cross-covariance operators and have been shown to be closely related to the
conditional mean embedding framework developed by the machine learning
community. The goal of this paper is to show how the dominant eigenfunctions of
these operators in combination with gradient-based optimization techniques can
be used to detect long-lived coherent patterns in high-dimensional time-series
data. The results will be illustrated using video data and a fluid flow
example.",http://arxiv.org/pdf/1805.10118v1,stat.ML
2018-05-14 15:33:58+00:00,Bayesian forecasting of many count-valued time series,"['Lindsay Berry', 'Mike West']","This paper develops forecasting methodology and application of new classes of
dynamic models for time series of non-negative counts. Novel univariate models
synthesise dynamic generalized linear models for binary and conditionally
Poisson time series, with dynamic random effects for over-dispersion. These
models allow use of dynamic covariates in both binary and non-zero count
components. Sequential Bayesian analysis allows fast, parallel analysis of sets
of decoupled time series. New multivariate models then enable information
sharing in contexts when data at a more highly aggregated level provide more
incisive inferences on shared patterns such as trends and seasonality. A novel
multi-scale approach-- one new example of the concept of decouple/recouple in
time series-- enables information sharing across series. This incorporates
cross-series linkages while insulating parallel estimation of univariate
models, hence enables scalability in the number of series. The major motivating
context is supermarket sales forecasting. Detailed examples drawn from a case
study in multi-step forecasting of sales of a number of related items showcase
forecasting of multiple series, with discussion of forecast accuracy metrics
and broader questions of probabilistic forecast accuracy assessment.",http://arxiv.org/pdf/1805.05232v1,stat.ME
2018-05-12 06:19:06+00:00,Bayesian Dynamic Modeling and Monitoring of Network Flows,"['Xi Chen', 'David Banks', 'Mike West']","In the context of a motivating study of dynamic network flow data on a
large-scale e-commerce web site, we develop Bayesian models for
on-line/sequential analysis for monitoring and adapting to changes reflected in
node-node traffic. For large-scale networks, we customize core Bayesian time
series analysis methods using dynamic generalized linear models (DGLMs). These
are integrated into the context of multivariate networks using the concept of
decouple/recouple that was recently introduced in multivariate time series.
This method enables flexible dynamic modeling of flows on large-scale networks
and exploitation of partial parallelization of analysis while maintaining
coherence with an over-arching multivariate dynamic flow model. This approach
is anchored in a case-study on internet data, with flows of visitors to a
commercial news web site defining a long time series of node-node counts on
over 56,000 node pairs. Central questions include characterizing inherent
stochasticity in traffic patterns, understanding node-node interactions,
adapting to dynamic changes in flows and allowing for sensitive monitoring to
flag anomalies. The methodology of dynamic network DGLMs applies to many
dynamic network flow studies.",http://arxiv.org/pdf/1805.04667v2,stat.ME
2018-05-10 09:46:45+00:00,Towards a universal neural network encoder for time series,"['Joan Serrà', 'Santiago Pascual', 'Alexandros Karatzoglou']","We study the use of a time series encoder to learn representations that are
useful on data set types with which it has not been trained on. The encoder is
formed of a convolutional neural network whose temporal output is summarized by
a convolutional attention mechanism. This way, we obtain a compact,
fixed-length representation from longer, variable-length time series. We
evaluate the performance of the proposed approach on a well-known time series
classification benchmark, considering full adaptation, partial adaptation, and
no adaptation of the encoder to the new data type. Results show that such
strategies are competitive with the state-of-the-art, often outperforming
conceptually-matching approaches. Besides accuracy scores, the facility of
adaptation and the efficiency of pre-trained encoders make them an appealing
option for the processing of scarcely- or non-labeled time series.",http://arxiv.org/pdf/1805.03908v1,cs.LG
2018-05-09 20:03:37+00:00,Foundations of Sequence-to-Sequence Modeling for Time Series,"['Vitaly Kuznetsov', 'Zelda Mariet']","The availability of large amounts of time series data, paired with the
performance of deep-learning algorithms on a broad class of problems, has
recently led to significant interest in the use of sequence-to-sequence models
for time series forecasting. We provide the first theoretical analysis of this
time series forecasting framework. We include a comparison of
sequence-to-sequence modeling to classical time series models, and as such our
theory can serve as a quantitative guide for practitioners choosing between
different modeling methodologies.",http://arxiv.org/pdf/1805.03714v2,cs.LG
2018-05-09 01:01:52+00:00,Modeling Multivariate Time Series with Copula-linked Univariate D-vines,"['Zifeng Zhao', 'Peng Shi', 'Zhengjun Zhang']","This paper proposes a novel multivariate time series model named
Copula-linked univariate D-vines (CuDvine), which enables the simultaneous
copula-based modeling of both temporal and cross-sectional dependence for
multivariate time series. To construct CuDvine, we first build a semiparametric
univariate D-vine time series model (uDvine) based on a D-vine. The uDvine
generalizes the existing first-order copula-based Markov chain models to Markov
chains of an arbitrary-order. Building upon uDvine, we construct CuDvine by
linking multiple uDvines via a parametric copula. As a simple and tractable
model, CuDvine provides flexible models for marginal behavior and temporal
dependence of time series, and can also incorporate sophisticated
cross-sectional dependence such as time-varying and spatio-temporal dependence
for high-dimensional applications. Robust and computationally efficient
procedures, including a sequential model selection method and a two-stage MLE,
are proposed for model estimation and inference, and their statistical
properties are investigated. Numerical experiments are conducted to demonstrate
the flexibility of CuDvine, and to examine the performance of the sequential
model selection procedure and the two-stage MLE. Real data applications on the
Australian electricity price data demonstrate the superior performance of
CuDvine to traditional multivariate time series models.",http://arxiv.org/pdf/1805.03336v3,stat.ME
2018-05-07 19:43:26+00:00,Real-time regression analysis with deep convolutional neural networks,"['E. A. Huerta', 'Daniel George', 'Zhizhen Zhao', 'Gabrielle Allen']","We discuss the development of novel deep learning algorithms to enable
real-time regression analysis for time series data. We showcase the application
of this new method with a timely case study, and then discuss the applicability
of this approach to tackle similar challenges across science domains.",http://arxiv.org/pdf/1805.02716v1,cs.LG
2018-05-02 13:06:58+00:00,COBRAS-TS: A new approach to Semi-Supervised Clustering of Time Series,"['Toon Van Craenendonck', 'Wannes Meert', 'Sebastijan Dumancic', 'Hendrik Blockeel']","Clustering is ubiquitous in data analysis, including analysis of time series.
It is inherently subjective: different users may prefer different clusterings
for a particular dataset. Semi-supervised clustering addresses this by allowing
the user to provide examples of instances that should (not) be in the same
cluster. This paper studies semi-supervised clustering in the context of time
series. We show that COBRAS, a state-of-the-art semi-supervised clustering
method, can be adapted to this setting. We refer to this approach as COBRAS-TS.
An extensive experimental evaluation supports the following claims: (1)
COBRAS-TS far outperforms the current state of the art in semi-supervised
clustering for time series, and thus presents a new baseline for the field; (2)
COBRAS-TS can identify clusters with separated components; (3) COBRAS-TS can
identify clusters that are characterized by small local patterns; (4) a small
amount of semi-supervision can greatly improve clustering quality for time
series; (5) the choice of the clustering algorithm matters (contrary to earlier
claims in the literature).",http://arxiv.org/pdf/1805.00779v1,stat.ML
2018-04-29 14:55:46+00:00,Statistical inference for heavy tailed series with extremal independence,"['Clemonell Bilayi-Biakana', 'Rafal Kulik', 'Philippe Soulier']","We consider stationary time series $\{X_j, j \in Z\} whose finite dimensional
distributions are regularly varying with extremal independence. We assume that
for each $h \geq 1$, conditionally on $X_0$ to exceed a threshold tending to
infinity, the conditional distribution of $X_h$ suitably normalized converges
weakly to a non degenerate distribution. We consider in this paper the
estimation of the normalization and of the limiting distribution.",http://arxiv.org/pdf/1804.10948v1,math.ST
2018-04-26 02:57:00+00:00,New HSIC-based tests for independence between two stationary multivariate time series,"['Guochang Wang', 'Wai Keung Li', 'Ke Zhu']","This paper proposes some novel one-sided omnibus tests for independence
between two multivariate stationary time series. These new tests apply the
Hilbert-Schmidt independence criterion (HSIC) to test the independence between
the innovations of both time series. Under regular conditions, the limiting
null distributions of our HSIC-based tests are established. Next, our
HSIC-based tests are shown to be consistent. Moreover, a residual bootstrap
method is used to obtain the critical values for our HSIC-based tests, and its
validity is justified. Compared with the existing cross-correlation-based tests
for linear dependence, our tests examine the general (including both linear and
non-linear) dependence to give investigators more complete information on the
causal relationship between two multivariate time series. The merits of our
tests are illustrated by some simulation results and a real example.",http://arxiv.org/pdf/1804.09866v1,stat.ME
2018-04-23 16:56:25+00:00,Spatio-Temporal Neural Networks for Space-Time Series Forecasting and Relations Discovery,"['Ali Ziat', 'Edouard Delasalles', 'Ludovic Denoyer', 'Patrick Gallinari']","We introduce a dynamical spatio-temporal model formalized as a recurrent
neural network for forecasting time series of spatial processes, i.e. series of
observations sharing temporal and spatial dependencies. The model learns these
dependencies through a structured latent dynamical component, while a decoder
predicts the observations from the latent representations. We consider several
variants of this model, corresponding to different prior hypothesis about the
spatial relations between the series. The model is evaluated and compared to
state-of-the-art baselines, on a variety of forecasting problems representative
of different application areas: epidemiology, geo-spatial statistics and
car-traffic prediction. Besides these evaluations, we also describe experiments
showing the ability of this approach to extract relevant spatial relations.",http://arxiv.org/pdf/1804.08562v1,cs.LG
2018-04-17 16:24:14+00:00,High Dimensional Time Series Generators,"['Jörg P. Bachmann', 'Johann-Christoph Freytag']","Multidimensional time series are sequences of real valued vectors. They occur
in different areas, for example handwritten characters, GPS tracking, and
gestures of modern virtual reality motion controllers. Within these areas, a
common task is to search for similar time series. Dynamic Time Warping (DTW) is
a common distance function to compare two time series. The Edit Distance with
Real Penalty (ERP) and the Dog Keeper Distance (DK) are two more distance
functions on time series. Their behaviour has been analyzed on 1-dimensional
time series. However, it is not easy to evaluate their behaviour in relation to
growing dimensionality. For this reason we propose two new data synthesizers
generating multidimensional time series. The first synthesizer extends the well
known cylinder-bell-funnel (CBF) dataset to multidimensional time series. Here,
each time series has an arbitrary type (cylinder, bell, or funnel) in each
dimension, thus for $d$-dimensional time series there are $3^{d}$ different
classes. The second synthesizer (RAM) creates time series with ideas adapted
from Brownian motions which is a common model of movement in physics. Finally,
we evaluate the applicability of a 1-nearest neighbor classifier using DTW on
datasets generated by our synthesizers.",http://arxiv.org/pdf/1804.06352v3,cs.LG
2018-04-12 03:33:27+00:00,Model identification for ARMA time series through convolutional neural networks,"['Wai Hoh Tang', 'Adrian Röllin']","In this paper, we use convolutional neural networks to address the problem of
model identification for autoregressive moving average time series models. We
compare the performance of several neural network architectures, trained on
simulated time series, with likelihood based methods, in particular the Akaike
and Bayesian information criteria. We find that our neural networks can
significantly outperform these likelihood based methods in terms of accuracy
and, by orders of magnitude, in terms of speed.",http://arxiv.org/pdf/1804.04299v2,stat.ME
2018-04-11 10:21:22+00:00,Structural causal models for macro-variables in time-series,"['Dominik Janzing', 'Paul Rubenstein', 'Bernhard Schölkopf']","We consider a bivariate time series $(X_t,Y_t)$ that is given by a simple
linear autoregressive model. Assuming that the equations describing each
variable as a linear combination of past values are considered structural
equations, there is a clear meaning of how intervening on one particular $X_t$
influences $Y_{t'}$ at later times $t'>t$. In the present work, we describe
conditions under which one can define a causal model between variables that are
coarse-grained in time, thus admitting statements like `setting $X$ to $x$
changes $Y$ in a certain way' without referring to specific time instances. We
show that particularly simple statements follow in the frequency domain, thus
providing meaning to interventions on frequencies.",http://arxiv.org/pdf/1804.03911v1,math.ST
2018-04-04 14:38:16+00:00,Model assessment for time series dynamics using copula spectral densities: a graphical tool,"['Stefan Birr', 'Tobias Kley', 'Stanislav Volgushev']","Finding parametric models that accurately describe the dependence structure
of observed data is a central task in the analysis of time series. Classical
frequency domain methods provide a popular set of tools for fitting and
diagnostics of time series models, but their applicability is seriously
impacted by the limitations of covariances as a measure of dependence.
Motivated by recent developments of frequency domain methods that are based on
copulas instead of covariances, we propose a novel graphical tool that allows
to access the quality of time series models for describing dependencies that go
beyond linearity. We provide a thorough theoretical justification of our
approach and show in simulations that it can successfully distinguish between
subtle differences of time series dynamics, including non-linear dynamics which
result from GARCH and EGARCH models. We also demonstrate the utility of the
proposed tools through an application to modeling returns of the S&P 500 stock
market index.",http://arxiv.org/pdf/1804.01440v2,stat.ME
2018-03-26 16:36:37+00:00,MOrdReD: Memory-based Ordinal Regression Deep Neural Networks for Time Series Forecasting,"['Bernardo Pérez Orozco', 'Gabriele Abbati', 'Stephen Roberts']","Time series forecasting is ubiquitous in the modern world. Applications range
from health care to astronomy, and include climate modelling, financial trading
and monitoring of critical engineering equipment. To offer value over this
range of activities, models must not only provide accurate forecasts, but also
quantify and adjust their uncertainty over time. In this work, we directly
tackle this task with a novel, fully end-to-end deep learning method for time
series forecasting. By recasting time series forecasting as an ordinal
regression task, we develop a principled methodology to assess long-term
predictive uncertainty and describe rich multimodal, non-Gaussian behaviour,
which arises regularly in applied settings.
  Notably, our framework is a wholly general-purpose approach that requires
little to no user intervention to be used. We showcase this key feature in a
large-scale benchmark test with 45 datasets drawn from both, a wide range of
real-world application domains, as well as a comprehensive list of synthetic
maps. This wide comparison encompasses state-of-the-art methods in both the
Machine Learning and Statistics modelling literature, such as the Gaussian
Process. We find that our approach does not only provide excellent predictive
forecasts, shadowing true future values, but also allows us to infer valuable
information, such as the predictive distribution of the occurrence of critical
events of interest, accurately and reliably even over long time horizons.",http://arxiv.org/pdf/1803.09704v4,stat.ML
2018-03-26 10:40:29+00:00,A general white noise test based on kernel lag-window estimates of the spectral density operator,"['Vaidotas Characiejus', 'Gregory Rice']","We propose a general white noise test for functional time series based on
estimating a distance between the spectral density operator of a weakly
stationary time series and the constant spectral density operator of an
uncorrelated time series. The estimator that we propose is based on a kernel
lag-window type estimator of the spectral density operator. When the observed
time series is a strong white noise in a real separable Hilbert space, we show
that the asymptotic distribution of the test statistic is standard normal, and
we further show that the test statistic diverges for general serially
correlated time series. These results recover as special cases those of Hong
(1996) and Horv\'ath et al. (2013). In order to implement the test, we propose
and study a number of kernel and bandwidth choices, including a new data
adaptive bandwidth, as well as data adaptive power transformations of the test
statistic that improve the normal approximation in finite samples. A simulation
study demonstrated that the proposed method has good size and improved power
when compared to other methods available in the literature, while also offering
a light computational burden.",http://arxiv.org/pdf/1803.09501v2,math.ST
2018-03-21 20:30:34+00:00,Seglearn: A Python Package for Learning Sequences and Time Series,"['David M. Burns', 'Cari M. Whyne']","Seglearn is an open-source python package for machine learning time series or
sequences using a sliding window segmentation approach. The implementation
provides a flexible pipeline for tackling classification, regression, and
forecasting problems with multivariate sequence and contextual data. This
package is compatible with scikit-learn and is listed under scikit-learn
Related Projects. The package depends on numpy, scipy, and scikit-learn.
Seglearn is distributed under the BSD 3-Clause License. Documentation includes
a detailed API description, user guide, and examples. Unit tests provide a high
degree of code coverage.",http://arxiv.org/pdf/1803.08118v3,stat.ML
2018-03-21 12:20:43+00:00,An Unsupervised Multivariate Time Series Kernel Approach for Identifying Patients with Surgical Site Infection from Blood Samples,"['Karl Øyvind Mikalsen', 'Cristina Soguero-Ruiz', 'Filippo Maria Bianchi', 'Arthur Revhaug', 'Robert Jenssen']","A large fraction of the electronic health records consists of clinical
measurements collected over time, such as blood tests, which provide important
information about the health status of a patient. These sequences of clinical
measurements are naturally represented as time series, characterized by
multiple variables and the presence of missing data, which complicate analysis.
In this work, we propose a surgical site infection detection framework for
patients undergoing colorectal cancer surgery that is completely unsupervised,
hence alleviating the problem of getting access to labelled training data. The
framework is based on powerful kernels for multivariate time series that
account for missing data when computing similarities. Our approach show
superior performance compared to baselines that have to resort to imputation
techniques and performs comparable to a supervised classification baseline.",http://arxiv.org/pdf/1803.07879v1,stat.ML
2018-03-16 20:01:48+00:00,Forecasting Economics and Financial Time Series: ARIMA vs. LSTM,"['Sima Siami-Namini', 'Akbar Siami Namin']","Forecasting time series data is an important subject in economics, business,
and finance. Traditionally, there are several techniques to effectively
forecast the next lag of time series data such as univariate Autoregressive
(AR), univariate Moving Average (MA), Simple Exponential Smoothing (SES), and
more notably Autoregressive Integrated Moving Average (ARIMA) with its many
variations. In particular, ARIMA model has demonstrated its outperformance in
precision and accuracy of predicting the next lags of time series. With the
recent advancement in computational power of computers and more importantly
developing more advanced machine learning algorithms and approaches such as
deep learning, new algorithms are developed to forecast time series data. The
research question investigated in this article is that whether and how the
newly developed deep learning-based algorithms for forecasting time series
data, such as ""Long Short-Term Memory (LSTM)"", are superior to the traditional
algorithms. The empirical studies conducted and reported in this article show
that deep learning-based algorithms such as LSTM outperform traditional-based
algorithms such as ARIMA model. More specifically, the average reduction in
error rates obtained by LSTM is between 84 - 87 percent when compared to ARIMA
indicating the superiority of LSTM to ARIMA. Furthermore, it was noticed that
the number of training times, known as ""epoch"" in deep learning, has no effect
on the performance of the trained forecast model and it exhibits a truly random
behavior.",http://arxiv.org/pdf/1803.06386v1,cs.LG
2018-03-15 17:03:04+00:00,Capturing Structure Implicitly from Time-Series having Limited Data,"['Daniel Emaasit', 'Matthew Johnson']","Scientific fields such as insider-threat detection and highway-safety
planning often lack sufficient amounts of time-series data to estimate
statistical models for the purpose of scientific discovery. Moreover, the
available limited data are quite noisy. This presents a major challenge when
estimating time-series models that are robust to overfitting and have
well-calibrated uncertainty estimates. Most of the current literature in these
fields involve visualizing the time-series for noticeable structure and hard
coding them into pre-specified parametric functions. This approach is
associated with two limitations. First, given that such trends may not be
easily noticeable in small data, it is difficult to explicitly incorporate
expressive structure into the models during formulation. Second, it is
difficult to know $\textit{a priori}$ the most appropriate functional form to
use. To address these limitations, a nonparametric Bayesian approach was
proposed to implicitly capture hidden structure from time series having limited
data. The proposed model, a Gaussian process with a spectral mixture kernel,
precludes the need to pre-specify a functional form and hard code trends, is
robust to overfitting and has well-calibrated uncertainty estimates.",http://arxiv.org/pdf/1803.05867v1,stat.ML
2018-03-15 15:37:40+00:00,Theory and Algorithms for Forecasting Time Series,"['Vitaly Kuznetsov', 'Mehryar Mohri']","We present data-dependent learning bounds for the general scenario of
non-stationary non-mixing stochastic processes. Our learning guarantees are
expressed in terms of a data-dependent measure of sequential complexity and a
discrepancy measure that can be estimated from data under some mild
assumptions. We also also provide novel analysis of stable time series
forecasting algorithm using this new notion of discrepancy that we introduce.
We use our learning bounds to devise new algorithms for non-stationary time
series forecasting for which we report some preliminary experimental results.",http://arxiv.org/pdf/1803.05814v1,cs.LG
2018-03-14 17:39:11+00:00,Generalised Structural CNNs (SCNNs) for time series data with arbitrary graph topology,"['Thomas Teh', 'Chaiyawan Auepanwiriyakul', 'John Alexander Harston', 'A. Aldo Faisal']","Deep Learning methods, specifically convolutional neural networks (CNNs),
have seen a lot of success in the domain of image-based data, where the data
offers a clearly structured topology in the regular lattice of pixels. This
4-neighbourhood topological simplicity makes the application of convolutional
masks straightforward for time series data, such as video applications, but
many high-dimensional time series data are not organised in regular lattices,
and instead values may have adjacency relationships with non-trivial
topologies, such as small-world networks or trees. In our application case,
human kinematics, it is currently unclear how to generalise convolutional
kernels in a principled manner. Therefore we define and implement here a
framework for general graph-structured CNNs for time series analysis. Our
algorithm automatically builds convolutional layers using the specified
adjacency matrix of the data dimensions and convolutional masks that scale with
the hop distance. In the limit of a lattice-topology our method produces the
well-known image convolutional masks. We test our method first on synthetic
data of arbitrarily-connected graphs and human hand motion capture data, where
the hand is represented by a tree capturing the mechanical dependencies of the
joints. We are able to demonstrate, amongst other things, that inclusion of the
graph structure of the data dimensions improves model prediction significantly,
when compared against a benchmark CNN model with only time convolution layers.",http://arxiv.org/pdf/1803.05419v2,stat.ML
2018-03-11 20:59:35+00:00,Sales forecasting using WaveNet within the framework of the Kaggle competition,"['Glib Kechyn', 'Lucius Yu', 'Yangguang Zang', 'Svyatoslav Kechyn']","We took part in the Corporacion Favorita Grocery Sales Forecasting
competition hosted on Kaggle and achieved the 2nd place. In this abstract
paper, we present an overall analysis and solution to the underlying
machine-learning problem based on time series data, where major challenges are
identified and corresponding preliminary methods are proposed. Our approach is
based on the adaptation of dilated convolutional neural network for time series
forecasting. By applying this technique iteratively to batches of n examples, a
big amount of time series data can be eventually processed with a decent speed
and accuracy. We hope this paper could serve, to some extent, as a review and
guideline of the time series forecasting benchmark, inspiring further attempts
and researches.",http://arxiv.org/pdf/1803.04037v1,cs.LG
2018-03-11 07:46:24+00:00,Detecting Nonlinear Causality in Multivariate Time Series with Sparse Additive Models,"['Yingxiang Yang', 'Adams Wei Yu', 'Zhaoran Wang', 'Tuo Zhao']","We propose a nonparametric method for detecting nonlinear causal relationship
within a set of multidimensional discrete time series, by using sparse additive
models (SpAMs). We show that, when the input to the SpAM is a $\beta$-mixing
time series, the model can be fitted by first approximating each unknown
function with a linear combination of a set of B-spline bases, and then solving
a group-lasso-type optimization problem with nonconvex regularization.
Theoretically, we characterize the oracle statistical properties of the
proposed sparse estimator in function estimation and model selection.
Numerically, we propose an efficient pathwise iterative shrinkage thresholding
algorithm (PISTA), which tames the nonconvexity and guarantees linear
convergence towards the desired sparse estimator with high probability.",http://arxiv.org/pdf/1803.03919v2,stat.ML
2018-03-11 06:56:29+00:00,Deep reinforcement learning for time series: playing idealized trading games,['Xiang Gao'],"Deep Q-learning is investigated as an end-to-end solution to estimate the
optimal strategies for acting on time series input. Experiments are conducted
on two idealized trading games. 1) Univariate: the only input is a wave-like
price time series, and 2) Bivariate: the input includes a random stepwise price
time series and a noisy signal time series, which is positively correlated with
future price changes. The Univariate game tests whether the agent can capture
the underlying dynamics, and the Bivariate game tests whether the agent can
utilize the hidden relation among the inputs. Stacked Gated Recurrent Unit
(GRU), Long Short-Term Memory (LSTM) units, Convolutional Neural Network (CNN),
and multi-layer perceptron (MLP) are used to model Q values. For both games,
all agents successfully find a profitable strategy. The GRU-based agents show
best overall performance in the Univariate game, while the MLP-based agents
outperform others in the Bivariate game.",http://arxiv.org/pdf/1803.03916v1,cs.LG
2018-03-08 21:49:38+00:00,Precision and Recall for Time Series,"['Nesime Tatbul', 'Tae Jun Lee', 'Stan Zdonik', 'Mejbah Alam', 'Justin Gottschlich']","Classical anomaly detection is principally concerned with point-based
anomalies, those anomalies that occur at a single point in time. Yet, many
real-world anomalies are range-based, meaning they occur over a period of time.
Motivated by this observation, we present a new mathematical model to evaluate
the accuracy of time series classification algorithms. Our model expands the
well-known Precision and Recall metrics to measure ranges, while simultaneously
enabling customization support for domain-specific preferences.",http://arxiv.org/pdf/1803.03639v3,cs.LG
2018-03-06 17:38:03+00:00,Dimensionality Reduction for Stationary Time Series via Stochastic Nonconvex Optimization,"['Minshuo Chen', 'Lin Yang', 'Mengdi Wang', 'Tuo Zhao']","Stochastic optimization naturally arises in machine learning. Efficient
algorithms with provable guarantees, however, are still largely missing, when
the objective function is nonconvex and the data points are dependent. This
paper studies this fundamental challenge through a streaming PCA problem for
stationary time series data. Specifically, our goal is to estimate the
principle component of time series data with respect to the covariance matrix
of the stationary distribution. Computationally, we propose a variant of Oja's
algorithm combined with downsampling to control the bias of the stochastic
gradient caused by the data dependency. Theoretically, we quantify the
uncertainty of our proposed stochastic algorithm based on diffusion
approximations. This allows us to prove the asymptotic rate of convergence and
further implies near optimal asymptotic sample complexity. Numerical
experiments are provided to support our analysis.",http://arxiv.org/pdf/1803.02312v4,cs.LG
2018-03-04 14:55:33+00:00,SAFE: Spectral Evolution Analysis Feature Extraction for Non-Stationary Time Series Prediction,"['Arief Koesdwiady', 'Fakhri Karray']","This paper presents a practical approach for detecting non-stationarity in
time series prediction. This method is called SAFE and works by monitoring the
evolution of the spectral contents of time series through a distance function.
This method is designed to work in combination with state-of-the-art machine
learning methods in real time by informing the online predictors to perform
necessary adaptation when a non-stationarity presents. We also propose an
algorithm to proportionally include some past data in the adaption process to
overcome the Catastrophic Forgetting problem. To validate our hypothesis and
test the effectiveness of our approach, we present comprehensive experiments in
different elements of the approach involving artificial and real-world
datasets. The experiments show that the proposed method is able to
significantly save computational resources in term of processor or GPU cycles
while maintaining high prediction performances.",http://arxiv.org/pdf/1803.01364v2,cs.LG
2018-03-03 15:46:18+00:00,Estimation and inference for precision matrices of non-stationary time series,"['Xiucai Ding', 'Zhou Zhou']","In this paper, we consider the estimation and inference of precision matrices
of a rich class of locally stationary and nonlinear time series assuming that
only one realization of the time series is observed. Using a Cholesky
decomposition technique, we show that the precision matrices can be directly
estimated via a series of least squares linear regressions with smoothly
time-varying coefficients. The method of sieves is utilized for the estimation
and is shown to be efficient and optimally adaptive in terms of estimation
accuracy and computational complexity. We establish an asymptotic theory for a
class of ${\cal L}^2$ tests based on the nonparametric sieve estimators. The
latter are used for testing whether the precision matrices are diagonal or
banded. A high dimensional Gaussian approximation result is established for a
wide class of quadratic form of non-stationary and nonlinear processes, which
is of interest by itself.",http://arxiv.org/pdf/1803.01188v4,math.ST
2018-02-27 02:24:06+00:00,A High GOPs/Slice Time Series Classifier for Portable and Embedded Biomedical Applications,"['Hamid Soleimani', 'Aliasghar', 'Makhlooghpour', 'Wilten Nicola', 'Claudia Clopath', 'Emmanuel. M. Drakakis']","Nowadays a diverse range of physiological data can be captured continuously
for various applications in particular wellbeing and healthcare. Such data
require efficient methods for classification and analysis. Deep learning
algorithms have shown remarkable potential regarding such analyses, however,
the use of these algorithms on low-power wearable devices is challenged by
resource constraints such as area and power consumption. Most of the available
on-chip deep learning processors contain complex and dense hardware
architectures in order to achieve the highest possible throughput. Such a trend
in hardware design may not be efficient in applications where on-node
computation is required and the focus is more on the area and power efficiency
as in the case of portable and embedded biomedical devices. This paper presents
an efficient time-series classifier capable of automatically detecting
effective features and classifying the input signals in real-time. In the
proposed classifier, throughput is traded off with hardware complexity and cost
using resource sharing techniques. A Convolutional Neural Network (CNN) is
employed to extract input features and then a Long-Short-Term-Memory (LSTM)
architecture with ternary weight precision classifies the input signals
according to the extracted features. Hardware implementation on a Xilinx FPGA
confirm that the proposed hardware can accurately classify multiple complex
biomedical time series data with low area and power consumption and outperform
all previously presented state-of-the-art records. Most notably, our classifier
reaches 1.3$\times$ higher GOPs/Slice than similar state of the art FPGA-based
accelerators.",http://arxiv.org/pdf/1802.10458v2,cs.LG
2018-02-26 20:15:16+00:00,A partial correlation vine based approach for modeling and forecasting multivariate volatility time-series,"['Nicole Barthel', 'Claudia Czado', 'Yarema Okhrin']","A novel approach for dynamic modeling and forecasting of realized covariance
matrices is proposed. Realized variances and realized correlation matrices are
jointly estimated. The one-to-one relationship between a positive definite
correlation matrix and its associated set of partial correlations corresponding
to any vine specification is used for data transformation. The model components
therefore are realized variances as well as realized standard and partial
correlations corresponding to a daily log-return series. As such, they have a
clear practical interpretation. A method to select a regular vine structure,
which allows for parsimonious time-series and dependence modeling of the model
components, is introduced. Being algebraically independent the latter do not
underlie any algebraic constraint. The proposed model approach is outlined in
detail and motivated along with a real data example on six highly liquid
stocks. The forecasting performance is evaluated both with respect to
statistical precision and in the context of portfolio optimization. Comparisons
with Cholesky decomposition based benchmark models support the excellent
prediction ability of the proposed model approach.",http://arxiv.org/pdf/1802.09585v2,stat.ME
2018-02-26 00:52:54+00:00,Partial Distance Correlation Screening for High Dimensional Time Series,"['Kashif Yousuf', 'Yang Feng']","High dimensional time series datasets are becoming increasingly common in
various fields such as economics, finance, meteorology, and neuroscience. Given
this ubiquity of time series data, it is surprising that very few works on
variable screening discuss the time series setting, and even fewer works have
developed methods which utilize the unique features of time series data. This
paper introduces several model free screening methods based on the partial
distance correlation and developed specifically to deal with time dependent
data. Methods are developed both for univariate models, such as nonlinear
autoregressive models with exogenous predictors (NARX), and multivariate models
such as linear or nonlinear VAR models. Sure screening properties are proved
for our methods, which depend on the moment conditions, and the strength of
dependence in the response and covariate processes, amongst other factors.
Dependence is quantified by functional dependence measures (Wu [Proc. Natl.
Acad. Sci. USA 102 (2005) 14150-14154]) and $\beta$-mixing coefficients, and
the results rely on the use of Nagaev and Rosenthal type inequalities for
dependent random variables. Finite sample performance of our methods is shown
through extensive simulation studies, and we include an application to
macroeconomic forecasting.",http://arxiv.org/pdf/1802.09116v3,stat.ME
2018-02-25 19:06:06+00:00,Model Agnostic Time Series Analysis via Matrix Estimation,"['Anish Agarwal', 'Muhammad Jehangir Amjad', 'Devavrat Shah', 'Dennis Shen']","We propose an algorithm to impute and forecast a time series by transforming
the observed time series into a matrix, utilizing matrix estimation to recover
missing values and de-noise observed entries, and performing linear regression
to make predictions. At the core of our analysis is a representation result,
which states that for a large model class, the transformed time series matrix
is (approximately) low-rank. In effect, this generalizes the widely used
Singular Spectrum Analysis (SSA) in time series literature, and allows us to
establish a rigorous link between time series analysis and matrix estimation.
The key to establishing this link is constructing a Page matrix with
non-overlapping entries rather than a Hankel matrix as is commonly done in the
literature (e.g., SSA). This particular matrix structure allows us to provide
finite sample analysis for imputation and prediction, and prove the asymptotic
consistency of our method. Another salient feature of our algorithm is that it
is model agnostic with respect to both the underlying time dynamics and the
noise distribution in the observations. The noise agnostic property of our
approach allows us to recover the latent states when only given access to noisy
and partial observations a la a Hidden Markov Model; e.g., recovering the
time-varying parameter of a Poisson process without knowing that the underlying
process is Poisson. Furthermore, since our forecasting algorithm requires
regression with noisy features, our approach suggests a matrix estimation based
method - coupled with a novel, non-standard matrix estimation error metric - to
solve the error-in-variable regression problem, which could be of interest in
its own right. Through synthetic and real-world datasets, we demonstrate that
our algorithm outperforms standard software packages (including R libraries) in
the presence of missing data as well as high levels of noise.",http://arxiv.org/pdf/1802.09064v6,cs.LG
2018-02-24 22:49:29+00:00,Time Series Learning using Monotonic Logical Properties,"['Marcell Vazquez-Chanlatte', 'Shromona Ghosh', 'Jyotirmoy V. Deshmukh', 'Alberto Sangiovanni-Vincentelli', 'Sanjit A. Seshia']","Cyber-physical systems of today are generating large volumes of time-series
data. As manual inspection of such data is not tractable, the need for learning
methods to help discover logical structure in the data has increased. We
propose a logic-based framework that allows domain-specific knowledge to be
embedded into formulas in a parametric logical specification over time-series
data. The key idea is to then map a time series to a surface in the parameter
space of the formula. Given this mapping, we identify the Hausdorff distance
between boundaries as a natural distance metric between two time-series data
under the lens of the parametric specification. This enables embedding
non-trivial domain-specific knowledge into the distance metric and then using
off-the-shelf machine learning tools to label the data. After labeling the
data, we demonstrate how to extract a logical specification for each label.
Finally, we showcase our technique on real world traffic data to learn
classifiers/monitors for slow-downs and traffic jams.",http://arxiv.org/pdf/1802.08924v2,cs.LG
2018-02-22 18:56:27+00:00,Structured low-rank matrix completion for forecasting in time series analysis,"['Jonathan Gillard', 'Konstantin Usevich']","In this paper we consider the low-rank matrix completion problem with
specific application to forecasting in time series analysis. Briefly, the
low-rank matrix completion problem is the problem of imputing missing values of
a matrix under a rank constraint. We consider a matrix completion problem for
Hankel matrices and a convex relaxation based on the nuclear norm. Based on new
theoretical results and a number of numerical and real examples, we investigate
the cases when the proposed approach can work. Our results highlight the
importance of choosing a proper weighting scheme for the known observations.",http://arxiv.org/pdf/1802.08242v1,stat.ME
2018-02-21 14:07:36+00:00,Emulating dynamic non-linear simulators using Gaussian processes,"['Hossein Mohammadi', 'Peter Challenor', 'Marc Goodfellow']","The dynamic emulation of non-linear deterministic computer codes where the
output is a time series, possibly multivariate, is examined. Such computer
models simulate the evolution of some real-world phenomenon over time, for
example models of the climate or the functioning of the human brain. The models
we are interested in are highly non-linear and exhibit tipping points,
bifurcations and chaotic behaviour. However, each simulation run could be too
time-consuming to perform analyses that require many runs, including
quantifying the variation in model output with respect to changes in the
inputs. Therefore, Gaussian process emulators are used to approximate the
output of the code. To do this, the flow map of the system under study is
emulated over a short time period. Then, it is used in an iterative way to
predict the whole time series. A number of ways are proposed to take into
account the uncertainty of inputs to the emulators, after fixed initial
conditions, and the correlation between them through the time series. The
methodology is illustrated with two examples: the highly non-linear dynamical
systems described by the Lorenz and Van der Pol equations. In both cases, the
predictive performance is relatively high and the measure of uncertainty
provided by the method reflects the extent of predictability in each system.",http://arxiv.org/pdf/1802.07575v4,stat.ML
2018-02-17 21:43:28+00:00,Exact and Robust Conformal Inference Methods for Predictive Machine Learning With Dependent Data,"['Victor Chernozhukov', 'Kaspar Wuthrich', 'Yinchu Zhu']","We extend conformal inference to general settings that allow for time series
data. Our proposal is developed as a randomization method and accounts for
potential serial dependence by including block structures in the permutation
scheme. As a result, the proposed method retains the exact, model-free validity
when the data are i.i.d. or more generally exchangeable, similar to usual
conformal inference methods. When exchangeability fails, as is the case for
common time series data, the proposed approach is approximately valid under
weak assumptions on the conformity score.",http://arxiv.org/pdf/1802.06300v3,stat.ML
2018-02-16 19:30:19+00:00,Mining Sub-Interval Relationships In Time Series Data,"['Saurabh Agrawal', 'Saurabh Verma', 'Gowtham Atluri', 'Anuj Karpatne', 'Stefan Liess', 'Angus Macdonald III', 'Snigdhansu Chatterjee', 'Vipin Kumar']","Time-series data is being increasingly collected and stud- ied in several
areas such as neuroscience, climate science, transportation, and social media.
Discovery of complex patterns of relationships between individual time-series,
using data-driven approaches can improve our understanding of real-world
systems. While traditional approaches typically study relationships between two
entire time series, many interesting relationships in real-world applications
exist in small sub-intervals of time while remaining absent or feeble during
other sub-intervals. In this paper, we define the notion of a sub-interval
relationship (SIR) to capture inter- actions between two time series that are
prominent only in certain sub-intervals of time. We propose a novel and
efficient approach to find most interesting SIR in a pair of time series. We
evaluate our proposed approach on two real-world datasets from climate science
and neuroscience domain and demonstrated the scalability and computational
efficiency of our proposed approach. We further evaluated our discovered SIRs
based on a randomization based procedure. Our results indicated the existence
of several such relationships that are statistically significant, some of which
were also found to have physical interpretation.",http://arxiv.org/pdf/1802.06095v1,stat.ML
2018-02-16 12:31:17+00:00,Pattern Localization in Time Series through Signal-To-Model Alignment in Latent Space,"['Steven Van Vaerenbergh', 'Ignacio Santamaria', 'Victor Elvira', 'Matteo Salvatori']","In this paper, we study the problem of locating a predefined sequence of
patterns in a time series. In particular, the studied scenario assumes a
theoretical model is available that contains the expected locations of the
patterns. This problem is found in several contexts, and it is commonly solved
by first synthesizing a time series from the model, and then aligning it to the
true time series through dynamic time warping. We propose a technique that
increases the similarity of both time series before aligning them, by mapping
them into a latent correlation space. The mapping is learned from the data
through a machine-learning setup. Experiments on data from non-destructive
testing demonstrate that the proposed approach shows significant improvements
over the state of the art.",http://arxiv.org/pdf/1802.05910v2,cs.LG
2018-02-15 10:45:46+00:00,Admissible Time Series Motif Discovery with Missing Data,"['Yan Zhu', 'Abdullah Mueen', 'Eamonn Keogh']","The discovery of time series motifs has emerged as one of the most useful
primitives in time series data mining. Researchers have shown its utility for
exploratory data mining, summarization, visualization, segmentation,
classification, clustering, and rule discovery. Although there has been more
than a decade of extensive research, there is still no technique to allow the
discovery of time series motifs in the presence of missing data, despite the
well-documented ubiquity of missing data in scientific, industrial, and medical
datasets. In this work, we introduce a technique for motif discovery in the
presence of missing data. We formally prove that our method is admissible,
producing no false negatives. We also show that our method can piggy-back off
the fastest known motif discovery method with a small constant factor
time/space overhead. We will demonstrate our approach on diverse datasets with
varying amounts of missing data",http://arxiv.org/pdf/1802.05472v1,cs.LG
2018-02-14 17:11:53+00:00,Statistical Inference for inter-arrival times of extreme events in bursty time series,"['Katharina Hees', 'Smarak Nayak', 'Peter Straka']","In many complex systems studied in statistical physics, inter-arrival times
between events such as solar flares, trades and neuron voltages follow a
heavy-tailed distribution. The set of event times is fractal-like, being dense
in some time windows and empty in others, a phenomenon which has been dubbed
""bursty"". A new model for the inter-exceedance times of events above high
thresholds is proposed. For high thresholds and infinite-mean waiting times, it
is shown that the times between threshold crossings are Mittag-Leffler
distributed, and thus form a ""fractional Poisson Process"" which generalizes the
standard Poisson Process of threshold exceedances. Graphical means of
estimating model parameters and assessing model fit are provided. The inference
method is applied to an empirical bursty time series, and it is shown how the
memory of the Mittag-Leffler distribution affects prediction of the time until
the next extreme event.""",http://arxiv.org/pdf/1802.05218v5,math.ST
2018-02-10 17:59:25+00:00,Learning Correlation Space for Time Series,"['Han Qiu', 'Hoang Thanh Lam', 'Francesco Fusco', 'Mathieu Sinn']","We propose an approximation algorithm for efficient correlation search in
time series data. In our method, we use Fourier transform and neural network to
embed time series into a low-dimensional Euclidean space. The given space is
learned such that time series correlation can be effectively approximated from
Euclidean distance between corresponding embedded vectors. Therefore, search
for correlated time series can be done using an index in the embedding space
for efficient nearest neighbor search. Our theoretical analysis illustrates
that our method's accuracy can be guaranteed under certain regularity
conditions. We further conduct experiments on real-world datasets and the
results show that our method indeed outperforms the baseline solution. In
particular, for approximation of correlation, our method reduces the
approximation loss by a half in most test cases compared to the baseline
solution. For top-$k$ highest correlation search, our method improves the
precision from 5\% to 20\% while the query time is similar to the baseline
approach query time.",http://arxiv.org/pdf/1802.03628v3,cs.LG
2018-02-10 17:57:25+00:00,Detecting Multiple Change Points Using Adaptive Regression Splines with Application to Neural Recordings,"['Hazem Toutounji', 'Daniel Durstewitz']","Time series, as frequently the case in neuroscience, are rarely stationary,
but often exhibit abrupt changes due to attractor transitions or bifurcations
in the dynamical systems producing them. A plethora of methods for detecting
such change points in time series statistics have been developed over the
years, in addition to test criteria to evaluate their significance. Issues to
consider when developing change point analysis methods include computational
demands, difficulties arising from either limited amount of data or a large
number of covariates, and arriving at statistical tests with sufficient power
to detect as many changes as contained in potentially high-dimensional time
series. Here, a general method called Paired Adaptive Regressors for Cumulative
Sum is developed for detecting multiple change points in the mean of
multivariate time series. The method's advantages over alternative approaches
are demonstrated through a series of simulation experiments. This is followed
by a real data application to neural recordings from rat medial prefrontal
cortex during learning. Finally, the method's flexibility to incorporate useful
features from state-of-the-art change point detection techniques is discussed,
along with potential drawbacks and suggestions to remedy them.",http://arxiv.org/pdf/1802.03627v3,stat.ME
2018-02-09 17:24:27+00:00,Predicting Customer Churn: Extreme Gradient Boosting with Temporal Data,['Bryan Gregory'],"Accurately predicting customer churn using large scale time-series data is a
common problem facing many business domains. The creation of model features
across various time windows for training and testing can be particularly
challenging due to temporal issues common to time-series data. In this paper,
we will explore the application of extreme gradient boosting (XGBoost) on a
customer dataset with a wide-variety of temporal features in order to create a
highly-accurate customer churn model. In particular, we describe an effective
method for handling temporally sensitive feature engineering. The proposed
model was submitted in the WSDM Cup 2018 Churn Challenge and achieved
first-place out of 575 teams.",http://arxiv.org/pdf/1802.03396v1,stat.ML
2018-02-08 16:29:49+00:00,TSViz: Demystification of Deep Learning Models for Time-Series Analysis,"['Shoaib Ahmed Siddiqui', 'Dominik Mercier', 'Mohsin Munir', 'Andreas Dengel', 'Sheraz Ahmed']","This paper presents a novel framework for demystification of convolutional
deep learning models for time-series analysis. This is a step towards making
informed/explainable decisions in the domain of time-series, powered by deep
learning. There have been numerous efforts to increase the interpretability of
image-centric deep neural network models, where the learned features are more
intuitive to visualize. Visualization in time-series domain is much more
complicated as there is no direct interpretation of the filters and inputs as
compared to the image modality. In addition, little or no concentration has
been devoted for the development of such tools in the domain of time-series in
the past. TSViz provides possibilities to explore and analyze a network from
different dimensions at different levels of abstraction which includes
identification of parts of the input that were responsible for a prediction
(including per filter saliency), importance of different filters present in the
network for a particular prediction, notion of diversity present in the network
through filter clustering, understanding of the main sources of variation
learnt by the network through inverse optimization, and analysis of the
network's robustness against adversarial noise. As a sanity check for the
computed influence values, we demonstrate results regarding pruning of neural
networks based on the computed influence information. These representations
allow to understand the network features so that the acceptability of deep
networks for time-series data can be enhanced. This is extremely important in
domains like finance, industry 4.0, self-driving cars, health-care,
counter-terrorism etc., where reasons for reaching a particular prediction are
equally important as the prediction itself. We assess the proposed framework
for interpretability with a set of desirable properties essential for any
method.",http://arxiv.org/pdf/1802.02952v3,cs.LG
2018-02-05 22:32:22+00:00,A Bayesian Nonparametric Approach to Dynamical Noise Reduction,"['Konstantinos Kaloudis', 'Spyridon J. Hatjispyros']","We propose a Bayesian nonparametric approach for the noise reduction of a
given chaotic time series contaminated by dynamical noise, based on Markov
Chain Monte Carlo methods (MCMC). The underlying unknown noise process
(possibly) exhibits heavy tailed behavior. We introduce the Dynamic Noise
Reduction Replicator (DNRR) model with which we reconstruct the unknown dynamic
equations and in parallel we replicate the dynamics under reduced noise level
dynamical perturbations. The dynamic noise reduction procedure is demonstrated
specifically in the case of polynomial maps. Simulations based on synthetic
time series are presented.",http://arxiv.org/pdf/1802.01718v2,stat.ME
2018-02-04 02:18:25+00:00,Deep Temporal Clustering : Fully Unsupervised Learning of Time-Domain Features,"['Naveen Sai Madiraju', 'Seid M. Sadat', 'Dimitry Fisher', 'Homa Karimabadi']","Unsupervised learning of time series data, also known as temporal clustering,
is a challenging problem in machine learning. Here we propose a novel
algorithm, Deep Temporal Clustering (DTC), to naturally integrate
dimensionality reduction and temporal clustering into a single end-to-end
learning framework, fully unsupervised. The algorithm utilizes an autoencoder
for temporal dimensionality reduction and a novel temporal clustering layer for
cluster assignment. Then it jointly optimizes the clustering objective and the
dimensionality reduction objec tive. Based on requirement and application, the
temporal clustering layer can be customized with any temporal similarity
metric. Several similarity metrics and state-of-the-art algorithms are
considered and compared. To gain insight into temporal features that the
network has learned for its clustering, we apply a visualization method that
generates a region of interest heatmap for the time series. The viability of
the algorithm is demonstrated using time series data from diverse domains,
ranging from earthquakes to spacecraft sensor data. In each case, we show that
the proposed algorithm outperforms traditional methods. The superior
performance is attributed to the fully integrated temporal dimensionality
reduction and clustering criterion.",http://arxiv.org/pdf/1802.01059v1,cs.LG
2018-01-21 16:28:23+00:00,Time series kernel similarities for predicting Paroxysmal Atrial Fibrillation from ECGs,"['Filippo Maria Bianchi', 'Lorenzo Livi', 'Alberto Ferrante', 'Jelena Milosevic', 'Miroslaw Malek']","We tackle the problem of classifying Electrocardiography (ECG) signals with
the aim of predicting the onset of Paroxysmal Atrial Fibrillation (PAF). Atrial
fibrillation is the most common type of arrhythmia, but in many cases PAF
episodes are asymptomatic. Therefore, in order to help diagnosing PAF, it is
important to design procedures for detecting and, more importantly, predicting
PAF episodes. We propose a method for predicting PAF events whose first step
consists of a feature extraction procedure that represents each ECG as a
multi-variate time series. Successively, we design a classification framework
based on kernel similarities for multi-variate time series, capable of handling
missing data. We consider different approaches to perform classification in the
original space of the multi-variate time series and in an embedding space,
defined by the kernel similarity measure. We achieve a classification accuracy
comparable with state of the art methods, with the additional advantage of
detecting the PAF onset up to 15 minutes in advance.",http://arxiv.org/pdf/1801.06845v2,cs.LG
2018-01-16 12:29:22+00:00,Compositional Correlation for Detecting Real Associations Among Time Series,['Fatih Dikbas'],"Correlation remains to be one of the most widely used statistical tools for
assessing the strength of relationships between data series. This paper
presents a novel compositional correlation method for detecting linear and
nonlinear relationships by considering the averages of all parts of all
possible compositions of the data series instead of considering the averages of
the whole series. The approach enables cumulative contribution of all local
associations to the resulting correlation value. The method is applied on two
different datasets: a set of four simple nonlinear polynomial functions and the
expression time series data of 4381 budding yeast (saccharomyces cerevisiae)
genes. The obtained results show that the introduced compositional correlation
method is capable of determining real direct and inverse linear, nonlinear and
monotonic relationships. Comparisons with Pearson's correlation, Spearman's
correlation, distance correlation and the simulated annealing genetic algorithm
maximal information coefficient (SGMIC) have shown that the presented method is
capable of detecting important associations which were not detected by the
compared methods.",http://arxiv.org/pdf/1801.05029v1,stat.ME
2018-01-14 10:25:58+00:00,On the number of signals in multivariate time series,"['Markus Matilainen', 'Klaus Nordhausen', 'Joni Virta']","We assume a second-order source separation model where the observed
multivariate time series is a linear mixture of latent, temporally uncorrelated
time series with some components pure white noise. To avoid the modelling of
noise, we extract the non-noise latent components using some standard method,
allowing the modelling of the extracted univariate time series individually. An
important question is the determination of which of the latent components are
of interest in modelling and which can be considered as noise. Bootstrap-based
methods have recently been used in determining the latent dimension in various
methods of unsupervised and supervised dimension reduction and we propose a set
of similar estimation strategies for second-order stationary time series.
Simulation studies and a sound wave example are used to show the method's
effectiveness.",http://arxiv.org/pdf/1801.04925v1,stat.ME
2018-01-14 03:00:53+00:00,Multivariate LSTM-FCNs for Time Series Classification,"['Fazle Karim', 'Somshubra Majumdar', 'Houshang Darabi', 'Samuel Harford']","Over the past decade, multivariate time series classification has received
great attention. We propose transforming the existing univariate time series
classification models, the Long Short Term Memory Fully Convolutional Network
(LSTM-FCN) and Attention LSTM-FCN (ALSTM-FCN), into a multivariate time series
classification model by augmenting the fully convolutional block with a
squeeze-and-excitation block to further improve accuracy. Our proposed models
outperform most state-of-the-art models while requiring minimum preprocessing.
The proposed models work efficiently on various complex multivariate time
series classification tasks such as activity recognition or action recognition.
Furthermore, the proposed models are highly efficient at test time and small
enough to deploy on memory constrained systems.",http://arxiv.org/pdf/1801.04503v2,cs.LG
2018-01-13 08:24:15+00:00,Cost-Sensitive Convolution based Neural Networks for Imbalanced Time-Series Classification,"['Yue Geng', 'Xinyu Luo']","Some deep convolutional neural networks were proposed for time-series
classification and class imbalanced problems. However, those models performed
degraded and even failed to recognize the minority class of an imbalanced
temporal sequences dataset. Minority samples would bring troubles for temporal
deep learning classifiers due to the equal treatments of majority and minority
class. Until recently, there were few works applying deep learning on
imbalanced time-series classification (ITSC) tasks. Here, this paper aimed at
tackling ITSC problems with deep learning. An adaptive cost-sensitive learning
strategy was proposed to modify temporal deep learning models. Through the
proposed strategy, classifiers could automatically assign misclassification
penalties to each class. In the experimental section, the proposed method was
utilized to modify five neural networks. They were evaluated on a large volume,
real-life and imbalanced time-series dataset with six metrics. Each single
network was also tested alone and combined with several mainstream data
samplers. Experimental results illustrated that the proposed cost-sensitive
modified networks worked well on ITSC tasks. Compared to other methods, the
cost-sensitive convolution neural network and residual network won out in the
terms of all metrics. Consequently, the proposed cost-sensitive learning
strategy can be used to modify deep learning classifiers from cost-insensitive
to cost-sensitive. Those cost-sensitive convolutional networks can be
effectively applied to address ITSC issues.",http://arxiv.org/pdf/1801.04396v1,cs.LG
2018-01-12 18:34:24+00:00,A note on Herglotz's theorem for time series on function spaces,"['Anne van Delft', 'Michael Eichler']","In this article, we prove Herglotz's theorem for Hilbert-valued time series.
This requires the notion of an operator-valued measure, which we shall make
precise for our setting. Herglotz's theorem for functional time series allows
to generalize existing results that are central to frequency domain analysis on
the function space. In particular, we use this result to prove the existence of
a functional Cram{\'e}r representation of a large class of processes, including
those with jumps in the spectral distribution and long-memory processes. We
furthermore obtain an optimal finite dimensional reduction of the time series
under weaker assumptions than available in the literature. The results of this
paper therefore enable Fourier analysis for processes of which the spectral
density operator does not necessarily exist.",http://arxiv.org/pdf/1801.04262v3,math.ST
2018-01-10 02:48:34+00:00,Multivariate Bayesian Structural Time Series Model,"['S. Rao Jammalamadaka', 'Jinwen Qiu', 'Ning Ning']","This paper deals with inference and prediction for multiple correlated time
series, where one has also the choice of using a candidate pool of
contemporaneous predictors for each target series. Starting with a structural
model for the time-series, Bayesian tools are used for model fitting,
prediction, and feature selection, thus extending some recent work along these
lines for the univariate case. The Bayesian paradigm in this multivariate
setting helps the model avoid overfitting as well as capture correlations among
the multiple time series with the various state components. The model provides
needed flexibility to choose a different set of components and available
predictors for each target series. The cyclical component in the model can
handle large variations in the short term, which may be caused by external
shocks. We run extensive simulations to investigate properties such as
estimation accuracy and performance in forecasting. We then run an empirical
study with one-step-ahead prediction on the max log return of a portfolio of
stocks that involve four leading financial institutions. Both the simulation
studies and the extensive empirical study confirm that this multivariate model
outperforms three other benchmark models, viz. a model that treats each target
series as independent, the autoregressive integrated moving average model with
regression (ARIMAX), and the multivariate ARIMAX (MARIMAX) model.",http://arxiv.org/pdf/1801.03222v2,stat.ML
2018-01-08 10:11:55+00:00,Weak convergence of the sequential empirical copula processes under long-range dependence,['Yusufu Simayi'],"We consider multivariate copula-based stationary time-series under Gaussian
subordination. Observed time series are subordinated to long-range dependent
Gaussian processes and characterized by arbitrary marginal copula
distributions. First of all, we establish limit theorems for the marginal and
quantile marginal empirical processes of multivariate stationary long-range
dependent sequences under Gaussian subordination. Furthermore, we establish the
asymptotic behavior of sequential empirical copula processes under
non-restrictive smoothness assumptions. The limiting processes in the case of
long-memory sequences are quite different from the cases of of i.i.d. and
weakly dependent observations.",http://arxiv.org/pdf/1801.02364v3,math.ST
2017-12-27 17:33:51+00:00,A Composite Quantile Fourier Neural Network for Multi-Step Probabilistic Forecasting of Nonstationary Univariate Time Series,"['Kostas Hatalis', 'Shalinee Kishore']","Point forecasting of univariate time series is a challenging problem with
extensive work having been conducted. However, nonparametric probabilistic
forecasting of time series, such as in the form of quantiles or prediction
intervals is an even more challenging problem. In an effort to expand the
possible forecasting paradigms we devise and explore an extrapolation-based
approach that has not been applied before for probabilistic forecasting. We
present a novel quantile Fourier neural network is for nonparametric
probabilistic forecasting of univariate time series. Multi-step predictions are
provided in the form of composite quantiles using time as the only input to the
model. This effectively is a form of extrapolation based nonlinear quantile
regression applied for forecasting. Experiments are conducted on eight real
world datasets that demonstrate a variety of periodic and aperiodic patterns.
Nine naive and advanced methods are used as benchmarks including quantile
regression neural network, support vector quantile regression, SARIMA, and
exponential smoothing. The obtained empirical results validate the
effectiveness of the proposed method in providing high quality and accurate
probabilistic predictions.",http://arxiv.org/pdf/1712.09641v2,stat.ML
2017-12-26 00:38:39+00:00,Variational Bayes Estimation of Discrete-Margined Copula Models with Application to Time Series,"['Ruben Loaiza-Maya', 'Michael Stanley Smith']","We propose a new variational Bayes estimator for high-dimensional copulas
with discrete, or a combination of discrete and continuous, margins. The method
is based on a variational approximation to a tractable augmented posterior, and
is faster than previous likelihood-based approaches. We use it to estimate
drawable vine copulas for univariate and multivariate Markov ordinal and mixed
time series. These have dimension $rT$, where $T$ is the number of observations
and $r$ is the number of series, and are difficult to estimate using previous
methods. The vine pair-copulas are carefully selected to allow for
heteroskedasticity, which is a feature of most ordinal time series data. When
combined with flexible margins, the resulting time series models also allow for
other common features of ordinal data, such as zero inflation, multiple modes
and under- or over-dispersion. Using six example series, we illustrate both the
flexibility of the time series copula models, and the efficacy of the
variational Bayes estimator for copulas of up to 792 dimensions and 60
parameters. This far exceeds the size and complexity of copula models for
discrete data that can be estimated using previous methods.",http://arxiv.org/pdf/1712.09150v2,stat.ME
2017-12-23 08:22:44+00:00,Online Forecasting Matrix Factorization,"['San Gultekin', 'John Paisley']","In this paper the problem of forecasting high dimensional time series is
considered. Such time series can be modeled as matrices where each column
denotes a measurement. In addition, when missing values are present, low rank
matrix factorization approaches are suitable for predicting future values. This
paper formally defines and analyzes the forecasting problem in the online
setting, i.e. where the data arrives as a stream and only a single pass is
allowed. We present and analyze novel matrix factorization techniques which can
learn low-dimensional embeddings effectively in an online manner. Based on
these embeddings a recursive minimum mean square error estimator is derived,
which learns an autoregressive model on them. Experiments with two real
datasets with tens of millions of measurements show the benefits of the
proposed approach.",http://arxiv.org/pdf/1712.08734v1,cs.LG
2017-12-21 11:04:14+00:00,Multi-task learning of time series and its application to the travel demand,['Boris Chidlovskii'],"We address the problem of modeling and prediction of a set of temporal events
in the context of intelligent transportation systems. To leverage the
information shared by different events, we propose a multi-task learning
framework. We develop a support vector regression model for joint learning of
mutually dependent time series. It is the regularization-based multi-task
learning previously developed for the classification case and extended to time
series. We discuss the relatedness of observed time series and first deploy the
dynamic time warping distance measure to identify groups of similar series.
Then we take into account both time and scale warping and propose to align
multiple time series by inferring their common latent representation. We test
the proposed models on the problem of travel demand prediction in Nancy
(France) public transport system and analyze the benefits of multi-task
learning.",http://arxiv.org/pdf/1712.08164v1,cs.LG
2017-12-20 09:17:40+00:00,EstimatedWold Representation and Spectral Density-Driven Bootstrap for Time Series,"['Jonas Krampe', 'Jens-Peter Kreiss', 'Efstathios Paparoditis']","The second-order dependence structure of purely nondeterministic stationary
process is described by the coefficients of the famous Wold representation.
These coefficients can be obtained by factorizing the spectral density of the
process. This relation together with some spectral density estimator is used in
order to obtain consistent estimators of these coefficients. A spectral
density-driven bootstrap for time series is then developed which uses the
entire sequence of estimated MA coefficients together with appropriately
generated pseudo innovations in order to obtain a bootstrap pseudo time series.
It is shown that if the underlying process is linear and if the pseudo
innovations are generated by means of an i.i.d. wild bootstrap which mimics, to
the necessary extent, the moment structure of the true innovations, this
bootstrap proposal asymptotically works for a wide range of statistics. The
relations of the proposed bootstrap procedure to some other bootstrap
procedures, including the autoregressive-sieve bootstrap, are discussed. It is
shown that the latter is a special case of the spectral density-driven
bootstrap, if a parametric autoregressive spectral density estimator is used.
Simulations investigate the performance of the new bootstrap procedure in
finite sample situations. Furthermore, a real-life data example is presented.",http://arxiv.org/pdf/1712.07371v1,math.ST
2017-12-18 14:40:23+00:00,A Shapelet Transform for Multivariate Time Series Classification,"['Aaron Bostrom', 'Anthony Bagnall']","Shapelets are phase independent subsequences designed for time series
classification. We propose three adaptations to the Shapelet Transform (ST) to
capture multivariate features in multivariate time series classification. We
create a unified set of data to benchmark our work on, and compare with three
other algorithms. We demonstrate that multivariate shapelets are not
significantly worse than other state-of-the-art algorithms.",http://arxiv.org/pdf/1712.06428v1,cs.LG
2017-12-18 11:23:51+00:00,Squeezed Convolutional Variational AutoEncoder for Unsupervised Anomaly Detection in Edge Device Industrial Internet of Things,"['Dohyung Kim', 'Hyochang Yang', 'Minki Chung', 'Sungzoon Cho']","In this paper, we propose Squeezed Convolutional Variational AutoEncoder
(SCVAE) for anomaly detection in time series data for Edge Computing in
Industrial Internet of Things (IIoT). The proposed model is applied to labeled
time series data from UCI datasets for exact performance evaluation, and
applied to real world data for indirect model performance comparison. In
addition, by comparing the models before and after applying Fire Modules from
SqueezeNet, we show that model size and inference times are reduced while
similar levels of performance is maintained.",http://arxiv.org/pdf/1712.06343v1,cs.LG
2017-12-17 16:08:53+00:00,Dynamic Boltzmann Machines for Second Order Moments and Generalized Gaussian Distributions,"['Rudy Raymond', 'Takayuki Osogami', 'Sakyasingha Dasgupta']","Dynamic Boltzmann Machine (DyBM) has been shown highly efficient to predict
time-series data. Gaussian DyBM is a DyBM that assumes the predicted data is
generated by a Gaussian distribution whose first-order moment (mean)
dynamically changes over time but its second-order moment (variance) is fixed.
However, in many financial applications, the assumption is quite limiting in
two aspects. First, even when the data follows a Gaussian distribution, its
variance may change over time. Such variance is also related to important
temporal economic indicators such as the market volatility. Second, financial
time-series data often requires learning datasets generated by the generalized
Gaussian distribution with an additional shape parameter that is important to
approximate heavy-tailed distributions. Addressing those aspects, we show how
to extend DyBM that results in significant performance improvement in
predicting financial time-series data.",http://arxiv.org/pdf/1712.06132v1,stat.ML
2017-12-12 10:46:27+00:00,Causal Patterns: Extraction of multiple causal relationships by Mixture of Probabilistic Partial Canonical Correlation Analysis,"['Hiroki Mori', 'Keisuke Kawano', 'Hiroki Yokoyama']","In this paper, we propose a mixture of probabilistic partial canonical
correlation analysis (MPPCCA) that extracts the Causal Patterns from two
multivariate time series. Causal patterns refer to the signal patterns within
interactions of two elements having multiple types of mutually causal
relationships, rather than a mixture of simultaneous correlations or the
absence of presence of a causal relationship between the elements. In
multivariate statistics, partial canonical correlation analysis (PCCA)
evaluates the correlation between two multivariates after subtracting the
effect of the third multivariate. PCCA can calculate the Granger Causal- ity
Index (which tests whether a time-series can be predicted from an- other
time-series), but is not applicable to data containing multiple partial
canonical correlations. After introducing the MPPCCA, we propose an
expectation-maxmization (EM) algorithm that estimates the parameters and latent
variables of the MPPCCA. The MPPCCA is expected to ex- tract multiple partial
canonical correlations from data series without any supervised signals to split
the data as clusters. The method was then eval- uated in synthetic data
experiments. In the synthetic dataset, our method estimated the multiple
partial canonical correlations more accurately than the existing method. To
determine the types of patterns detectable by the method, experiments were also
conducted on real datasets. The method estimated the communication patterns In
motion-capture data. The MP- PCCA is applicable to various type of signals such
as brain signals, human communication and nonlinear complex multibody systems.",http://arxiv.org/pdf/1712.04221v1,stat.ME
2017-12-10 12:04:19+00:00,Comparative analysis of criteria for filtering time series of word usage frequencies,"['Inna A. Belashova', 'Vladimir V. Bochkarev']","This paper describes a method of nonlinear wavelet thresholding of time
series. The Ramachandran-Ranganathan runs test is used to assess the quality of
approximation. To minimize the objective function, it is proposed to use
genetic algorithms - one of the stochastic optimization methods. The suggested
method is tested both on the model series and on the word frequency series
using the Google Books Ngram data. It is shown that method of filtering which
uses the runs criterion shows significantly better results compared with the
standard wavelet thresholding. The method can be used when quality of filtering
is of primary importance but not the speed of calculations.",http://arxiv.org/pdf/1712.03512v1,stat.ME
2017-12-06 19:32:18+00:00,Predictive inference for locally stationary time series with an application to climate data,"['Srinjoy Das', 'Dimitris N. Politis']","The Model-free Prediction Principle of Politis (2015) has been successfully
applied to general regression problems, as well as problems involving
stationary time series. However, with long time series, e.g. annual temperature
measurements spanning over 100 years or daily financial returns spanning
several years, it may be unrealistic to assume stationarity throughout the span
of the dataset. In the paper at hand, we show how Model-free Prediction can be
applied to handle time series that are only locally stationary, i.e., they can
be assumed to be as stationary only over short time-windows. Surprisingly there
is little literature on point prediction for general locally stationary time
series even in model-based setups and there is no literature on the
construction of prediction intervals of locally stationary time series. We
attempt to fill this gap here as well. Both one-step-ahead point predictors and
prediction intervals are constructed, and the performance of model-free is
compared to model-based prediction using models that incorporate a trend and/or
heteroscedasticity. Both aspects of the paper, model-free and model-based, are
novel in the context of time-series that are locally (but not globally)
stationary. We also demonstrate the application of our Model-based and
Model-free prediction methods to speleothem climate data which exhibits local
stationarity and show that our best model-free point prediction results
outperform that obtained with the RAMPFIT algorithm previously used for
analysis of this data.",http://arxiv.org/pdf/1712.02383v2,stat.ME
2017-11-29 19:01:32+00:00,A Multi-Horizon Quantile Recurrent Forecaster,"['Ruofeng Wen', 'Kari Torkkola', 'Balakrishnan Narayanaswamy', 'Dhruv Madeka']","We propose a framework for general probabilistic multi-step time series
regression. Specifically, we exploit the expressiveness and temporal nature of
Sequence-to-Sequence Neural Networks (e.g. recurrent and convolutional
structures), the nonparametric nature of Quantile Regression and the efficiency
of Direct Multi-Horizon Forecasting. A new training scheme,
*forking-sequences*, is designed for sequential nets to boost stability and
performance. We show that the approach accommodates both temporal and static
covariates, learning across multiple related series, shifting seasonality,
future planned event spikes and cold-starts in real life large-scale
forecasting. The performance of the framework is demonstrated in an application
to predict the future demand of items sold on Amazon.com, and in a public
probabilistic forecasting competition to predict electricity price and load.",http://arxiv.org/pdf/1711.11053v2,stat.ML
2017-11-29 16:22:37+00:00,"Extended Poisson INAR(1) processes with equidispersion, underdispersion and overdispersion","['Marcelo Bourguignon', 'Josemar Rodrigues', 'Manoel Santos-Neto']","Real count data time series often show the phenomenon of the underdispersion
and overdispersion. In this paper, we develop two extensions of the first-order
integer-valued autoregressive process with Poisson innovations, based on
binomial thinning, for modeling integer-valued time series with equidispersion,
underdispersion and overdispersion. The main properties of the models are
derived. The methods of conditional maximum likelihood, Yule-Walker and
conditional least squares are used for estimating the parameters, and their
asymptotic properties are established. We also use a test based on our
processes for checking if the count time series considered is overdispersed or
underdispersed. The proposed models are fitted to time series of number of
weekly sales and of cases of family violence illustrating its capabilities in
challenging cases of overdispersed and underdispersed count data.",http://arxiv.org/pdf/1711.10940v1,stat.ME
2017-11-24 22:22:41+00:00,Warped-Linear Models for Time Series Classification,['Brijnesh J. Jain'],"This article proposes and studies warped-linear models for time series
classification. The proposed models are time-warp invariant analogues of linear
models. Their construction is in line with time series averaging and extensions
of k-means and learning vector quantization to dynamic time warping (DTW)
spaces. The main theoretical result is that warped-linear models correspond to
polyhedral classifiers in Euclidean spaces. This result simplifies the analysis
of time-warp invariant models by reducing to max-linear functions. We exploit
this relationship and derive solutions to the label-dependency problem and the
problem of learning warped-linear models. Empirical results on time series
classification suggest that warped-linear functions better trade solution
quality against computation time than nearest-neighbor and prototype-based
methods.",http://arxiv.org/pdf/1711.09156v1,cs.LG
2017-11-22 17:00:39+00:00,An Efficient ADMM Algorithm for Structural Break Detection in Multivariate Time Series,"['Alex Tank', 'Emily B. Fox', 'Ali Shojaie']","We present an efficient alternating direction method of multipliers (ADMM)
algorithm for segmenting a multivariate non-stationary time series with
structural breaks into stationary regions. We draw from recent work where the
series is assumed to follow a vector autoregressive model within segments and a
convex estimation procedure may be formulated using group fused lasso
penalties. Our ADMM approach first splits the convex problem into a global
quadratic program and a simple group lasso proximal update. We show that the
global problem may be parallelized over rows of the time dependent transition
matrices and furthermore that each subproblem may be rewritten in a form
identical to the log-likelihood of a Gaussian state space model. Consequently,
we develop a Kalman smoothing algorithm to solve the global update in time
linear in the length of the series.",http://arxiv.org/pdf/1711.08392v2,stat.ML
2017-11-22 07:44:20+00:00,An Interpretable and Sparse Neural Network Model for Nonlinear Granger Causality Discovery,"['Alex Tank', 'Ian Cover', 'Nicholas J. Foti', 'Ali Shojaie', 'Emily B. Fox']","While most classical approaches to Granger causality detection repose upon
linear time series assumptions, many interactions in neuroscience and economics
applications are nonlinear. We develop an approach to nonlinear Granger
causality detection using multilayer perceptrons where the input to the network
is the past time lags of all series and the output is the future value of a
single series. A sufficient condition for Granger non-causality in this setting
is that all of the outgoing weights of the input data, the past lags of a
series, to the first hidden layer are zero. For estimation, we utilize a group
lasso penalty to shrink groups of input weights to zero. We also propose a
hierarchical penalty for simultaneous Granger causality and lag estimation. We
validate our approach on simulated data from both a sparse linear
autoregressive model and the sparse and nonlinear Lorenz-96 model.",http://arxiv.org/pdf/1711.08160v2,stat.ML
2017-11-20 19:49:44+00:00,Non-Gaussian Autoregressive Processes with Tukey g-and-h Transformations,"['Yuan Yan', 'Marc Genton']","When performing a time series analysis of continuous data, for example from
climate or environmental problems, the assumption that the process is Gaussian
is often violated. Therefore, we introduce two non-Gaussian autoregressive time
series models that are able to fit skewed and heavy-tailed time series data.
Our two models are based on the Tukey g-and-h transformation. We discuss
parameter estimation, order selection, and forecasting procedures for our
models and examine their performances in a simulation study. We demonstrate the
usefulness of our models by applying them to two sets of wind speed data.",http://arxiv.org/pdf/1711.07516v2,stat.ME
2017-11-15 10:08:27+00:00,Fisher information matrix of binary time series,"['Xu Gao', 'Hernando Ombao', 'Daniel Gillen']","A common approach to analyzing categorical correlated time series data is to
fit a generalized linear model (GLM) with past data as covariate inputs. There
remain challenges to conducting inference for short time series length. By
treating the historical data as covariate inputs, standard errors of estimates
of GLM parameters computed using the empirical Fisher information do not fully
account the auto-correlation in the data. To overcome this serious limitation,
we derive the exact conditional Fisher information matrix of a general logistic
autoregressive model with endogenous covariates for any series length $T$.
Moreover, we also develop an iterative computational formula that allows for
relatively easy implementation of the proposed estimator. Our simulation
studies show that confidence intervals derived using the exact Fisher
information matrix tend to be narrower than those utilizing the empirical
Fisher information matrix while maintaining type I error rates at or below
nominal levels. Further, we establish that the exact Fisher information matrix
approaches, as T tends to infinity, the asymptotic Fisher information matrix
previously derived for binary time series data. The developed exact conditional
Fisher information matrix is applied to time-series data on respiratory rate
among a cohort of expectant mothers where it is found to provide narrower
confidence intervals for functionals of scientific interest and lead to greater
statistical power when compared to the empirical Fisher information matrix.",http://arxiv.org/pdf/1711.05483v2,math.ST
2017-11-13 13:33:46+00:00,Deep-ESN: A Multiple Projection-encoding Hierarchical Reservoir Computing Framework,"['Qianli Ma', 'Lifeng Shen', 'Garrison W. Cottrell']","As an efficient recurrent neural network (RNN) model, reservoir computing
(RC) models, such as Echo State Networks, have attracted widespread attention
in the last decade. However, while they have had great success with time series
data [1], [2], many time series have a multiscale structure, which a
single-hidden-layer RC model may have difficulty capturing. In this paper, we
propose a novel hierarchical reservoir computing framework we call Deep Echo
State Networks (Deep-ESNs). The most distinctive feature of a Deep-ESN is its
ability to deal with time series through hierarchical projections.
Specifically, when an input time series is projected into the high-dimensional
echo-state space of a reservoir, a subsequent encoding layer (e.g., a PCA,
autoencoder, or a random projection) can project the echo-state representations
into a lower-dimensional space. These low-dimensional representations can then
be processed by another ESN. By using projection layers and encoding layers
alternately in the hierarchical framework, a Deep-ESN can not only attenuate
the effects of the collinearity problem in ESNs, but also fully take advantage
of the temporal kernel property of ESNs to explore multiscale dynamics of time
series. To fuse the multiscale representations obtained by each reservoir, we
add connections from each encoding layer to the last output layer. Theoretical
analyses prove that stability of a Deep-ESN is guaranteed by the echo state
property (ESP), and the time complexity is equivalent to a conventional ESN.
Experimental results on some artificial and real world time series demonstrate
that Deep-ESNs can capture multiscale dynamics, and outperform both standard
ESNs and previous hierarchical ESN-based models.",http://arxiv.org/pdf/1711.05255v1,cs.LG
2017-11-10 16:26:14+00:00,Attend and Diagnose: Clinical Time Series Analysis using Attention Models,"['Huan Song', 'Deepta Rajan', 'Jayaraman J. Thiagarajan', 'Andreas Spanias']","With widespread adoption of electronic health records, there is an increased
emphasis for predictive models that can effectively deal with clinical
time-series data. Powered by Recurrent Neural Network (RNN) architectures with
Long Short-Term Memory (LSTM) units, deep neural networks have achieved
state-of-the-art results in several clinical prediction tasks. Despite the
success of RNNs, its sequential nature prohibits parallelized computing, thus
making it inefficient particularly when processing long sequences. Recently,
architectures which are based solely on attention mechanisms have shown
remarkable success in transduction tasks in NLP, while being computationally
superior. In this paper, for the first time, we utilize attention models for
clinical time-series modeling, thereby dispensing recurrence entirely. We
develop the \textit{SAnD} (Simply Attend and Diagnose) architecture, which
employs a masked, self-attention mechanism, and uses positional encoding and
dense interpolation strategies for incorporating temporal order. Furthermore,
we develop a multi-task variant of \textit{SAnD} to jointly infer models with
multiple diagnosis tasks. Using the recent MIMIC-III benchmark datasets, we
demonstrate that the proposed approach achieves state-of-the-art performance in
all tasks, outperforming LSTM models and classical baselines with
hand-engineered features.",http://arxiv.org/pdf/1711.03905v2,stat.ML
2017-11-09 22:15:33+00:00,Interpretable Vector AutoRegressions with Exogenous Time Series,"['Ines Wilms', 'Sumanta Basu', 'Jacob Bien', 'David S. Matteson']","The Vector AutoRegressive (VAR) model is fundamental to the study of
multivariate time series. Although VAR models are intensively investigated by
many researchers, practitioners often show more interest in analyzing VARX
models that incorporate the impact of unmodeled exogenous variables (X) into
the VAR. However, since the parameter space grows quadratically with the number
of time series, estimation quickly becomes challenging. While several proposals
have been made to sparsely estimate large VAR models, the estimation of large
VARX models is under-explored. Moreover, typically these sparse proposals
involve a lasso-type penalty and do not incorporate lag selection into the
estimation procedure. As a consequence, the resulting models may be difficult
to interpret. In this paper, we propose a lag-based hierarchically sparse
estimator, called ""HVARX"", for large VARX models. We illustrate the usefulness
of HVARX on a cross-category management marketing application. Our results show
how it provides a highly interpretable model, and improves out-of-sample
forecast accuracy compared to a lasso-type approach.",http://arxiv.org/pdf/1711.03623v1,stat.ML
2017-11-05 22:03:43+00:00,Multivariate Bayesian Predictive Synthesis in Macroeconomic Forecasting,"['Kenichiro McAlinn', 'Knut Are Aastveit', 'Jouchi Nakajima', 'Mike West']","We develop the methodology and a detailed case study in use of a class of
Bayesian predictive synthesis (BPS) models for multivariate time series
forecasting. This extends the recently introduced foundational framework of BPS
to the multivariate setting, with detailed application in the topical and
challenging context of multi-step macroeconomic forecasting in a monetary
policy setting. BPS evaluates-- sequentially and adaptively over time-- varying
forecast biases and facets of miscalibration of individual forecast densities,
and-- critically-- of time-varying inter-dependencies among them over multiple
series. We develop new BPS methodology for a specific subclass of the dynamic
multivariate latent factor models implied by BPS theory. Structured dynamic
latent factor BPS is here motivated by the application context-- sequential
forecasting of multiple US macroeconomic time series with forecasts generated
from several traditional econometric time series models. The case study
highlights the potential of BPS to improve of forecasts of multiple series at
multiple forecast horizons, and its use in learning dynamic relationships among
forecasting models or agents.",http://arxiv.org/pdf/1711.01667v4,stat.ME
2017-11-02 16:51:06+00:00,Channel masking for multivariate time series shapelets,"['Dripta S. Raychaudhuri', 'Josif Grabocka', 'Lars Schmidt-Thieme']","Time series shapelets are discriminative sub-sequences and their similarity
to time series can be used for time series classification. Initial shapelet
extraction algorithms searched shapelets by complete enumeration of all
possible data sub-sequences. Research on shapelets for univariate time series
proposed a mechanism called shapelet learning which parameterizes the shapelets
and learns them jointly with a prediction model in an optimization procedure.
Trivial extension of this method to multivariate time series does not yield
very good results due to the presence of noisy channels which lead to
overfitting. In this paper we propose a shapelet learning scheme for
multivariate time series in which we introduce channel masks to discount noisy
channels and serve as an implicit regularization.",http://arxiv.org/pdf/1711.00812v1,cs.LG
2017-10-26 19:14:01+00:00,Exact results of the limited penetrable horizontal visibility graph associated to random time series and its application,"['Minggang Wang', 'Andre L. M. Vilela', 'Ruijin Du', 'Longfeng Zhao', 'Gaogao Dong', 'Lixin Tian', 'H. Eugene Stanley']","The limited penetrable horizontal visibility algorithm is a new time analysis
tool and is a further development of the horizontal visibility algorithm. We
present some exact results on the topological properties of the limited
penetrable horizontal visibility graph associated with random series. We show
that the random series maps on a limited penetrable horizontal visibility graph
with exponential degree distribution $P(k)\sim exp[-\lambda (k-2\rho-2)],
\lambda = ln[(2\rho+3)/(2\rho+2)],\rho=0,1,2,...,k=2\rho+2,2\rho+3,...$,
independent of the probability distribution from which the series was
generated. We deduce the exact expressions of the mean degree and the
clustering coefficient and demonstrate the long distance visibility property.
Numerical simulations confirm the accuracy of our theoretical results. We then
examine several deterministic chaotic series (a logistic map, the
H$\acute{e}$non map, the Lorentz system, and an energy price chaotic system)
and a real crude oil price series to test our results. The empirical results
show that the limited penetrable horizontal visibility algorithm is direct, has
a low computational cost when discriminating chaos from uncorrelated
randomness, and is able to measure the global evolution characteristics of the
real time series.",http://arxiv.org/pdf/1710.09877v1,stat.ME
2017-10-23 19:37:00+00:00,A Unified Framework for Long Range and Cold Start Forecasting of Seasonal Profiles in Time Series,"['Christopher Xie', 'Alex Tank', 'Alec Greaves-Tunnell', 'Emily Fox']","Providing long-range forecasts is a fundamental challenge in time series
modeling, which is only compounded by the challenge of having to form such
forecasts when a time series has never previously been observed. The latter
challenge is the time series version of the cold-start problem seen in
recommender systems which, to our knowledge, has not been addressed in previous
work. A similar problem occurs when a long range forecast is required after
only observing a small number of time points --- a warm start forecast. With
these aims in mind, we focus on forecasting seasonal profiles---or baseline
demand---for periods on the order of a year in three cases: the long range case
with multiple previously observed seasonal profiles, the cold start case with
no previous observed seasonal profiles, and the warm start case with only a
single partially observed profile. Classical time series approaches that
perform iterated step-ahead forecasts based on previous observations struggle
to provide accurate long range predictions; in settings with little to no
observed data, such approaches are simply not applicable. Instead, we present a
straightforward framework which combines ideas from high-dimensional regression
and matrix factorization on a carefully constructed data matrix. Key to our
formulation and resulting performance is leveraging (1) repeated patterns over
fixed periods of time and across series, and (2) metadata associated with the
individual series; without this additional data, the cold-start/warm-start
problems are nearly impossible to solve. We demonstrate that our framework can
accurately forecast an array of seasonal profiles on multiple large scale
datasets.",http://arxiv.org/pdf/1710.08473v2,stat.ML
2017-10-18 19:17:43+00:00,"Temporally-Reweighted Chinese Restaurant Process Mixtures for Clustering, Imputing, and Forecasting Multivariate Time Series","['Feras A. Saad', 'Vikash K. Mansinghka']","This article proposes a Bayesian nonparametric method for forecasting,
imputation, and clustering in sparsely observed, multivariate time series data.
The method is appropriate for jointly modeling hundreds of time series with
widely varying, non-stationary dynamics. Given a collection of $N$ time series,
the Bayesian model first partitions them into independent clusters using a
Chinese restaurant process prior. Within a cluster, all time series are modeled
jointly using a novel ""temporally-reweighted"" extension of the Chinese
restaurant process mixture. Markov chain Monte Carlo techniques are used to
obtain samples from the posterior distribution, which are then used to form
predictive inferences. We apply the technique to challenging forecasting and
imputation tasks using seasonal flu data from the US Center for Disease Control
and Prevention, demonstrating superior forecasting accuracy and competitive
imputation accuracy as compared to multiple widely used baselines. We further
show that the model discovers interpretable clusters in datasets with hundreds
of time series, using macroeconomic data from the Gapminder Foundation.",http://arxiv.org/pdf/1710.06900v2,stat.ME
2017-10-16 14:39:38+00:00,Time Series Prediction : Predicting Stock Price,"['Aaron Elliot', 'Cheng Hua Hsu']","Time series forecasting is widely used in a multitude of domains. In this
paper, we present four models to predict the stock price using the SPX index as
input time series data. The martingale and ordinary linear models require the
strongest assumption in stationarity which we use as baseline models. The
generalized linear model requires lesser assumptions but is unable to
outperform the martingale. In empirical testing, the RNN model performs the
best comparing to other two models, because it will update the input through
LSTM instantaneously, but also does not beat the martingale. In addition, we
introduce an online to batch algorithm and discrepancy measure to inform
readers the newest research in time series predicting method, which doesn't
require any stationarity or non mixing assumptions in time series data.
Finally, to apply these forecasting to practice, we introduce basic trading
strategies that can create Win win and Zero sum situations.",http://arxiv.org/pdf/1710.05751v2,stat.ML
2017-10-12 05:28:05+00:00,Deep Learning in Multiple Multistep Time Series Prediction,['Chuanyun Zang'],"The project aims to research on combining deep learning specifically
Long-Short Memory (LSTM) and basic statistics in multiple multistep time series
prediction. LSTM can dive into all the pages and learn the general trends of
variation in a large scope, while the well selected medians for each page can
keep the special seasonality of different pages so that the future trend will
not fluctuate too much from the reality. A recent Kaggle competition on 145K
Web Traffic Time Series Forecasting [1] is used to thoroughly illustrate and
test this idea.",http://arxiv.org/pdf/1710.04373v1,stat.ML
2017-10-09 04:08:15+00:00,Forecasting Across Time Series Databases using Recurrent Neural Networks on Groups of Similar Series: A Clustering Approach,"['Kasun Bandara', 'Christoph Bergmeir', 'Slawek Smyl']","With the advent of Big Data, nowadays in many applications databases
containing large quantities of similar time series are available. Forecasting
time series in these domains with traditional univariate forecasting procedures
leaves great potentials for producing accurate forecasts untapped. Recurrent
neural networks (RNNs), and in particular Long Short-Term Memory (LSTM)
networks, have proven recently that they are able to outperform
state-of-the-art univariate time series forecasting methods in this context
when trained across all available time series. However, if the time series
database is heterogeneous, accuracy may degenerate, so that on the way towards
fully automatic forecasting methods in this space, a notion of similarity
between the time series needs to be built into the methods. To this end, we
present a prediction model that can be used with different types of RNN models
on subgroups of similar time series, which are identified by time series
clustering techniques. We assess our proposed methodology using LSTM networks,
a widely popular RNN variant. Our method achieves competitive results on
benchmarking datasets under competition evaluation procedures. In particular,
in terms of mean sMAPE accuracy, it consistently outperforms the baseline LSTM
model and outperforms all other methods on the CIF2016 forecasting competition
dataset.",http://arxiv.org/pdf/1710.03222v2,cs.LG
2017-10-06 03:39:33+00:00,Discovering Playing Patterns: Time Series Clustering of Free-To-Play Game Data,"['Alain Saas', 'Anna Guitart', 'África Periáñez']","The classification of time series data is a challenge common to all
data-driven fields. However, there is no agreement about which are the most
efficient techniques to group unlabeled time-ordered data. This is because a
successful classification of time series patterns depends on the goal and the
domain of interest, i.e. it is application-dependent.
  In this article, we study free-to-play game data. In this domain, clustering
similar time series information is increasingly important due to the large
amount of data collected by current mobile and web applications. We evaluate
which methods cluster accurately time series of mobile games, focusing on
player behavior data. We identify and validate several aspects of the
clustering: the similarity measures and the representation techniques to reduce
the high dimensionality of time series. As a robustness test, we compare
various temporal datasets of player activity from two free-to-play video-games.
  With these techniques we extract temporal patterns of player behavior
relevant for the evaluation of game events and game-business diagnosis. Our
experiments provide intuitive visualizations to validate the results of the
clustering and to determine the optimal number of clusters. Additionally, we
assess the common characteristics of the players belonging to the same group.
This study allows us to improve the understanding of player dynamics and churn
behavior.",http://arxiv.org/pdf/1710.02268v1,stat.ML
2017-10-05 18:34:25+00:00,Random Walk Null Models for Time Series Data,"['Daryl DeFord', 'Katherine Moore']","Permutation entropy has become a standard tool for time series analysis that
exploits the temporal properties of these data sets. Many current applications
use an approach based on Shannon entropy, which implicitly assumes an
underlying uniform distribution of patterns. In this paper, we analyze random
walk null models for time series and determine the corresponding permutation
distributions. These new techniques allow us to explicitly describe the
behavior of real world data in terms of more complex generative processes.
Additionally, building on recent results of Martinez, we define a validation
measure that allows us to determine when a random walk is an appropriate model
for a time series. We demonstrate the usefulness of our methods using empirical
data drawn from a variety of fields.",http://arxiv.org/pdf/1710.02175v1,stat.ME
2017-10-03 13:38:47+00:00,An Updated Literature Review of Distance Correlation and its Applications to Time Series,"['Dominic Edelmann', 'Konstantinos Fokianos', 'Maria Pitsillou']","The concept of distance covariance/correlation was introduced recently to
characterize dependence among vectors of random variables. We review some
statistical aspects of distance covariance/correlation function and we
demonstrate its applicability to time series analysis. We will see that the
auto-distance covariance/correlation function is able to identify nonlinear
relationships and can be employed for testing the i.i.d.\ hypothesis.
Comparisons with other measures of dependence are included.",http://arxiv.org/pdf/1710.01146v2,stat.ME
2017-10-01 23:28:33+00:00,DeepTFP: Mobile Time Series Data Analytics based Traffic Flow Prediction,"['Yuanfang Chen', 'Falin Chen', 'Yizhi Ren', 'Ting Wu', 'Ye Yao']","Traffic flow prediction is an important research issue to avoid traffic
congestion in transportation systems. Traffic congestion avoiding can be
achieved by knowing traffic flow and then conducting transportation planning.
Achieving traffic flow prediction is challenging as the prediction is affected
by many complex factors such as inter-region traffic, vehicles' relations, and
sudden events. However, as the mobile data of vehicles has been widely
collected by sensor-embedded devices in transportation systems, it is possible
to predict the traffic flow by analysing mobile data. This study proposes a
deep learning based prediction algorithm, DeepTFP, to collectively predict the
traffic flow on each and every traffic road of a city. This algorithm uses
three deep residual neural networks to model temporal closeness, period, and
trend properties of traffic flow. Each residual neural network consists of a
branch of residual convolutional units. DeepTFP aggregates the outputs of the
three residual neural networks to optimize the parameters of a time series
prediction model. Contrast experiments on mobile time series data from the
transportation system of England demonstrate that the proposed DeepTFP
outperforms the Long Short-Term Memory (LSTM) architecture based method in
prediction accuracy.",http://arxiv.org/pdf/1710.01695v1,cs.LG
2017-09-23 13:33:53+00:00,Feature-based time-series analysis,['Ben D. Fulcher'],"This work presents an introduction to feature-based time-series analysis. The
time series as a data type is first described, along with an overview of the
interdisciplinary time-series analysis literature. I then summarize the range
of feature-based representations for time series that have been developed to
aid interpretable insights into time-series structure. Particular emphasis is
given to emerging research that facilitates wide comparison of feature-based
representations that allow us to understand the properties of a time-series
dataset that make it suited to a particular feature-based representation or
analysis algorithm. The future of time-series analysis is likely to embrace
approaches that exploit machine learning methods to partially automate human
learning to aid understanding of the complex dynamical patterns in the time
series we measure from the world.",http://arxiv.org/pdf/1709.08055v2,cs.LG
2017-09-15 17:47:51+00:00,Granger Mediation Analysis of Multiple Time Series with an Application to fMRI,"['Yi Zhao', 'Xi Luo']","It becomes increasingly popular to perform mediation analysis for complex
data from sophisticated experimental studies. In this paper, we present Granger
Mediation Analysis (GMA), a new framework for causal mediation analysis of
multiple time series. This framework is motivated by a functional magnetic
resonance imaging (fMRI) experiment where we are interested in estimating the
mediation effects between a randomized stimulus time series and brain activity
time series from two brain regions. The stable unit treatment assumption for
causal mediation analysis is thus unrealistic for this type of time series
data. To address this challenge, our framework integrates two types of models:
causal mediation analysis across the variables and vector autoregressive models
across the temporal observations. We further extend this framework to handle
multilevel data to address individual variability and correlated errors between
the mediator and the outcome variables. These models not only provide valid
causal mediation for time series data but also model the causal dynamics across
time. We show that the modeling parameters in our models are identifiable, and
we develop computationally efficient methods to maximize the likelihood-based
optimization criteria. Simulation studies show that our method reduces the
estimation bias and improve statistical power, compared to existing approaches.
On a real fMRI data set, our approach not only infers the causal effects of
brain pathways but accurately captures the feedback effect of the outcome
region on the mediator region.",http://arxiv.org/pdf/1709.05328v1,stat.ME
2017-09-11 07:23:57+00:00,Support Spinor Machine,"['Kabin Kanjamapornkul', 'Richard Pinčák', 'Sanphet Chunithpaisan', 'Erik Bartoš']","We generalize a support vector machine to a support spinor machine by using
the mathematical structure of wedge product over vector machine in order to
extend field from vector field to spinor field. The separated hyperplane is
extended to Kolmogorov space in time series data which allow us to extend a
structure of support vector machine to a support tensor machine and a support
tensor machine moduli space. Our performance test on support spinor machine is
done over one class classification of end point in physiology state of time
series data after empirical mode analysis and compared with support vector
machine test. We implement algorithm of support spinor machine by using
Holo-Hilbert amplitude modulation for fully nonlinear and nonstationary time
series data analysis.",http://arxiv.org/pdf/1709.03943v1,cs.LG
2017-09-10 19:29:49+00:00,R2N2: Residual Recurrent Neural Networks for Multivariate Time Series Forecasting,"['Hardik Goel', 'Igor Melnyk', 'Arindam Banerjee']","Multivariate time-series modeling and forecasting is an important problem
with numerous applications. Traditional approaches such as VAR (vector
auto-regressive) models and more recent approaches such as RNNs (recurrent
neural networks) are indispensable tools in modeling time-series data. In many
multivariate time series modeling problems, there is usually a significant
linear dependency component, for which VARs are suitable, and a nonlinear
component, for which RNNs are suitable. Modeling such times series with only
VAR or only RNNs can lead to poor predictive performance or complex models with
large training times. In this work, we propose a hybrid model called R2N2
(Residual RNN), which first models the time series with a simple linear model
(like VAR) and then models its residual errors using RNNs. R2N2s can be trained
using existing algorithms for VARs and RNNs. Through an extensive empirical
evaluation on two real world datasets (aviation and climate domains), we show
that R2N2 is competitive, usually better than VAR or RNN, used alone. We also
show that R2N2 is faster to train as compared to an RNN, while requiring less
number of hidden units.",http://arxiv.org/pdf/1709.03159v1,cs.LG
2017-09-08 13:35:36+00:00,LSTM Fully Convolutional Networks for Time Series Classification,"['Fazle Karim', 'Somshubra Majumdar', 'Houshang Darabi', 'Shun Chen']","Fully convolutional neural networks (FCN) have been shown to achieve
state-of-the-art performance on the task of classifying time series sequences.
We propose the augmentation of fully convolutional networks with long short
term memory recurrent neural network (LSTM RNN) sub-modules for time series
classification. Our proposed models significantly enhance the performance of
fully convolutional networks with a nominal increase in model size and require
minimal preprocessing of the dataset. The proposed Long Short Term Memory Fully
Convolutional Network (LSTM-FCN) achieves state-of-the-art performance compared
to others. We also explore the usage of attention mechanism to improve time
series classification with the Attention Long Short Term Memory Fully
Convolutional Network (ALSTM-FCN). Utilization of the attention mechanism
allows one to visualize the decision process of the LSTM cell. Furthermore, we
propose fine-tuning as a method to enhance the performance of trained models.
An overall analysis of the performance of our model is provided and compared to
other techniques.",http://arxiv.org/pdf/1709.05206v1,cs.LG
2017-09-08 12:24:57+00:00,Combining cumulative sum change-point detection tests for assessing the stationarity of univariate time series,"['Axel Bücher', 'Jean-David Fermanian', 'Ivan Kojadinovic']","We derive tests of stationarity for univariate time series by combining
change-point tests sensitive to changes in the contemporary distribution with
tests sensitive to changes in the serial dependence. The proposed approach
relies on a general procedure for combining dependent tests based on
resampling. After proving the asymptotic validity of the combining procedure
under the conjunction of null hypotheses and investigating its consistency, we
study rank-based tests of stationarity by combining cumulative sum change-point
tests based on the contemporary empirical distribution function and on the
empirical autocopula at a given lag. Extensions based on tests solely focusing
on second-order characteristics are proposed next. The finite-sample behaviors
of all the derived statistical procedures for assessing stationarity are
investigated in large-scale Monte Carlo experiments and illustrations on two
real data sets are provided. Extensions to multivariate time series are briefly
discussed as well.",http://arxiv.org/pdf/1709.02673v3,stat.ME
2017-09-06 17:29:50+00:00,Deep and Confident Prediction for Time Series at Uber,"['Lingxue Zhu', 'Nikolay Laptev']","Reliable uncertainty estimation for time series prediction is critical in
many fields, including physics, biology, and manufacturing. At Uber,
probabilistic time series forecasting is used for robust prediction of number
of trips during special events, driver incentive allocation, as well as
real-time anomaly detection across millions of metrics. Classical time series
models are often used in conjunction with a probabilistic formulation for
uncertainty estimation. However, such models are hard to tune, scale, and add
exogenous variables to. Motivated by the recent resurgence of Long Short Term
Memory networks, we propose a novel end-to-end Bayesian deep model that
provides time series prediction along with uncertainty estimation. We provide
detailed experiments of the proposed solution on completed trips data, and
successfully apply it to large-scale time series anomaly detection at Uber.",http://arxiv.org/pdf/1709.01907v1,stat.ML
2017-09-05 09:27:01+00:00,Boosting the kernelized shapelets: Theory and algorithms for local features,"['Daiki Suehiro', 'Kohei Hatano', 'Eiji Takimoto', 'Shuji Yamamoto', 'Kenichi Bannai', 'Akiko Takeda']","We consider binary classification problems using local features of objects.
One of motivating applications is time-series classification, where features
reflecting some local closeness measure between a time series and a pattern
sequence called shapelet are useful. Despite the empirical success of such
approaches using local features, the generalization ability of resulting
hypotheses is not fully understood and previous work relies on a bunch of
heuristics. In this paper, we formulate a class of hypotheses using local
features, where the richness of features is controlled by kernels. We derive
generalization bounds of sparse ensembles over the class which is exponentially
better than a standard analysis in terms of the number of possible local
features. The resulting optimization problem is well suited to the boosting
approach and the weak learning problem is formulated as a DC program, for which
practical algorithms exist. In preliminary experiments on time-series data
sets, our method achieves competitive accuracy with the state-of-the-art
algorithms with small parameter-tuning cost.",http://arxiv.org/pdf/1709.01300v3,cs.LG
2017-08-30 05:21:26+00:00,Interpretable Categorization of Heterogeneous Time Series Data,"['Ritchie Lee', 'Mykel J. Kochenderfer', 'Ole J. Mengshoel', 'Joshua Silbermann']","Understanding heterogeneous multivariate time series data is important in
many applications ranging from smart homes to aviation. Learning models of
heterogeneous multivariate time series that are also human-interpretable is
challenging and not adequately addressed by the existing literature. We propose
grammar-based decision trees (GBDTs) and an algorithm for learning them. GBDTs
extend decision trees with a grammar framework. Logical expressions derived
from a context-free grammar are used for branching in place of simple
thresholds on attributes. The added expressivity enables support for a wide
range of data types while retaining the interpretability of decision trees. In
particular, when a grammar based on temporal logic is used, we show that GBDTs
can be used for the interpretable classi cation of high-dimensional and
heterogeneous time series data. Furthermore, we show how GBDTs can also be used
for categorization, which is a combination of clustering and generating
interpretable explanations for each cluster. We apply GBDTs to analyze the
classic Australian Sign Language dataset as well as data on near mid-air
collisions (NMACs). The NMAC data comes from aircraft simulations used in the
development of the next-generation Airborne Collision Avoidance System (ACAS
X).",http://arxiv.org/pdf/1708.09121v2,cs.LG
2017-08-17 12:56:15+00:00,A nonparametric test for stationarity in functional time series,"['Anne van Delft', 'Vaidotas Characiejus', 'Holger Dette']","We propose a new measure for stationarity of a functional time series, which
is based on an explicit representation of the $L^2$-distance between the
spectral density operator of a non-stationary process and its best
($L^2$-)approximation by a spectral density operator corresponding to a
stationary process. This distance can easily be estimated by sums of
Hilbert-Schmidt inner products of periodogram operators (evaluated at different
frequencies), and asymptotic normality of an appropriately standardized version
of the estimator can be established for the corresponding estimate under the
null hypothesis and alternative. As a result we obtain a simple asymptotic
frequency domain level $\alpha$ test (using the quantiles of the normal
distribution) for the hypothesis of stationarity of functional time series.
Other applications such as asymptotic confidence intervals for a measure of
stationarity or the construction of tests for ""relevant deviations from
stationarity"", are also briefly mentioned. We demonstrate in a small simulation
study that the new method has very good finite sample properties. Moreover, we
apply our test to annual temperature curves.",http://arxiv.org/pdf/1708.05248v2,stat.ME
2017-08-15 22:16:35+00:00,Forecasting Multiple Time Series with One-Sided Dynamic Principal Components,"['Daniel Peña', 'Ezequiel Smucler', 'Victor J. Yohai']","We define one-sided dynamic principal components (ODPC) for time series as
linear combinations of the present and past values of the series that minimize
the reconstruction mean squared error. Previous definitions of dynamic
principal components depend on past and future values of the series. For this
reason, they are not appropriate for forecasting purposes. On the contrary, it
is shown that the ODPC introduced in this paper can be successfully used for
forecasting high-dimensional multiple time series. An alternating least squares
algorithm to compute the proposed ODPC is presented. We prove that for
stationary and ergodic time series the estimated values converge to their
population analogues. We also prove that asymptotically, when both the number
of series and the sample size go to infinity, if the data follows a dynamic
factor model, the reconstruction obtained with ODPC converges, in mean squared
error, to the common part of the factor model. Monte Carlo results shows that
forecasts obtained by the ODPC compare favourably with other forecasting
methods based on dynamic factor models.",http://arxiv.org/pdf/1708.04705v1,stat.ME
2017-08-08 14:06:30+00:00,Local Gaussian cross-spectrum analysis,"['Lars Arne Jordanger', 'Dag Tjøstheim']","The ordinary spectrum is restricted in its applications, since it is based on
the second order moments (auto and cross-covariances). Alternative approaches
to spectrum analysis have been investigated based on other measures of
dependence. One such approach was developed for univariate time series by the
authors of this paper using the local Gaussian auto-spectrum based on the local
Gaussian auto-correlations. This makes it possible to detect local structures
in univariate time series that looks like white noise when investigated by the
ordinary auto-spectrum. In this paper the local Gaussian approach is extended
to a local Gaussian cross-spectrum for multivariate time series. The local
Gaussian cross-spectrum has the desirable property that it coincides with the
ordinary cross-spectrum for Gaussian time series, which implies that it can be
used to detect non-Gaussian traits in the time series under investigation. In
particular: If the ordinary spectrum is flat, then peaks and troughs of the
local Gaussian spectrum can indicate nonlinear traits, which potentially might
reveal local periodic phenomena that goes undetected in an ordinary spectral
analysis.",http://arxiv.org/pdf/1708.02495v2,stat.ME
2017-08-07 15:27:51+00:00,Nonlinear spectral analysis: A local Gaussian approach,"['Lars Arne Jordanger', 'Dag Tjøstheim']","The spectral distribution $f(\omega)$ of a stationary time series
$\{Y_t\}_{t\in\mathbb{Z}}$ can be used to investigate whether or not periodic
structures are present in $\{Y_t\}_{t\in\mathbb{Z}}$, but $f(\omega)$ has some
limitations due to its dependence on the autocovariances $\gamma(h)$. For
example, $f(\omega)$ can not distinguish white i.i.d. noise from GARCH-type
models (whose terms are dependent, but uncorrelated), which implies that
$f(\omega)$ can be an inadequate tool when $\{Y_t\}_{t\in\mathbb{Z}}$ contains
asymmetries and nonlinear dependencies.
  Asymmetries between the upper and lower tails of a time series can be
investigated by means of the local Gaussian autocorrelations introduced in
Tj{\o}stheim and Hufthammer (2013), and these local measures of dependence can
be used to construct the local Gaussian spectral density presented in this
paper. A key feature of the new local spectral density is that it coincides
with $f(\omega)$ for Gaussian time series, which implies that it can be used to
detect non-Gaussian traits in the time series under investigation. In
particular, if $f(\omega)$ is flat, then peaks and troughs of the new local
spectral density can indicate nonlinear traits, which potentially might
discover local periodic phenomena that remain undetected in an ordinary
spectral analysis.",http://arxiv.org/pdf/1708.02166v4,stat.ME
2017-07-31 22:09:58+00:00,Dynamic Variable Selection with Spike-and-Slab Process Priors,"['Veronika Rockova', 'Kenichiro McAlinn']","We address the problem of dynamic variable selection in time series
regression with unknown residual variances, where the set of active predictors
is allowed to evolve over time. To capture time-varying variable selection
uncertainty, we introduce new dynamic shrinkage priors for the time series of
regression coefficients. These priors are characterized by two main
ingredients: smooth parameter evolutions and intermittent zeroes for modeling
predictive breaks. More formally, our proposed Dynamic Spike-and-Slab (DSS)
priors are constructed as mixtures of two processes: a spike process for the
irrelevant coefficients and a slab autoregressive process for the active
coefficients. The mixing weights are themselves time-varying and depend on
lagged values of the series. Our DSS priors are probabilistically coherent in
the sense that their stationary distribution is fully known and characterized
by spike-and-slab marginals. For posterior sampling over dynamic regression
coefficients, model selection indicators as well as unknown dynamic residual
variances, we propose a Dynamic SSVS algorithm based on forward-filtering and
backward-sampling. To scale our method to large data sets, we develop a Dynamic
EMVS algorithm for MAP smoothing. We demonstrate, through simulation and a
topical macroeconomic dataset, that DSS priors are very effective at separating
active and noisy coefficients. Our fast implementation significantly extends
the reach of spike-and-slab methods to large time series data.",http://arxiv.org/pdf/1708.00085v3,stat.ME
2017-07-11 10:51:42+00:00,DeepTrend: A Deep Hierarchical Neural Network for Traffic Flow Prediction,"['Xingyuan Dai', 'Rui Fu', 'Yilun Lin', 'Li Li', 'Fei-Yue Wang']","In this paper, we consider the temporal pattern in traffic flow time series,
and implement a deep learning model for traffic flow prediction. Detrending
based methods decompose original flow series into trend and residual series, in
which trend describes the fixed temporal pattern in traffic flow and residual
series is used for prediction. Inspired by the detrending method, we propose
DeepTrend, a deep hierarchical neural network used for traffic flow prediction
which considers and extracts the time-variant trend. DeepTrend has two stacked
layers: extraction layer and prediction layer. Extraction layer, a fully
connected layer, is used to extract the time-variant trend in traffic flow by
feeding the original flow series concatenated with corresponding simple average
trend series. Prediction layer, an LSTM layer, is used to make flow prediction
by feeding the obtained trend from the output of extraction layer and
calculated residual series. To make the model more effective, DeepTrend needs
first pre-trained layer-by-layer and then fine-tuned in the entire network.
Experiments show that DeepTrend can noticeably boost the prediction performance
compared with some traditional prediction models and LSTM with detrending based
methods.",http://arxiv.org/pdf/1707.03213v1,cs.LG
2017-07-10 05:50:59+00:00,Composition Properties of Inferential Privacy for Time-Series Data,"['Shuang Song', 'Kamalika Chaudhuri']","With the proliferation of mobile devices and the internet of things,
developing principled solutions for privacy in time series applications has
become increasingly important. While differential privacy is the gold standard
for database privacy, many time series applications require a different kind of
guarantee, and a number of recent works have used some form of inferential
privacy to address these situations.
  However, a major barrier to using inferential privacy in practice is its lack
of graceful composition -- even if the same or related sensitive data is used
in multiple releases that are safe individually, the combined release may have
poor privacy properties. In this paper, we study composition properties of a
form of inferential privacy called Pufferfish when applied to time-series data.
We show that while general Pufferfish mechanisms may not compose gracefully, a
specific Pufferfish mechanism, called the Markov Quilt Mechanism, which was
recently introduced, has strong composition properties comparable to that of
pure differential privacy when applied to time series data.",http://arxiv.org/pdf/1707.02702v1,cs.LG
2017-07-04 17:03:59+00:00,Structured Black Box Variational Inference for Latent Time Series Models,"['Robert Bamler', 'Stephan Mandt']","Continuous latent time series models are prevalent in Bayesian modeling;
examples include the Kalman filter, dynamic collaborative filtering, or dynamic
topic models. These models often benefit from structured, non mean field
variational approximations that capture correlations between time steps. Black
box variational inference with reparameterization gradients (BBVI) allows us to
explore a rich new class of Bayesian non-conjugate latent time series models;
however, a naive application of BBVI to such structured variational models
would scale quadratically in the number of time steps. We describe a BBVI
algorithm analogous to the forward-backward algorithm which instead scales
linearly in time. It allows us to efficiently sample from the variational
distribution and estimate the gradients of the ELBO. Finally, we show results
on the recently proposed dynamic word embedding model, which was trained using
our method.",http://arxiv.org/pdf/1707.01069v1,stat.ML
2017-06-23 19:14:38+00:00,Time series experiments and causal estimands: exact randomization tests and trading,"['Iavor Bojinov', 'Neil Shephard']","We define causal estimands for experiments on single time series, extending
the potential outcome framework to dealing with temporal data. Our approach
allows the estimation of some of these estimands and exact randomization based
p-values for testing causal effects, without imposing stringent assumptions. We
test our methodology on simulated ""potential autoregressions,""which have a
causal interpretation. Our methodology is partially inspired by data from a
large number of experiments carried out by a financial company who compared the
impact of two different ways of trading equity futures contracts. We use our
methodology to make causal statements about their trading methods.",http://arxiv.org/pdf/1706.07840v2,stat.ME
2017-06-23 19:06:13+00:00,TimeNet: Pre-trained deep recurrent neural network for time series classification,"['Pankaj Malhotra', 'Vishnu TV', 'Lovekesh Vig', 'Puneet Agarwal', 'Gautam Shroff']","Inspired by the tremendous success of deep Convolutional Neural Networks as
generic feature extractors for images, we propose TimeNet: a deep recurrent
neural network (RNN) trained on diverse time series in an unsupervised manner
using sequence to sequence (seq2seq) models to extract features from time
series. Rather than relying on data from the problem domain, TimeNet attempts
to generalize time series representation across domains by ingesting time
series from several domains simultaneously. Once trained, TimeNet can be used
as a generic off-the-shelf feature extractor for time series. The
representations or embeddings given by a pre-trained TimeNet are found to be
useful for time series classification (TSC). For several publicly available
datasets from UCR TSC Archive and an industrial telematics sensor data from
vehicles, we observe that a classifier learned over the TimeNet embeddings
yields significantly better performance compared to (i) a classifier learned
over the embeddings given by a domain-specific RNN, as well as (ii) a nearest
neighbor classifier based on Dynamic Time Warping.",http://arxiv.org/pdf/1706.08838v1,cs.LG
2017-06-22 08:57:49+00:00,The Simplicial Characterisation of TS networks: Theory and applications,"['Neelima Gupte', 'N. Nirmal Thyagu', 'Malayaja Chutani']","We use the visibility algorithm to construct the time series networks
obtained from the time series of different dynamical regimes of the logistic
map. We define the simplicial characterisers of networks which can analyse the
simplicial structure at both the global and local levels. These characterisers
are used to analyse the TS networks obtained in different dynamical regimes of
the logisitic map. It is seen that the simplicial characterisers are able to
distinguish between distinct dynamical regimes. We also apply the simplicial
characterisers to time series networks constructed from fMRI data, where the
preliminary results indicate that the characterisers are able to differentiate
between distinct TS networks.",http://arxiv.org/pdf/1707.00013v1,stat.ME
2017-06-20 07:09:19+00:00,A review and comparative study on functional time series techniques,['J. Álvarez-Liébana'],"This paper reviews the main estimation and prediction results derived in the
context of functional time series, when Hilbert and Banach spaces are
considered, specially, in the context of autoregressive processes of order one
(ARH(1) and ARB(1) processes, for H and B being a Hilbert and Banach space,
respectively). Particularly, we pay attention to the estimation and prediction
results, and statistical tests, derived in both parametric and non-parametric
frameworks. A comparative study between different ARH(1) prediction approaches
is developed in the simulation study undertaken.",http://arxiv.org/pdf/1706.06288v1,math.ST
2017-06-18 14:30:01+00:00,Adaptive Bayesian Power Spectrum Analysis of Multivariate Nonstationary Time Series,"['Zeda Li', 'Robert T. Krafty']","This article introduces a nonparametric approach to multivariate time-varying
power spectrum analysis. The procedure adaptively partitions a time series into
an unknown number of approximately stationary segments, where some spectral
components may remain unchanged across segments, allowing components to evolve
differently over time. Local spectra within segments are fit through Whittle
likelihood based penalized spline models of modified Cholesky components, which
provide flexible nonparametric estimates that preserve positive definite
structures of spectral matrices. The approach is formulated in a Bayesian
framework, in which the number and location of partitions are random, and
relies on reversible jump Markov chain and Hamiltonian Monte Carlo methods that
can adapt to the unknown number of segments and parameters. By averaging over
the distribution of partitions, the approach can approximate both abrupt and
slow-varying changes in spectral matrices. Empirical performance is evaluated
in simulation studies and illustrated through analyses of
electroencephalography during sleep and of the El Ni\~no-Southern Oscillation.",http://arxiv.org/pdf/1706.05661v2,stat.ME
2017-06-11 21:45:24+00:00,Conformal k-NN Anomaly Detector for Univariate Data Streams,"['Vladislav Ishimtsev', 'Ivan Nazarov', 'Alexander Bernstein', 'Evgeny Burnaev']","Anomalies in time-series data give essential and often actionable information
in many applications. In this paper we consider a model-free anomaly detection
method for univariate time-series which adapts to non-stationarity in the data
stream and provides probabilistic abnormality scores based on the conformal
prediction paradigm. Despite its simplicity the method performs on par with
complex prediction-based models on the Numenta Anomaly Detection benchmark and
the Yahoo! S5 dataset.",http://arxiv.org/pdf/1706.03412v1,stat.ML
2017-06-10 00:52:05+00:00,Toeplitz Inverse Covariance-Based Clustering of Multivariate Time Series Data,"['David Hallac', 'Sagar Vare', 'Stephen Boyd', 'Jure Leskovec']","Subsequence clustering of multivariate time series is a useful tool for
discovering repeated patterns in temporal data. Once these patterns have been
discovered, seemingly complicated datasets can be interpreted as a temporal
sequence of only a small number of states, or clusters. For example, raw sensor
data from a fitness-tracking application can be expressed as a timeline of a
select few actions (i.e., walking, sitting, running). However, discovering
these patterns is challenging because it requires simultaneous segmentation and
clustering of the time series. Furthermore, interpreting the resulting clusters
is difficult, especially when the data is high-dimensional. Here we propose a
new method of model-based clustering, which we call Toeplitz Inverse
Covariance-based Clustering (TICC). Each cluster in the TICC method is defined
by a correlation network, or Markov random field (MRF), characterizing the
interdependencies between different observations in a typical subsequence of
that cluster. Based on this graphical representation, TICC simultaneously
segments and clusters the time series data. We solve the TICC problem through
alternating minimization, using a variation of the expectation maximization
(EM) algorithm. We derive closed-form solutions to efficiently solve the two
resulting subproblems in a scalable way, through dynamic programming and the
alternating direction method of multipliers (ADMM), respectively. We validate
our approach by comparing TICC to several state-of-the-art baselines in a
series of synthetic experiments, and we then demonstrate on an automobile
sensor dataset how TICC can be used to learn interpretable clusters in
real-world scenarios.",http://arxiv.org/pdf/1706.03161v2,cs.LG
2017-06-09 04:05:01+00:00,Time Series Using Exponential Smoothing Cells,"['Avner Abrami', 'Aleksandr Y. Aravkin', 'Younghun Kim']","Time series analysis is used to understand and predict dynamic processes,
including evolving demands in business, weather, markets, and biological
rhythms. Exponential smoothing is used in all these domains to obtain simple
interpretable models of time series and to forecast future values. Despite its
popularity, exponential smoothing fails dramatically in the presence of
outliers, large amounts of noise, or when the underlying time series changes.
  We propose a flexible model for time series analysis, using exponential
smoothing cells for overlapping time windows. The approach can detect and
remove outliers, denoise data, fill in missing observations, and provide
meaningful forecasts in challenging situations. In contrast to classic
exponential smoothing, which solves a nonconvex optimization problem over the
smoothing parameters and initial state, the proposed approach requires solving
a single structured convex optimization problem. Recent developments in
efficient convex optimization of large-scale dynamic models make the approach
tractable. We illustrate new capabilities using synthetic examples, and then
use the approach to analyze and forecast noisy real-world time series. Code for
the approach and experiments is publicly available.",http://arxiv.org/pdf/1706.02829v4,stat.ML
2017-06-08 22:02:06+00:00,Granger Causality Networks for Categorical Time Series,"['Alex Tank', 'Emily B. Fox', 'Ali Shojaie']","We present a new framework for learning Granger causality networks for
multivariate categorical time series, based on the mixture transition
distribution (MTD) model. Traditionally, MTD is plagued by a nonconvex
objective, non-identifiability, and presence of many local optima. To
circumvent these problems, we recast inference in the MTD as a convex problem.
The new formulation facilitates the application of MTD to high-dimensional
multivariate time series. As a baseline, we also formulate a multi-output
logistic autoregressive model (mLTD), which while a straightforward extension
of autoregressive Bernoulli generalized linear models, has not been previously
applied to the analysis of multivariate categorial time series. We develop
novel identifiability conditions of the MTD model and compare them to those for
mLTD. We further devise novel and efficient optimization algorithm for the MTD
based on the new convex formulation, and compare the MTD and mLTD in both
simulated and real data experiments. Our approach simultaneously provides a
comparison of methods for network inference in categorical time series and
opens the door to modern, regularized inference with the MTD model.",http://arxiv.org/pdf/1706.02781v1,stat.ME
2017-06-08 15:19:02+00:00,Real-valued (Medical) Time Series Generation with Recurrent Conditional GANs,"['Cristóbal Esteban', 'Stephanie L. Hyland', 'Gunnar Rätsch']","Generative Adversarial Networks (GANs) have shown remarkable success as a
framework for training models to produce realistic-looking data. In this work,
we propose a Recurrent GAN (RGAN) and Recurrent Conditional GAN (RCGAN) to
produce realistic real-valued multi-dimensional time series, with an emphasis
on their application to medical data. RGANs make use of recurrent neural
networks in the generator and the discriminator. In the case of RCGANs, both of
these RNNs are conditioned on auxiliary information. We demonstrate our models
in a set of toy datasets, where we show visually and quantitatively (using
sample likelihood and maximum mean discrepancy) that they can successfully
generate realistic time-series. We also describe novel evaluation methods for
GANs, where we generate a synthetic labelled training dataset, and evaluate on
a real test set the performance of a model trained on the synthetic data, and
vice-versa. We illustrate with these metrics that RCGANs can generate
time-series data useful for supervised training, with only minor degradation in
performance on real test data. This is demonstrated on digit classification
from 'serialised' MNIST and by training an early warning system on a medical
dataset of 17,000 patients from an intensive care unit. We further discuss and
analyse the privacy concerns that may arise when using RCGANs to generate
realistic synthetic medical time series data.",http://arxiv.org/pdf/1706.02633v2,stat.ML
2017-06-06 20:46:56+00:00,Inference for heavy tailed stationary time series based on sliding blocks,"['Axel Bücher', 'Johan Segers']","The block maxima method in extreme value theory consists of fitting an
extreme value distribution to a sample of block maxima extracted from a time
series. Traditionally, the maxima are taken over disjoint blocks of
observations. Alternatively, the blocks can be chosen to slide through the
observation period, yielding a larger number of overlapping blocks. Inference
based on sliding blocks is found to be more efficient than inference based on
disjoint blocks. The asymptotic variance of the maximum likelihood estimator of
the Fr\'{e}chet shape parameter is reduced by more than 18%. Interestingly, the
amount of the efficiency gain is the same whatever the serial dependence of the
underlying time series: as for disjoint blocks, the asymptotic distribution
depends on the serial dependence only through the sequence of scaling
constants. The findings are illustrated by simulation experiments and are
applied to the estimation of high return levels of the daily log-returns of the
Standard & Poor's 500 stock market index.",http://arxiv.org/pdf/1706.01968v2,math.ST
2017-06-06 20:10:53+00:00,Sparse causality network retrieval from short time series,"['Tomaso Aste', 'T. Di Matteo']","We investigate how efficiently a known underlying sparse causality structure
of a simulated multivariate linear process can be retrieved from the analysis
of time-series of short lengths. Causality is quantified from conditional
transfer entropy and the network is constructed by retaining only the
statistically validated contributions. We compare results from three
methodologies: two commonly used regularization methods, Glasso and ridge, and
a newly introduced technique, LoGo, based on the combination of information
filtering network and graphical modelling. For these three methodologies we
explore the regions of time series lengths and model-parameters where a
significant fraction of true causality links is retrieved. We conclude that,
when time-series are short, with their lengths shorter than the number of
variables, sparse models are better suited to uncover true causality links with
LoGo retrieving the true causality network more accurately than Glasso and
ridge.",http://arxiv.org/pdf/1706.01954v2,stat.ME
2017-06-05 09:04:07+00:00,Bayesian LSTMs in medicine,"['Jos van der Westhuizen', 'Joan Lasenby']","The medical field stands to see significant benefits from the recent advances
in deep learning. Knowing the uncertainty in the decision made by any machine
learning algorithm is of utmost importance for medical practitioners. This
study demonstrates the utility of using Bayesian LSTMs for classification of
medical time series. Four medical time series datasets are used to show the
accuracy improvement Bayesian LSTMs provide over standard LSTMs. Moreover, we
show cherry-picked examples of confident and uncertain classifications of the
medical time series. With simple modifications of the common practice for deep
learning, significant improvements can be made for the medical practitioner and
patient.",http://arxiv.org/pdf/1706.01242v1,stat.ML
2017-06-03 13:11:01+00:00,Financial Series Prediction: Comparison Between Precision of Time Series Models and Machine Learning Methods,['Xin-Yao Qian'],"Precise financial series predicting has long been a difficult problem because
of unstableness and many noises within the series. Although Traditional time
series models like ARIMA and GARCH have been researched and proved to be
effective in predicting, their performances are still far from satisfying.
Machine Learning, as an emerging research field in recent years, has brought
about many incredible improvements in tasks such as regressing and classifying,
and it's also promising to exploit the methodology in financial time series
predicting. In this paper, the predicting precision of financial time series
between traditional time series models and mainstream machine learning models
including some state-of-the-art ones of deep learning are compared through
experiment using real stock index data from history. The result shows that
machine learning as a modern method far surpasses traditional models in
precision.",http://arxiv.org/pdf/1706.00948v5,cs.LG
2017-05-31 00:31:27+00:00,An empirical evaluation of alternative methods of estimation for Permutation Entropy in time series with tied values,"['Francisco Traversaro', 'Marcelo Risk', 'Osvaldo Rosso', 'Francisco Redelico']","Bandt and Pompe introduced Permutation Entropy in 2002 for Time Series where
equal values, xt1 = xt2, t1 = t2, were neglected and only inequalities between
the xt were considered. Since then, this measure has been modified and
extended, in particular in cases when the amount of equal values in the series
can not be neglected, (i.e. heart rate variability (HRV) time series). We
review the different existing methodologies that treats this subject by
classifying them according to their different strategies. In addition, a novel
Bayesian Missing Data Imputation is presented that proves to outperform the
existing methodologies that deals with type of time series. All this facts are
illustrated by simulations and also by distinguishing patients suffering from
Congestive Heart Failure from a (healthy) control group using HRV time series",http://arxiv.org/pdf/1707.01517v1,stat.ME
2017-05-24 22:23:14+00:00,Modeling The Intensity Function Of Point Process Via Recurrent Neural Networks,"['Shuai Xiao', 'Junchi Yan', 'Stephen M. Chu', 'Xiaokang Yang', 'Hongyuan Zha']","Event sequence, asynchronously generated with random timestamp, is ubiquitous
among applications. The precise and arbitrary timestamp can carry important
clues about the underlying dynamics, and has lent the event data fundamentally
different from the time-series whereby series is indexed with fixed and equal
time interval. One expressive mathematical tool for modeling event is point
process. The intensity functions of many point processes involve two
components: the background and the effect by the history. Due to its inherent
spontaneousness, the background can be treated as a time series while the other
need to handle the history events. In this paper, we model the background by a
Recurrent Neural Network (RNN) with its units aligned with time series indexes
while the history effect is modeled by another RNN whose units are aligned with
asynchronous events to capture the long-range dynamics. The whole model with
event type and timestamp prediction output layers can be trained end-to-end.
Our approach takes an RNN perspective to point process, and models its
background and history effect. For utility, our method allows a black-box
treatment for modeling the intensity which is often a pre-defined parametric
form in point processes. Meanwhile end-to-end training opens the venue for
reusing existing rich techniques in deep network for point process modeling. We
apply our model to the predictive maintenance problem using a log dataset by
more than 1000 ATMs from a global bank headquartered in North America.",http://arxiv.org/pdf/1705.08982v1,cs.LG
2017-05-22 08:27:37+00:00,A copula approach for dependence modeling in multivariate nonparametric time series,"['Natalie Neumeyer', 'Marek Omelka', 'Sarka Hudecova']","This paper is concerned with modeling the dependence structure of two (or
more) time-series in the presence of a (possible multivariate) covariate which
may include past values of the time series. We assume that the covariate
influences only the conditional mean and the conditional variance of each of
the time series but the distribution of the standardized innovations is not
influenced by the covariate and is stable in time. The joint distribution of
the time series is then determined by the conditional means, the conditional
variances and the marginal distributions of the innovations, which we estimate
nonparametrically, and the copula of the innovations, which represents the
dependency structure. We consider a nonparametric as well as a semiparametric
estimator based on the estimated residuals. We show that under suitable
assumptions these copula estimators are asymptotically equivalent to estimators
that would be based on the unobserved innovations. The theoretical results are
illustrated by simulations and a real data example.",http://arxiv.org/pdf/1705.07605v2,math.ST
2017-05-18 03:17:02+00:00,Confidence Intervals and Hypothesis Testing for the Permutation Entropy with an application to Epilepsy,"['Francisco Traversaro', 'Francisco Redelico']","In nonlinear dynamics, and to a lesser extent in other fields, a widely used
measure of complexity is the Permutation Entropy. But there is still no known
method to determine the accuracy of this measure. There has been little
research on the statistical properties of this quantity that characterize time
series. The literature describes some resampling methods of quantities used in
nonlinear dynamics - as the largest Lyapunov exponent - but all of these seems
to fail. In this contribution we propose a parametric bootstrap methodology
using a symbolic representation of the time series in order to obtain the
distribution of the Permutation Entropy estimator. We perform several time
series simulations given by well known stochastic processes: the 1=f? noise
family, and show in each case that the proposed accuracy measure is as
efficient as the one obtained by the frequentist approach of repeating the
experiment. The complexity of brain electrical activity, measured by the
Permutation Entropy, has been extensively used in epilepsy research for
detection in dynamical changes in electroencephalogram (EEG) signal with no
consideration of the variability of this complexity measure. An application of
the parametric bootstrap methodology is used to compare normal and pre-ictal
EEG signals.",http://arxiv.org/pdf/1705.06732v1,stat.ME
2017-05-16 12:41:25+00:00,Optimal Warping Paths are unique for almost every Pair of Time Series,"['Brijnesh J. Jain', 'David Schultz']","Update rules for learning in dynamic time warping spaces are based on optimal
warping paths between parameter and input time series. In general, optimal
warping paths are not unique resulting in adverse effects in theory and
practice. Under the assumption of squared error local costs, we show that no
two warping paths have identical costs almost everywhere in a measure-theoretic
sense. Two direct consequences of this result are: (i) optimal warping paths
are unique almost everywhere, and (ii) the set of all pairs of time series with
multiple equal-cost warping paths coincides with the union of exponentially
many zero sets of quadratic forms. One implication of the proposed results is
that typical distance-based cost functions such as the k-means objective are
differentiable almost everywhere and can be minimized by subgradient methods.",http://arxiv.org/pdf/1705.05681v2,cs.LG
2017-05-13 13:31:49+00:00,Tests for comparing time-invariant and time-varying spectra based on the Anderson-Darling statistic,"['Shibin Zhang', 'Xin M. Tu']","Based on periodogram-ratios of two univariate time series at different
frequency points, two tests are proposed for comparing their spectra. One is an
Anderson-Darling-like statistic for testing the equality of two time-invariant
spectra. The other is the maximum of Anderson-Darling-like statistics for
testing the equality of two spectra no matter that they are time-invariant and
time-varying. Both of two tests are applicable for independent or dependent
time series. Several simulation examples show that the proposed statistics
outperform those that are also based on periodogram-ratios but constructed by
the Pearson-like statistics.",http://arxiv.org/pdf/1705.04821v3,stat.ME
2017-05-13 06:00:01+00:00,ShortFuse: Biomedical Time Series Representations in the Presence of Structured Information,"['Madalina Fiterau', 'Suvrat Bhooshan', 'Jason Fries', 'Charles Bournhonesque', 'Jennifer Hicks', 'Eni Halilaj', 'Christopher Ré', 'Scott Delp']","In healthcare applications, temporal variables that encode movement, health
status and longitudinal patient evolution are often accompanied by rich
structured information such as demographics, diagnostics and medical exam data.
However, current methods do not jointly optimize over structured covariates and
time series in the feature extraction process. We present ShortFuse, a method
that boosts the accuracy of deep learning models for time series by explicitly
modeling temporal interactions and dependencies with structured covariates.
ShortFuse introduces hybrid convolutional and LSTM cells that incorporate the
covariates via weights that are shared across the temporal domain. ShortFuse
outperforms competing models by 3% on two biomedical applications, forecasting
osteoarthritis-related cartilage degeneration and predicting surgical outcomes
for cerebral palsy patients, matching or exceeding the accuracy of models that
use features engineered by domain experts.",http://arxiv.org/pdf/1705.04790v2,stat.ML
2017-04-17 17:10:28+00:00,Hidden Markov model for discrete circular-linear wind data time series,"['Gianluca Mastrantonio', 'Gianfranco Calise']","In this work, we deal with a bivariate time series of wind speed and
direction. Our observed data have peculiar features, such as informative
missing values, non-reliable measures under a specific condition and
interval-censored data, that we take into account in the model specification.
We analyze the time series with a non-parametric Bayesian hidden Markov model,
introducing a new emission distribution based on the invariant wrapped Poisson,
the Poisson and the hurdle density, suitable to model our data. The model is
estimated on simulated datasets and on the real data example that motivated
this work.",http://arxiv.org/pdf/1704.05037v1,stat.ME
2017-04-08 18:29:02+00:00,Identifiability and Estimation of Structural Vector Autoregressive Models for Subsampled and Mixed Frequency Time Series,"['Alex Tank', 'Emily B. Fox', 'Ali Shojaie']","Causal inference in multivariate time series is challenging due to the fact
that the sampling rate may not be as fast as the timescale of the causal
interactions. In this context, we can view our observed series as a subsampled
version of the desired series. Furthermore, due to technological and other
limitations, series may be observed at different sampling rates, representing a
mixed frequency setting. To determine instantaneous and lagged effects between
time series at the true causal scale, we take a model-based approach based on
structural vector autoregressive (SVAR) models. In this context, we present a
unifying framework for parameter identifiability and estimation under both
subsampling and mixed frequencies when the noise, or shocks, are non-Gaussian.
Importantly, by studying the SVAR case, we are able to both provide
identifiability and estimation methods for the causal structure of both lagged
and instantaneous effects at the desired time scale. We further derive an exact
EM algorithm for inference in both subsampled and mixed frequency settings. We
validate our approach in simulated scenarios and on two real world data sets.",http://arxiv.org/pdf/1704.02519v1,stat.ME
2017-04-07 23:50:09+00:00,A Dual-Stage Attention-Based Recurrent Neural Network for Time Series Prediction,"['Yao Qin', 'Dongjin Song', 'Haifeng Chen', 'Wei Cheng', 'Guofei Jiang', 'Garrison Cottrell']","The Nonlinear autoregressive exogenous (NARX) model, which predicts the
current value of a time series based upon its previous values as well as the
current and past values of multiple driving (exogenous) series, has been
studied for decades. Despite the fact that various NARX models have been
developed, few of them can capture the long-term temporal dependencies
appropriately and select the relevant driving series to make predictions. In
this paper, we propose a dual-stage attention-based recurrent neural network
(DA-RNN) to address these two issues. In the first stage, we introduce an input
attention mechanism to adaptively extract relevant driving series (a.k.a.,
input features) at each time step by referring to the previous encoder hidden
state. In the second stage, we use a temporal attention mechanism to select
relevant encoder hidden states across all time steps. With this dual-stage
attention scheme, our model can not only make predictions effectively, but can
also be easily interpreted. Thorough empirical studies based upon the SML 2010
dataset and the NASDAQ 100 Stock dataset demonstrate that the DA-RNN can
outperform state-of-the-art methods for time series prediction.",http://arxiv.org/pdf/1704.02971v4,cs.LG
2017-04-03 20:16:58+00:00,Time Series Cluster Kernel for Learning Similarities between Multivariate Time Series with Missing Data,"['Karl Øyvind Mikalsen', 'Filippo Maria Bianchi', 'Cristina Soguero-Ruiz', 'Robert Jenssen']","Similarity-based approaches represent a promising direction for time series
analysis. However, many such methods rely on parameter tuning, and some have
shortcomings if the time series are multivariate (MTS), due to dependencies
between attributes, or the time series contain missing data. In this paper, we
address these challenges within the powerful context of kernel methods by
proposing the robust \emph{time series cluster kernel} (TCK). The approach
taken leverages the missing data handling properties of Gaussian mixture models
(GMM) augmented with informative prior distributions. An ensemble learning
approach is exploited to ensure robustness to parameters by combining the
clustering results of many GMM to form the final kernel.
  We evaluate the TCK on synthetic and real data and compare to other
state-of-the-art techniques. The experimental results demonstrate that the TCK
is robust to parameter choices, provides competitive results for MTS without
missing data and outstanding results for missing data.",http://arxiv.org/pdf/1704.00794v2,stat.ML
2017-04-02 15:29:15+00:00,Inference for the cross-covariance operator of stationary functional time series,"['Gregory Rice', 'Marco Shum']","When considering two or more time series of functions or curves, for instance
those derived from densely observed intraday stock price data of several
companies, the empirical cross-covariance operator is of fundamental importance
due to its role in functional lagged regression and exploratory data analysis.
Despite its relevance, statistical procedures for measuring the significance of
such estimators are undeveloped. We present methodology based on a functional
central limit theorem for conducting statistical inference for the
cross-covariance operator estimated between two stationary, weakly dependent,
functional time series. Specifically, we consider testing the null hypothesis
that two series possess a specified cross-covariance structure at a given lag.
Since this test assumes that the series are jointly stationary, we also develop
a change-point detection procedure to validate this assumption, which is of
independent interest. The most imposing technical hurdle in implementing the
proposed tests involves estimating the spectrum of a high dimensional spectral
density operator at frequency zero. We propose a simple dimension reduction
procedure based on functional PCA to achieve this, which is shown to perform
well in a small simulation study. We illustrate the proposed methodology with
an application to densely observed intraday price data of stocks listed on the
NYSE.",http://arxiv.org/pdf/1704.00315v1,math.ST
2017-03-30 09:43:35+00:00,Blind source separation of tensor-valued time series,"['Joni Virta', 'Klaus Nordhausen']","The blind source separation model for multivariate time series generally
assumes that the observed series is a linear transformation of an unobserved
series with temporally uncorrelated or independent components. Given the
observations, the objective is to find a linear transformation that recovers
the latent series. Several methods for accomplishing this exist and three
particular ones are the classic SOBI and the recently proposed generalized FOBI
(gFOBI) and generalized JADE (gJADE), each based on the use of joint lagged
moments. In this paper we generalize the methodologies behind these algorithms
for tensor-valued time series. We assume that our data consists of a tensor
observed at each time point and that the observations are linear
transformations of latent tensors we wish to estimate. The tensorial
generalizations are shown to have particularly elegant forms and we show that
each of them is Fisher consistent and orthogonal equivariant. Comparing the new
methods with the original ones in various settings shows that the tensorial
extensions are superior to both their vector-valued counterparts and to two
existing tensorial dimension reduction methods for i.i.d. data. Finally,
applications to fMRI-data and video processing show that the methods are
capable of extracting relevant information from noisy high-dimensional data.",http://arxiv.org/pdf/1703.10381v1,math.ST
2017-03-29 15:11:16+00:00,Position-based Content Attention for Time Series Forecasting with Sequence-to-sequence RNNs,"['Yagmur G. Cinar', 'Hamid Mirisaee', 'Parantapa Goswami', 'Eric Gaussier', 'Ali Ait-Bachir', 'Vadim Strijov']","We propose here an extended attention model for sequence-to-sequence
recurrent neural networks (RNNs) designed to capture (pseudo-)periods in time
series. This extended attention model can be deployed on top of any RNN and is
shown to yield state-of-the-art performance for time series forecasting on
several univariate and multivariate time series.",http://arxiv.org/pdf/1703.10089v2,cs.LG
2017-03-29 09:05:40+00:00,Grouped Convolutional Neural Networks for Multivariate Time Series,"['Subin Yi', 'Janghoon Ju', 'Man-Ki Yoon', 'Jaesik Choi']","Analyzing multivariate time series data is important for many applications
such as automated control, fault diagnosis and anomaly detection. One of the
key challenges is to learn latent features automatically from dynamically
changing multivariate input. In visual recognition tasks, convolutional neural
networks (CNNs) have been successful to learn generalized feature extractors
with shared parameters over the spatial domain. However, when high-dimensional
multivariate time series is given, designing an appropriate CNN model structure
becomes challenging because the kernels may need to be extended through the
full dimension of the input volume. To address this issue, we present two
structure learning algorithms for deep CNN models. Our algorithms exploit the
covariance structure over multiple time series to partition input volume into
groups. The first algorithm learns the group CNN structures explicitly by
clustering individual input sequences. The second algorithm learns the group
CNN structures implicitly from the error backpropagation. In experiments with
two real-world datasets, we demonstrate that our group CNNs outperform existing
CNN based regression methods.",http://arxiv.org/pdf/1703.09938v4,cs.LG
2017-03-28 12:10:45+00:00,Discovering Latent Covariance Structures for Multiple Time Series,"['Anh Tong', 'Jaesik Choi']","Analyzing multivariate time series data is important to predict future events
and changes of complex systems in finance, manufacturing, and administrative
decisions. The expressiveness power of Gaussian Process (GP) regression methods
has been significantly improved by compositional covariance structures. In this
paper, we present a new GP model which naturally handles multiple time series
by placing an Indian Buffet Process (IBP) prior on the presence of shared
kernels. Our selective covariance structure decomposition allows exploiting
shared parameters over a set of multiple, selected time series. We also
investigate the well-definedness of the models when infinite latent components
are introduced. We present a pragmatic search algorithm which explores a larger
structure space efficiently. Experiments conducted on five real-world data sets
demonstrate that our new model outperforms existing methods in term of
structure discoveries and predictive performances.",http://arxiv.org/pdf/1703.09528v4,stat.ML
2017-03-24 20:59:52+00:00,The Inner Structure of Time-Dependent Signals,['David N. Levin'],"This paper shows how a time series of measurements of an evolving system can
be processed to create an inner time series that is unaffected by any
instantaneous invertible, possibly nonlinear transformation of the
measurements. An inner time series contains information that does not depend on
the nature of the sensors, which the observer chose to monitor the system.
Instead, it encodes information that is intrinsic to the evolution of the
observed system. Because of its sensor-independence, an inner time series may
produce fewer false negatives when it is used to detect events in the presence
of sensor drift. Furthermore, if the observed physical system is comprised of
non-interacting subsystems, its inner time series is separable; i.e., it
consists of a collection of time series, each one being the inner time series
of an isolated subsystem. Because of this property, an inner time series can be
used to detect a specific behavior of one of the independent subsystems without
using blind source separation to disentangle that subsystem from the others.
The method is illustrated by applying it to: 1) an analytic example; 2) the
audio waveform of one speaker; 3) video images from a moving camera; 4)
mixtures of audio waveforms of two speakers.",http://arxiv.org/pdf/1703.08596v1,stat.ME
2017-03-24 17:29:14+00:00,Joint Modeling of Event Sequence and Time Series with Attentional Twin Recurrent Neural Networks,"['Shuai Xiao', 'Junchi Yan', 'Mehrdad Farajtabar', 'Le Song', 'Xiaokang Yang', 'Hongyuan Zha']","A variety of real-world processes (over networks) produce sequences of data
whose complex temporal dynamics need to be studied. More especially, the event
timestamps can carry important information about the underlying network
dynamics, which otherwise are not available from the time-series evenly sampled
from continuous signals. Moreover, in most complex processes, event sequences
and evenly-sampled times series data can interact with each other, which
renders joint modeling of those two sources of data necessary. To tackle the
above problems, in this paper, we utilize the rich framework of (temporal)
point processes to model event data and timely update its intensity function by
the synergic twin Recurrent Neural Networks (RNNs). In the proposed
architecture, the intensity function is synergistically modulated by one RNN
with asynchronous events as input and another RNN with time series as input.
Furthermore, to enhance the interpretability of the model, the attention
mechanism for the neural point process is introduced. The whole model with
event type and timestamp prediction output layers can be trained end-to-end and
allows a black-box treatment for modeling the intensity. We substantiate the
superiority of our model in synthetic data and three real-world benchmark
datasets.",http://arxiv.org/pdf/1703.08524v1,cs.LG
2017-03-21 00:33:36+00:00,Modeling Long- and Short-Term Temporal Patterns with Deep Neural Networks,"['Guokun Lai', 'Wei-Cheng Chang', 'Yiming Yang', 'Hanxiao Liu']","Multivariate time series forecasting is an important machine learning problem
across many domains, including predictions of solar plant energy output,
electricity consumption, and traffic jam situation. Temporal data arise in
these real-world applications often involves a mixture of long-term and
short-term patterns, for which traditional approaches such as Autoregressive
models and Gaussian Process may fail. In this paper, we proposed a novel deep
learning framework, namely Long- and Short-term Time-series network (LSTNet),
to address this open challenge. LSTNet uses the Convolution Neural Network
(CNN) and the Recurrent Neural Network (RNN) to extract short-term local
dependency patterns among variables and to discover long-term patterns for time
series trends. Furthermore, we leverage traditional autoregressive model to
tackle the scale insensitive problem of the neural network model. In our
evaluation on real-world data with complex mixtures of repetitive patterns,
LSTNet achieved significant performance improvements over that of several
state-of-the-art baseline methods. All the data and experiment codes are
available online.",http://arxiv.org/pdf/1703.07015v3,cs.LG
2017-03-14 20:07:12+00:00,Conditional Time Series Forecasting with Convolutional Neural Networks,"['Anastasia Borovykh', 'Sander Bohte', 'Cornelis W. Oosterlee']","We present a method for conditional time series forecasting based on an
adaptation of the recent deep convolutional WaveNet architecture. The proposed
network contains stacks of dilated convolutions that allow it to access a broad
range of history when forecasting, a ReLU activation function and conditioning
is performed by applying multiple convolutional filters in parallel to separate
time series which allows for the fast processing of data and the exploitation
of the correlation structure between the multivariate time series. We test and
analyze the performance of the convolutional network both unconditionally as
well as conditionally for financial time series forecasting using the S&P500,
the volatility index, the CBOE interest rate and several exchange rates and
extensively compare it to the performance of the well-known autoregressive
model and a long-short term memory network. We show that a convolutional
network is well-suited for regression-type problems and is able to effectively
learn dependencies in and between the series without the need for long
historical time series, is a time-efficient and easy to implement alternative
to recurrent-type networks and tends to outperform linear and recurrent models.",http://arxiv.org/pdf/1703.04691v5,stat.ML
2017-03-12 14:03:19+00:00,Autoregressive Convolutional Neural Networks for Asynchronous Time Series,"['Mikołaj Bińkowski', 'Gautier Marti', 'Philippe Donnat']","We propose Significance-Offset Convolutional Neural Network, a deep
convolutional network architecture for regression of multivariate asynchronous
time series. The model is inspired by standard autoregressive (AR) models and
gating mechanisms used in recurrent neural networks. It involves an AR-like
weighting system, where the final predictor is obtained as a weighted sum of
adjusted regressors, while the weights are datadependent functions learnt
through a convolutional network. The architecture was designed for applications
on asynchronous time series and is evaluated on such datasets: a hedge fund
proprietary dataset of over 2 million quotes for a credit derivative index, an
artificially generated noisy autoregressive series and UCI household
electricity consumption dataset. The proposed architecture achieves promising
results as compared to convolutional and recurrent neural networks.",http://arxiv.org/pdf/1703.04122v4,cs.LG
2017-03-05 01:30:28+00:00,Soft-DTW: a Differentiable Loss Function for Time-Series,"['Marco Cuturi', 'Mathieu Blondel']","We propose in this paper a differentiable learning loss between time series,
building upon the celebrated dynamic time warping (DTW) discrepancy. Unlike the
Euclidean distance, DTW can compare time series of variable size and is robust
to shifts or dilatations across the time dimension. To compute DTW, one
typically solves a minimal-cost alignment problem between two time series using
dynamic programming. Our work takes advantage of a smoothed formulation of DTW,
called soft-DTW, that computes the soft-minimum of all alignment costs. We show
in this paper that soft-DTW is a differentiable loss function, and that both
its value and gradient can be computed with quadratic time/space complexity
(DTW has quadratic time but linear space complexity). We show that this
regularization is particularly well suited to average and cluster time series
under the DTW geometry, a task for which our proposal significantly outperforms
existing baselines. Next, we propose to tune the parameters of a machine that
outputs time series by minimizing its fit with ground-truth labels in a
soft-DTW sense.",http://arxiv.org/pdf/1703.01541v2,stat.ML
2017-03-02 07:31:13+00:00,Inference for Multiple Change-points in Linear and Non-linear Time Series Models,"['Wai Leong Ng', 'Shenyi Pan', 'Chun Yip Yau']","In this paper we develop a generalized likelihood ratio scan method (GLRSM)
for multiple change-points inference in piecewise stationary time series, which
estimates the number and positions of change-points and provides a confidence
interval for each change-point. The computational complexity of using GLRSM for
multiple change-points detection is as low as $O(n(\log n)^3)$ for a series of
length $n$. Consistency of the estimated numbers and positions of the
change-points is established. Extensive simulation studies are provided to
demonstrate the effectiveness of the proposed methodology under different
scenarios.",http://arxiv.org/pdf/1703.00647v1,math.ST
2017-02-22 21:09:19+00:00,Detecting causal associations in large nonlinear time series datasets,"['Jakob Runge', 'Peer Nowack', 'Marlene Kretschmer', 'Seth Flaxman', 'Dino Sejdinovic']","Identifying causal relationships from observational time series data is a key
problem in disciplines such as climate science or neuroscience, where
experiments are often not possible. Data-driven causal inference is challenging
since datasets are often high-dimensional and nonlinear with limited sample
sizes. Here we introduce a novel method that flexibly combines linear or
nonlinear conditional independence tests with a causal discovery algorithm that
allows to reconstruct causal networks from large-scale time series datasets. We
validate the method on a well-established climatic teleconnection connecting
the tropical Pacific with extra-tropical temperatures and using large-scale
synthetic datasets mimicking the typical properties of real data. The
experiments demonstrate that our method outperforms alternative techniques in
detection power from small to large-scale datasets and opens up entirely new
possibilities to discover causal networks from time series across a range of
research fields.",http://arxiv.org/pdf/1702.07007v2,stat.ME
2017-02-22 09:07:00+00:00,Ensembles of Randomized Time Series Shapelets Provide Improved Accuracy while Reducing Computational Costs,"['Atif Raza', 'Stefan Kramer']","Shapelets are discriminative time series subsequences that allow generation
of interpretable classification models, which provide faster and generally
better classification than the nearest neighbor approach. However, the shapelet
discovery process requires the evaluation of all possible subsequences of all
time series in the training set, making it extremely computation intensive.
Consequently, shapelet discovery for large time series datasets quickly becomes
intractable. A number of improvements have been proposed to reduce the training
time. These techniques use approximation or discretization and often lead to
reduced classification accuracy compared to the exact method.
  We are proposing the use of ensembles of shapelet-based classifiers obtained
using random sampling of the shapelet candidates. Using random sampling reduces
the number of evaluated candidates and consequently the required computational
cost, while the classification accuracy of the resulting models is also not
significantly different than that of the exact algorithm. The combination of
randomized classifiers rectifies the inaccuracies of individual models because
of the diversity of the solutions. Based on the experiments performed, it is
shown that the proposed approach of using an ensemble of inexpensive
classifiers provides better classification accuracy compared to the exact
method at a significantly lesser computational cost.",http://arxiv.org/pdf/1702.06712v1,cs.LG
2017-02-13 06:17:16+00:00,Coresets for Kernel Regression,"['Yan Zheng', 'Jeff M. Phillips']","Kernel regression is an essential and ubiquitous tool for non-parametric data
analysis, particularly popular among time series and spatial data. However, the
central operation which is performed many times, evaluating a kernel on the
data set, takes linear time. This is impractical for modern large data sets.
  In this paper we describe coresets for kernel regression: compressed data
sets which can be used as proxy for the original data and have provably bounded
worst case error. The size of the coresets are independent of the raw number of
data points, rather they only depend on the error guarantee, and in some cases
the size of domain and amount of smoothing. We evaluate our methods on very
large time series and spatial data, and demonstrate that they incur negligible
error, can be constructed extremely efficiently, and allow for great
computational gains.",http://arxiv.org/pdf/1702.03644v2,cs.LG
2017-02-07 19:08:41+00:00,Robust Clustering for Time Series Using Spectral Densities and Functional Data Analysis,"['Diego Rivera-García', 'Luis Angel García-Escudero', 'Agustín Mayo-Iscar', 'Joaquín Ortega']","In this work a robust clustering algorithm for stationary time series is
proposed. The algorithm is based on the use of estimated spectral densities,
which are considered as functional data, as the basic characteristic of
stationary time series for clustering purposes. A robust algorithm for
functional data is then applied to the set of spectral densities. Trimming
techniques and restrictions on the scatter within groups reduce the effect of
noise in the data and help to prevent the identification of spurious clusters.
The procedure is tested in a simulation study, and is also applied to a real
data set.",http://arxiv.org/pdf/1702.02165v1,stat.ML
2017-02-06 22:34:44+00:00,Hierarchical Symbolic Dynamic Filtering of Streaming Non-stationary Time Series Data,"['Adedotun Akintayo', 'Soumik Sarkar']","This paper proposes a hierarchical feature extractor for non-stationary
streaming time series based on the concept of switching observable Markov chain
models. The slow time-scale non-stationary behaviors are considered to be a
mixture of quasi-stationary fast time-scale segments that are exhibited by
complex dynamical systems. The idea is to model each unique stationary
characteristic without a priori knowledge (e.g., number of possible unique
characteristics) at a lower logical level, and capture the transitions from one
low-level model to another at a higher level. In this context, the concepts in
the recently developed Symbolic Dynamic Filtering (SDF) is extended, to build
an online algorithm suited for handling quasi-stationary data at a lower level
and a non-stationary behavior at a higher level without a priori knowledge. A
key observation made in this study is that the rate of change of data
likelihood seems to be a better indicator of change in data characteristics
compared to the traditional methods that mostly consider data likelihood for
change detection. The algorithm minimizes model complexity and captures data
likelihood. Efficacy demonstration and comparative evaluation of the proposed
algorithm are performed using time series data simulated from systems that
exhibit nonlinear dynamics. We discuss results that show that the proposed
hierarchical SDF algorithm can identify underlying features with significantly
high degree of accuracy, even under very noisy conditions. Algorithm is
demonstrated to perform better than the baseline Hierarchical Dirichlet
Process-Hidden Markov Models (HDP-HMM). The low computational complexity of
algorithm makes it suitable for on-board, real time operations.",http://arxiv.org/pdf/1702.01811v1,stat.ML
2017-02-02 16:05:01+00:00,Evaluation of time series models under non-stationarity with application to the comparison of regional climate models,"['T. M. Erhardt', 'C. Czado', 'T. L. Thorarinsdottir']","Different disciplines pursue the aim to develop models which characterize
certain phenomena as accurately as possible. Climatology is a prime example,
where the temporal evolution of the climate is modeled. In order to compare and
improve different models, methodology for a fair model evaluation is
indispensable. As models and forecasts of a phenomenon are usually associated
with uncertainty, proper scoring rules, which are tools that account for this
kind of uncertainty, are an adequate choice for model evaluation. However,
under the presence of non-stationarity, such a model evaluation becomes
challenging, as the characteristics of the phenomenon of interest change. We
provide methodology for model evaluation in the context of non-stationary time
series. Our methodology assumes stationarity of the time series in shorter
moving time windows. These moving windows, which are selected based on a
changepoint analysis, are used to characterize the uncertainty of the
phenomenon/model for the corresponding time instances. This leads to the
concept of moving scores allowing for a temporal assessment of the model
performance. The merits of the proposed methodology are illustrated in a
simulation and a case study.",http://arxiv.org/pdf/1702.00728v1,stat.ME
2017-01-26 16:38:00+00:00,Riemannian-geometry-based modeling and clustering of network-wide non-stationary time series: The brain-network case,"['Konstantinos Slavakis', 'Shiva Salsabilian', 'David S. Wack', 'Sarah F. Muldoon', 'Henry E. Baidoo-Williams', 'Jean M. Vettel', 'Matthew Cieslak', 'Scott T. Grafton']","This paper advocates Riemannian multi-manifold modeling in the context of
network-wide non-stationary time-series analysis. Time-series data, collected
sequentially over time and across a network, yield features which are viewed as
points in or close to a union of multiple submanifolds of a Riemannian
manifold, and distinguishing disparate time series amounts to clustering
multiple Riemannian submanifolds. To support the claim that exploiting the
latent Riemannian geometry behind many statistical features of time series is
beneficial to learning from network data, this paper focuses on brain networks
and puts forth two feature-generation schemes for network-wide dynamic time
series. The first is motivated by Granger-causality arguments and uses an
auto-regressive moving average model to map low-rank linear vector subspaces,
spanned by column vectors of appropriately defined observability matrices, to
points into the Grassmann manifold. The second utilizes (non-linear)
dependencies among network nodes by introducing kernel-based partial
correlations to generate points in the manifold of positive-definite matrices.
Capitilizing on recently developed research on clustering Riemannian
submanifolds, an algorithm is provided for distinguishing time series based on
their geometrical properties, revealed within Riemannian feature spaces.
Extensive numerical tests demonstrate that the proposed framework outperforms
classical and state-of-the-art techniques in clustering brain-network
states/structures hidden beneath synthetic fMRI time series and brain-activity
signals generated from real brain-network structural connectivity matrices.",http://arxiv.org/pdf/1701.07767v1,cs.LG
2017-01-17 19:37:47+00:00,Beyond Whittle: Nonparametric correction of a parametric likelihood with a focus on Bayesian time series analysis,"['Claudia Kirch', 'Matthew C. Edwards', 'Alexander Meier', 'Renate Meyer']","The Whittle likelihood is widely used for Bayesian nonparametric estimation
of the spectral density of stationary time series. However, the loss of
efficiency for non-Gaussian time series can be substantial. On the other hand,
parametric methods are more powerful if the model is well-specified, but may
fail entirely otherwise. Therefore, we suggest a nonparametric correction of a
parametric likelihood taking advantage of the efficiency of parametric models
while mitigating sensitivities through a nonparametric amendment. Using a
Bernstein-Dirichlet prior for the nonparametric spectral correction, we show
posterior consistency and illustrate the performance of our procedure in a
simulation study and with LIGO gravitational wave data.",http://arxiv.org/pdf/1701.04846v1,stat.ME
2017-01-12 11:30:04+00:00,Intrinsic wavelet regression for curves of Hermitian positive definite matrices,"['Joris Chau', 'Rainer von Sachs']","Intrinsic wavelet transforms and wavelet estimation methods are introduced
for curves in the non-Euclidean space of Hermitian positive definite matrices,
with in mind the application to Fourier spectral estimation of multivariate
stationary time series. The main focus is on intrinsic average-interpolation
wavelet transforms in the space of positive definite matrices equipped with an
affine-invariant Riemannian metric, and convergence rates of linear wavelet
thresholding are derived for intrinsically smooth curves of Hermitian positive
definite matrices. In the context of multivariate Fourier spectral estimation,
intrinsic wavelet thresholding is equivariant under a change of basis of the
time series, and nonlinear wavelet thresholding is able to capture localized
features in the spectral density matrix across frequency, always guaranteeing
positive definite estimates. The finite-sample performance of intrinsic wavelet
thresholding is assessed by means of simulated data and compared to several
benchmark estimators in the Riemannian manifold. Further illustrations are
provided by examining the multivariate spectra of trial-replicated brain signal
time series recorded during a learning experiment.",http://arxiv.org/pdf/1701.03314v6,stat.ME
2017-01-07 21:44:04+00:00,Deep Learning for Time-Series Analysis,['John Cristian Borges Gamboa'],"In many real-world application, e.g., speech recognition or sleep stage
classification, data are captured over the course of time, constituting a
Time-Series. Time-Series often contain temporal dependencies that cause two
otherwise identical points of time to belong to different classes or predict
different behavior. This characteristic generally increases the difficulty of
analysing them. Existing techniques often depended on hand-crafted features
that were expensive to create and required expert knowledge of the field. With
the advent of Deep Learning new models of unsupervised learning of features for
Time-series analysis and forecast have been developed. Such new developments
are the topic of this paper: a review of the main Deep Learning techniques is
presented, and some applications on Time-Series analysis are summaried. The
results make it clear that Deep Learning has a lot to contribute to the field.",http://arxiv.org/pdf/1701.01887v1,cs.LG
2017-01-06 19:40:45+00:00,Testing for stationarity of functional time series in the frequency domain,"['Alexander Aue', 'Anne van Delft']","Interest in functional time series has spiked in the recent past with papers
covering both methodology and applications being published at a much increased
pace. This article contributes to the research in this area by proposing a new
stationarity test for functional time series based on frequency domain methods.
The proposed test statistics is based on joint dimension reduction via
functional principal components analysis across the spectral density operators
at all Fourier frequencies, explicitly allowing for frequency-dependent levels
of truncation to adapt to the dynamics of the underlying functional time
series. The properties of the test are derived both under the null hypothesis
of stationary functional time series and under the smooth alternative of
locally stationary functional time series. The methodology is theoretically
justified through asymptotic results. Evidence from simulation studies and an
application to annual temperature curves suggests that the test works well in
finite samples.",http://arxiv.org/pdf/1701.01741v3,stat.ME
2017-01-03 18:29:16+00:00,Estimating functional time series by moving average model fitting,"['Alexander Aue', 'Johannes Klepsch']","Functional time series have become an integral part of both functional data
and time series analysis. Important contributions to methodology, theory and
application for the prediction of future trajectories and the estimation of
functional time series parameters have been made in the recent past. This paper
continues this line of research by proposing a first principled approach to
estimate invertible functional time series by fitting functional moving average
processes. The idea is to estimate the coefficient operators in a functional
linear filter. To do this a functional Innovations Algorithm is utilized as a
starting point to estimate the corresponding moving average operators via
suitable projections into principal directions. In order to establish
consistency of the proposed estimators, asymptotic theory is developed for
increasing subspaces of these principal directions. For practical purposes,
several strategies to select the number of principal directions to include in
the estimation procedure as well as the choice of order of the functional
moving average process are discussed. Their empirical performance is evaluated
through simulations and an application to vehicle traffic data.",http://arxiv.org/pdf/1701.00770v1,stat.ME
2016-12-21 15:43:02+00:00,Methodology and Convergence Rates for Functional Time Series Regression,"['Tung Pham', 'Victor Panaretos']","The functional linear model extends the notion of linear regression to the
case where the response and covariates are iid elements of an infinite
dimensional Hilbert space. The unknown to be estimated is a Hilbert-Schmidt
operator, whose inverse is by definition unbounded, rendering the problem of
inference ill-posed. In this paper, we consider the more general context where
the sample of response/covariate pairs forms a weakly dependent stationary
process in the respective product Hilbert space: simply stated, the case where
we have a regression between functional time series. We consider a general
framework of potentially nonlinear processes, exploiting recent advances in the
spectral analysis of time series. Our main result is the establishment of the
rate of convergence for the corresponding estimators of the regression
coefficients, the latter forming a summable sequence in the space of
Hilbert-Schmidt operators. In a sense, our main result can be seen as a
generalisation of the classical functional linear model rates, to the case of
time series, and rests only upon cumulant mixing conditions. While the analysis
becomes considerably more involved in the dependent case, the rates are
strikingly comparable to those of the i.i.d. case, but at the expense of an
additional factor caused by the necessity to estimate the spectral density
operator at a nonparametric rate, as opposed to the parametric rate for
covariance operator estimation.",http://arxiv.org/pdf/1612.07197v1,math.ST
2016-12-20 19:33:35+00:00,Temporal Feature Selection on Networked Time Series,"['Haishuai Wang', 'Jia Wu', 'Peng Zhang', 'Chengqi Zhang']","This paper formulates the problem of learning discriminative features
(\textit{i.e.,} segments) from networked time series data considering the
linked information among time series. For example, social network users are
considered to be social sensors that continuously generate social signals
(tweets) represented as a time series. The discriminative segments are often
referred to as \emph{shapelets} in a time series. Extracting shapelets for time
series classification has been widely studied. However, existing works on
shapelet selection assume that the time series are independent and identically
distributed (i.i.d.). This assumption restricts their applications to social
networked time series analysis, since a user's actions can be correlated to
his/her social affiliations. In this paper we propose a new Network Regularized
Least Squares (NetRLS) feature selection model that combines typical time
series data and user network data for analysis. Experiments on real-world
networked time series Twitter and DBLP data demonstrate the performance of the
proposed method. NetRLS performs better than LTS, the state-of-the-art time
series feature selection approach, on real-world data.",http://arxiv.org/pdf/1612.06856v2,cs.LG
2016-12-20 14:24:49+00:00,Multivariate Industrial Time Series with Cyber-Attack Simulation: Fault Detection Using an LSTM-based Predictive Data Model,"['Pavel Filonov', 'Andrey Lavrentyev', 'Artem Vorontsov']","We adopted an approach based on an LSTM neural network to monitor and detect
faults in industrial multivariate time series data. To validate the approach we
created a Modelica model of part of a real gasoil plant. By introducing hacks
into the logic of the Modelica model, we were able to generate both the roots
and causes of fault behavior in the plant. Having a self-consistent data set
with labeled faults, we used an LSTM architecture with a forecasting error
threshold to obtain precision and recall quality metrics. The dependency of the
quality metric on the threshold level is considered. An appropriate mechanism
such as ""one handle"" was introduced for filtering faults that are outside of
the plant operator field of interest.",http://arxiv.org/pdf/1612.06676v2,cs.LG
2016-12-15 22:40:57+00:00,Automatic time-series phenotyping using massive feature extraction,"['Ben D Fulcher', 'Nick S Jones']","Across a far-reaching diversity of scientific and industrial applications, a
general key problem involves relating the structure of time-series data to a
meaningful outcome, such as detecting anomalous events from sensor recordings,
or diagnosing patients from physiological time-series measurements like heart
rate or brain activity. Currently, researchers must devote considerable effort
manually devising, or searching for, properties of their time series that are
suitable for the particular analysis problem at hand. Addressing this
non-systematic and time-consuming procedure, here we introduce a new tool,
hctsa, that selects interpretable and useful properties of time series
automatically, by comparing implementations over 7700 time-series features
drawn from diverse scientific literatures. Using two exemplar biological
applications, we show how hctsa allows researchers to leverage decades of
time-series research to quantify and understand informative structure in their
time-series data.",http://arxiv.org/pdf/1612.05296v1,cs.LG
2016-12-08 20:17:03+00:00,Change point detection in heteroscedastic time series,"['Tomasz Gorecki', 'Lajos Horvath', 'Piotr Kokoszka']","Many time series exhibit changes both in level and in variability. Generally,
it is more important to detect a change in the level, and changing or smoothly
evolving variability can confound existing tests. This paper develops a
framework for testing for shifts in the level of a series which accommodates
the possibility of changing variability. The resulting tests are robust both to
heteroskedasticity and serial dependence. They rely on a new functional central
limit theorem for dependent random variables whose variance can change or trend
in a substantial way. This new result is of independent interest as it can be
applied in many inferential contexts applicable to time series. Its application
to change point tests relies on a new approach which utilizes
Karhunen--Lo{\'e}ve expansions of the limit Gaussian processes. After
presenting the theory in the most commonly encountered setting of the detection
of a change point in the mean, we show how it can be extended to linear and
nonlinear regression. Finite sample performance is examined by means of a
simulation study and an application to yields on US treasury bonds.",http://arxiv.org/pdf/1612.02794v1,math.ST
2016-12-07 11:06:15+00:00,Generalized Exponential smoothing in prediction of hierarchical time series,"['Daniel Kosiorowski', 'Dominik Mielczarek', 'Jerzy P. Rydlewski', 'Małgorzata Snarska']","Shang and Hyndman (2017) proposed a grouped functional time series
forecasting approach as a combination of individual forecasts obtained using
generalized least squares method. We modify their methodology using generalized
exponential smoothing technique for the most disaggregated functional time
series in order to obtain more robust predictor. We discuss some properties of
our proposals basing on results obtained via simulation studies and analysis of
real data related to a prediction of a demand for electricity in Australia in
2016.",http://arxiv.org/pdf/1612.02195v3,stat.ME
2016-12-05 05:53:47+00:00,Deep Symbolic Representation Learning for Heterogeneous Time-series Classification,"['Shengdong Zhang', 'Soheil Bahrampour', 'Naveen Ramakrishnan', 'Mohak Shah']","In this paper, we consider the problem of event classification with
multi-variate time series data consisting of heterogeneous (continuous and
categorical) variables. The complex temporal dependencies between the variables
combined with sparsity of the data makes the event classification problem
particularly challenging. Most state-of-art approaches address this either by
designing hand-engineered features or breaking up the problem over homogeneous
variates. In this work, we propose and compare three representation learning
algorithms over symbolized sequences which enables classification of
heterogeneous time-series data using a deep architecture. The proposed
representations are trained jointly along with the rest of the network
architecture in an end-to-end fashion that makes the learned features
discriminative for the given task. Experiments on three real-world datasets
demonstrate the effectiveness of the proposed approaches.",http://arxiv.org/pdf/1612.01254v1,cs.LG
2016-12-02 11:27:44+00:00,A General Framework for Density Based Time Series Clustering Exploiting a Novel Admissible Pruning Strategy,"['Nurjahan Begum', 'Liudmila Ulanova', 'Hoang Anh Dau', 'Jun Wang', 'Eamonn Keogh']","Time Series Clustering is an important subroutine in many higher-level data
mining analyses, including data editing for classifiers, summarization, and
outlier detection. It is well known that for similarity search the superiority
of Dynamic Time Warping (DTW) over Euclidean distance gradually diminishes as
we consider ever larger datasets. However, as we shall show, the same is not
true for clustering. Clustering time series under DTW remains a computationally
expensive operation. In this work, we address this issue in two ways. We
propose a novel pruning strategy that exploits both the upper and lower bounds
to prune off a very large fraction of the expensive distance calculations. This
pruning strategy is admissible and gives us provably identical results to the
brute force algorithm, but is at least an order of magnitude faster. For
datasets where even this level of speedup is inadequate, we show that we can
use a simple heuristic to order the unavoidable calculations in a
most-useful-first ordering, thus casting the clustering into an anytime
framework. We demonstrate the utility of our ideas with both single and
multidimensional case studies in the domains of astronomy, speech physiology,
medicine and entomology. In addition, we show the generality of our clustering
framework to other domains by efficiently obtaining semantically significant
clusters in protein sequences using the Edit Distance, the discrete data
analogue of DTW.",http://arxiv.org/pdf/1612.00637v1,cs.LG
2016-11-30 21:32:43+00:00,Principal component analysis of periodically correlated functional time series,"['Łukasz Kidziński', 'Piotr Kokoszka', 'Neda Mohammadi Jouzdani']","Within the framework of functional data analysis, we develop principal
component analysis for periodically correlated time series of functions. We
define the components of the above analysis including periodic, operator-valued
filters, score processes and the inversion formulas. We show that these objects
are defined via convergent series under a simple condition requiring
summability of the Hilbert-Schmidt norms of the filter coefficients, and that
they poses optimality properties.
  We explain how the Hilbert space theory reduces to an approximate
finite-dimensional setting which is implemented in a custom build R package. A
data example and a simulation study show that the new methodology is superior
to existing tools if the functional time series exhibit periodic
characteristics.",http://arxiv.org/pdf/1612.00040v1,stat.ME
2016-11-29 21:39:23+00:00,Autism Spectrum Disorder Classification using Graph Kernels on Multidimensional Time Series,"['Rushil Anirudh', 'Jayaraman J. Thiagarajan', 'Irene Kim', 'Wolfgang Polonik']","We present an approach to model time series data from resting state fMRI for
autism spectrum disorder (ASD) severity classification. We propose to adopt
kernel machines and employ graph kernels that define a kernel dot product
between two graphs. This enables us to take advantage of spatio-temporal
information to capture the dynamics of the brain network, as opposed to
aggregating them in the spatial or temporal dimension. In addition to the
conventional similarity graphs, we explore the use of L1 graph using sparse
coding, and the persistent homology of time delay embeddings, in the proposed
pipeline for ASD classification. In our experiments on two datasets from the
ABIDE collection, we demonstrate a consistent and significant advantage in
using graph kernels over traditional linear or non linear kernels for a variety
of time series features.",http://arxiv.org/pdf/1611.09897v1,stat.ML
2016-11-29 17:05:00+00:00,Multiscale and multilevel technique for consistent segmentation of nonstationary time series,"['Haeran Cho', 'Piotr Fryzlewicz']","In this paper, we propose a fast, well-performing, and consistent method for
segmenting a piecewise-stationary, linear time series with an unknown number of
breakpoints. The time series model we use is the nonparametric Locally
Stationary Wavelet model, in which a complete description of the
piecewise-stationary second-order structure is provided by wavelet periodograms
computed at multiple scales and locations. The initial stage of our method is a
new binary segmentation procedure, with a theoretically justified and rapidly
computable test criterion that detects breakpoints in wavelet periodograms
separately at each scale. This is followed by within-scale and across-scales
post-processing steps, leading to consistent estimation of the number and
locations of breakpoints in the second-order structure of the original process.
An extensive simulation study demonstrates good performance of our method.",http://arxiv.org/pdf/1611.09727v1,stat.ME
2016-11-28 15:34:30+00:00,Times series averaging and denoising from a probabilistic perspective on time-elastic kernels,['Pierre-François Marteau'],"In the light of regularized dynamic time warping kernels, this paper
re-considers the concept of time elastic centroid for a setof time series. We
derive a new algorithm based on a probabilistic interpretation of kernel
alignment matrices. This algorithm expressesthe averaging process in terms of a
stochastic alignment automata. It uses an iterative agglomerative heuristic
method for averagingthe aligned samples, while also averaging the times of
occurrence of the aligned samples. By comparing classification accuracies for45
heterogeneous time series datasets obtained by first nearest centroid/medoid
classifiers we show that: i) centroid-basedapproaches significantly outperform
medoid-based approaches, ii) for the considered datasets, our algorithm that
combines averagingin the sample space and along the time axes, emerges as the
most significantly robust model for time-elastic averaging with apromising
noise reduction capability. We also demonstrate its benefit in an isolated
gesture recognition experiment and its ability tosignificantly reduce the size
of training instance sets. Finally we highlight its denoising capability using
demonstrative synthetic data:we show that it is possible to retrieve, from few
noisy instances, a signal whose components are scattered in a wide spectral
band.",http://arxiv.org/pdf/1611.09194v4,cs.LG
2016-11-25 23:47:30+00:00,Multiple-change-point detection for high dimensional time series via sparsified binary segmentation,"['Haeran Cho', 'Piotr Fryzlewicz']","Time series segmentation, a.k.a. multiple change-point detection, is a
well-established problem. However, few solutions are designed specifically for
high-dimensional situations. In this paper, our interest is in segmenting the
second-order structure of a high-dimensional time series. In a generic step of
a binary segmentation algorithm for multivariate time series, one natural
solution is to combine CUSUM statistics obtained from local periodograms and
cross-periodograms of the components of the input time series. However, the
standard ""maximum"" and ""average"" methods for doing so often fail in high
dimensions when, for example, the change-points are sparse across the panel or
the CUSUM statistics are spuriously large. In this paper, we propose the
Sparsified Binary Segmentation (SBS) algorithm which aggregates the CUSUM
statistics by adding only those that pass a certain threshold. This
""sparsifying"" step reduces the impact of irrelevant, noisy contributions, which
is particularly beneficial in high dimensions. In order to show the consistency
of SBS, we introduce the multivariate Locally Stationary Wavelet model for time
series, which is a separate contribution of this work.",http://arxiv.org/pdf/1611.08639v1,stat.ME
2016-11-25 23:33:11+00:00,A test for second-order stationarity of time series based on unsystematic sub-samples,['Haeran Cho'],"In this paper, we introduce a new method for testing the stationarity of time
series, where the test statistic is obtained from measuring and maximising the
difference in the second-order structure over pairs of randomly drawn
intervals. The asymptotic normality of the test statistic is established for
both Gaussian and a range of non-Gaussian time series, and a bootstrap
procedure is proposed for estimating the variance of the main statistics.
Further, we show the consistency of our test under local alternatives. Due to
the flexibility inherent in the random, unsystematic sub-samples used for test
statistic construction, the proposed method is able to identify the intervals
of significant departure from the stationarity without any dyadic constraints,
which is an advantage over other tests employing systematic designs. We
demonstrate its good finite sample performance on both simulated and real data,
particularly in detecting localised departure from the stationarity.",http://arxiv.org/pdf/1611.08636v1,stat.ME
2016-11-21 21:03:01+00:00,Time Series Structure Discovery via Probabilistic Program Synthesis,"['Ulrich Schaechtle', 'Feras Saad', 'Alexey Radul', 'Vikash Mansinghka']","There is a widespread need for techniques that can discover structure from
time series data. Recently introduced techniques such as Automatic Bayesian
Covariance Discovery (ABCD) provide a way to find structure within a single
time series by searching through a space of covariance kernels that is
generated using a simple grammar. While ABCD can identify a broad class of
temporal patterns, it is difficult to extend and can be brittle in practice.
This paper shows how to extend ABCD by formulating it in terms of probabilistic
program synthesis. The key technical ideas are to (i) represent models using
abstract syntax trees for a domain-specific probabilistic language, and (ii)
represent the time series model prior, likelihood, and search strategy using
probabilistic programs in a sufficiently expressive language. The final
probabilistic program is written in under 70 lines of probabilistic code in
Venture. The paper demonstrates an application to time series clustering that
involves a non-parametric extension to ABCD, experiments for interpolation and
extrapolation on real-world econometric data, and improvements in accuracy over
both non-parametric and standard regression baselines.",http://arxiv.org/pdf/1611.07051v3,stat.ML
2016-11-21 16:08:12+00:00,Probabilistic structure discovery in time series data,"['David Janz', 'Brooks Paige', 'Tom Rainforth', 'Jan-Willem van de Meent', 'Frank Wood']","Existing methods for structure discovery in time series data construct
interpretable, compositional kernels for Gaussian process regression models.
While the learned Gaussian process model provides posterior mean and variance
estimates, typically the structure is learned via a greedy optimization
procedure. This restricts the space of possible solutions and leads to
over-confident uncertainty estimates. We introduce a fully Bayesian approach,
inferring a full posterior over structures, which more reliably captures the
uncertainty of the model.",http://arxiv.org/pdf/1611.06863v1,stat.ML
2016-11-14 20:55:33+00:00,Earliness-Aware Deep Convolutional Networks for Early Time Series Classification,"['Wenlin Wang', 'Changyou Chen', 'Wenqi Wang', 'Piyush Rai', 'Lawrence Carin']","We present Earliness-Aware Deep Convolutional Networks (EA-ConvNets), an
end-to-end deep learning framework, for early classification of time series
data. Unlike most existing methods for early classification of time series
data, that are designed to solve this problem under the assumption of the
availability of a good set of pre-defined (often hand-crafted) features, our
framework can jointly perform feature learning (by learning a deep hierarchy of
\emph{shapelets} capturing the salient characteristics in each time series),
along with a dynamic truncation model to help our deep feature learning
architecture focus on the early parts of each time series. Consequently, our
framework is able to make highly reliable early predictions, outperforming
various state-of-the-art methods for early time series classification, while
also being competitive when compared to the state-of-the-art time series
classification algorithms that work with \emph{fully observed} time series
data. To the best of our knowledge, the proposed framework is the first to
perform data-driven (deep) feature learning in the context of early
classification of time series data. We perform a comprehensive set of
experiments, on several benchmark data sets, which demonstrate that our method
yields significantly better predictions than various state-of-the-art methods
designed for early time series classification. In addition to obtaining high
accuracies, our experiments also show that the learned deep shapelets based
features are also highly interpretable and can help gain better understanding
of the underlying characteristics of time series data.",http://arxiv.org/pdf/1611.04578v1,cs.LG
2016-11-14 16:54:27+00:00,"Predictive, finite-sample model choice for time series under stationarity and non-stationarity","['Tobias Kley', 'Philip Preuß', 'Piotr Fryzlewicz']","In statistical research there usually exists a choice between structurally
simpler or more complex models. We argue that, even if a more complex, locally
stationary time series model were true, then a simple, stationary time series
model may be advantageous to work with under parameter uncertainty. We present
a new model choice methodology, where one of two competing approaches is chosen
based on its empirical, finite-sample performance with respect to prediction,
in a manner that ensures interpretability. A rigorous, theoretical analysis of
the procedure is provided. As an important side result we prove, for possibly
diverging model order, that the localised Yule-Walker estimator is strongly,
uniformly consistent under local stationarity. An R package, forecastSNSTS, is
provided and used to apply the methodology to financial and meteorological data
in empirical examples. We further provide an extensive simulation study and
discuss when it is preferable to base forecasts on the more volatile
time-varying estimates and when it is advantageous to forecast as if the data
were from a stationary process, even though they might not be.",http://arxiv.org/pdf/1611.04460v3,math.ST
2016-11-08 02:20:46+00:00,NonSTOP: A NonSTationary Online Prediction Method for Time Series,"['Christopher Xie', 'Avleen Bijral', 'Juan Lavista Ferres']","We present online prediction methods for time series that let us explicitly
handle nonstationary artifacts (e.g. trend and seasonality) present in most
real time series. Specifically, we show that applying appropriate
transformations to such time series before prediction can lead to improved
theoretical and empirical prediction performance. Moreover, since these
transformations are usually unknown, we employ the learning with experts
setting to develop a fully online method (NonSTOP-NonSTationary Online
Prediction) for predicting nonstationary time series. This framework allows for
seasonality and/or other trends in univariate time series and cointegration in
multivariate time series. Our algorithms and regret analysis subsume recent
related work while significantly expanding the applicability of such methods.
For all the methods, we provide sub-linear regret bounds using relaxed
assumptions. The theoretical guarantees do not fully capture the benefits of
the transformations, thus we provide a data-dependent analysis of the
follow-the-leader algorithm that provides insight into the success of using
such transformations. We support all of our results with experiments on
simulated and real data.",http://arxiv.org/pdf/1611.02365v4,stat.ML
2016-11-07 20:36:56+00:00,Learning Time Series Detection Models from Temporally Imprecise Labels,"['Roy J. Adams', 'Benjamin M. Marlin']","In this paper, we consider a new low-quality label learning problem: learning
time series detection models from temporally imprecise labels. In this problem,
the data consist of a set of input time series, and supervision is provided by
a sequence of noisy time stamps corresponding to the occurrence of positive
class events. Such temporally imprecise labels commonly occur in areas like
mobile health research where human annotators are tasked with labeling the
occurrence of very short duration events. We propose a general learning
framework for this problem that can accommodate different base classifiers and
noise models. We present results on real mobile health data showing that the
proposed framework significantly outperforms a number of alternatives including
assuming that the label time stamps are noise-free, transforming the problem
into the multiple instance learning framework, and learning on labels that were
manually re-aligned.",http://arxiv.org/pdf/1611.02258v2,stat.ML
2016-11-04 13:45:48+00:00,Partial autocorrelation parameterization for subset autoregression,"['A. Ian McLeod', 'Ying Zhang']","A new version of the partial autocorrelation plot and a new family of subset
autoregressive models are introduced. A comprehensive approach to model
identification, estimation and diagnostic checking is developed for these
models. These models are better suited to efficient model building of
high-order autoregressions with long time series. Several illustrative examples
are given.",http://arxiv.org/pdf/1611.01370v1,math.ST
2016-11-04 13:09:04+00:00,Portmanteau Tests for ARMA Models with Infinite Variance,"['Jen-Wen Lin', 'A. Ian McLeod']","Autoregressive and moving-average (ARMA) models with stable Paretian errors
is one of the most studied models for time series with infinite variance.
Estimation methods for these models have been studied by many researchers but
the problem of diagnostic checking fitted models has not been addressed. In
this paper, we develop portmanteau tests for checking randomness of a time
series with infinite variance and as a diagnostic tool for checking model
adequacy of fitted ARMA models. It is assumed that least-squares or an
asymptotically equivalent estimation method, such as Gaussian maximum
likelihood in the case of AR models, is used. And it is assumed that the
distribution of the innovations is IID stable Paretian. It is seen via
simulation that the proposed portmanteau tests do not converge well to the
corresponding limiting distributions for practical series length so a
Monte-Carlo test is suggested. Simulation experiments show that the proposed
test procedure works effectively. Two illustrative applications to actual data
are provided to demonstrate that an incorrect conclusion may result if the
usual portmanteau test based on the finite variance assumption is used.",http://arxiv.org/pdf/1611.01360v1,math.ST
2016-11-04 12:37:29+00:00,Improved Pena-Rodriguez Portmanteau Test,"['Jen-Wen Lin', 'A. Ian McLeod']","Several problems with the diagnostic check suggested by Pena and Rodriguez
[2002. A powerful portmanteau test of lack of fit for time series. J. Amer.
Statist. Assoc. 97, 601-610.] are noted and an improved Monte-Carlo version of
this test is suggested. It is shown that quite often the test statistic
recommended by Pena and Rodriguez [2002. A powerful portmanteau test of lack of
fit for time series. J. Amer. Statist. Assoc. 97, 601-610.] may not exist and
their asymptotic distribution of the test does not agree with the suggested
gamma approximation very well if the number of lags used by the test is small.
It is shown that the convergence of this test statistic to its asymptotic
distribution may be quite slow when the series length is less than 1000 and so
a Monte-Carlo test is recommended. Simulation experiments suggest the
Monte-Carlo test is usually more powerful than the test given by Pena and
Rodriguez [2002. A powerful portmanteau test of lack of fit for time series. J.
Amer. Statist. Assoc. 97, 601-610.] and often much more powerful than the
Ljung-Box portmanteau test. Two illustrative examples of enhanced diagnostic
checking with the Monte-Carlo test are given.",http://arxiv.org/pdf/1611.01351v1,math.ST
2016-11-04 10:21:55+00:00,Achieving Shrinkage in a Time-Varying Parameter Model Framework,"['Angela Bitto', 'Sylvia Frühwirth-Schnatter']","Shrinkage for time-varying parameter (TVP) models is investigated within a
Bayesian framework, with the aim to automatically reduce time-varying
parameters to static ones, if the model is overfitting. This is achieved
through placing the double gamma shrinkage prior on the process variances. An
efficient Markov chain Monte Carlo scheme is developed, exploiting boosting
based on the ancillarity-sufficiency interweaving strategy. The method is
applicable both to TVP models for univariate as well as multivariate time
series. Applications include a TVP generalized Phillips curve for EU area
inflation modelling and a multivariate TVP Cholesky stochastic volatility model
for joint modelling of the returns from the DAX-30 index.",http://arxiv.org/pdf/1611.01310v2,stat.ME
2016-11-04 01:49:06+00:00,Computer Algebra Derivation of the Bias of Burg Estimators,"['Ying Zhang', 'A. Ian McLeod']","A symbolic method is discussed which can be used to obtain the asymptotic
bias and variance to order $O(1/n)$ for estimators in stationary time series.
Using this method the bias to $O(1/n)$ of the Burg estimator in AR(1) and AR(2)
models is shown to be equal to that of the least squares estimators in both the
known and unknown mean cases. Previous researchers have only been able to
obtain simulation results for this bias because this problem is too intractable
without using computer algebra.",http://arxiv.org/pdf/1611.01240v1,math.ST
2016-11-02 22:03:48+00:00,Hyperbolic decay time series,['A. Ian McLeod'],"Hyperbolic decay time series such as, fractional Gaussian noise (FGN) or
fractional autoregressive moving-average (FARMA) process, each exhibit two
distinct types of behaviour: strong persistence or antipersistence. Beran
(1994) characterized the family of strongly persistent time series. A more
general family of hyperbolic decay time series is introduced and its basic
properties are characterized in terms of the autocovariance and spectral
density functions. The random shock and inverted form representations are
derived. It is shown that every strongly persistent series is the dual of an
antipersistent series and vice versa. The asymptotic generalized variance of
hyperbolic decay time series with unit innovation variance is shown to be
infinite which implies that the variance of the minimum mean-square error
one-step linear predictor using the last $k$ observations decays slowly to the
innovation variance as $k$ gets large.",http://arxiv.org/pdf/1611.00826v1,math.ST
2016-11-02 01:53:20+00:00,Improved multivariate portmanteau test,"['Esam Mahdi', 'A. Ian McLeod']","A new portmanteau diagnostic test for vector autoregressive moving average
(VARMA) models that is based on the determinant of the standardized
multivariate residual autocorrelations is derived. The new test statistic may
be considered an extension of the univariate portmanteau test statistic
suggested by Pena and Rodriguez (2002, A Powerful Portmanteau Test of Lack of
Test for Time Series, Journal of American Statistical Association) The
asymptotic distribution of the test statistic is derived as well as a
chi-square approximation. However, the Monte-Carlo test is recommended unless
the series is very long. Extensive simulation experiments demonstrate the
usefulness of this test as well as its improved power performance compared to
widely used previous multivariate portmanteau diagnostic check. Two
illustrative applications are given.",http://arxiv.org/pdf/1611.00442v1,math.ST
2016-11-01 15:08:09+00:00,Causal Compression,"['Aleksander Wieczorek', 'Volker Roth']","We propose a new method of discovering causal relationships in temporal data
based on the notion of causal compression. To this end, we adopt the Pearlian
graph setting and the directed information as an information theoretic tool for
quantifying causality. We introduce chain rule for directed information and use
it to motivate causal sparsity. We show two applications of the proposed
method: causal time series segmentation which selects time points capturing the
incoming and outgoing causal flow between time points belonging to different
signals, and causal bipartite graph recovery. We prove that modelling of
causality in the adopted set-up only requires estimating the copula density of
the data distribution and thus does not depend on its marginals. We evaluate
the method on time resolved gene expression data.",http://arxiv.org/pdf/1611.00261v1,stat.ML
2016-10-31 09:24:28+00:00,Analysis of Nonstationary Time Series Using Locally Coupled Gaussian Processes,"['Luca Ambrogioni', 'Eric Maris']","The analysis of nonstationary time series is of great importance in many
scientific fields such as physics and neuroscience. In recent years, Gaussian
process regression has attracted substantial attention as a robust and powerful
method for analyzing time series. In this paper, we introduce a new framework
for analyzing nonstationary time series using locally stationary Gaussian
process analysis with parameters that are coupled through a hidden Markov
model. The main advantage of this framework is that arbitrary complex
nonstationary covariance functions can be obtained by combining simpler
stationary building blocks whose hidden parameters can be estimated in
closed-form. We demonstrate the flexibility of the method by analyzing two
examples of synthetic nonstationary signals: oscillations with time varying
frequency and time series with two dynamical states. Finally, we report an
example application on real magnetoencephalographic measurements of brain
activity.",http://arxiv.org/pdf/1610.09838v1,stat.ML
2016-10-28 15:32:33+00:00,Root-n consistent estimation of the marginal density in some time series models,['Lionel Truquet'],"In this paper, we consider the problem of estimating the marginal density in
some nonlinear autoregressive time series models for which the conditional mean
and variance have a parametric specification. Under some regularity conditions,
we show that a kernel type estimate based on the residuals can be root-n
consistent even if the noise density is unknown. Our results, which are shown
to be valid for classical time series models such as ARMA or GARCH processes,
extend substantially the existing results obtained for some homoscedatic time
series models. Asymptotic expansion of our estimator is obtained by combining
some martingale type arguments and a coupling method for time series which is
of independent interest. We also study the uniform convergence of our estimator
on compact intervals.",http://arxiv.org/pdf/1610.09272v1,math.ST
2016-10-26 15:06:36+00:00,Nonparametric Dynamic State Space Modeling of Observed Circular Time Series with Circular Latent States: A Bayesian Perspective,"['Satyaki Mazumder', 'Sourabh Bhattacharya']","Circular time series has received relatively little attention in statistics
and modeling complex circular time series using the state space approach is
non-existent in the literature. In this article we introduce a flexible
Bayesian nonparametric approach to state space modeling of observed circular
time series where even the latent states are circular random variables.
Crucially, we assume that the forms of both observational and evolutionary
functions, both of which are circular in nature, are unknown and time-varying.
We model these unknown circular functions by appropriate wrapped Gaussian
processes having desirable properties.
  We develop an effective Markov chain Monte Carlo strategy for implementing
our Bayesian model, by judiciously combining Gibbs sampling and
Metropolis-Hastings methods. Validation of our ideas with a simulation study
and two real bivariate circular time series data sets, where we assume one of
the variables to be unobserved, revealed very encouraging performance of our
model and methods.
  We finally analyse a data consisting of directions of whale migration,
considering the unobserved ocean current direction as the latent circular
process of interest. The results that we obtain are encouraging, and the
posterior predictive distribution of the observed process correctly predicts
the observed whale movement.",http://arxiv.org/pdf/1610.08367v2,stat.ME
2016-10-25 20:09:42+00:00,Gaussian Process Kernels for Popular State-Space Time Series Models,"['Alexander Grigorievskiy', 'Juha Karhunen']","In this paper we investigate a link between state- space models and Gaussian
Processes (GP) for time series modeling and forecasting. In particular, several
widely used state- space models are transformed into continuous time form and
corresponding Gaussian Process kernels are derived. Experimen- tal results
demonstrate that the derived GP kernels are correct and appropriate for
Gaussian Process Regression. An experiment with a real world dataset shows that
the modeling is identical with state-space models and with the proposed GP
kernels. The considered connection allows the researchers to look at their
models from a different angle and facilitate sharing ideas between these two
different modeling approaches.",http://arxiv.org/pdf/1610.08074v1,stat.ML
2016-10-25 03:31:58+00:00,Distributed and parallel time series feature extraction for industrial big data applications,"['Maximilian Christ', 'Andreas W. Kempa-Liehr', 'Michael Feindt']","The all-relevant problem of feature selection is the identification of all
strongly and weakly relevant attributes. This problem is especially hard to
solve for time series classification and regression in industrial applications
such as predictive maintenance or production line optimization, for which each
label or regression target is associated with several time series and
meta-information simultaneously. Here, we are proposing an efficient, scalable
feature extraction algorithm for time series, which filters the available
features in an early stage of the machine learning pipeline with respect to
their significance for the classification or regression task, while controlling
the expected percentage of selected but irrelevant features. The proposed
algorithm combines established feature extraction methods with a feature
importance filter. It has a low computational complexity, allows to start on a
problem with only limited domain knowledge available, can be trivially
parallelized, is highly scalable and based on well studied non-parametric
hypothesis tests. We benchmark our proposed algorithm on all binary
classification problems of the UCR time series classification archive as well
as time series from a production line optimization project and simulated
stochastic processes with underlying qualitative change of dynamics.",http://arxiv.org/pdf/1610.07717v3,cs.LG
2016-10-24 15:10:38+00:00,Hybrid Quantile Regression Estimation for Time Series Models with Conditional Heteroscedasticity,"['Yao Zheng', 'Qianqian Zhu', 'Guodong Li', 'Zhijie Xiao']","Estimating conditional quantiles of financial time series is essential for
risk management and many other applications in finance. It is well-known that
financial time series display conditional heteroscedasticity. Among the large
number of conditional heteroscedastic models, the generalized autoregressive
conditional heteroscedastic (GARCH) process is the most popular and influential
one. So far, feasible quantile regression methods for this task have been
confined to a variant of the GARCH model, the linear GARCH model, owing to its
tractable conditional quantile structure. This paper considers the widely used
GARCH model. An easy-to-implement hybrid conditional quantile estimation
procedure is developed based on a simple albeit nontrivial transformation.
Asymptotic properties of the proposed estimator and statistics are derived,
which facilitate corresponding inferences. To approximate the asymptotic
distribution of the quantile regression estimator, we introduce a mixed
bootstrapping procedure, where a time-consuming optimization is replaced by a
sample averaging. Moreover, diagnostic tools based on the residual quantile
autocorrelation function are constructed to check the adequacy of the fitted
conditional quantiles. Simulation experiments are carried out to assess the
finite-sample performance of the proposed approach. The favorable performance
of the conditional quantile estimator and the usefulness of the inference tools
are further illustrated by an empirical application.",http://arxiv.org/pdf/1610.07453v1,stat.ME
2016-10-24 03:39:35+00:00,Encoding Temporal Markov Dynamics in Graph for Visualizing and Mining Time Series,"['Lu Liu', 'Zhiguang Wang']","Time series and signals are attracting more attention across statistics,
machine learning and pattern recognition as it appears widely in the industry
especially in sensor and IoT related research and applications, but few
advances has been achieved in effective time series visual analytics and
interaction due to its temporal dimensionality and complex dynamics. Inspired
by recent effort on using network metrics to characterize time series for
classification, we present an approach to visualize time series as complex
networks based on the first order Markov process in its temporal ordering. In
contrast to the classical bar charts, line plots and other statistics based
graph, our approach delivers more intuitive visualization that better preserves
both the temporal dependency and frequency structures. It provides a natural
inverse operation to map the graph back to raw signals, making it possible to
use graph statistics to characterize time series for better visual exploration
and statistical analysis. Our experimental results suggest the effectiveness on
various tasks such as pattern discovery and classification on both synthetic
and the real time series and sensor data.",http://arxiv.org/pdf/1610.07273v4,cs.LG
2016-10-24 01:53:12+00:00,Representation Learning with Deconvolution for Multivariate Time Series Classification and Visualization,"['Zhiguang Wang', 'Wei Song', 'Lu Liu', 'Fan Zhang', 'Junxiao Xue', 'Yangdong Ye', 'Ming Fan', 'Mingliang Xu']","We propose a new model based on the deconvolutional networks and SAX
discretization to learn the representation for multivariate time series.
Deconvolutional networks fully exploit the advantage the powerful
expressiveness of deep neural networks in the manner of unsupervised learning.
We design a network structure specifically to capture the cross-channel
correlation with deconvolution, forcing the pooling operation to perform the
dimension reduction along each position in the individual channel.
Discretization based on Symbolic Aggregate Approximation is applied on the
feature vectors to further extract the bag of features. We show how this
representation and bag of features helps on classification. A full comparison
with the sequence distance based approach is provided to demonstrate the
effectiveness of our approach on the standard datasets. We further build the
Markov matrix from the discretized representation from the deconvolution to
visualize the time series as complex networks, which show more class-specific
statistical properties and clear structures with respect to different labels.",http://arxiv.org/pdf/1610.07258v3,cs.LG
2016-10-21 12:30:30+00:00,Maximally Divergent Intervals for Anomaly Detection,"['Erik Rodner', 'Björn Barz', 'Yanira Guanche', 'Milan Flach', 'Miguel Mahecha', 'Paul Bodesheim', 'Markus Reichstein', 'Joachim Denzler']","We present new methods for batch anomaly detection in multivariate time
series. Our methods are based on maximizing the Kullback-Leibler divergence
between the data distribution within and outside an interval of the time
series. An empirical analysis shows the benefits of our algorithms compared to
methods that treat each time step independently from each other without
optimizing with respect to all possible intervals.",http://arxiv.org/pdf/1610.06761v1,stat.ML
2016-10-15 20:37:52+00:00,Similarity Learning for Time Series Classification,"['Maria-Irina Nicolae', 'Éric Gaussier', 'Amaury Habrard', 'Marc Sebban']","Multivariate time series naturally exist in many fields, like energy,
bioinformatics, signal processing, and finance. Most of these applications need
to be able to compare these structured data. In this context, dynamic time
warping (DTW) is probably the most common comparison measure. However, not much
research effort has been put into improving it by learning. In this paper, we
propose a novel method for learning similarities based on DTW, in order to
improve time series classification. Making use of the uniform stability
framework, we provide the first theoretical guarantees in the form of a
generalization bound for linear classification. The experimental study shows
that the proposed approach is efficient, while yielding sparse classifiers.",http://arxiv.org/pdf/1610.04783v1,cs.LG
2016-10-12 03:32:59+00:00,How Many Components should be Retained from a Multivariate Time Series PCA?,"['Alethea Rea', 'William Rea']","We report on the results of two new approaches to considering how many
principal components to retain from an analysis of a multivariate time series.
The first is by using a ""heat map"" based approach. A heat map in this context
refers to a series of principal component coefficients created by applying a
sliding window to a multivariate time series. Furthermore the heat maps can
provide detailed insights into the evolution of the structure of each principal
component over time. The second is by examining the change of the angle of the
principal component over time within the high-dimensional data space. We
provide evidence that both are useful in studying structure and evolution of a
multivariate time series.",http://arxiv.org/pdf/1610.03588v2,stat.ME
2016-10-11 07:07:53+00:00,Specification testing in nonparametric AR-ARCH models,"['Marie Hušková', 'Natalie Neumeyer', 'Tobias Niebuhr', 'Leonie Selk']","In this paper an autoregressive time series model with conditional
heteroscedasticity is considered, where both conditional mean and conditional
variance function are modeled nonparametrically. A test for the model
assumption of independence of innovations from past time series values is
suggested. The test is based on an weighted $L^2$-distance of empirical
characteristic functions. The asymptotic distribution under the null hypothesis
of independence is derived and consistency against fixed alternatives is shown.
A smooth autoregressive residual bootstrap procedure is suggested and its
performance is shown in a simulation study.",http://arxiv.org/pdf/1610.03215v1,math.ST
2016-10-06 14:36:31+00:00,Factor Models for Matrix-Valued High-Dimensional Time Series,"['Dong Wang', 'Xialu Liu', 'Rong Chen']","In finance, economics and many other fields, observations in a matrix form
are often observed over time. For example, many economic indicators are
obtained in different countries over time. Various financial characteristics of
many companies are reported over time. Although it is natural to turn a matrix
observation into a long vector then use standard vector time series models or
factor analysis, it is often the case that the columns and rows of a matrix
represent different sets of information that are closely interrelated in a very
structural way. We propose a novel factor model that maintains and utilizes the
matrix structure to achieve greater dimensional reduction as well as finding
clearer and more interpretable factor structures. Estimation procedure and its
theoretical properties are investigated and demonstrated with simulated and
real examples.",http://arxiv.org/pdf/1610.01889v2,stat.ME
2016-10-06 00:30:57+00:00,Central Limit Theory for Combined Cross-Section and Time Series with an Application to Aggregate Productivity Shocks,"['Jinyong Hahn', 'Guido Kuersteiner', 'Maurizio Mazzocco']","Combining cross-section and time series data is a long and well established
practice in empirical economics. We develop a central limit theory that
explicitly accounts for possible dependence between the two data sets. We focus
on common factors as the mechanism behind this dependence. Using our central
limit theorem (CLT) we establish the asymptotic properties of parameter
estimates of a general class of models based on a combination of
cross-sectional and time series data, recognizing the interdependence between
the two data sources in the presence of aggregate shocks. Despite the
complicated nature of the analysis required to formulate the joint CLT, it is
straightforward to implement the resulting parameter limiting distributions due
to a formal similarity of our approximations with the standard Murphy and
Topel's (1985) formula.",http://arxiv.org/pdf/1610.01697v4,stat.ME
2016-10-05 15:58:18+00:00,Recovering Multiple Nonnegative Time Series From a Few Temporal Aggregates,"['Jiali Mei', 'Yohann De Castro', 'Yannig Goude', 'Georges Hébrail']","Motivated by electricity consumption metering, we extend existing nonnegative
matrix factorization (NMF) algorithms to use linear measurements as
observations, instead of matrix entries. The objective is to estimate multiple
time series at a fine temporal scale from temporal aggregates measured on each
individual series. Furthermore, our algorithm is extended to take into account
individual autocorrelation to provide better estimation, using a recent convex
relaxation of quadratically constrained quadratic program. Extensive
experiments on synthetic and real-world electricity consumption datasets
illustrate the effectiveness of our matrix recovery algorithms.",http://arxiv.org/pdf/1610.01492v1,stat.ML
2016-09-24 00:03:49+00:00,Derivative Delay Embedding: Online Modeling of Streaming Time Series,"['Zhifei Zhang', 'Yang Song', 'Wei Wang', 'Hairong Qi']","The staggering amount of streaming time series coming from the real world
calls for more efficient and effective online modeling solution. For time
series modeling, most existing works make some unrealistic assumptions such as
the input data is of fixed length or well aligned, which requires extra effort
on segmentation or normalization of the raw streaming data. Although some
literature claim their approaches to be invariant to data length and
misalignment, they are too time-consuming to model a streaming time series in
an online manner. We propose a novel and more practical online modeling and
classification scheme, DDE-MGM, which does not make any assumptions on the time
series while maintaining high efficiency and state-of-the-art performance. The
derivative delay embedding (DDE) is developed to incrementally transform time
series to the embedding space, where the intrinsic characteristics of data is
preserved as recursive patterns regardless of the stream length and
misalignment. Then, a non-parametric Markov geographic model (MGM) is proposed
to both model and classify the pattern in an online manner. Experimental
results demonstrate the effectiveness and superior classification accuracy of
the proposed DDE-MGM in an online setting as compared to the state-of-the-art.",http://arxiv.org/pdf/1609.07540v1,cs.LG
2016-09-22 04:49:12+00:00,An Exponential Inequality for U-Statistics under Mixing Conditions,['Fang Han'],"The family of U-statistics plays a fundamental role in statistics. This paper
proves a novel exponential inequality for U-statistics under the time series
setting. Explicit mixing conditions are given for guaranteeing fast
convergence, the bound proves to be analogous to the one under independence,
and extension to non-stationary time series is straightforward. The proof
relies on a novel decomposition of U-statistics via exploiting the temporal
correlatedness structure. Such results are of interest in many fields where
high dimensional time series data are present. In particular, applications to
high dimensional time series inference are discussed.",http://arxiv.org/pdf/1609.06821v3,math.ST
2016-09-20 06:18:05+00:00,Sieve Bootstrap for Functional Time Series,['Efstathios Paparoditis'],"A bootstrap procedure for functional time series is proposed which exploits a
general vector autoregressive representation of the time series of Fourier
coefficients appearing in the Karhunen-Lo\`eve expansion of the functional
process. A double sieve-type bootstrap method is developed which avoids the
estimation of process operators and generates functional pseudo-time series
that appropriately mimic the dependence structure of the functional time series
at hand. The method uses a finite set of functional principal components to
capture the essential driving parts of the infinite dimensional process and a
finite order vector autoregressive process to imitate the temporal dependence
structure of the corresponding vector time series of Fourier coefficients. By
allowing the number of functional principal components as well as the
autoregressive order used to increase to infinity (at some appropriate rate) as
the sample size increases, a basic bootstrap central limit theorem is
established which shows validity of the bootstrap procedure proposed for
functional finite Fourier transforms. Some numerical examples illustrate the
good finite sample performance of the new bootstrap method proposed.",http://arxiv.org/pdf/1609.06029v4,math.ST
2016-09-14 07:41:34+00:00,The Gaussian Graphical Model in Cross-sectional and Time-series Data,"['Sacha Epskamp', 'Lourens J. Waldorp', 'René Mõttus', 'Denny Borsboom']","We discuss the Gaussian graphical model (GGM; an undirected network of
partial correlation coefficients) and detail its utility as an exploratory data
analysis tool. The GGM shows which variables predict one-another, allows for
sparse modeling of covariance structures, and may highlight potential causal
relationships between observed variables. We describe the utility in 3 kinds of
psychological datasets: datasets in which consecutive cases are assumed
independent (e.g., cross-sectional data), temporally ordered datasets (e.g., n
= 1 time series), and a mixture of the 2 (e.g., n > 1 time series). In
time-series analysis, the GGM can be used to model the residual structure of a
vector-autoregression analysis (VAR), also termed graphical VAR. Two network
models can then be obtained: a temporal network and a contemporaneous network.
When analyzing data from multiple subjects, a GGM can also be formed on the
covariance structure of stationary means---the between-subjects network. We
discuss the interpretation of these models and propose estimation methods to
obtain these networks, which we implement in the R packages graphicalVAR and
mlVAR. The methods are showcased in two empirical examples, and simulation
studies on these methods are included in the supplementary materials.",http://arxiv.org/pdf/1609.04156v6,stat.ME
2016-09-06 12:05:15+00:00,Quantifying Heteroskedasticity via Bhattacharyya Distance,"['Marwa Hassan', 'Mo Hossny', 'Douglas Creighton', 'Saeid Nahavandi']","Heteroskedasticity is a statistical anomaly that describes differing
variances of error terms in a time series dataset. The presence of
heteroskedasticity in data imposes serious challenges for forecasting models
and many statistical tests are not valid in the presence of heteroskedasticity.
Heteroskedasticity of the data affects the relation between the predictor
variable and the outcome, which leads to false positive and false negative
decisions in the hypothesis testing. Available approaches to study
heteroskedasticity thus far adopt the strategy of accommodating
heteroskedasticity in the time series and consider it an inevitable source of
noise. In these existing approaches, two forecasting models are prepared for
normal and heteroskedastic scenarios and a statistical test is to determine
whether or not the data is heteroskedastic.
  This work-in-progress research introduces a quantifying measurement for
heteroskedasticity. The idea behind the proposed metric is the fact that a
heteroskedastic time series features a uniformly distributed local variances.
The proposed measurement is obtained by calculating the local variances using
linear time invariant filters. A probability density function of the calculated
local variances is then derived and compared to a uniform distribution of
theoretical ultimate heteroskedasticity using statistical divergence
measurements. The results demonstrated on synthetic datasets shows a strong
correlation between the proposed metric and number of variances locally
estimated in a heteroskedastic time series.",http://arxiv.org/pdf/1609.06145v1,math.ST
2016-09-02 18:49:44+00:00,Adaptive Bayesian Spectral Analysis of Nonstationary Biomedical Time Series,"['Scott A. Bruce', 'Martica H. Hall', 'Daniel J. Buysse', 'Robert T. Krafty']","Many studies of biomedical time series signals aim to measure the association
between frequency-domain properties of time series and clinical and behavioral
covariates. However, the time-varying dynamics of these associations are
largely ignored due to a lack of methods that can assess the changing nature of
the relationship through time. This article introduces a method for the
simultaneous and automatic analysis of the association between the time-varying
power spectrum and covariates. The procedure adaptively partitions the grid of
time and covariate values into an unknown number of approximately stationary
blocks and nonparametrically estimates local spectra within blocks through
penalized splines. The approach is formulated in a fully Bayesian framework, in
which the number and locations of partition points are random, and fit using
reversible jump Markov chain Monte Carlo techniques. Estimation and inference
averaged over the distribution of partitions allows for the accurate analysis
of spectra with both smooth and abrupt changes. The proposed methodology is
used to analyze the association between the time-varying spectrum of heart rate
variability and self-reported sleep quality in a study of older adults serving
as the primary caregiver for their ill spouse.",http://arxiv.org/pdf/1609.00696v2,stat.ME
2016-08-10 12:57:29+00:00,"Modelling, simulation and inference for multivariate time series of counts",['Almut E. D. Veraart'],"This article presents a new continuous-time modelling framework for
multivariate time series of counts which have an infinitely divisible marginal
distribution. The model is based on a mixed moving average process driven by
L\'{e}vy noise - called a trawl process - where the serial correlation and the
cross-sectional dependence are modelled independently of each other. Such
processes can exhibit short or long memory. We derive a stochastic simulation
algorithm and a statistical inference method for such processes. The new
methodology is then applied to high frequency financial data, where we
investigate the relationship between the number of limit order submissions and
deletions in a limit order book.",http://arxiv.org/pdf/1608.03154v1,stat.ME
2016-08-06 04:51:35+00:00,Testing for high-dimensional white noise using maximum cross-correlations,"['Jinyuan Chang', 'Qiwei Yao', 'Wen Zhou']","We propose a new omnibus test for vector white noise using the maximum
absolute auto-correlations and cross-correlations of the component series.
Based on the newly established approximation by the $L_\infty$-norm of a normal
random vector, the critical value of the test can be evaluated by bootstrapping
from a multivariate normal distribution. In contrast to the conventional white
noise test, the new method is proved to be valid for testing the departure from
non-IID white noise. We illustrate the accuracy and the power of the proposed
test by simulation, which also shows that the new test outperforms several
commonly used methods including, for example, the Lagrange multiplier test and
the multivariate Box-Pierce portmanteau tests especially when the dimension of
time series is high in relation to the sample size. The numerical results also
indicate that the performance of the new test can be further enhanced when it
is applied to the pre-transformed data obtained via the time series principal
component analysis proposed by Chang, Guo and Yao (2014). The proposed
procedures have been implemented in an R-package HDtest and is available online
at CRAN.",http://arxiv.org/pdf/1608.02067v3,stat.ME
2016-08-03 04:42:02+00:00,Fuzzy c-Shape: A new algorithm for clustering finite time series waveforms,"['Fateme Fahiman', 'Jame C. Bezdek', 'Sarah M. Erfani', 'Christopher Leckie', 'Marimuthu Palaniswami']","The existence of large volumes of time series data in many applications has
motivated data miners to investigate specialized methods for mining time series
data. Clustering is a popular data mining method due to its powerful
exploratory nature and its usefulness as a preprocessing step for other data
mining techniques. This article develops two novel clustering algorithms for
time series data that are extensions of a crisp c-shapes algorithm. The two new
algorithms are heuristic derivatives of fuzzy c-means (FCM). Fuzzy c-Shapes
plus (FCS+) replaces the inner product norm in the FCM model with a shape-based
distance function. Fuzzy c-Shapes double plus (FCS++) uses the shape-based
distance, and also replaces the FCM cluster centers with shape-extracted
prototypes. Numerical experiments on 48 real time series data sets show that
the two new algorithms outperform state-of-the-art shape-based clustering
algorithms in terms of accuracy and efficiency. Four external cluster validity
indices (the Rand index, Adjusted Rand Index, Variation of Information, and
Normalized Mutual Information) are used to match candidate partitions generated
by each of the studied algorithms. All four indices agree that for these finite
waveform data sets, FCS++ gives a small improvement over FCS+, and in turn,
FCS+ is better than the original crisp c-shapes method. Finally, we apply two
tests of statistical significance to the three algorithms. The Wilcoxon and
Friedman statistics both rank the three algorithms in exactly the same way as
the four cluster validity indices.",http://arxiv.org/pdf/1608.01072v1,cs.LG
2016-08-01 15:54:26+00:00,R package imputeTestbench to compare imputations methods for univariate time series,"['Neeraj Bokde', 'Kishore Kulat', 'Marcus W Beck', 'Gualberto Asencio-Cortés']","This paper describes the R package imputeTestbench that provides a testbench
for comparing imputation methods for missing data in univariate time series.
The imputeTestbench package can be used to simulate the amount and type of
missing data in a complete dataset and compare filled data using different
imputation methods. The user has the option to simulate missing data by
removing observations completely at random or in blocks of different sizes.
Several default imputation methods are included with the package, including
historical means, linear interpolation, and last observation carried forward.
The testbench is not limited to the default functions and users can add or
remove additional methods using a simple two-step process. The testbench
compares the actual missing and imputed data for each method with different
error metrics, including RMSE, MAE, and MAPE. Alternative error metrics can
also be supplied by the user. The simplicity of use and significant reduction
in time to compare imputation methods for missing data in univariate time
series is a significant advantage of the package. This paper provides an
overview of the core functions, including a demonstration with examples.",http://arxiv.org/pdf/1608.00476v2,stat.ME
2016-07-15 14:24:09+00:00,Modelling high-dimensional time series efficiently by means of constrained spatio--temporal models,['Maria Lucia Parrella'],"Many econometric analyses involve spatio--temporal data. A considerable
amount of literature has addressed spatio--temporal models, with Spatial
Dynamic Panel Data (SDPD) being widely investigated and applied. In real data
applications, checking the validity of the theoretical assumptions underlying
the SDPD models is essential but sometimes difficult. At other times, the
assumptions are clearly violated. For example, the spatial matrix is assumed to
be known but it may actually be unknown and needs to be estimated. In such
cases, the performance of the SDPD model's estimator is generally affected.
Motivated by such considerations, we propose a new model (called stationary
SDPD) and a new estimation procedure based on simple and clear assumptions that
can be easily checked with real data. The new model is highly adaptive, and the
estimation procedure has a rate of convergence that is not affected by the
dimension of the time series (under general assumptions), notwithstanding the
relatively high number of parameters to be estimated. The new model may be used
to represent a wide class of multivariate time series, not necessarily
spatio-temporal. So, it can be used as a valid alternative to vector
autoregressive (VAR) models with two immediate advantages: i) a faster rate of
convergence of the estimation procedure and ii) the possibility of estimating
the model even when the dimension is higher than the time series length,
overcoming the curse of dimensionality typical of the VAR models. The
simulation study shows that the new estimation procedure performs well compared
with the classic alternative procedure, even when the spatial matrix is unknown
and therefore estimated.",http://arxiv.org/pdf/1607.04522v1,stat.ME
2016-07-11 21:33:05+00:00,"A note on Rényi's ""record"" problem and Engel's series","['Lulu Fang', 'Min Wu']","In 1973, Williams introduced two interesting discrete Markov processes,
namely $C$-processes and $A$-processes, which are related to record times in
statistics and Engel's series in number theory respectively. Moreover, he
showed that these two processes share the same classical limit theorems, such
as the law of large numbers, central limit theorem and law of the iterated
logarithm. In this paper, we consider the large deviations for these two Markov
processes, which indicate that there is a difference between $C$-processes and
$A$-processes in the context of large deviations.",http://arxiv.org/pdf/1607.03173v3,math.ST
2016-07-07 13:58:31+00:00,Detection of periodicity in functional time series,"['Siegfried Hörmann', 'Piotr Kokoszka', 'Gilles Nisol']","We derive several tests for the presence of a periodic component in a time
series of functions. We consider both the traditional setting in which the
periodic functional signal is contaminated by functional white noise, and a
more general setting of a contaminating process which is weakly dependent.
Several forms of the periodic component are considered. Our tests are motivated
by the likelihood principle and fall into two broad categories, which we term
multivariate and fully functional. Overall, for the functional series that
motivate this research, the fully functional tests exhibit a superior balance
of size and power. Asymptotic null distributions of all tests are derived and
their consistency is established. Their finite sample performance is examined
and compared by numerical studies and application to pollution data.",http://arxiv.org/pdf/1607.02017v1,stat.ME
2016-07-06 14:21:41+00:00,Bayesian emulation for optimization in multi-step portfolio decisions,"['Kaoru Irie', 'Mike West']","We discuss the Bayesian emulation approach to computational solution of
multi-step portfolio studies in financial time series. ""Bayesian emulation for
decisions"" involves mapping the technical structure of a decision analysis
problem to that of Bayesian inference in a purely synthetic ""emulating""
statistical model. This provides access to standard posterior analytic,
simulation and optimization methods that yield indirect solutions of the
decision problem. We develop this in time series portfolio analysis using
classes of economically and psychologically relevant multi-step ahead portfolio
utility functions. Studies with multivariate currency, commodity and stock
index time series illustrate the approach and show some of the practical
utility and benefits of the Bayesian emulation methodology.",http://arxiv.org/pdf/1607.01631v1,stat.ME
2016-07-04 00:50:30+00:00,Automatic Generation of Probabilistic Programming from Time Series Data,"['Anh Tong', 'Jaesik Choi']","Probabilistic programming languages represent complex data with intermingled
models in a few lines of code. Efficient inference algorithms in probabilistic
programming languages make possible to build unified frameworks to compute
interesting probabilities of various large, real-world problems. When the
structure of model is given, constructing a probabilistic program is rather
straightforward. Thus, main focus have been to learn the best model parameters
and compute marginal probabilities. In this paper, we provide a new perspective
to build expressive probabilistic program from continue time series data when
the structure of model is not given. The intuition behind of our method is to
find a descriptive covariance structure of time series data in nonparametric
Gaussian process regression. We report that such descriptive covariance
structure efficiently derives a probabilistic programming description
accurately.",http://arxiv.org/pdf/1607.00710v2,stat.ML
2016-07-01 08:17:27+00:00,Efficient and Consistent Robust Time Series Analysis,"['Kush Bhatia', 'Prateek Jain', 'Parameswaran Kamalaruban', 'Purushottam Kar']","We study the problem of robust time series analysis under the standard
auto-regressive (AR) time series model in the presence of arbitrary outliers.
We devise an efficient hard thresholding based algorithm which can obtain a
consistent estimate of the optimal AR model despite a large fraction of the
time series points being corrupted. Our algorithm alternately estimates the
corrupted set of points and the model parameters, and is inspired by recent
advances in robust regression and hard-thresholding methods. However, a direct
application of existing techniques is hindered by a critical difference in the
time-series domain: each point is correlated with all previous points rendering
existing tools inapplicable directly. We show how to overcome this hurdle using
novel proof techniques. Using our techniques, we are also able to provide the
first efficient and provably consistent estimator for the robust regression
problem where a standard linear observation model with white additive noise is
corrupted arbitrarily. We illustrate our methods on synthetic datasets and show
that our methods indeed are able to consistently recover the optimal parameters
despite a large fraction of points being corrupted.",http://arxiv.org/pdf/1607.00146v1,cs.LG
2016-06-29 17:06:45+00:00,Disease Trajectory Maps,"['Peter Schulam', 'Raman Arora']","Medical researchers are coming to appreciate that many diseases are in fact
complex, heterogeneous syndromes composed of subpopulations that express
different variants of a related complication. Time series data extracted from
individual electronic health records (EHR) offer an exciting new way to study
subtle differences in the way these diseases progress over time. In this paper,
we focus on answering two questions that can be asked using these databases of
time series. First, we want to understand whether there are individuals with
similar disease trajectories and whether there are a small number of degrees of
freedom that account for differences in trajectories across the population.
Second, we want to understand how important clinical outcomes are associated
with disease trajectories. To answer these questions, we propose the Disease
Trajectory Map (DTM), a novel probabilistic model that learns low-dimensional
representations of sparse and irregularly sampled time series. We propose a
stochastic variational inference algorithm for learning the DTM that allows the
model to scale to large modern medical datasets. To demonstrate the DTM, we
analyze data collected on patients with the complex autoimmune disease,
scleroderma. We find that DTM learns meaningful representations of disease
trajectories and that the representations are significantly associated with
important clinical outcomes.",http://arxiv.org/pdf/1606.09184v1,stat.ML
2016-06-28 15:40:17+00:00,Bayesian analysis of immune response dynamics with sparse time series data,"['Fernando V. Bonassi', 'Cliburn Chan', 'Mike West']","In vaccine development, the temporal profiles of relative abundance of
subtypes of immune cells (T-cells) is key to understanding vaccine efficacy.
Complex and expensive experimental studies generate very sparse time series
data on this immune response. Fitting multi-parameter dynamic models of the
immune response dynamics-- central to evaluating mechanisms underlying vaccine
efficacy-- is challenged by data sparsity. The research reported here addresses
this challenge. For HIV/SIV vaccine studies in macaques, we: (a) introduce
novel dynamic models of progression of cellular populations over time with
relevant, time-delayed components reflecting the vaccine response; (b) define
an effective Bayesian model fitting strategy that couples Markov chain Monte
Carlo (MCMC) with Approximate Bayesian Computation (ABC)-- building on the
complementary strengths of the two approaches, neither of which is effective
alone; (c) explore questions of information content in the sparse time series
for each of the model parameters, linking into experimental design and model
simplification for future experiments; and (d) develop, apply and compare the
analysis with samples from a recent HIV/SIV experiment, with novel insights and
conclusions about the progressive response to the vaccine, and how this varies
across subjects.",http://arxiv.org/pdf/1606.08759v1,stat.ME
2016-06-27 16:05:42+00:00,Dynamic dependence networks: Financial time series forecasting and portfolio decisions (with discussion),"['Zoey Yi Zhao', 'Meng Xie', 'Mike West']","We discuss Bayesian forecasting of increasingly high-dimensional time series,
a key area of application of stochastic dynamic models in the financial
industry and allied areas of business. Novel state-space models characterizing
sparse patterns of dependence among multiple time series extend existing
multivariate volatility models to enable scaling to higher numbers of
individual time series. The theory of these ""dynamic dependence network"" models
shows how the individual series can be ""decoupled"" for sequential analysis, and
then ""recoupled"" for applied forecasting and decision analysis. Decoupling
allows fast, efficient analysis of each of the series in individual univariate
models that are linked-- for later recoupling-- through a theoretical
multivariate volatility structure defined by a sparse underlying graphical
model. Computational advances are especially significant in connection with
model uncertainty about the sparsity patterns among series that define this
graphical model; Bayesian model averaging using discounting of historical
information builds substantially on this computational advance. An extensive,
detailed case study showcases the use of these models, and the improvements in
forecasting and financial portfolio investment decisions that are achievable.
Using a long series of daily international currency, stock indices and
commodity prices, the case study includes evaluations of multi-day forecasts
and Bayesian portfolio analysis with a variety of practical utility functions,
as well as comparisons against commodity trading advisor benchmarks.",http://arxiv.org/pdf/1606.08339v1,stat.ME
2016-06-27 14:03:40+00:00,Out-of-Sample Extension for Dimensionality Reduction of Noisy Time Series,"['Hamid Dadkhahi', 'Marco F. Duarte', 'Benjamin Marlin']","This paper proposes an out-of-sample extension framework for a global
manifold learning algorithm (Isomap) that uses temporal information in
out-of-sample points in order to make the embedding more robust to noise and
artifacts. Given a set of noise-free training data and its embedding, the
proposed framework extends the embedding for a noisy time series. This is
achieved by adding a spatio-temporal compactness term to the optimization
objective of the embedding. To the best of our knowledge, this is the first
method for out-of-sample extension of manifold embeddings that leverages timing
information available for the extension set. Experimental results demonstrate
that our out-of-sample extension algorithm renders a more robust and accurate
embedding of sequentially ordered image data in the presence of various noise
and artifacts when compared to other timing-aware embeddings. Additionally, we
show that an out-of-sample extension framework based on the proposed algorithm
outperforms the state of the art in eye-gaze estimation.",http://arxiv.org/pdf/1606.08282v3,stat.ML
2016-06-20 18:54:28+00:00,High-dimensional changepoint estimation via sparse projection,"['Tengyao Wang', 'Richard J. Samworth']","Changepoints are a very common feature of Big Data that arrive in the form of
a data stream. In this paper, we study high-dimensional time series in which,
at certain time points, the mean structure changes in a sparse subset of the
coordinates. The challenge is to borrow strength across the coordinates in
order to detect smaller changes than could be observed in any individual
component series. We propose a two-stage procedure called `inspect' for
estimation of the changepoints: first, we argue that a good projection
direction can be obtained as the leading left singular vector of the matrix
that solves a convex optimisation problem derived from the CUSUM transformation
of the time series. We then apply an existing univariate changepoint estimation
algorithm to the projected series. Our theory provides strong guarantees on
both the number of estimated changepoints and the rates of convergence of their
locations, and our numerical studies validate its highly competitive empirical
performance for a wide range of data generating mechanisms. Software
implementing the methodology is available in the R package
`InspectChangepoint'.",http://arxiv.org/pdf/1606.06246v2,stat.ME
2016-06-17 11:14:29+00:00,Applications of Distance Correlation to Time Series,"['Richard A. Davis', 'Muneya Matsui', 'Thomas Mikosch', 'Phyllis Wan']","The use of empirical characteristic functions for inference problems,
including estimation in some special parametric settings and testing for
goodness of fit, has a long history dating back to the 70s (see for example,
Feuerverger and Mureika (1977), Csorgo (1981a,1981b,1981c), Feuerverger
(1993)). More recently, there has been renewed interest in using empirical
characteristic functions in other inference settings. The distance covariance
and correlation, developed by Szekely and Rizzo (2009) for measuring dependence
and testing independence between two random vectors, are perhaps the best known
illustrations of this. We apply these ideas to stationary univariate and
multivariate time series to measure lagged auto- and cross-dependence in a time
series. Assuming strong mixing, we establish the relevant asymptotic theory for
the sample auto- and cross-distance correlation functions. We also apply the
auto-distance correlation function (ADCF) to the residuals of an autoregressive
processes as a test of goodness of fit. Under the null that an autoregressive
model is true, the limit distribution of the empirical ADCF can differ markedly
from the corresponding one based on an iid sequence. We illustrate the use of
the empirical auto- and cross-distance correlation functions for testing
dependence and cross-dependence of time series in a variety of different
contexts.",http://arxiv.org/pdf/1606.05481v1,math.ST
2016-06-14 16:31:14+00:00,A scalable end-to-end Gaussian process adapter for irregularly sampled time series classification,"['Steven Cheng-Xian Li', 'Benjamin Marlin']","We present a general framework for classification of sparse and
irregularly-sampled time series. The properties of such time series can result
in substantial uncertainty about the values of the underlying temporal
processes, while making the data difficult to deal with using standard
classification methods that assume fixed-dimensional feature spaces. To address
these challenges, we propose an uncertainty-aware classification framework
based on a special computational layer we refer to as the Gaussian process
adapter that can connect irregularly sampled time series data to any black-box
classifier learnable using gradient descent. We show how to scale up the
required computations based on combining the structured kernel interpolation
framework and the Lanczos approximation method, and how to discriminatively
train the Gaussian process adapter in combination with a number of classifiers
end-to-end using backpropagation.",http://arxiv.org/pdf/1606.04443v2,stat.ML
2016-06-14 15:49:06+00:00,Nonparametric causal inference from observational time series through marginal integration,"['Shu Li', 'Jan Ernest', 'Peter Bühlmann']","Causal inference from observational data is an ambitious but highly relevant
task, with diverse applications ranging from natural to social sciences. Within
the scope of nonparametric time series, causal inference defined through
interventions (cf. Pearl (2000)) is largely unexplored, although time order
simplifies the problem substantially. We consider a marginal integration scheme
for inferring causal effects from observational time series data, MINT-T
(marginal integration in time series), which is an adaptation for time series
of a method proposed by Ernest and B\""{u}hlmann (Electron. J. Statist, pp.
3155-3194, vol. 9, 2015) for the case of independent data. Our approach for
stationary stochastic processes is fully nonparametric and, assuming no
instantaneous effects consistently recovers the total causal effect of a single
intervention with optimal one-dimensional nonparametric convergence rate
$n^{-2/5}$ assuming regularity conditions and twice differentiability of a
certain corresponding regression function. Therefore, MINT-T remains largely
unaffected by the curse of dimensionality as long as smoothness conditions hold
in higher dimensions and it is feasible for a large class of stationary time
series, including nonlinear and multivariate processes. For the case with
instantaneous effects, we provide a procedure which guards against false
positive causal statements.",http://arxiv.org/pdf/1606.04431v3,stat.ME
2016-06-14 15:33:57+00:00,Exponential Growth Series and Benford's Law,['Alex Ely Kossovsky'],"Exponential growth occurs when the growth rate of a given quantity is
proportional to the quantity's current value. Surprisingly, when exponential
growth data is plotted as a simple histogram disregarding the time dimension, a
remarkable fit to the positively skewed k/x distribution is found, where the
small is numerous and the big is rare. Such quantitative preference for the
small has a corresponding digital preference known as Benford's Law which
predicts that the first significant digit on the left-most side of numbers in
typical real-life data is proportioned between all possible 1 to 9 digits
approximately as in LOG(1 + 1/digit), so that low digits occur much more
frequently than high digits in the first place. Exponential growth series with
high growth rate are nearly perfectly Benford given that plenty of elements are
considered. An additional constraint is that the logarithm of the growth factor
must be an irrational number. Since the irrationals vastly outnumber the
rationals, on the face of it, this constraint seems to constitute the
explanation of why almost all growth series are Benford, yet, in reality this
is all too simplistic, and the real and more complex explanation is provided in
this article. Empirical examinations of close to a half a million growth series
via computerized programs almost perfectly match the prediction of the
theoretical study on rational versus irrational occurrences, thus in a sense
confirming both, the empirical work as well as the theoretical study. In
addition, a rigorous mathematical proof is provided in the continuous growth
case showing that it exactly obeys Benford's Law. A non-rigorous proof is given
in the discrete case via uniformity of mantissa argument. Finally cases of
discrete series embedded within continuous series are studied, detailing the
degree of deviation from the ideal Benford configuration.",http://arxiv.org/pdf/1606.04425v2,math.ST
2016-06-13 20:34:35+00:00,Modeling Missing Data in Clinical Time Series with RNNs,"['Zachary C. Lipton', 'David C. Kale', 'Randall Wetzel']","We demonstrate a simple strategy to cope with missing data in sequential
inputs, addressing the task of multilabel classification of diagnoses given
clinical time series. Collected from the pediatric intensive care unit (PICU)
at Children's Hospital Los Angeles, our data consists of multivariate time
series of observations. The measurements are irregularly spaced, leading to
missingness patterns in temporally discretized sequences. While these artifacts
are typically handled by imputation, we achieve superior predictive performance
by treating the artifacts as features. Unlike linear models, recurrent neural
networks can realize this improvement using only simple binary indicators of
missingness. For linear models, we show an alternative strategy to capture this
signal. Training models on missingness patterns only, we show that for some
diseases, what tests are run can be as predictive as the results themselves.",http://arxiv.org/pdf/1606.04130v5,cs.LG
2016-06-08 15:57:35+00:00,Specific Differential Entropy Rate Estimation for Continuous-Valued Time Series,['David Darmon'],"We introduce a method for quantifying the inherent unpredictability of a
continuous-valued time series via an extension of the differential Shannon
entropy rate. Our extension, the specific entropy rate, quantifies the amount
of predictive uncertainty associated with a specific state, rather than
averaged over all states. We relate the specific entropy rate to popular
`complexity' measures such as Approximate and Sample Entropies. We provide a
data-driven approach for estimating the specific entropy rate of an observed
time series. Finally, we consider three case studies of estimating specific
entropy rate from synthetic and physiological data relevant to the analysis of
heart rate variability.",http://arxiv.org/pdf/1606.02615v1,cs.LG
2016-06-06 19:08:41+00:00,Recurrent Neural Networks for Multivariate Time Series with Missing Values,"['Zhengping Che', 'Sanjay Purushotham', 'Kyunghyun Cho', 'David Sontag', 'Yan Liu']","Multivariate time series data in practical applications, such as health care,
geoscience, and biology, are characterized by a variety of missing values. In
time series prediction and other related tasks, it has been noted that missing
values and their missing patterns are often correlated with the target labels,
a.k.a., informative missingness. There is very limited work on exploiting the
missing patterns for effective imputation and improving prediction performance.
In this paper, we develop novel deep learning models, namely GRU-D, as one of
the early attempts. GRU-D is based on Gated Recurrent Unit (GRU), a
state-of-the-art recurrent neural network. It takes two representations of
missing patterns, i.e., masking and time interval, and effectively incorporates
them into a deep model architecture so that it not only captures the long-term
temporal dependencies in time series, but also utilizes the missing patterns to
achieve better prediction results. Experiments of time series classification
tasks on real-world clinical datasets (MIMIC-III, PhysioNet) and synthetic
datasets demonstrate that our models achieve state-of-the-art performance and
provides useful insights for better understanding and utilization of missing
values in time series analysis.",http://arxiv.org/pdf/1606.01865v2,cs.LG
2016-06-03 07:03:18+00:00,Detecting Serial Dependence in Binomial Time Series II: Observation Driven Models,"['W. T. M. Dunsmuir', 'J. Y. He']","The detection of serial dependence in binary or binomial valued time series
is difficult using standard time series methods, particularly when there are
regression effects to be modelled. In this paper we derive score-type tests for
detecting departures from independence in the directions of the GLARMA\ and
BARMA\ type observation driven models. These score tests can easily be applied
using a standard logistic regression and so may have appeal to practitioners
who wish to initially assess the need to incorporate serial dependence effects.
To deal with the nuisance parameters in some GLARMA models a supremum type test
is implemented.",http://arxiv.org/pdf/1606.00984v1,math.ST
2016-06-03 07:02:09+00:00,Testing for Serial Dependence in Binomial Time Series I: Parameter Driven Models,"['W. T. M. Dunsmuir', 'J. Y. He']","Binomial time series in which the logit of the probability of success is
modelled as a linear function of observed regressors and a stationary latent
Gaussian process are considered. Score tests are developed to first test for
the existence of a latent process and, subsequent to that, evidence of serial
dependence in that latent process. The test for the existence of a latent
process is important because, if one is present, standard logistic regression
methods will produce inconsistent estimates of the regression parameters.
However the score test is non-standard and any serial dependence in the latent
process will require consideration of nuisance parameters which cannot be
estimated under the null hypothesis of no latent process. The paper describes
how a supremum-type test can be applied. If a latent process is detected,
consistent estimation of its variance and the regression parameters can be done
using marginal estimation which is easily implemented using generalised linear
mixed model methods. The test for serial dependence in a latent process does
not involve nuisance parameters and is based on the covariances between
residuals centered at functions of the latent process conditional on the
observations. This requires numerical integration in order to compute the test
statistic. Relevant asymptotic results are derived and confirmed using
simulation evidence. Application to binary and binomial time series is made.
For binary series in particular, a complication is that the variance of the
latent process, even if present, can be estimated to be zero with a high
probability.",http://arxiv.org/pdf/1606.00983v1,math.ST
2016-06-03 06:27:34+00:00,Marginal Estimation of Parameter Driven Binomial Time Series Models,"['W. T. M. Dunsmuir', 'J. Y. He']","This paper develops asymptotic theory for estimation of parameters in
regression models for binomial response time series where serial dependence is
present through a latent process. Use of generalized linear model (GLM)
estimating equations leads to asymptotically biased estimates of regression
coefficients for binomial responses. An alternative is to use marginal
likelihood, in which the variance of the latent process but not the serial
dependence is accounted for. In practice this is equivalent to using
generalized linear mixed model estimation procedures treating the observations
as independent with a random effect on the intercept term in the regression
model. We prove this method leads to consistent and asymptotically normal
estimates even if there is an autocorrelated latent process. Simulations
suggest that the use of marginal likelihood can lead to GLM estimates result.
This problem reduces rapidly with increasing number of binomial trials at each
time point but, for binary data, the chance of it can remain over 45% even in
very long time series. We provide a combination of theoretical and heuristic
explanations for this phenomenon in terms of the properties of the regression
component of the model and these can be used to guide application of the method
in practice.",http://arxiv.org/pdf/1606.00976v1,math.ST
2016-06-02 06:04:47+00:00,Modelling discrete valued cross sectional time series with observation driven models,"['W. T. M. Dunsmuir', 'C. McKendry', 'R. T. Dean']","This paper develops computationally feasible methods for estimating random
effects models in the context of regression modelling of multiple independent
time series of discrete valued counts in which there is serial dependence.
Given covariates, random effects and process history, the observed responses at
each time in each series are independent and have an exponential family
distribution. We develop maximum likelihood estimation of the mixed effects
model using an observation driven generalized linear autoregressive moving
average specification for the serial dependence in each series. The paper
presents an easily implementable approach which uses existing single time
series methods to handle the serial dependence structure in combination with
adaptive Gaussian quadrature to approximate the integrals over the regression
random effects required for the likelihood and its derivatives. The models and
methods presented allow extension of existing mixed model procedures for count
data by incorporating serial dependence which can differ in form and strength
across the individual series. The structure of the model has some similarities
to longitudinal data transition models with random effects. However, in
contrast to that setting, where there are many cases and few to moderate
observations per case, the time series setting has many observations per series
and a few to moderate number of cross sectional time series. The method is
illustrated on time series of binary responses to musical features obtained
from a panel of listeners.",http://arxiv.org/pdf/1606.00547v2,stat.ME
2016-05-30 05:12:02+00:00,Analysis of nonstationary modulated time series with applications to oceanographic flow measurements,"['Arthur P. Guillaumin', 'Adam M. Sykulski', 'Sofia C. Olhede', 'Jeffrey J. Early', 'Jonathan M. Lilly']","We propose a new class of univariate nonstationary time series models, using
the framework of modulated time series, which is appropriate for the analysis
of rapidly-evolving time series as well as time series observations with
missing data. We extend our techniques to a class of bivariate time series that
are isotropic. Exact inference is often not computationally viable for time
series analysis, and so we propose an estimation method based on the
Whittle-likelihood, a commonly adopted pseudo-likelihood. Our inference
procedure is shown to be consistent under standard assumptions, as well as
having considerably lower computational cost than exact likelihood in general.
We show the utility of this framework for the analysis of drifting instruments,
an analysis that is key to characterising global ocean circulation and
therefore also for decadal to century-scale climate understanding.",http://arxiv.org/pdf/1605.09107v2,stat.ME
2016-05-19 12:12:33+00:00,A Frequency Domain Test for Propriety of Complex-Valued Vector Time Series,"['Swati Chandna', 'Andrew T. Walden']","This paper proposes a frequency domain approach to test the hypothesis that a
complex-valued vector time series is proper, i.e., for testing whether the
vector time series is uncorrelated with its complex conjugate. If the
hypothesis is rejected, frequency bands causing the rejection will be
identified and might usefully be related to known properties of the physical
processes. The test needs the associated spectral matrix which can be estimated
by multitaper methods using, say, $K$ tapers. Standard asymptotic distributions
for the test statistic are of no use since they would require $K \rightarrow
\infty,$ but, as $K$ increases so does resolution bandwidth which causes
spectral blurring. In many analyses $K$ is necessarily kept small, and hence
our efforts are directed at practical and accurate methodology for hypothesis
testing for small $K.$ Our generalized likelihood ratio statistic combined with
exact cumulant matching gives very accurate rejection percentages and
outperforms other methods. We also prove that the statistic on which the test
is based is comprised of canonical coherencies arising from our complex-valued
vector time series.Our methodology is demonstrated on ocean current data
collected at different depths in the Labrador Sea. Overall this work extends
results on propriety testing for complex-valued vectors to the complex-valued
vector time series setting.",http://arxiv.org/pdf/1605.05910v1,stat.ME
2016-05-17 12:46:46+00:00,Automatic Classification of Irregularly Sampled Time Series with Unequal Lengths: A Case Study on Estimated Glomerular Filtration Rate,"['Santosh Tirunagari', 'Simon Bull', 'Norman Poh']","A patient's estimated glomerular filtration rate (eGFR) can provide important
information about disease progression and kidney function. Traditionally, an
eGFR time series is interpreted by a human expert labelling it as stable or
unstable. While this approach works for individual patients, the time consuming
nature of it precludes the quick evaluation of risk in large numbers of
patients. However, automating this process poses significant challenges as eGFR
measurements are usually recorded at irregular intervals and the series of
measurements differs in length between patients. Here we present a two-tier
system to automatically classify an eGFR trend. First, we model the time series
using Gaussian process regression (GPR) to fill in `gaps' by resampling a fixed
size vector of fifty time-dependent observations. Second, we classify the
resampled eGFR time series using a K-NN/SVM classifier, and evaluate its
performance via 5-fold cross validation. Using this approach we achieved an
F-score of 0.90, compared to 0.96 for 5 human experts when scored amongst
themselves.",http://arxiv.org/pdf/1605.05142v1,cs.LG
2016-05-09 19:55:24+00:00,Gaussian Processes for Local Polynomial Forecasting of Time Series,['Kerry Fendick'],"Non-stationary time series with non-linear trends are frequently encountered
in applications. We consider here the feasibility of accurately forecasting the
signals of multiple such time series considering jointly when the number of
historic samples is inadequate for accurately forecasting the signal of each
considered in isolation. We develop a new forecasting methodology based on
Gaussian process regression that is successful in doing so in examples for
which the method of generalized least-squares is not. The new method employs a
form of deep machine learning.",http://arxiv.org/pdf/1605.02718v2,stat.ME
2016-05-03 08:13:58+00:00,Temporal Clustering of Time Series via Threshold Autoregressive Models: Application to Commodity Prices,"['Sipan Aslan', 'Ceylan Yozgatligil', 'Cem Iyigun']","This study aimed to find temporal clusters for several commodity prices using
the threshold non-linear autoregressive model. It is expected that the process
of determining the commodity groups that are time-dependent will advance the
current knowledge about the dynamics of co-moving and coherent prices, and can
serve as a basis for multivariate time series analyses. The clustering of
commodity prices was examined using the proposed clustering approach based on
time series models to incorporate the time varying properties of price series
into the clustering scheme. Accordingly, the primary aim in this study was
grouping time series according to the similarity between their Data Generating
Mechanisms (DGMs) rather than comparing pattern similarities in the time series
traces. The approximation to the DGM of each series was accomplished using
threshold autoregressive models, which are recognized for their ability to
represent nonlinear features in time series, such as abrupt changes,
time-irreversibility and regime-shifting behavior. Through the use of the
proposed approach, one can determine and monitor the set of co-moving time
series variables across the time dimension. Furthermore, generating a time
varying commodity price index and sub-indexes can become possible.
Consequently, we conducted a simulation study to assess the effectiveness of
the proposed clustering approach and the results are presented for both the
simulated and real data sets.",http://arxiv.org/pdf/1605.00779v1,stat.ML
2016-05-02 04:17:49+00:00,Multiple Change Point Analysis: Fast Implementation And Strong Consistency,"['Jie Ding', 'Yu Xiang', 'Lu Shen', 'Vahid Tarokh']","One of the main challenges in identifying structural changes in stochastic
processes is to carry out analysis for time series with dependency structure in
a computationally tractable way. Another challenge is that the number of true
change points is usually unknown, requiring a suitable model selection
criterion to arrive at informative conclusions. To address the first challenge,
we model the data generating process as a segment-wise autoregression, which is
composed of several segments (time epochs), each of which modeled by an
autoregressive model. We propose a multi-window method that is both effective
and efficient for discovering the structural changes. The proposed approach was
motivated by transforming a segment-wise autoregression into a multivariate
time series that is asymptotically segment-wise independent and identically
distributed. To address the second challenge, we derive theoretical guarantees
for (almost surely) selecting the true number of change points of segment-wise
independent multivariate time series. Specifically, under mild assumptions, we
show that a Bayesian Information Criterion (BIC)-like criterion gives a
strongly consistent selection of the optimal number of change points, while an
Akaike Information Criterion (AIC)-like criterion cannot. Finally, we
demonstrate the theory and strength of the proposed algorithms by experiments
on both synthetic and real-world data, including the Eastern US temperature
data and the El Nino data from 1854 to 2015. The experiment leads to some
interesting discoveries about temporal variability of the summer-time
temperature over the Eastern US, and about the most dominant factor of ocean
influence on climate.",http://arxiv.org/pdf/1605.00346v2,stat.ME
2016-04-22 15:42:25+00:00,"Supplementary Material for ""Should we sample a time series more frequently? Decision support via multirate spectrum estimation (with discussion)""","['Guy P. Nason', 'Ben Powell', 'Duncan Elliott', 'Paul A. Smith']","This technical report includes an assortment of technical details and
extended discussions related to paper ""Should we sample a time series more
frequently? Decision support via multirate spectrum estimation (with
discussion)"", which introduces a model for estimating the log-spectral density
of a stationary discrete time process given systematically missing data and
models the cost implication for changing the sampling rate.",http://arxiv.org/pdf/1604.06716v1,stat.ME
2016-04-21 03:38:38+00:00,Adjusted Empirical Likelihood for Long-memory Time Series Models,"['Ramadha D. Piyadi Gamage', 'Wei Ning', 'Arjun K. Gupta']","Empirical likelihood method has been applied to short-memory time series
models by Monti (1997) through the Whittle's estimation method. Yau (2012)
extended this idea to long-memory time series models. Asymptotic distributions
of the empirical likelihood ratio statistic for short and long-memory time
series have been derived to construct confidence regions for the corresponding
model parameters. However, computing profile empirical likelihood function
involving constrained maximization does not always have a solution which leads
to several drawbacks. In this paper, we propose an adjusted empirical
likelihood procedure to modify the one proposed by Yau (2012) for
autoregressive fractionally integrated moving average (ARFIMA) model. It
guarantees the existence of a solution to the required maximization problem as
well as maintains same asymptotic properties obtained by Yau (2012).
Simulations have been carried out to illustrate that the adjusted empirical
likelihood method for different long-time series models provides better
confidence regions and coverage probabilities than the unadjusted ones,
especially for small sample sizes.",http://arxiv.org/pdf/1604.06170v1,stat.ME
2016-04-19 16:31:25+00:00,A copula-based model for multivariate ordinal panel data: application to well-being composition,"['Aristidis K. Nikoloulopoulos', 'Emmanouil Mentzakis']","A novel copula-based multivariate panel ordinal model is developed to
estimate structural relations among components of well-being. Each ordinal
time-series is modelled using a copula-based Markov model to relate the
marginal distributions of the response at each time of observation and then, at
each observation time, the conditional distributions of each ordinal
time-series are joined using a multivariate t copula. Maximum simulated
likelihood based on evaluating the multidimensional integrals of the likelihood
with randomized quasi Monte Carlo methods is used for the estimation.
Asymptotic calculations show that our method is nearly as efficient as maximum
likelihood for fully specified multivariate copula models. Our findings
highlight the importance of one's relative position in evaluating their
well-being with no direct effects of socio-economic characteristics on
well-being but strong indirect effects through their impact on components of
well-being. Temporal resilience, habit formation and behavioural traits can
explain the dependence in the joint tails over time and across well-being
components.",http://arxiv.org/pdf/1604.05643v2,stat.ME
2016-04-13 14:00:30+00:00,Detecting a Structural Change in Functional Time Series Using Local Wilcoxon Statistic,"['Daniel Kosiorowski', 'Jerzy P. Rydlewski', 'Małgorzata Snarska']","Functional data analysis (FDA) is a part of modern multivariate statistics
that analyses data providing information about curves, surfaces or anything
else varying over a certain continuum. In economics and empirical finance we
often have to deal with time series of functional data, where we cannot easily
decide, whether they are to be considered as homogeneous or heterogeneous. At
present a discussion on adequate tests of homogenity for functional data is
carried. We propose a novel statistic for detetecting a structural change in
functional time series based on a local Wilcoxon statistic induced by a local
depth function proposed by Paindaveine and Van Bever (2013).",http://arxiv.org/pdf/1604.03776v3,stat.ME
2016-04-10 15:17:10+00:00,Identifying the Spectral Representation of Hilbertian Time Series,"['Eduardo Horta', 'Flavio Ziegelmann']","We provide square-root n consistency results regarding estimation of the
spectral representation of covariance operators of Hilbertian time series, in a
setting with imperfect measurements. This is a generalization of the method
developed in Bathia et al. (2010). The generalization relies on an important
property of centered random elements in a separable Hilbert space, namely, that
they lie almost surely in the closed linear span of the associated covariance
operator. We provide a straightforward proof to this fact. This result is, to
our knowledge, overlooked in the literature. It incidentally gives a rigorous
formulation of PCA in Hilbert spaces.",http://arxiv.org/pdf/1604.02702v1,math.ST
2016-03-24 14:44:52+00:00,Clustering Time-Series Energy Data from Smart Meters,"['Alexander Lavin', 'Diego Klabjan']","Investigations have been performed into using clustering methods in data
mining time-series data from smart meters. The problem is to identify patterns
and trends in energy usage profiles of commercial and industrial customers over
24-hour periods, and group similar profiles. We tested our method on energy
usage data provided by several U.S. power utilities. The results show accurate
grouping of accounts similar in their energy usage patterns, and potential for
the method to be utilized in energy efficiency programs.",http://arxiv.org/pdf/1603.07602v1,stat.ML
2016-03-16 12:24:24+00:00,Short-term time series prediction using Hilbert space embeddings of autoregressive processes,"['Edgar A. Valencia', 'Mauricio A. Álvarez']","Linear autoregressive models serve as basic representations of discrete time
stochastic processes. Different attempts have been made to provide non-linear
versions of the basic autoregressive process, including different versions
based on kernel methods. Motivated by the powerful framework of Hilbert space
embeddings of distributions, in this paper we apply this methodology for the
kernel embedding of an autoregressive process of order $p$. By doing so, we
provide a non-linear version of an autoregressive process, that shows increased
performance over the linear model in highly complex time series. We use the
method proposed for one-step ahead forecasting of different time-series, and
compare its performance against other non-linear methods.",http://arxiv.org/pdf/1603.05060v1,stat.ML
2016-03-13 10:47:00+00:00,Clustering Financial Time Series: How Long is Enough?,"['Gautier Marti', 'Sébastien Andler', 'Frank Nielsen', 'Philippe Donnat']","Researchers have used from 30 days to several years of daily returns as
source data for clustering financial time series based on their correlations.
This paper sets up a statistical framework to study the validity of such
practices. We first show that clustering correlated random variables from their
observed values is statistically consistent. Then, we also give a first
empirical answer to the much debated question: How long should the time series
be? If too short, the clusters found can be spurious; if too long, dynamics can
be smoothed out.",http://arxiv.org/pdf/1603.04017v2,stat.ML
2016-03-10 17:12:03+00:00,Scalable Linear Causal Inference for Irregularly Sampled Time Series with Long Range Dependencies,"['Francois W. Belletti', 'Evan R. Sparks', 'Michael J. Franklin', 'Alexandre M. Bayen', 'Joseph E. Gonzalez']","Linear causal analysis is central to a wide range of important application
spanning finance, the physical sciences, and engineering. Much of the existing
literature in linear causal analysis operates in the time domain.
Unfortunately, the direct application of time domain linear causal analysis to
many real-world time series presents three critical challenges: irregular
temporal sampling, long range dependencies, and scale. Moreover, real-world
data is often collected at irregular time intervals across vast arrays of
decentralized sensors and with long range dependencies which make naive time
domain correlation estimators spurious. In this paper we present a frequency
domain based estimation framework which naturally handles irregularly sampled
data and long range dependencies while enabled memory and communication
efficient distributed processing of time series data. By operating in the
frequency domain we eliminate the need to interpolate and help mitigate the
effects of long range dependencies. We implement and evaluate our new work-flow
in the distributed setting using Apache Spark and demonstrate on both Monte
Carlo simulations and high-frequency financial trading that we can accurately
recover causal structure at scale.",http://arxiv.org/pdf/1603.03336v1,cs.LG
2016-03-10 11:08:26+00:00,"Modelling, Detrending and Decorrelation of Network Time Series","['M. I. Knight', 'M. A. Nunes', 'G. P. Nason']","A network time series is a multivariate time series augmented by a graph that
describes how variables (or nodes) are connected. We introduce the network
autoregressive (integrated) moving average (NARIMA) processes: a set of
flexible models for network time series. For fixed networks the NARIMA models
are essentially equivalent to vector autoregressive moving average-type models.
However, NARIMA models are especially useful when the structure of the graph,
associated with the multivariate time series, changes over time. Such network
topology changes are invisible to standard VARMA-like models. For integrated
NARIMA models we introduce network differencing, based on the network lifting
(wavelet) transform, which removes trend. We exhibit our techniques on a
network time series describing the evolution of mumps throughout counties of
England and Wales weekly during 2005. We further demonstrate the action of
network lifting on a simple bivariate VAR(1) model with associated two-node
graph. We show theoretically that decorrelation occurs only in certain
circumstances and maybe less than expected. This suggests that the
time-decorrelation properties of spatial network lifting are due more to the
trend removal properties of lifting rather than any kind of stochastic
decorrelation.",http://arxiv.org/pdf/1603.03221v1,stat.ME
2016-03-09 07:55:34+00:00,Semiparametric generalized linear models for time-series data,"['Thomas Fung', 'Alan Huang']","Time-series data in population health and epidemiology often involve
non-Gaussian responses. In this note, we propose a semiparametric generalized
linear models framework for time-series data that does not require
specification of a working conditional response distribution for the data.
Instead, the underlying response distribution is treated as an
infinite-dimensional parameter which is estimated simultaneously with the usual
finite-dimensional parameters via a maximum empirical likelihood approach. A
general consistency result for the resulting estimators is given. Simulations
suggest that both estimation and inferences using the proposed method can
perform as well as correctly-specified parametric models even for moderate
sample sizes, but can be more robust than parametric methods under model
misspecification. The method is used to analyse the Polio dataset from Zeger
(1988) and a recent Kings Cross assault dataset from Menendez et al. (2015).",http://arxiv.org/pdf/1603.02802v1,stat.ME
2016-03-02 16:37:40+00:00,The Arrow of Time in Multivariate Time Series,"['Stefan Bauer', 'Bernhard Schölkopf', 'Jonas Peters']","We prove that a time series satisfying a (linear) multivariate autoregressive
moving average (VARMA) model satisfies the same model assumption in the
reversed time direction, too, if all innovations are normally distributed. This
reversibility breaks down if the innovations are non-Gaussian. This means that
under the assumption of a VARMA process with non-Gaussian noise, the arrow of
time becomes detectable. Our work thereby provides a theoretic justification of
an algorithm that has been used for inferring the direction of video snippets.
We present a slightly modified practical algorithm that estimates the time
direction for a given sample and prove its consistency. We further investigate
how the performance of the algorithm depends on sample size, number of
dimensions of the time series and the order of the process. An application to
real world data from economics shows that considering multivariate processes
instead of univariate processes can be beneficial for estimating the time
direction. Our result extends earlier work on univariate time series. It
relates to the concept of causal inference, where recent methods exploit
non-Gaussianity of the error terms for causal structure learning.",http://arxiv.org/pdf/1603.00784v1,math.ST
2016-02-29 20:34:41+00:00,Adjusted Empirical Likelihood for Time Series Models,"['Ramadha D. Piyadi Gamage', 'Wei Ning', 'Arjun K. Gupta']","Empirical likelihood method has been applied to dependent observations by
Monti (1997) through the Whittle's estimation method. Similar asymptotic
distribution of the empirical likelihood ratio statistic for stationary time
series has been derived to construct the confidence regions for the parameters.
However, required numerical problem of computing profile empirical likelihood
function which involves constrained maximization has no solution sometimes,
which leads to the drawbacks of using the original version of the empirical
likelihood ratio. In this paper, we propose an adjusted empirical likelihood
ratio statistic to modify the one proposed by Monti so that it guarantees the
existence of the solution of the required maximization problem, while
maintaining the similar asymptotic properties as Monti obtained. Simulations
have been conducted to illustrate the coverage probabilities obtained by the
adjusted version for different time series models which are better than the
ones obtained by Monti's version, especially for small sample sizes.",http://arxiv.org/pdf/1602.09128v1,stat.ME
2016-02-28 01:07:22+00:00,Testing for parameter change in general integer-valued time series,"['Mamadou Lamine Diop', 'William Kengne']","We consider the structural change in a class of discrete valued time series
that the conditional distribution follows a one-parameter exponential family.
We propose a change-point test based on the maximum likelihood estimator of the
parameter of the model. Under the null hypothesis (of no change), the test
statistics converges to a well known distribution, allowing for the calculation
of the critical values of the test. The test statistic diverges to infinity
under the alternative, that is, the test asymptotically has power one. Some
simulation results and real data applications are reported to show the
applicability of the test procedure.",http://arxiv.org/pdf/1602.08654v1,math.ST
2016-02-17 15:47:40+00:00,Estimating the turning point location in shifted exponential model of time series,['Camillo Cammarota'],"We consider the distribution of the turning point location of time series
modeled as the sum of deterministic trend plus random noise. If the variables
are modeled by shifted exponentials, whose location parameters define the
trend, we provide a formula for computing the distribution of the turning point
location and consequently to estimate a confidence interval for the location.
We test this formula in simulated data series having a trend with asymmetric
minimum, investigating the coverage rate as a function of a bandwidth
parameter. The method is applied to estimate the confidence interval of the
minimum location of the time series of RT intervals extracted from the
electrocardiogram recorded during the exercise test. We discuss the connection
with stochastic ordering.",http://arxiv.org/pdf/1602.05906v1,stat.ME
2016-02-16 18:29:17+00:00,Locally Stationary Functional Time Series,"['Anne van Delft', 'Michael Eichler']","The literature on time series of functional data has focused on processes of
which the probabilistic law is either constant over time or constant up to its
second-order structure. Especially for long stretches of data it is desirable
to be able to weaken this assumption. This paper introduces a framework that
will enable meaningful statistical inference of functional data of which the
dynamics change over time. We put forward the concept of local stationarity in
the functional setting and establish a class of processes that have a
functional time-varying spectral representation. Subsequently, we derive
conditions that allow for fundamental results from nonstationary multivariate
time series to carry over to the function space. In particular, time-varying
functional ARMA processes are investigated and shown to be functional locally
stationary according to the proposed definition. As a side-result, we establish
a Cram\'er representation for an important class of weakly stationary
functional processes. Important in our context is the notion of a time-varying
spectral density operator of which the properties are studied and uniqueness is
derived. Finally, we provide a consistent nonparametric estimator of this
operator and show it is asymptotically Gaussian using a weaker tightness
criterion than what is usually deemed necessary.",http://arxiv.org/pdf/1602.05125v3,stat.ME
2016-02-15 21:51:45+00:00,Memory properties of transformations of linear processes,"['Hailin Sang', 'Yongli Sang']","In this paper, we study the memory properties of transformations of linear
processes. Dittmann and Granger (2002) studied the polynomial transformations
of Gaussian FARIMA(0,d,0) processes by applying the orthonormality of the
Hermite polynomials under the measure for the standard normal distribution.
Nevertheless, the orthogonality does not hold for transformations of
non-Gaussian linear processes. Instead, we use the decomposition developed by
Ho and Hsing (1996, 1997) to study the memory properties of nonlinear
transformations of linear processes, which include the FARIMA(p,d,q) processes,
and obtain consistent results as in the Gaussian case. In particular, for
stationary processes, the transformations of short-memory time series still
have short-memory and the transformation of long-memory time series may have
different weaker memory parameters which depend on the power rank of the
transformation. On the other hand, the memory properties of transformations of
non-stationary time series may not depend on the power ranks of the
transformations. This study has application in econometrics and financial data
analysis when the time series observations have non-Gaussian heavy tails. As an
example, the memory properties of call option processes at different strike
prices are discussed in details.",http://arxiv.org/pdf/1602.04850v2,math.ST
2016-02-12 23:44:53+00:00,Lasso Guarantees for Time Series Estimation Under Subgaussian Tails and $ β$-Mixing,"['Kam Chung Wong', 'Zifan Li', 'Ambuj Tewari']","Many theoretical results on estimation of high dimensional time series
require specifying an underlying data generating model (DGM). Instead, along
the footsteps of~\cite{wong2017lasso}, this paper relies only on (strict)
stationarity and $ \beta $-mixing condition to establish consistency of lasso
when data comes from a $\beta$-mixing process with marginals having subgaussian
tails. Because of the general assumptions, the data can come from DGMs
different than standard time series models such as VAR or ARCH. When the true
DGM is not VAR, the lasso estimates correspond to those of the best linear
predictors using the past observations. We establish non-asymptotic
inequalities for estimation and prediction errors of the lasso estimates.
Together with~\cite{wong2017lasso}, we provide lasso guarantees that cover full
spectrum of the parameters in specifications of $ \beta $-mixing subgaussian
time series. Applications of these results potentially extend to non-Gaussian,
non-Markovian and non-linear times series models as the examples we provide
demonstrate. In order to prove our results, we derive a novel Hanson-Wright
type concentration inequality for $\beta$-mixing subgaussian random vectors
that may be of independent interest.",http://arxiv.org/pdf/1602.04265v4,stat.ML
2016-02-04 15:24:22+00:00,The Great Time Series Classification Bake Off: An Experimental Evaluation of Recently Proposed Algorithms. Extended Version,"['Anthony Bagnall', 'Aaron Bostrom', 'James Large', 'Jason Lines']","In the last five years there have been a large number of new time series
classification algorithms proposed in the literature. These algorithms have
been evaluated on subsets of the 47 data sets in the University of California,
Riverside time series classification archive. The archive has recently been
expanded to 85 data sets, over half of which have been donated by researchers
at the University of East Anglia. Aspects of previous evaluations have made
comparisons between algorithms difficult. For example, several different
programming languages have been used, experiments involved a single train/test
split and some used normalised data whilst others did not. The relaunch of the
archive provides a timely opportunity to thoroughly evaluate algorithms on a
larger number of datasets. We have implemented 18 recently proposed algorithms
in a common Java framework and compared them against two standard benchmark
classifiers (and each other) by performing 100 resampling experiments on each
of the 85 datasets. We use these results to test several hypotheses relating to
whether the algorithms are significantly more accurate than the benchmarks and
each other. Our results indicate that only 9 of these algorithms are
significantly more accurate than both benchmarks and that one classifier, the
Collective of Transformation Ensembles, is significantly more accurate than all
of the others. All of our experiments and results are reproducible: we release
all of our code, results and experimental details and we hope these experiments
form the basis for more rigorous testing of new algorithms in the future.",http://arxiv.org/pdf/1602.01711v1,cs.LG
2016-01-27 17:44:34+00:00,Dynamic Bayesian Predictive Synthesis in Time Series Forecasting,"['Kenichiro McAlinn', 'Mike West']","We discuss model and forecast combination in time series forecasting. A
foundational Bayesian perspective based on agent opinion analysis theory
defines a new framework for density forecast combination, and encompasses
several existing forecast pooling methods. We develop a novel class of dynamic
latent factor models for time series forecast synthesis; simulation-based
computation enables implementation. These models can dynamically adapt to
time-varying biases, miscalibration and inter-dependencies among multiple
models or forecasters. A macroeconomic forecasting study highlights the dynamic
relationships among synthesized forecast densities, as well as the potential
for improved forecast accuracy at multiple horizons.",http://arxiv.org/pdf/1601.07463v6,stat.ME
2016-01-26 19:35:22+00:00,On the robustness to small trends of parameter estimation for continuous-time stationary models with memory,"['M. S. Ginovyan', 'A. A. Sahakyan']","The paper deals with a question of robustness of inferences, carried out on a
continuous-time stationary process contaminated by a small trend, to this
departure from stationarity. We show that a smoothed periodogram approach to
parameter estimation is highly robust to the presence of a small trend in the
model. The obtained result is a continuous version of that of Hede and Dai
(Journal of Time Series Analysis, 17, 141-150, 1996) for discrete time
processes.",http://arxiv.org/pdf/1601.07141v1,math.ST
2016-01-17 19:37:58+00:00,A Bayesian Nonparametric Markovian Model for Nonstationary Time Series,"['Maria DeYoreo', 'Athanasios Kottas']","Stationary time series models built from parametric distributions are, in
general, limited in scope due to the assumptions imposed on the residual
distribution and autoregression relationship. We present a modeling approach
for univariate time series data, which makes no assumptions of stationarity,
and can accommodate complex dynamics and capture nonstandard distributions. The
model for the transition density arises from the conditional distribution
implied by a Bayesian nonparametric mixture of bivariate normals. This implies
a flexible autoregressive form for the conditional transition density, defining
a time-homogeneous, nonstationary, Markovian model for real-valued data indexed
in discrete-time. To obtain a more computationally tractable algorithm for
posterior inference, we utilize a square-root-free Cholesky decomposition of
the mixture kernel covariance matrix. Results from simulated data suggest the
model is able to recover challenging transition and predictive densities. We
also illustrate the model on time intervals between eruptions of the Old
Faithful geyser. Extensions to accommodate higher order structure and to
develop a state-space model are also discussed.",http://arxiv.org/pdf/1601.04331v3,stat.ME
2016-01-14 08:31:20+00:00,Spatial Clustering of Time-Series via Mixture of Autoregressions Models and Markov Random Fields,"['Hien D Nguyen', 'Geoffrey J McLachlan', 'Jeremy F P Ullmann', 'Andrew L Janke']","Time-series data arise in many medical and biological imaging scenarios. In
such images, a time-series is obtained at each of a large number of
spatially-dependent data units. It is interesting to organize these data into
model-based clusters. A two-stage procedure is proposed. In Stage 1, a mixture
of autoregressions (MoAR) model is used to marginally cluster the data. The
MoAR model is fitted using maximum marginal likelihood (MMaL) estimation via an
MM (minorization--maximization) algorithm. In Stage 2, a Markov random field
(MRF) model induces a spatial structure onto the Stage 1 clustering. The MRF
model is fitted using maximum pseudolikelihood (MPL) estimation via an MM
algorithm. Both the MMaL and MPL estimators are proved to be consistent.
Numerical properties are established for both MM algorithms. A simulation study
demonstrates the performance of the two-stage procedure. An application to the
segmentation of a zebrafish brain calcium image is presented.",http://arxiv.org/pdf/1601.03517v1,stat.ME
2016-01-10 13:17:46+00:00,On Clustering Time Series Using Euclidean Distance and Pearson Correlation,"['Michael R. Berthold', 'Frank Höppner']","For time series comparisons, it has often been observed that z-score
normalized Euclidean distances far outperform the unnormalized variant. In this
paper we show that a z-score normalized, squared Euclidean Distance is, in
fact, equal to a distance based on Pearson Correlation. This has profound
impact on many distance-based classification or clustering methods. In addition
to this theoretically sound result we also show that the often used k-Means
algorithm formally needs a mod ification to keep the interpretation as Pearson
correlation strictly valid. Experimental results demonstrate that in many cases
the standard k-Means algorithm generally produces the same results.",http://arxiv.org/pdf/1601.02213v1,cs.LG
2016-01-08 09:06:44+00:00,Dense Bag-of-Temporal-SIFT-Words for Time Series Classification,"['Adeline Bailly', 'Simon Malinowski', 'Romain Tavenard', 'Thomas Guyet', 'Laetitia Chapel']","Time series classification is an application of particular interest with the
increase of data to monitor. Classical techniques for time series
classification rely on point-to-point distances. Recently, Bag-of-Words
approaches have been used in this context. Words are quantized versions of
simple features extracted from sliding windows. The SIFT framework has proved
efficient for image classification. In this paper, we design a time series
classification scheme that builds on the SIFT framework adapted to time series
to feed a Bag-of-Words. We then refine our method by studying the impact of
normalized Bag-of-Words, as well as densely extract point descriptors. Proposed
adjustements achieve better performance. The evaluation shows that our method
outperforms classical techniques in terms of classification.",http://arxiv.org/pdf/1601.01799v2,cs.LG
2015-12-31 17:05:12+00:00,Robust Inference for Time Series Models: a Wavelet-based Framework,"['Stephane Guerrier', 'Roberto Molinari']","We present a new framework for the robust estimation of latent time series
models which is fairly general and, for example, covers models going from ARMA
to state-space models. This approach provides estimators which are (i)
consistent and asymptotically normally distributed, (ii) applicable to various
classes of time series models, (iii) straightforward to implement and (iv)
computationally efficient. The framework is based on the recently developed
Generalized Method of Wavelet Moments (GMWM) and a new robust estimator of the
wavelet variance. Compared to existing methods, the latter directly estimates
the quantity of interest while performing better in finite samples and using
milder conditions for its asymptotic properties to hold. Moreover, results are
given showing the identifiability of the GMWM for various classes of time
series models thereby allowing this method to consistently estimate many models
(and combinations thereof) under mild conditions. Hence, not only does this
paper provide an alternative estimator which allows to perform wavelet variance
analysis when data are contaminated but also a general approach to robustly
estimate the parameters of a variety of (latent) time series models. The
simulation studies carried out confirm the better performance of the proposed
estimators and the usefulness and broadness of the proposed methodology is
shown using practical examples from the domains of economics and engineering
with sample sizes up to 900,000.",http://arxiv.org/pdf/1512.09325v3,stat.ME
2015-12-07 18:13:32+00:00,A Time-varying Parameter Based Seasonally-adjusted Bayesian State-space Model for Forecasting,['Arnab Hazra'],"In this paper, we develop a time-varying parameter based seasonally-adjusted
Bayesian state-space model for non-stationary time series datasets where both
the trend and seasonal components are present and it is the general scenario
for most of the real datasets in various scientific disciplines. In spite of
removing such terms using some do-and-check procedure to make the data
stationary, our model directly fits a dataset and forecasts a number of future
observations. For a specific prior construction we have considered, every
parameter update is one-dimensional so that we don't need to invert any matrix
and also we overcome the difficulty of Metropolis-Hastings steps simply by
Gibbs sampling which is another advantage of this model. It can handle missing
data as well which occurs very often in time series contexts. We implement it
on the sufficiently large (24 years of monthly average temperature series, i.e.
the number of observations =288) for 57 meteorological stations across India
and show that for most of the cases, our method forecasts quite accurately for
the months of the 25-th year.",http://arxiv.org/pdf/1512.02149v1,stat.ME
2015-12-03 17:33:25+00:00,Bayesian Uncertainty Management in Temporal Dependence of Extremes,"['Thomas Lugrin', 'Anthony C. Davison', 'Jonathan A. Tawn']","Both marginal and dependence features must be described when modelling the
extremes of a stationary time series. There are standard approaches to marginal
modelling, but long- and short-range dependence of extremes may both appear. In
applications, an assumption of long-range independence often seems reasonable,
but short-range dependence, i.e., the clustering of extremes, needs attention.
The extremal index $0<\theta\le 1$ is a natural limiting measure of clustering,
but for wide classes of dependent processes, including all stationary Gaussian
processes, it cannot distinguish dependent processes from independent processes
with $\theta=1$. Eastoe and Tawn (2012) exploit methods from multivariate
extremes to treat the subasymptotic extremal dependence structure of stationary
time series, covering both $0<\theta<1$ and $\theta=1$, through the
introduction of a threshold-based extremal index. Inference for their
dependence models uses an inefficient stepwise procedure that has various
weaknesses and has no reliable assessment of uncertainty. We overcome these
issues using a Bayesian semiparametric approach. Simulations and the analysis
of a UK daily river flow time series show that the new approach provides
improved efficiency for estimating properties of functionals of clusters.",http://arxiv.org/pdf/1512.01169v2,stat.ME
2015-12-02 15:00:50+00:00,Comparing entropy with tests for randomness as a measure of complexity in time series,"['Chee Chun Gan', 'Gerard Learmonth']","Entropy measures have become increasingly popular as an evaluation metric for
complexity in the analysis of time series data, especially in physiology and
medicine. Entropy measures the rate of information gain, or degree of
regularity in a time series e.g. heartbeat. Ideally, entropy should be able to
quantify the complexity of any underlying structure in the series, as well as
determine if the variation arises from a random process. Unfortunately current
entropy measures mostly are unable to perform the latter differentiation. Thus,
a high entropy score indicates a random or chaotic series, whereas a low score
indicates a high degree of regularity. This leads to the observation that
current entropy measures are equivalent to evaluating how random a series is,
or conversely the degree of regularity in a time series. This raises the
possibility that existing tests for randomness, such as the runs test or
permutation test, may have similar utility in diagnosing certain conditions.
This paper compares various tests for randomness with existing entropy-based
measurements such as sample entropy, permutation entropy and multi-scale
entropy. Our experimental results indicate that the test statistics of the runs
test and permutation test are often highly correlated with entropy scores and
may be able to provide further information regarding the complexity of time
series.",http://arxiv.org/pdf/1512.00725v1,stat.ME
2015-11-26 10:26:51+00:00,The Automatic Statistician: A Relational Perspective,"['Yunseong Hwang', 'Anh Tong', 'Jaesik Choi']","Gaussian Processes (GPs) provide a general and analytically tractable way of
modeling complex time-varying, nonparametric functions. The Automatic Bayesian
Covariance Discovery (ABCD) system constructs natural-language description of
time-series data by treating unknown time-series data nonparametrically using
GP with a composite covariance kernel function. Unfortunately, learning a
composite covariance kernel with a single time-series data set often results in
less informative kernel that may not give qualitative, distinctive descriptions
of data. We address this challenge by proposing two relational kernel learning
methods which can model multiple time-series data sets by finding common,
shared causes of changes. We show that the relational kernel learning methods
find more accurate models for regression problems on several real-world data
sets; US stock data, US house price index data and currency exchange rate data.",http://arxiv.org/pdf/1511.08343v2,cs.LG
2015-11-24 09:08:38+00:00,Maximum likelihood estimation for the Fréchet distribution based on block maxima extracted from a time series,"['Axel Bücher', 'Johan Segers']","The block maxima method in extreme-value analysis proceeds by fitting an
extreme-value distribution to a sample of block maxima extracted from an
observed stretch of a time series. The method is usually validated under two
simplifying assumptions: the block maxima should be distributed according to an
extreme-value distribution and the sample of block maxima should be
independent. Both assumptions are only approximately true.
  For general triangular arrays of block maxima attracted to the Fr\'echet
distribution, consistency and asymptotic normality is established for the
maximum likelihood estimator of the parameters of the limiting Fr\'echet
distribution. The results are specialized to the setting of block maxima
extracted from a strictly stationary time series. The case where the underlying
random variables are independent and identically distributed is further worked
out in detail. The results are illustrated by theoretical examples and Monte
Carlo simulations.",http://arxiv.org/pdf/1511.07613v2,math.ST
2015-11-23 14:32:38+00:00,Multiple Changepoint Detection with Partial Information on Changepoint Times,"['Yingbo Li', 'Robert Lund', 'Anuradha Hewaarachchi']","This paper proposes a new minimum description length procedure to detect
multiple changepoints in time series data when some times are a priori thought
more likely to be changepoints. This scenario arises with temperature time
series homogenization pursuits, our focus here. Our Bayesian procedure
constructs a natural prior distribution for the situation, and is shown to
estimate the changepoint locations consistently, with an optimal convergence
rate. Our methods substantially improve changepoint detection power when prior
information is available. The methods are also tailored to bivariate data,
allowing changes to occur in one or both component series.",http://arxiv.org/pdf/1511.07238v4,stat.ME
2015-11-16 10:34:32+00:00,The tail empirical process of regularly varying functions of geometrically ergodic Markov chains,"['Rafal Kulik', 'Philippe Soulier', 'Olivier Wintenberger', 'Rafa Kulik']","We consider a stationary regularly varying time series which can be
expressedas a function of a geometrically ergodic Markov chain. We obtain
practical conditionsfor the weak convergence of the tail array sums and
feasible estimators ofcluster statistics. These conditions include the
so-called geometric drift or Foster-Lyapunovcondition and can be easily checked
for most usual time series models witha Markovian structure. We illustrate
these conditions on several models and statisticalapplications. A
counterexample is given to show a different limiting behaviorwhen the geometric
drift condition is not fulfilled.",http://arxiv.org/pdf/1511.04903v2,math.ST
2015-11-11 11:35:21+00:00,Granger Causality in Multi-variate Time Series using a Time Ordered Restricted Vector Autoregressive Model,"['Elsa Siggiridou', 'Dimitris Kugiumtzis']","Granger causality has been used for the investigation of the inter-dependence
structure of the underlying systems of multi-variate time series. In
particular, the direct causal effects are commonly estimated by the conditional
Granger causality index (CGCI). In the presence of many observed variables and
relatively short time series, CGCI may fail because it is based on vector
autoregressive models (VAR) involving a large number of coefficients to be
estimated. In this work, the VAR is restricted by a scheme that modifies the
recently developed method of backward-in-time selection (BTS) of the lagged
variables and the CGCI is combined with BTS. Further, the proposed approach is
compared favorably to other restricted VAR representations, such as the
top-down strategy, the bottom-up strategy, and the least absolute shrinkage and
selection operator (LASSO), in terms of sensitivity and specificity of CGCI.
This is shown by using simulations of linear and nonlinear, low and
high-dimensional systems and different time series lengths. For nonlinear
systems, CGCI from the restricted VAR representations are compared with
analogous nonlinear causality indices. Further, CGCI in conjunction with BTS
and other restricted VAR representations is applied to multi-channel scalp
electroencephalogram (EEG) recordings of epileptic patients containing
epileptiform discharges. CGCI on the restricted VAR, and BTS in particular,
could track the changes in brain connectivity before, during and after
epileptiform discharges, which was not possible using the full VAR
representation.",http://arxiv.org/pdf/1511.03463v1,stat.ME
2015-10-31 18:00:39+00:00,Prediction of Dynamical time Series Using Kernel Based Regression and Smooth Splines,"['Raymundo Navarrete', 'Divakar Viswanath']","Prediction of dynamical time series with additive noise using support vector
machines or kernel based regression has been proved to be consistent for
certain classes of discrete dynamical systems. Consistency implies that these
methods are effective at computing the expected value of a point at a future
time given the present coordinates. However, the present coordinates themselves
are noisy, and therefore, these methods are not necessarily effective at
removing noise. In this article, we consider denoising and prediction as
separate problems for flows, as opposed to discrete time dynamical systems, and
show that the use of smooth splines is more effective at removing noise.
Combination of smooth splines and kernel based regression yields predictors
that are more accurate on benchmarks typically by a factor of 2 or more. We
prove that kernel based regression in combination with smooth splines converges
to the exact predictor for time series extracted from any compact invariant set
of any sufficiently smooth flow. As a consequence of convergence, one can find
examples where the combination of kernel based regression with smooth splines
is superior by even a factor of $100$. The predictors that we compute operate
on delay coordinate data and not the full state vector, which is typically not
observable.",http://arxiv.org/pdf/1511.00158v3,stat.ML
2015-10-28 17:28:38+00:00,Linear-time Detection of Non-linear Changes in Massively High Dimensional Time Series,"['Hoang-Vu Nguyen', 'Jilles Vreeken']","Change detection in multivariate time series has applications in many
domains, including health care and network monitoring. A common approach to
detect changes is to compare the divergence between the distributions of a
reference window and a test window. When the number of dimensions is very
large, however, the naive approach has both quality and efficiency issues: to
ensure robustness the window size needs to be large, which not only leads to
missed alarms but also increases runtime.
  To this end, we propose LIGHT, a linear-time algorithm for robustly detecting
non-linear changes in massively high dimensional time series. Importantly,
LIGHT provides high flexibility in choosing the window size, allowing the
domain expert to fit the level of details required. To do such, we 1) perform
scalable PCA to reduce dimensionality, 2) perform scalable factorization of the
joint distribution, and 3) scalably compute divergences between these lower
dimensional distributions. Extensive empirical evaluation on both synthetic and
real-world data show that LIGHT outperforms state of the art with up to 100%
improvement in both quality and efficiency.",http://arxiv.org/pdf/1510.08385v1,stat.ML
2015-10-26 20:18:56+00:00,Phenotyping of Clinical Time Series with LSTM Recurrent Neural Networks,"['Zachary C. Lipton', 'David C. Kale', 'Randall C. Wetzel']","We present a novel application of LSTM recurrent neural networks to
multilabel classification of diagnoses given variable-length time series of
clinical measurements. Our method outperforms a strong baseline on a variety of
metrics.",http://arxiv.org/pdf/1510.07641v2,cs.LG
2015-10-23 12:09:32+00:00,A New Method for Partial Correction of Residual Confounding in Time-Series and other Observational Studies,"['W. Dana Flanders', 'Matthew J. Strickland', 'Mitchel Klein']","Introduction: Methods now exist to detect residual confounding. One requires
an ""indicator"" with two key properties: conditional independence of the outcome
(given exposure and measured covariates) absent confounding and other model
miss-specification; and an association with unmeasured confounders (like the
exposure). We now present a new method for correcting for residual confounding
in time-series and other epidemiological studies. We argue that estimators from
models that include an indicator with these key properties should have less
bias than those from models without the indicator.
  Methods: Using causal reasoning and basic regression theory we present
theoretical arguments to support our claims. In simulations, we empirically
evaluate our approach using a time-series study of ozone effects on emergency
department visits for asthma (AV). We base simulations on observed data for
ozone, meteorological factors and asthma.
  Results: In simulations, results from models that included ozone
concentrations one day after the AV yielded effect estimators with slightly or
modestly less residual confounding.
  Conclusion: Theory and simulations show that including the indicator based on
future air pollution levels can reduce residual confounding. Our method differs
from available methods because it uses a regression approach involving an
exposure-based indicator rather than a negative outcome control.",http://arxiv.org/pdf/1510.06905v1,stat.ME
2015-10-14 23:28:35+00:00,Explicit solutions to a vector time series model and its induced model for business cycles,['Xiongzhi Chen'],"This article gives the explicit solution to a general vector time series
model that describes interacting, heterogeneous agents that operate under
uncertainties but according to Keynesian principles, from which a model for
business cycle is induced by a weighted average of the growth rates of the
agents in the model. The explicit solution enables a direct simulation of the
time series defined by the model and better understanding of the joint behavior
of the growth rates. In addition, the induced model for business cycles and its
solutions are explicitly given and analyzed. The explicit solutions provide a
better understanding of the mathematics of these models and the econometric
properties they try to incorporate.",http://arxiv.org/pdf/1510.04346v1,stat.ME
2015-10-07 22:42:43+00:00,High-Dimensional Multivariate Time Series With Additional Structure,"['Michael Schweinberger', 'Sergii Babkin', 'Katherine Ensor']","High-dimensional multivariate time series are challenging due to the
dependent and high-dimensional nature of the data, but in many applications
there is additional structure that can be exploited to reduce computing time
along with statistical error. We consider high-dimensional vector
autoregressive processes with spatial structure, a simple and common form of
additional structure. We propose novel high-dimensional methods that take
advantage of such structure without making model assumptions about how distance
affects dependence. We provide non-asymptotic bounds on the statistical error
of parameter estimators in high-dimensional settings and show that the proposed
approach reduces the statistical error. An application to air pollution in the
US demonstrates that the estimation approach reduces both computing time and
prediction error and gives rise to results that are meaningful from a
scientific point of view, in contrast to high-dimensional methods that ignore
spatial structure. In practice, these high-dimensional methods can be used to
decompose high-dimensional multivariate time series into lower-dimensional
multivariate time series that can be studied by other methods in more depth.",http://arxiv.org/pdf/1510.02159v5,stat.ME
2015-10-06 07:10:49+00:00,Change-point detection using the conditional entropy of ordinal patterns,"['Anton M. Unakafov', 'Karsten Keller']","This paper is devoted to change-point detection using only the ordinal
structure of a time series. A statistic based on the conditional entropy of
ordinal patterns characterizing the local up and down in a time series is
introduced and investigated. The statistic requires only minimal a priori
information on given data and shows good performance in numerical experiments.",http://arxiv.org/pdf/1510.01457v2,math.ST
2015-09-28 14:37:14+00:00,High-dimensional Time Series Prediction with Missing Values,"['Hsiang-Fu Yu', 'Nikhil Rao', 'Inderjit S. Dhillon']","High-dimensional time series prediction is needed in applications as diverse
as demand forecasting and climatology. Often, such applications require methods
that are both highly scalable, and deal with noisy data in terms of corruptions
or missing values. Classical time series methods usually fall short of handling
both these issues. In this paper, we propose to adapt matrix matrix completion
approaches that have previously been successfully applied to large scale noisy
data, but which fail to adequately model high-dimensional time series due to
temporal dependencies. We present a novel temporal regularized matrix
factorization (TRMF) framework which supports data-driven temporal dependency
learning and enables forecasting ability to our new matrix factorization
approach. TRMF is highly general, and subsumes many existing matrix
factorization approaches for time series data. We make interesting connections
to graph regularized matrix factorization methods in the context of learning
the dependencies. Experiments on both real and synthetic data show that TRMF
outperforms several existing approaches for common time series tasks.",http://arxiv.org/pdf/1509.08333v3,cs.LG
2015-09-27 21:17:09+00:00,Optimal Copula Transport for Clustering Multivariate Time Series,"['Gautier Marti', 'Frank Nielsen', 'Philippe Donnat']","This paper presents a new methodology for clustering multivariate time series
leveraging optimal transport between copulas. Copulas are used to encode both
(i) intra-dependence of a multivariate time series, and (ii) inter-dependence
between two time series. Then, optimal copula transport allows us to define two
distances between multivariate time series: (i) one for measuring
intra-dependence dissimilarity, (ii) another one for measuring inter-dependence
dissimilarity based on a new multivariate dependence coefficient which is
robust to noise, deterministic, and which can target specified dependencies.",http://arxiv.org/pdf/1509.08144v2,cs.LG
2015-09-22 01:45:50+00:00,A new approach for analyzing panel AR(1) series with application to the unit root test,"['Yu-Pin Hu', 'J. T. Gene Hwang']","This paper derives several novel tests to improve on the t-test for testing
AR(1) coefficients of panel time series, i.e., of multiple time series, when
each has a small number of observations. These tests can determine the
acceptance or the rejection of each hypothesis individually while controlling
the average type one error. Strikingly, the testing statistics derived by the
empirical Bayes approach can be approximated by a simple form similar to the
t-statistic; the only difference is that the means and the variances are
estimated by shrinkage estimators. Simulations demonstrate that the proposed
tests have higher average power than the t-test in all settings we examine
including those when the priors are miss-specified and the cross section series
are dependent.",http://arxiv.org/pdf/1509.06442v1,math.ST
2015-09-21 19:36:46+00:00,Discriminant Analysis of Time Series in the Presence of Within-Group Spectral Variability,['Robert T. Krafty'],"Many studies record replicated time series epochs from different groups with
the goal of using frequency domain properties to discriminate between the
groups. In many applications, there exists variation in cyclical patterns from
time series in the same group. Although a number of frequency domain methods
for the discriminant analysis of time series have been explored, there is a
dearth of models and methods that account for within-group spectral
variability. This article proposes a model for groups of time series in which
transfer functions are modeled as stochastic variables that can account for
both between-group and within-group differences in spectra that are identified
from individual replicates. An ensuing discriminant analysis of stochastic
cepstra under this model is developed to obtain parsimonious measures of
relative power that optimally separate groups in the presence of within-group
spectral variability. The approach possess favorable properties in classifying
new observations and can be consistently estimated through a simple
discriminant analysis of a finite number of estimated cepstral coefficients.
Benefits in accounting for within-group spectral variability are empirically
illustrated in a simulation study and through an analysis of gait variability.",http://arxiv.org/pdf/1509.06358v1,stat.ME
2015-09-15 17:15:08+00:00,Forecasting Method for Grouped Time Series with the Use of k-Means Algorithm,"['N. N. Astakhova', 'L. A. Demidova', 'E. V. Nikulchev']","The paper is focused on the forecasting method for time series groups with
the use of algorithms for cluster analysis. $K$-means algorithm is suggested to
be a basic one for clustering. The coordinates of the centers of clusters have
been put in correspondence with summarizing time series data the centroids of
the clusters. A description of time series, the centroids of the clusters, is
implemented with the use of forecasting models. They are based on strict binary
trees and a modified clonal selection algorithm. With the help of such
forecasting models, the possibility of forming analytic dependences is shown.
It is suggested to use a common forecasting model, which is constructed for
time series the centroid of the cluster, in forecasting the private
(individual) time series in the cluster. The promising application of the
suggested method for grouped time series forecasting is demonstrated.",http://arxiv.org/pdf/1509.04705v1,cs.LG
2015-09-11 03:16:52+00:00,Learning the Number of Autoregressive Mixtures in Time Series Using the Gap Statistics,"['Jie Ding', 'Mohammad Noshad', 'Vahid Tarokh']","Using a proper model to characterize a time series is crucial in making
accurate predictions. In this work we use time-varying autoregressive process
(TVAR) to describe non-stationary time series and model it as a mixture of
multiple stable autoregressive (AR) processes. We introduce a new model
selection technique based on Gap statistics to learn the appropriate number of
AR filters needed to model a time series. We define a new distance measure
between stable AR filters and draw a reference curve that is used to measure
how much adding a new AR filter improves the performance of the model, and then
choose the number of AR filters that has the maximum gap with the reference
curve. To that end, we propose a new method in order to generate uniform random
stable AR filters in root domain. Numerical results are provided demonstrating
the performance of the proposed approach.",http://arxiv.org/pdf/1509.03381v1,stat.ML
2015-08-27 21:15:43+00:00,Gaussian Approximation for High Dimensional Time Series,"['Danna Zhang', 'Wei Biao Wu']","We consider the problem of approximating sums of high-dimensional stationary
time series by Gaussian vectors, using the framework of functional dependence
measure. The validity of the Gaussian approximation depends on the sample size
$n$, the dimension $p$, the moment condition and the dependence of the
underlying processes. We also consider an estimator for long-run covariance
matrices and study its convergence properties. Our results allow constructing
simultaneous confidence intervals for mean vectors of high-dimensional time
series with asymptotically correct coverage probabilities. A Gaussian
multiplier bootstrap method is proposed. A simulation study indicates the
quality of Gaussian approximation with different $n$, $p$ under different
moment and dependence conditions.",http://arxiv.org/pdf/1508.07036v1,math.ST
2015-08-19 19:55:08+00:00,Time Series Clustering via Community Detection in Networks,"['Leonardo N. Ferreira', 'Liang Zhao']","In this paper, we propose a technique for time series clustering using
community detection in complex networks. Firstly, we present a method to
transform a set of time series into a network using different distance
functions, where each time series is represented by a vertex and the most
similar ones are connected. Then, we apply community detection algorithms to
identify groups of strongly connected vertices (called a community) and,
consequently, identify time series clusters. Still in this paper, we make a
comprehensive analysis on the influence of various combinations of time series
distance functions, network generation methods and community detection
techniques on clustering results. Experimental study shows that the proposed
network-based approach achieves better results than various classic or
up-to-date clustering techniques under consideration. Statistical tests confirm
that the proposed method outperforms some classic clustering algorithms, such
as $k$-medoids, diana, median-linkage and centroid-linkage in various data
sets. Interestingly, the proposed method can effectively detect shape patterns
presented in time series due to the topological structure of the underlying
network constructed in the clustering process. At the same time, other
techniques fail to identify such patterns. Moreover, the proposed method is
robust enough to group time series presenting similar pattern but with time
shifts and/or amplitude variations. In summary, the main point of the proposed
method is the transformation of time series from time-space domain to
topological domain. Therefore, we hope that our approach contributes not only
for time series clustering, but also for general time series analysis tasks.",http://arxiv.org/pdf/1508.04757v1,stat.ML
2015-08-03 05:58:52+00:00,Time-series modeling with undecimated fully convolutional neural networks,['Roni Mittelman'],"We present a new convolutional neural network-based time-series model.
Typical convolutional neural network (CNN) architectures rely on the use of
max-pooling operators in between layers, which leads to reduced resolution at
the top layers. Instead, in this work we consider a fully convolutional network
(FCN) architecture that uses causal filtering operations, and allows for the
rate of the output signal to be the same as that of the input signal. We
furthermore propose an undecimated version of the FCN, which we refer to as the
undecimated fully convolutional neural network (UFCNN), and is motivated by the
undecimated wavelet transform. Our experimental results verify that using the
undecimated version of the FCN is necessary in order to allow for effective
time-series modeling. The UFCNN has several advantages compared to other
time-series models such as the recurrent neural network (RNN) and long
short-term memory (LSTM), since it does not suffer from either the vanishing or
exploding gradients problems, and is therefore easier to train. Convolution
operations can also be implemented more efficiently compared to the recursion
that is involved in RNN-based models. We evaluate the performance of our model
in a synthetic target tracking task using bearing only measurements generated
from a state-space model, a probabilistic modeling of polyphonic music
sequences problem, and a high frequency trading task using a time-series of
ask/bid quotes and their corresponding volumes. Our experimental results using
synthetic and real datasets verify the significant advantages of the UFCNN
compared to the RNN and LSTM baselines.",http://arxiv.org/pdf/1508.00317v1,stat.ML
2015-07-28 07:19:19+00:00,"Modulus of continuity of some conditionally sub-Gaussian fields, application to stable random fields","['Hermine Biermé', 'Céline Lacaux']","In this paper, we study modulus of continuity and rate of convergence of
series of conditionally sub-Gaussian random fields. This framework includes
both classical series representations of Gaussian fields and LePage series
representations of stable fields. We enlighten their anisotropic properties by
using an adapted quasi-metric instead of the classical Euclidean norm. We
specify our assumptions in the case of shot noise series where arrival times of
a Poisson process are involved. This allows us to state unified results for
harmonizable (multi)operator scaling stable random fields through their LePage
series representation, as well as to study sample path properties of their
multistable analogous.",http://arxiv.org/pdf/1507.07669v1,math.ST
2015-07-20 11:48:01+00:00,AMP: a new time-frequency feature extraction method for intermittent time-series data,"['Duncan Barrack', 'James Goulding', 'Keith Hopcraft', 'Simon Preston', 'Gavin Smith']","The characterisation of time-series data via their most salient features is
extremely important in a range of machine learning task, not least of all with
regards to classification and clustering. While there exist many feature
extraction techniques suitable for non-intermittent time-series data, these
approaches are not always appropriate for intermittent time-series data, where
intermittency is characterized by constant values for large periods of time
punctuated by sharp and transient increases or decreases in value.
  Motivated by this, we present aggregation, mode decomposition and projection
(AMP) a feature extraction technique particularly suited to intermittent
time-series data which contain time-frequency patterns. For our method all
individual time-series within a set are combined to form a non-intermittent
aggregate. This is decomposed into a set of components which represent the
intrinsic time-frequency signals within the data set. Individual time-series
can then be fit to these components to obtain a set of numerical features that
represent their intrinsic time-frequency patterns. To demonstrate the
effectiveness of AMP, we evaluate against the real word task of clustering
intermittent time-series data. Using synthetically generated data we show that
a clustering approach which uses the features derived from AMP significantly
outperforms traditional clustering methods. Our technique is further
exemplified on a real world data set where AMP can be used to discover
groupings of individuals which correspond to real world sub-populations.",http://arxiv.org/pdf/1507.05455v2,cs.LG
2015-07-16 00:06:59+00:00,Estimation with Aggregate Shocks,"['Jinyong Hahn', 'Guido Kuersteiner', 'Maurizio Mazzocco']","Aggregate shocks affect most households' and firms' decisions. Using three
stylized models we show that inference based on cross-sectional data alone
generally fails to correctly account for decision making of rational agents
facing aggregate uncertainty. We propose an econometric framework that
overcomes these problems by explicitly parameterizing the agents' inference
problem relative to aggregate shocks. Our framework and examples illustrate
that the cross-sectional and time-series aspects of the model are often
interdependent. Therefore, estimation of model parameters in the presence of
aggregate shocks requires the combined use of cross-sectional and time series
data. We provide easy-to-use formulas for test statistics and confidence
intervals that account for the interaction between the cross-sectional and
time-series variation. Lastly, we perform Monte Carlo simulations that
highlight the properties of the proposed method and the risks of not properly
accounting for the presence of aggregate shocks.",http://arxiv.org/pdf/1507.04415v3,stat.ME
2015-07-10 00:12:03+00:00,Iterative algorithms for weighted and unweighted finite-rank time-series approximations,"['Nikita Zvonarev', 'Nina Golyandina']","The problem of time series approximation by series of finite rank is
considered from the viewpoint of signal extraction. For signal estimation, a
weighted least-squares method is applied to the trajectory matrix of the
considered time series. Matrix weights are chosen to obtain equal or
approximately equal weights in the equivalent problem of time-series
least-squares approximation. Several new methods are suggested and examined
together with the Cadzow's iterative method. The questions of convergence,
computational complexity, and accuracy are considered for the proposed methods.
The methods are compared on numeric examples.",http://arxiv.org/pdf/1507.02751v1,stat.ME
2015-06-16 19:20:00+00:00,Time Series Classification using the Hidden-Unit Logistic Model,"['Wenjie Pei', 'Hamdi Dibeklioğlu', 'David M. J. Tax', 'Laurens van der Maaten']","We present a new model for time series classification, called the hidden-unit
logistic model, that uses binary stochastic hidden units to model latent
structure in the data. The hidden units are connected in a chain structure that
models temporal dependencies in the data. Compared to the prior models for time
series classification such as the hidden conditional random field, our model
can model very complex decision boundaries because the number of latent states
grows exponentially with the number of hidden units. We demonstrate the strong
performance of our model in experiments on a variety of (computer vision)
tasks, including handwritten character recognition, speech recognition, facial
expression, and action recognition. We also present a state-of-the-art system
for facial action unit detection based on the hidden-unit logistic model.",http://arxiv.org/pdf/1506.05085v2,cs.LG
2015-06-11 20:56:20+00:00,Regularized estimation of linear functionals of precision matrices for high-dimensional time series,"['Xiaohui Chen', 'Mengyu Xu', 'Wei Biao Wu']","This paper studies a Dantzig-selector type regularized estimator for linear
functionals of high-dimensional linear processes. Explicit rates of convergence
of the proposed estimator are obtained and they cover the broad regime from
i.i.d. samples to long-range dependent time series and from sub-Gaussian
innovations to those with mild polynomial moments. It is shown that the
convergence rates depend on the degree of temporal dependence and the moment
conditions of the underlying linear processes. The Dantzig-selector estimator
is applied to the sparse Markowitz portfolio allocation and the optimal linear
prediction for time series, in which the ratio consistency when compared with
an oracle estimator is established. The effect of dependence and innovation
moment conditions is further illustrated in the simulation study. Finally, the
regularized estimator is applied to classify the cognitive states on a real
fMRI dataset and to portfolio optimization on a financial dataset.",http://arxiv.org/pdf/1506.03832v5,math.ST
2015-06-10 15:00:27+00:00,A Robust Method for Shift Detection in Time Series,"['Herold Dehling', 'Roland Fried', 'Martin Wendler']","We present a robust test for change-points in time series which is based on
the two-sample Hodges-Lehmann estimator. We develop new limit theory for a
class of statistics based on the two-sample U-quantile processes, in the case
of short range dependent observations. Using this theory we can derive the
asymptotic distribution of our test statistic under the null hypothesis. We
study the finite sample properties of our test via a simulation study and
compare the test with the classical CUSUM test and a test based on the
Wilcoxon-Mann-Whitney statistic.",http://arxiv.org/pdf/1506.03345v2,math.ST
2015-06-08 23:52:04+00:00,Empirical Studies on Symbolic Aggregation Approximation Under Statistical Perspectives for Knowledge Discovery in Time Series,"['Wei Song', 'Zhiguang Wang', 'Yangdong Ye', 'Ming Fan']","Symbolic Aggregation approXimation (SAX) has been the de facto standard
representation methods for knowledge discovery in time series on a number of
tasks and applications. So far, very little work has been done in empirically
investigating the intrinsic properties and statistical mechanics in SAX words.
In this paper, we applied several statistical measurements and proposed a new
statistical measurement, i.e. information embedding cost (IEC) to analyze the
statistical behaviors of the symbolic dynamics. Our experiments on the
benchmark datasets and the clinical signals demonstrate that SAX can always
reduce the complexity while preserving the core information embedded in the
original time series with significant embedding efficiency. Our proposed IEC
score provide a priori to determine if SAX is adequate for specific dataset,
which can be generalized to evaluate other symbolic representations. Our work
provides an analytical framework with several statistical tools to analyze,
evaluate and further improve the symbolic dynamics for knowledge discovery in
time series.",http://arxiv.org/pdf/1506.02732v1,cs.LG
2015-06-05 09:22:00+00:00,Handy sufficient conditions for the convergence of the maximum likelihood estimator in observation-driven models,"['Randal Douc', 'François Roueff', 'Tepmony Sim']","This paper generalizes asymptotic properties obtained in the
observation-driven times series models considered by \cite{dou:kou:mou:2013} in
the sense that the conditional law of each observation is also permitted to
depend on the parameter. The existence of ergodic solutions and the consistency
of the Maximum Likelihood Estimator (MLE) are derived under easy-to-check
conditions. The obtained conditions appear to apply for a wide class of models.
We illustrate our results with specific observation-driven times series,
including the recently introduced NBIN-GARCH and NM-GARCH models, demonstrating
the consistency of the MLE for these two models.",http://arxiv.org/pdf/1506.01831v1,math.ST
2015-06-04 14:29:13+00:00,Asymptotic properties of QML estimators for VARMA models with time-dependent coefficients: Part I,"['Abdelkamel Alj', 'Christophe Ley', 'Guy Mélard']","This paper is about vector autoregressive-moving average (VARMA) models with
time-dependent coefficients to represent non-stationary time series. Contrarily
to other papers in the univariate case, the coefficients depend on time but not
on the length of the series $n$. Under appropriate assumptions, it is shown
that a Gaussian quasi-maximum likelihood estimator is almost surely consistent
and asymptotically normal. The theoretical results are illustrated by means of
two examples of bivariate processes. It is shown that the assumptions
underlying the theoretical results apply. In the second example the innovations
are also marginally heteroscedastic with a correlation ranging from -0.8 to
0.8. In the two examples, the asymptotic information matrix is obtained in the
Gaussian case. Finally, the finite-sample behaviour is checked via a Monte
Carlo simulation study for $n$ going from 25 to 400. The results confirm the
validity of the asymptotic properties even for short series and reveal that the
asymptotic information matrix deduced from the theory is correct.",http://arxiv.org/pdf/1506.01606v1,math.ST
2015-06-02 12:31:48+00:00,Reaction times of monitoring schemes for ARMA time series,"['Alexander Aue', 'Christopher Dienes', 'Stefan Fremdt', 'Josef Steinebach']","This paper is concerned with deriving the limit distributions of stopping
times devised to sequentially uncover structural breaks in the parameters of an
autoregressive moving average, ARMA, time series. The stopping rules are
defined as the first time lag for which detectors, based on CUSUMs and Page's
CUSUMs for residuals, exceed the value of a prescribed threshold function. It
is shown that the limit distributions crucially depend on a drift term induced
by the underlying ARMA parameters. The precise form of the asymptotic is
determined by an interplay between the location of the break point and the size
of the change implied by the drift. The theoretical results are accompanied by
a simulation study and applications to electroencephalography, EEG, and IBM
data. The empirical results indicate a satisfactory behavior in finite samples.",http://arxiv.org/pdf/1506.00859v1,math.ST
2015-06-02 09:52:27+00:00,Covariance matrix estimation and linear process bootstrap for multivariate time series of possibly increasing dimension,"['Carsten Jentsch', 'Dimitris N. Politis']","Multivariate time series present many challenges, especially when they are
high dimensional. The paper's focus is twofold. First, we address the subject
of consistently estimating the autocovariance sequence; this is a sequence of
matrices that we conveniently stack into one huge matrix. We are then able to
show consistency of an estimator based on the so-called flat-top tapers; most
importantly, the consistency holds true even when the time series dimension is
allowed to increase with the sample size. Second, we revisit the linear process
bootstrap (LPB) procedure proposed by McMurry and Politis [J. Time Series Anal.
31 (2010) 471-482] for univariate time series. Based on the aforementioned
stacked autocovariance matrix estimator, we are able to define a version of the
LPB that is valid for multivariate time series. Under rather general
assumptions, we show that our multivariate linear process bootstrap (MLPB) has
asymptotic validity for the sample mean in two important cases: (a) when the
time series dimension is fixed and (b) when it is allowed to increase with
sample size. As an aside, in case (a) we show that the MLPB works also for
spectral density estimators which is a novel result even in the univariate
case. We conclude with a simulation study that demonstrates the superiority of
the MLPB in some important cases.",http://arxiv.org/pdf/1506.00816v1,math.ST
2015-06-01 02:17:06+00:00,Imaging Time-Series to Improve Classification and Imputation,"['Zhiguang Wang', 'Tim Oates']","Inspired by recent successes of deep learning in computer vision, we propose
a novel framework for encoding time series as different types of images,
namely, Gramian Angular Summation/Difference Fields (GASF/GADF) and Markov
Transition Fields (MTF). This enables the use of techniques from computer
vision for time series classification and imputation. We used Tiled
Convolutional Neural Networks (tiled CNNs) on 20 standard datasets to learn
high-level features from the individual and compound GASF-GADF-MTF images. Our
approaches achieve highly competitive results when compared to nine of the
current best time series classification approaches. Inspired by the bijection
property of GASF on 0/1 rescaled data, we train Denoised Auto-encoders (DA) on
the GASF images of four standard and one synthesized compound dataset. The
imputation MSE on test data is reduced by 12.18%-48.02% when compared to using
the raw data. An analysis of the features and weights learned via tiled CNNs
and DAs explains why the approaches work.",http://arxiv.org/pdf/1506.00327v1,cs.LG
2015-05-29 04:25:46+00:00,Oracally Efficient Estimation of Functional-Coefficient Autoregressive Models,['Qiwei Li'],"Nonlinear autoregressive models are very useful for modeling many natural
processes, however, the size of the class of these models is large.
Functional-coefficient autoregressive models (FCAR) are useful structures for
reducing the size of the class of these models. Although this structure reduces
the class of nonlinear models, it is broad enough to include some common time
series models as specific cases. A recent development in estimating nonlinear
time series data is the spline backfitted kernel (SBK) method. This method
combines the computational speed of splines with the asymptotic properties of
kernel smoothing. To estimate a component function in the model, all other
component functions are pre-estimated with splines and then the difference is
taken of the observed time series and the pre-estimates. This difference is
then used as pseudo-responses for which kernel smoothing is used to estimate
the function of interest. By constructing the estimates in this way, the method
does not suffer from the curse of dimensionality. In this paper, we adapt the
SBK method to FCAR models.",http://arxiv.org/pdf/1505.07917v1,stat.ME
2015-05-26 11:02:36+00:00,Times series averaging from a probabilistic interpretation of time-elastic kernel,['Pierre-François Marteau'],"At the light of regularized dynamic time warping kernels, this paper
reconsider the concept of time elastic centroid (TEC) for a set of time series.
From this perspective, we show first how TEC can easily be addressed as a
preimage problem. Unfortunately this preimage problem is ill-posed, may suffer
from over-fitting especially for long time series and getting a sub-optimal
solution involves heavy computational costs. We then derive two new algorithms
based on a probabilistic interpretation of kernel alignment matrices that
expresses in terms of probabilistic distributions over sets of alignment paths.
The first algorithm is an iterative agglomerative heuristics inspired from the
state of the art DTW barycenter averaging (DBA) algorithm proposed specifically
for the Dynamic Time Warping measure. The second proposed algorithm achieves a
classical averaging of the aligned samples but also implements an averaging of
the time of occurrences of the aligned samples. It exploits a straightforward
progressive agglomerative heuristics. An experimentation that compares for 45
time series datasets classification error rates obtained by first near
neighbors classifiers exploiting a single medoid or centroid estimate to
represent each categories show that: i) centroids based approaches
significantly outperform medoids based approaches, ii) on the considered
experience, the two proposed algorithms outperform the state of the art DBA
algorithm, and iii) the second proposed algorithm that implements an averaging
jointly in the sample space and along the time axes emerges as the most
significantly robust time elastic averaging heuristic with an interesting noise
reduction capability. Index Terms-Time series averaging Time elastic kernel
Dynamic Time Warping Time series clustering and classification.",http://arxiv.org/pdf/1505.06897v3,cs.LG
2015-05-24 08:17:46+00:00,Bayesian prediction of minimal repair times of a series system based on hybrid censored sample of components' lifetimes under Rayleigh distribution,"['S. M. T. K. MirMostafaee', 'Morteza Amini', 'A. Asgharzadeh']","In this paper, we develop Bayesian predictive inferential procedures for
prediction of repair times of a series system, applying a minimal repair
strategy, using the information contained in an independent observed hybrid
censored sample of the lifetimes of the components of the system, assuming the
underlying distribution of the lifetimes to be Rayleigh distribution. An
illustrative real data example and a simulation study are presented for the
purpose of illustration and comparison of the proposed predictors.",http://arxiv.org/pdf/1505.06417v1,math.ST
2015-05-21 09:48:06+00:00,A factor model approach for the joint segmentation with between-series correlation,"['Xavier Collilieux', 'Emilie Lebarbier', 'Stéphane Robin']","We consider the segmentation of set of correlated time-series, the
correlation being allowed to take an arbitrary form but being the same at each
time-position. We show that encoding the dependency in a factor model enables
us to use the dynamic programming algorithm for the inference of the
breakpoints, which remains one the most efficient algorithm. We propose a model
selection procedure to determine both the number of breakpoints and the number
of factors. This proposed method is implemented in the FASeg R package, which
is available on the CRAN. We demonstrate the performances of our procedure
through simulation experiments and an application to geodesic data is
presented.",http://arxiv.org/pdf/1505.05660v2,stat.ME
2015-05-16 20:11:52+00:00,Sequential Bayesian inference for implicit hidden Markov models and current limitations,['Pierre E. Jacob'],"Hidden Markov models can describe time series arising in various fields of
science, by treating the data as noisy measurements of an arbitrarily complex
Markov process. Sequential Monte Carlo (SMC) methods have become standard tools
to estimate the hidden Markov process given the observations and a fixed
parameter value. We review some of the recent developments allowing the
inclusion of parameter uncertainty as well as model uncertainty. The
shortcomings of the currently available methodology are emphasised from an
algorithmic complexity perspective. The statistical objects of interest for
time series analysis are illustrated on a toy ""Lotka-Volterra"" model used in
population ecology. Some open challenges are discussed regarding the
scalability of the reviewed methodology to longer time series,
higher-dimensional state spaces and more flexible models.",http://arxiv.org/pdf/1505.04321v1,stat.ME
2015-05-16 17:58:26+00:00,Change Points via Probabilistically Pruned Objectives,"['Nicholas A. James', 'David S. Matteson']","The concept of homogeneity plays a critical role in statistics, both in its
applications as well as its theory. Change point analysis is a statistical tool
that aims to attain homogeneity within time series data. This is accomplished
through partitioning the time series into a number of contiguous homogeneous
segments. The applications of such techniques range from identifying chromosome
alterations to solar flare detection. In this manuscript we present a general
purpose search algorithm called cp3o that can be used to identify change points
in multivariate time series. This new search procedure can be applied with a
large class of goodness of fit measures. Additionally, a reduction in the
computational time needed to identify change points is accomplish by means of
probabilistic pruning. With mild assumptions about the goodness of fit measure
this new search algorithm is shown to generate consistent estimates for both
the number of change points and their locations, even when the number of change
points increases with the time series length.
  A change point algorithm that incorporates the cp3o search algorithm and
E-Statistics, e-cp3o, is also presented. The only distributional assumption
that the e-cp3o procedure makes is that the absolute $\alpha$th moment exists,
for some $\alpha\in(0,2)$. Due to this mild restriction, the e-cp3o procedure
can be applied to a majority of change point problems. Furthermore, even with
such a mild restriction, the e-cp3o procedure has the ability to detect any
type of distributional change within a time series. Simulation studies are used
to compare the e-cp3o procedure to other parametric and nonparametric change
point procedures, we highlight applications of e-cp3o to climate and financial
datasets.",http://arxiv.org/pdf/1505.04302v1,stat.ME
2015-05-12 19:37:20+00:00,Bayesian Structure Learning for Stationary Time Series,"['Alex Tank', 'Nicholas Foti', 'Emily Fox']","While much work has explored probabilistic graphical models for independent
data, less attention has been paid to time series. The goal in this setting is
to determine conditional independence relations between entire time series,
which for stationary series, are encoded by zeros in the inverse spectral
density matrix. We take a Bayesian approach to structure learning, placing
priors on (i) the graph structure and (ii) spectral matrices given the graph.
We leverage a Whittle likelihood approximation and define a conjugate
prior---the hyper complex inverse Wishart---on the complex-valued and
graph-constrained spectral matrices. Due to conjugacy, we can analytically
marginalize the spectral matrices and obtain a closed-form marginal likelihood
of the time series given a graph. Importantly, our analytic marginal likelihood
allows us to avoid inference of the complex spectral matrices themselves and
places us back into the framework of standard (Bayesian) structure learning. In
particular, combining this marginal likelihood with our graph prior leads to
efficient inference of the time series graph itself, which we base on a
stochastic search procedure, though any standard approach can be
straightforwardly modified to our time series case. We demonstrate our methods
on analyzing stock data and neuroimaging data of brain activity during various
auditory tasks.",http://arxiv.org/pdf/1505.03131v2,stat.ME
2015-05-04 21:33:25+00:00,Identifying Cointegration by Eigenanalysis,"['Rongmao Zhang', 'Peter Robinson', 'Qiwei Yao']","We propose a new and easy-to-use method for identifying cointegrated
components of nonstationary time series, consisting of an eigenanalysis for a
certain non-negative definite matrix. Our setting is model-free, and we allow
the integer-valued integration orders of the observable series to be unknown,
and to possibly differ. Consistency of estimates of the cointegration space and
cointegration rank is established both when the dimension of the observable
time series is fixed as sample size increases, and when it diverges slowly. The
proposed methodology is also extended and justified in a fractional setting. A
Monte Carlo study of finite-sample performance, and a small empirical
illustration, are reported.",http://arxiv.org/pdf/1505.00821v3,stat.ME
2015-04-29 22:35:10+00:00,Estimation of connectivity measures in gappy time series,"['G. Papadopoulos', 'D. Kugiumtzis']","A new method is proposed to compute connectivity measures on multivariate
time series with gaps. Rather than removing or filling the gaps, the rows of
the joint data matrix containing empty entries are removed and the calculations
are done on the remainder matrix. The method, called measure adapted gap
removal (MAGR), can be applied to any connectivity measure that uses a joint
data matrix, such as cross correlation, cross mutual information and transfer
entropy. MAGR is favorably compared using these three measures to a number of
known gap-filling techniques, as well as the gap closure. The superiority of
MAGR is illustrated on time series from synthetic systems and financial time
series.",http://arxiv.org/pdf/1505.00003v1,stat.ME
2015-04-29 21:08:52+00:00,Note on Equivalence Between Recurrent Neural Network Time Series Models and Variational Bayesian Models,"['Jascha Sohl-Dickstein', 'Diederik P. Kingma']","We observe that the standard log likelihood training objective for a
Recurrent Neural Network (RNN) model of time series data is equivalent to a
variational Bayesian training objective, given the proper choice of generative
and inference models. This perspective may motivate extensions to both RNNs and
variational Bayesian models. We propose one such extension, where multiple
particles are used for the hidden state of an RNN, allowing a natural
representation of uncertainty or multimodality.",http://arxiv.org/pdf/1504.08025v2,cs.LG
2015-04-23 17:56:33+00:00,A new approach for physiological time series,"['Dong Mao', 'Yang Wang', 'Qiang Wu']","We developed a new approach for the analysis of physiological time series. An
iterative convolution filter is used to decompose the time series into various
components. Statistics of these components are extracted as features to
characterize the mechanisms underlying the time series. Motivated by the
studies that show many normal physiological systems involve irregularity while
the decrease of irregularity usually implies the abnormality, the statistics
for ""outliers"" in the components are used as features measuring irregularity.
Support vector machines are used to select the most relevant features that are
able to differentiate the time series from normal and abnormal systems. This
new approach is successfully used in the study of congestive heart failure by
heart beat interval time series.",http://arxiv.org/pdf/1504.06274v1,cs.LG
2015-04-23 13:53:32+00:00,On Locally Dyadic Stationary Processes,"['Theodoros Moysiadis', 'Konstantinos Fokianos']","We introduce the concept of local dyadic stationarity, to account for
non-stationary time series, within the framework of Walsh-Fourier analysis. We
define and study the time varying dyadic ARMA models (tvDARMA). It is proven
that the general tvDARMA process can be approximated locally by either a tvDMA
and a tvDAR process.",http://arxiv.org/pdf/1504.06185v3,math.ST
2015-04-14 15:54:29+00:00,Splitting hybrid Make-To-Order and Make-To-Stock demand profiles,"['Wolfgang Garn', 'James Aitken']","In this paper a demand time series is analysed to support Make-To-Stock (MTS)
and Make-To-Order (MTO) production decisions. Using a purely MTS production
strategy based on the given demand can lead to unnecessarily high inventory
levels thus it is necessary to identify likely MTO episodes.
  This research proposes a novel outlier detection algorithm based on special
density measures. We divide the time series' histogram into three clusters. One
with frequent-low volume covers MTS items whilst a second accounts for high
volumes which is dedicated to MTO items. The third cluster resides between the
previous two with its elements being assigned to either the MTO or MTS class.
The algorithm can be applied to a variety of time series such as stationary and
non-stationary ones.
  We use empirical data from manufacturing to study the extent of inventory
savings. The percentage of MTO items is reflected in the inventory savings
which were shown to be an average of 18.1%.",http://arxiv.org/pdf/1504.03594v1,stat.ME
2015-04-07 12:21:03+00:00,Bidirectional Recurrent Neural Networks as Generative Models - Reconstructing Gaps in Time Series,"['Mathias Berglund', 'Tapani Raiko', 'Mikko Honkala', 'Leo Kärkkäinen', 'Akos Vetek', 'Juha Karhunen']","Bidirectional recurrent neural networks (RNN) are trained to predict both in
the positive and negative time directions simultaneously. They have not been
used commonly in unsupervised tasks, because a probabilistic interpretation of
the model has been difficult. Recently, two different frameworks, GSN and NADE,
provide a connection between reconstruction and probabilistic modeling, which
makes the interpretation possible. As far as we know, neither GSN or NADE have
been studied in the context of time series before. As an example of an
unsupervised task, we study the problem of filling in gaps in high-dimensional
time series with complex dynamics. Although unidirectional RNNs have recently
been trained successfully to model such time series, inference in the negative
time direction is non-trivial. We propose two probabilistic interpretations of
bidirectional RNNs that can be used to reconstruct missing gaps efficiently.
Our experiments on text data show that both proposed methods are much more
accurate than unidirectional reconstructions, although a bit less accurate than
a computationally complex bidirectional Bayesian inference on the
unidirectional RNN. We also provide results on music data for which the
Bayesian inference is computationally infeasible, demonstrating the scalability
of the proposed methods.",http://arxiv.org/pdf/1504.01575v3,cs.LG
2015-03-17 12:41:30+00:00,Ultra-Fast Shapelets for Time Series Classification,"['Martin Wistuba', 'Josif Grabocka', 'Lars Schmidt-Thieme']","Time series shapelets are discriminative subsequences and their similarity to
a time series can be used for time series classification. Since the discovery
of time series shapelets is costly in terms of time, the applicability on long
or multivariate time series is difficult. In this work we propose Ultra-Fast
Shapelets that uses a number of random shapelets. It is shown that Ultra-Fast
Shapelets yield the same prediction quality as current state-of-the-art
shapelet-based time series classifiers that carefully select the shapelets by
being by up to three orders of magnitudes. Since this method allows a
ultra-fast shapelet discovery, using shapelets for long multivariate time
series classification becomes feasible.
  A method for using shapelets for multivariate time series is proposed and
Ultra-Fast Shapelets is proven to be successful in comparison to
state-of-the-art multivariate time series classifiers on 15 multivariate time
series datasets from various domains. Finally, time series derivatives that
have proven to be useful for other time series classifiers are investigated for
the shapelet-based classifiers. It is shown that they have a positive impact
and that they are easy to integrate with a simple preprocessing step, without
the need of adapting the shapelet discovery algorithm.",http://arxiv.org/pdf/1503.05018v1,cs.LG
2015-03-15 17:32:44+00:00,Estimation of the time of change in panel data,"['Lajos Horváth', 'Marie Hušková', 'Gregory Rice', 'Jia Wang']","We consider the problem of estimating the common time of a change in the mean
parameters of panel data when dependence is allowed between the panels in the
form of a common factor. A CUSUM type estimator is proposed, and we establish
first and second order asymptotics that can be used to derive consistent
confidence intervals for the time of change. Our results improve upon existing
theory in two primary directions. Firstly, the conditions we impose on the
model errors only pertain to the order of their long run moments, and hence our
results hold for nearly all stationary time series models of interest,
including nonlinear time series like the ARCH and GARCH processes. Secondly, we
study how the asymptotic distribution and norming sequences of the estimator
depend on the magnitude of the changes in each panel and the common factor
loadings. The performance of our results in finite samples is demonstrated with
a Monte Carlo simulation study, and we consider applications to two real data
sets: the exchange rates of 23 currencies with respect to the US dollar, and
the GDP per capita in 113 countries.",http://arxiv.org/pdf/1503.04455v1,math.ST
2015-03-11 23:08:06+00:00,The Optimised Theta Method,"['José Augusto Fioruci', 'Tiago Ribeiro Pellegrini', 'Francisco Louzada', 'Fotios Petropoulos']","Accurate and robust forecasting methods for univariate time series are very
important when the objective is to produce estimates for a large number of time
series. In this context, the Theta method called researchers attention due its
performance in the largest up-to-date forecasting competition, the
M3-Competition. Theta method proposes the decomposition of the deseasonalised
data into two ""theta lines"". The first theta line removes completely the
curvatures of the data, thus being a good estimator of the long-term trend
component. The second theta line doubles the curvatures of the series, as to
better approximate the short-term behaviour. In this paper, we propose a
generalisation of the Theta method by optimising the selection of the second
theta line, based on various validation schemes where the out-of-sample
accuracy of the candidate variants is measured. The recomposition process of
the original time series builds on the asymmetry of the decomposed theta lines.
An empirical investigation through the M3-Competition data set shows
improvements on the forecasting accuracy of the proposed optimised Theta
method.",http://arxiv.org/pdf/1503.03529v1,stat.ME
2015-03-11 09:38:49+00:00,Scalable Discovery of Time-Series Shapelets,"['Josif Grabocka', 'Martin Wistuba', 'Lars Schmidt-Thieme']","Time-series classification is an important problem for the data mining
community due to the wide range of application domains involving time-series
data. A recent paradigm, called shapelets, represents patterns that are highly
predictive for the target variable. Shapelets are discovered by measuring the
prediction accuracy of a set of potential (shapelet) candidates. The candidates
typically consist of all the segments of a dataset, therefore, the discovery of
shapelets is computationally expensive. This paper proposes a novel method that
avoids measuring the prediction accuracy of similar candidates in Euclidean
distance space, through an online clustering pruning technique. In addition,
our algorithm incorporates a supervised shapelet selection that filters out
only those candidates that improve classification accuracy. Empirical evidence
on 45 datasets from the UCR collection demonstrate that our method is 3-4
orders of magnitudes faster than the fastest existing shapelet-discovery
method, while providing better prediction accuracy.",http://arxiv.org/pdf/1503.03238v1,cs.LG
2015-03-07 21:26:05+00:00,Series representations for bivariate time-changed L{é}vy models,"['Vladimir Panov', 'Igor Sirotkin']","In this paper, we analyze a L{\'e}vy model based on two popular concepts -
subordination and L{\'e}vy copulas. More precisely, we consider a
two-dimensional L{\'e}vy process such that each component is a time-changed
(subordinated) Brownian motion and the dependence between subordinators is
described via some L{\'e}vy copula. We prove a series representation for our
model, which can be efficiently used for simulation purposes, and provide some
practical examples based on real data",http://arxiv.org/pdf/1503.02214v1,math.ST
2015-03-06 09:10:34+00:00,Ranking and significance of variable-length similarity-based time series motifs,"['Joan Serrà', 'Isabel Serra', 'Álvaro Corral', 'Josep Lluis Arcos']","The detection of very similar patterns in a time series, commonly called
motifs, has received continuous and increasing attention from diverse
scientific communities. In particular, recent approaches for discovering
similar motifs of different lengths have been proposed. In this work, we show
that such variable-length similarity-based motifs cannot be directly compared,
and hence ranked, by their normalized dissimilarities. Specifically, we find
that length-normalized motif dissimilarities still have intrinsic dependencies
on the motif length, and that lowest dissimilarities are particularly affected
by this dependency. Moreover, we find that such dependencies are generally
non-linear and change with the considered data set and dissimilarity measure.
Based on these findings, we propose a solution to rank those motifs and measure
their significance. This solution relies on a compact but accurate model of the
dissimilarity space, using a beta distribution with three parameters that
depend on the motif length in a non-linear way. We believe the incomparability
of variable-length dissimilarities could go beyond the field of time series,
and that similar modeling strategies as the one used here could be of help in a
more broad context.",http://arxiv.org/pdf/1503.01883v1,cs.LG
2015-03-02 21:05:19+00:00,On the asymptotic normality of kernel estimators of the long run covariance of functional time series,"['István Berkes', 'Lajos Horváth', 'Gregory Rice']","We consider the asymptotic normality in $L^2$ of kernel estimators of the
long run covariance kernel of stationary functional time series. Our results
are established assuming a weakly dependent Bernoulli shift structure for the
underlying observations, which contains most stationary functional time series
models, under mild conditions. As a corollary, we obtain joint asymptotics for
functional principal components computed from empirical long run covariance
operators, showing that they have the favorable property of being
asymptotically independent.",http://arxiv.org/pdf/1503.00741v2,math.ST
2015-02-27 09:00:36+00:00,High Dimensional and Banded Vector Autoregressions,"['Shaojun Guo', 'Yazhen Wang', 'Qiwei Yao']","We consider a class of vector autoregressive models with banded coefficient
matrices. The setting represents a type of sparse structure for
high-dimensional time series, though the implied autocovariance matrices are
not banded. The structure is also practically meaningful when the order of
component time series is arranged appropriately. The convergence rates for the
estimated banded autoregressive coefficient matrices are established. We also
propose a Bayesian information criterion for determining the width of the bands
in the coefficient matrices, which is proved to be consistent. By exploring
some approximate banded structure for the auto-covariance functions of banded
vector autoregressive processes, consistent estimators for the auto-covariance
matrices are constructed.",http://arxiv.org/pdf/1502.07831v2,stat.ME
2015-02-26 10:37:06+00:00,The Fourier Decomposition Method for nonlinear and nonstationary time series analysis,"['Pushpendra Singh', 'Shiv Dutt Joshi', 'Rakesh Kumar Patney', 'Kaushik Saha']","Since many decades, there is a general perception in literature that the
Fourier methods are not suitable for the analysis of nonlinear and
nonstationary data. In this paper, we propose a Fourier Decomposition Method
(FDM) and demonstrate its efficacy for the analysis of nonlinear (i.e. data
generated by nonlinear systems) and nonstationary time series. The proposed FDM
decomposes any data into a small number of `Fourier intrinsic band functions'
(FIBFs). The FDM presents a generalized Fourier expansion with variable
amplitudes and frequencies of a time series by the Fourier method itself. We
propose an idea of zero-phase filter bank based multivariate FDM (MFDM)
algorithm, for the analysis of multivariate nonlinear and nonstationary time
series, from the FDM. We also present an algorithm to obtain cutoff frequencies
for MFDM. The MFDM algorithm is generating finite number of band limited
multivariate FIBFs (MFIBFs). The MFDM preserves some intrinsic physical
properties of the multivariate data, such as scale alignment, trend and
instantaneous frequency. The proposed methods produce the results in a
time-frequency-energy distribution that reveal the intrinsic structures of a
data. Simulations have been carried out and comparison is made with the
Empirical Mode Decomposition (EMD) methods in the analysis of various simulated
as well as real life time series, and results show that the proposed methods
are powerful tools for analyzing and obtaining the time-frequency-energy
representation of any data.",http://arxiv.org/pdf/1503.06675v2,stat.ME
2015-02-25 10:24:16+00:00,Functional Time Series,['Łukasz Kidziński'],"The continuous advances in data collection and storage techniques allow us to
observe and record real-life processes in great detail. Examples include
financial transaction data, fMRI images, satellite photos, earths pollution
distribution in time etc. Due to the high dimensionality of such data,
classical statistical tools become inadequate and inefficient. The need for new
methods emerges and one of the most prominent techniques in this context is
functional data analysis (FDA).
  The main objective of this article is to present techniques of the analysis
of temporal dependence in FDA. Such dependence occurs, for example, if the data
consist of a continuous time process which has been cut into segments, days for
instance. We are then in the context of so-called functional time series.",http://arxiv.org/pdf/1502.07113v1,stat.ME
2015-02-23 19:14:39+00:00,Iteratively reweighted adaptive lasso for conditional heteroscedastic time series with applications to AR-ARCH type processes,['Florian Ziel'],"Shrinkage algorithms are of great importance in almost every area of
statistics due to the increasing impact of big data. Especially time series
analysis benefits from efficient and rapid estimation techniques such as the
lasso. However, currently lasso type estimators for autoregressive time series
models still focus on models with homoscedastic residuals. Therefore, an
iteratively reweighted adaptive lasso algorithm for the estimation of time
series models under conditional heteroscedasticity is presented in a
high-dimensional setting. The asymptotic behaviour of the resulting estimator
is analysed. It is found that the proposed estimation procedure performs
substantially better than its homoscedastic counterpart. A special case of the
algorithm is suitable to compute the estimated multivariate AR-ARCH type models
efficiently. Extensions to the model like periodic AR-ARCH, threshold AR-ARCH
or ARMA-GARCH are discussed. Finally, different simulation results and
applications to electricity market data and returns of metal prices are shown.",http://arxiv.org/pdf/1502.06557v2,stat.ME
2015-02-18 04:25:23+00:00,Temporal Embedding in Convolutional Neural Networks for Robust Learning of Abstract Snippets,"['Jiajun Liu', 'Kun Zhao', 'Brano Kusy', 'Ji-rong Wen', 'Raja Jurdak']","The prediction of periodical time-series remains challenging due to various
types of data distortions and misalignments. Here, we propose a novel model
called Temporal embedding-enhanced convolutional neural Network (TeNet) to
learn repeatedly-occurring-yet-hidden structural elements in periodical
time-series, called abstract snippets, for predicting future changes. Our model
uses convolutional neural networks and embeds a time-series with its potential
neighbors in the temporal domain for aligning it to the dominant patterns in
the dataset. The model is robust to distortions and misalignments in the
temporal domain and demonstrates strong prediction power for periodical
time-series.
  We conduct extensive experiments and discover that the proposed model shows
significant and consistent advantages over existing methods on a variety of
data modalities ranging from human mobility to household power consumption
records. Empirical results indicate that the model is robust to various factors
such as number of samples, variance of data, numerical ranges of data etc. The
experiments also verify that the intuition behind the model can be generalized
to multiple data types and applications and promises significant improvement in
prediction performances across the datasets studied.",http://arxiv.org/pdf/1502.05113v1,cs.LG
2015-02-17 10:08:48+00:00,Generalized Gradient Learning on Time Series under Elastic Transformations,['Brijnesh Jain'],"The majority of machine learning algorithms assumes that objects are
represented as vectors. But often the objects we want to learn on are more
naturally represented by other data structures such as sequences and time
series. For these representations many standard learning algorithms are
unavailable. We generalize gradient-based learning algorithms to time series
under dynamic time warping. To this end, we introduce elastic functions, which
extend functions on time series to matrix spaces. Necessary conditions are
presented under which generalized gradient learning on time series is
consistent. We indicate how results carry over to arbitrary elastic distance
functions and to sequences consisting of symbolic elements. Specifically, four
linear classifiers are extended to time series under dynamic time warping and
applied to benchmark datasets. Results indicate that generalized gradient
learning via elastic functions have the potential to complement the
state-of-the-art in statistical pattern recognition on time series.",http://arxiv.org/pdf/1502.04843v2,cs.LG
2015-02-11 21:56:13+00:00,Dependent Matérn Processes for Multivariate Time Series,"['Alexander Vandenberg-Rodes', 'Babak Shahbaba']","For the challenging task of modeling multivariate time series, we propose a
new class of models that use dependent Mat\'ern processes to capture the
underlying structure of data, explain their interdependencies, and predict
their unknown values. Although similar models have been proposed in the
econometric, statistics, and machine learning literature, our approach has
several advantages that distinguish it from existing methods: 1) it is flexible
to provide high prediction accuracy, yet its complexity is controlled to avoid
overfitting; 2) its interpretability separates it from black-box methods; 3)
finally, its computational efficiency makes it scalable for high-dimensional
time series. In this paper, we use several simulated and real data sets to
illustrate these advantages. We will also briefly discuss some extensions of
our model.",http://arxiv.org/pdf/1502.03466v1,stat.ML
2015-02-11 21:49:26+00:00,Variable and Fixed Interval Exponential Smoothing,['Javier R. Movellan'],"Exponential smoothers are a simple and memory efficient way to compute
running averages of time series. Here we define and describe practical
properties of exponential smoothers for signals observed at constant and
variable intervals.",http://arxiv.org/pdf/1502.03465v1,stat.ML
2015-02-04 01:03:06+00:00,Extracting Common Time Trends from Concurrent Time Series: Maximum Autocorrelation Factors with Application to Tree Ring Time Series Data,"['Matz A. Haugen', 'Bala Rajaratnam', 'Paul Switzer']","Concurrent time series commonly arise in various applications, including when
monitoring the environment such as in air quality measurement networks, weather
stations, oceanographic buoys, or in paleo form such as lake sediments, tree
rings, ice cores, or coral isotopes, with each monitoring or sampling site
providing one of the time series. The goal in such applications is to extract a
common time trend or signal in the observed data. Other examples where the goal
is to extract a common time trend for multiple time series are in stock price
time series, neurological time series, and quality control time series. For
this purpose we develop properties of MAF [Maximum Autocorrelation Factors]
that linearly combines time series in order to maximize the resulting SNR
[signal-to-noise-ratio] where there are multiple smooth signals present in the
data. Equivalence is established in a regression setting between MAF and CCA
[Canonical Correlation Analysis] even though MAF does not require specific
signal knowledge as opposed to CCA. We proceed to derive the theoretical
properties of MAF and quantify the SNR advantages of MAF in comparison with PCA
[Principal Components Analysis], a commonly used method for linearly combining
time series, and compare their statistical sample properties. MAF and PCA are
then applied to real and simulated data sets to illustrate MAFs efficacy.",http://arxiv.org/pdf/1502.01073v3,stat.ME
2015-01-29 14:48:28+00:00,Testing for Structural Breaks via Ordinal Pattern Dependence,"['Alexander Schnurr', 'Herold Dehling']","We propose new concepts in order to analyze and model the dependence
structure between two time series. Our methods rely exclusively on the order
structure of the data points. Hence, the methods are stable under monotone
transformations of the time series and robust against small perturbations or
measurement errors. Ordinal pattern dependence can be characterized by four
parameters. We propose estimators for these parameters, and we calculate their
asymptotic distributions. Furthermore, we derive a test for structural breaks
within the dependence structure. All results are supplemented by simulation
studies and empirical examples.
  For three consecutive data points attaining different values, there are six
possibilities how their values can be ordered. These possibilities are called
ordinal patterns. Our first idea is simply to count the number of coincidences
of patterns in both time series, and to compare this with the expected number
in the case of independence. If we detect a lot of coincident patterns, this
means that the up-and-down behavior is similar. Hence, our concept can be seen
as a way to measure non-linear `correlation'. We show in the last section, how
to generalize the concept in order to capture various other kinds of
dependence.",http://arxiv.org/pdf/1501.07858v1,math.ST
2015-01-29 10:18:46+00:00,Particle swarm optimization for time series motif discovery,"['Joan Serrà', 'Josep Lluis Arcos']","Efficiently finding similar segments or motifs in time series data is a
fundamental task that, due to the ubiquity of these data, is present in a wide
range of domains and situations. Because of this, countless solutions have been
devised but, to date, none of them seems to be fully satisfactory and flexible.
In this article, we propose an innovative standpoint and present a solution
coming from it: an anytime multimodal optimization algorithm for time series
motif discovery based on particle swarms. By considering data from a variety of
domains, we show that this solution is extremely competitive when compared to
the state-of-the-art, obtaining comparable motifs in considerably less time
using minimal memory. In addition, we show that it is robust to different
implementation choices and see that it offers an unprecedented degree of
flexibility with regard to the task. All these qualities make the presented
solution stand out as one of the most prominent candidates for motif discovery
in long time series streams. Besides, we believe the proposed standpoint can be
exploited in further time series analysis and mining tasks, widening the scope
of research and potentially yielding novel effective solutions.",http://arxiv.org/pdf/1501.07399v1,cs.LG
2015-01-16 17:01:30+00:00,Time Series Clustering using the Total Variation Distance with Applications in Oceanography,"['Pedro C. Alvarez-Esteban', 'C. Euán', 'J. Ortega']","An algorithm for determining stationary periods for time series of random sea
waves is proposed in this work. This is a problem in which changes between
stationary sea states are usually slow and segmentation procedures based on
change-point detection frequently give poor results. The method is based on a
new procedure for time series clustering, built on the use of the total
variation distance between normalized spectra as a measure of dissimilarity.
The oscillatory behavior of the series is thus considered the central
characteristic for classification purposes. The proposed algorithm is compared
to several other methods which are also based on features extracted from the
original series and the results show that its performance is comparable to the
best methods available and in some tests it performs better. This clustering
method may be of independent interest.",http://arxiv.org/pdf/1501.04050v3,stat.ME
2015-01-09 14:28:16+00:00,Limiting distributions for explosive PAR(1) time series with strongly mixing innovation,['Dominique Dehay'],"This work deals with the limiting distribution of the least squares
estimators of the coefficients a r of an explosive periodic autoregressive of
order 1 (PAR(1)) time series X r = a r X r--1 +u r when the innovation {u k }
is strongly mixing. More precisely {a r } is a periodic sequence of real
numbers with period P \textgreater{} 0 and such that P r=1 |a r |
\textgreater{} 1. The time series {u r } is periodically distributed with the
same period P and satisfies the strong mixing property, so the random variables
u r can be correlated.",http://arxiv.org/pdf/1501.02151v1,math.ST
2014-12-03 00:00:42+00:00,Highly comparative fetal heart rate analysis,"['B. D. Fulcher', 'A. E. Georgieva', 'C. W. G. Redman', 'Nick S. Jones']","A database of fetal heart rate (FHR) time series measured from 7221 patients
during labor is analyzed with the aim of learning the types of features of
these recordings that are informative of low cord pH. Our 'highly comparative'
analysis involves extracting over 9000 time-series analysis features from each
FHR time series, including measures of autocorrelation, entropy, distribution,
and various model fits. This diverse collection of features was developed in
previous work, and is publicly available. We describe five features that most
accurately classify a balanced training set of 59 'low pH' and 59 'normal pH'
FHR recordings. We then describe five of the features with the strongest linear
correlation to cord pH across the full dataset of FHR time series. The features
identified in this work may be used as part of a system for guiding
intervention during labor in future. This work successfully demonstrates the
utility of comparing across a large, interdisciplinary literature on
time-series analysis to automatically contribute new scientific results for
specific biomedical signal processing challenges.",http://arxiv.org/pdf/1412.1138v1,cs.LG
2014-11-26 19:11:02+00:00,Random Matrix Derived Shrinkage of Spectral Precision Matrices,"['A. T. Walden', 'D. Schneider-Luftman']","Much research has been carried out on shrinkage methods for real-valued
covariance matrices. In spectral analysis of $p$-vector-valued time series
there is often a need for good shrinkage methods too, most notably when the
complex-valued spectral matrix is singular. The equivalent of the Ledoit-Wolf
(LW) covariance matrix estimator for spectral matrices can be improved on using
a Rao-Blackwell estimator, and using random matrix theory we derive its form.
Such estimators can be used to better estimate inverse spectral (precision)
matrices too, and a random matrix method has previously been proposed and
implemented via extensive simulations. We describe the method, but carry out
computations entirely analytically, and suggest a way of selecting an important
parameter using a predictive risk approach. We show that both the Rao-Blackwell
estimator and the random matrix estimator of the precision matrix can
substantially outperform the inverse of the LW estimator in a time series
setting. Our new methodology is applied to EEG-derived time series data where
it is seen to work well and deliver substantial improvements for precision
matrix estimation.",http://arxiv.org/pdf/1411.7334v1,math.ST
2014-11-04 02:43:06+00:00,A Bayesian Multivariate Functional Dynamic Linear Model,"['Daniel R. Kowal', 'David S. Matteson', 'David Ruppert']","We present a Bayesian approach for modeling multivariate, dependent
functional data. To account for the three dominant structural features in the
data--functional, time dependent, and multivariate components--we extend
hierarchical dynamic linear models for multivariate time series to the
functional data setting. We also develop Bayesian spline theory in a more
general constrained optimization framework. The proposed methods identify a
time-invariant functional basis for the functional observations, which is
smooth and interpretable, and can be made common across multivariate
observations for additional information sharing. The Bayesian framework permits
joint estimation of the model parameters, provides exact inference (up to MCMC
error) on specific parameters, and allows generalized dependence structures.
Sampling from the posterior distribution is accomplished with an efficient
Gibbs sampling algorithm. We illustrate the proposed framework with two
applications: (1) multi-economy yield curve data from the recent global
recession, and (2) local field potential brain signals in rats, for which we
develop a multivariate functional time series approach for multivariate
time-frequency analysis. Supplementary materials, including R code and the
multi-economy yield curve data, are available online.",http://arxiv.org/pdf/1411.0764v2,stat.ME
2014-10-22 20:11:28+00:00,Tests for Time Series of Counts Based on the Probability Generating Function,"['Šárka Hudecová', 'Marie Hušková', 'Simos G. Meintanis']","We propose testing procedures for the hypothesis that a given set of discrete
observations may be formulated as a particular time series of counts with a
specific conditional law. The new test statistics incorporate the empirical
probability generating function computed from the observations. Special
emphasis is given to the popular models of integer autoregression and Poisson
autoregression. The asymptotic properties of the proposed test statistics are
studied under the null hypothesis as well as under alternatives. A Monte Carlo
power study on bootstrap versions of the new methods is included as well as
real-data examples.",http://arxiv.org/pdf/1410.6172v1,math.ST
2014-10-09 00:53:06+00:00,Principal component analysis for second-order stationary vector time series,"['Jinyuan Chang', 'Bin Guo', 'Qiwei Yao']","We extend the principal component analysis (PCA) to second-order stationary
vector time series in the sense that we seek for a contemporaneous linear
transformation for a $p$-variate time series such that the transformed series
is segmented into several lower-dimensional subseries, and those subseries are
uncorrelated with each other both contemporaneously and serially. Therefore
those lower-dimensional series can be analysed separately as far as the linear
dynamic structure is concerned. Technically it boils down to an eigenanalysis
for a positive definite matrix. When $p$ is large, an additional step is
required to perform a permutation in terms of either maximum cross-correlations
or FDR based on multiple tests. The asymptotic theory is established for both
fixed $p$ and diverging $p$ when the sample size $n$ tends to infinity.
Numerical experiments with both simulated and real data sets indicate that the
proposed method is an effective initial step in analysing multiple time series
data, which leads to substantial dimension reduction in modelling and
forecasting high-dimensional linear dynamical structures. Unlike PCA for
independent data, there is no guarantee that the required linear transformation
exists. When it does not, the proposed method provides an approximate
segmentation which leads to the advantages in, for example, forecasting for
future values. The method can also be adapted to segment multiple volatility
processes.",http://arxiv.org/pdf/1410.2323v4,stat.ME
2014-10-05 17:57:23+00:00,Graphical LASSO Based Model Selection for Time Series,"['Alexander Jung', 'Gabor Hannak', 'Norbert Görtz']","We propose a novel graphical model selection (GMS) scheme for
high-dimensional stationary time series or discrete time process. The method is
based on a natural generalization of the graphical LASSO (gLASSO), introduced
originally for GMS based on i.i.d. samples, and estimates the conditional
independence graph (CIG) of a time series from a finite length observation. The
gLASSO for time series is defined as the solution of an l1-regularized maximum
(approximate) likelihood problem. We solve this optimization problem using the
alternating direction method of multipliers (ADMM). Our approach is
nonparametric as we do not assume a finite dimensional (e.g., an
autoregressive) parametric model for the observed process. Instead, we require
the process to be sufficiently smooth in the spectral domain. For Gaussian
processes, we characterize the performance of our method theoretically by
deriving an upper bound on the probability that our algorithm fails to
correctly identify the CIG. Numerical experiments demonstrate the ability of
our method to recover the correct CIG from a limited amount of samples.",http://arxiv.org/pdf/1410.1184v3,stat.ML
2014-09-05 15:44:34+00:00,On Optimal Multiple Changepoint Algorithms for Large Data,"['Robert Maidstone', 'Toby Hocking', 'Guillem Rigaill', 'Paul Fearnhead']","There is an increasing need for algorithms that can accurately detect
changepoints in long time-series, or equivalent, data. Many common approaches
to detecting changepoints, for example based on penalised likelihood or minimum
description length, can be formulated in terms of minimising a cost over
segmentations. Dynamic programming methods exist to solve this minimisation
problem exactly, but these tend to scale at least quadratically in the length
of the time-series. Algorithms, such as Binary Segmentation, exist that have a
computational cost that is close to linear in the length of the time-series,
but these are not guaranteed to find the optimal segmentation. Recently pruning
ideas have been suggested that can speed up the dynamic programming algorithms,
whilst still being guaranteed to find true minimum of the cost function. Here
we extend these pruning methods, and introduce two new algorithms for
segmenting data, FPOP and SNIP. Empirical results show that FPOP is
substantially faster than existing dynamic programming methods, and unlike the
existing methods its computational efficiency is robust to the number of
changepoints in the data. We evaluate the method at detecting Copy Number
Variations and observe that FPOP has a computational cost that is competitive
with that of Binary Segmentation.",http://arxiv.org/pdf/1409.1842v1,stat.ME
2014-09-05 13:35:52+00:00,A new framework for extracting coarse-grained models from time series with multiscale structure,"['Serafim Kalliadasis', 'Sebastian Krumscheid', 'Grigorios A. Pavliotis']","In many applications it is desirable to infer coarse-grained models from
observational data. The observed process often corresponds only to a few
selected degrees of freedom of a high-dimensional dynamical system with
multiple time scales. In this work we consider the inference problem of
identifying an appropriate coarse-grained model from a single time series of a
multiscale system. It is known that estimators such as the maximum likelihood
estimator or the quadratic variation of the path estimator can be strongly
biased in this setting. Here we present a novel parametric inference
methodology for problems with linear parameter dependency that does not suffer
from this drawback. Furthermore, we demonstrate through a wide spectrum of
examples that our methodology can be used to derive appropriate coarse-grained
models from time series of partial observations of a multiscale system in an
effective and systematic fashion.",http://arxiv.org/pdf/1409.1787v2,math.ST
2014-08-16 11:11:59+00:00,Multi-Sensor Event Detection using Shape Histograms,"['Ehtesham Hassan', 'Gautam Shroff', 'Puneet Agarwal']","Vehicular sensor data consists of multiple time-series arising from a number
of sensors. Using such multi-sensor data we would like to detect occurrences of
specific events that vehicles encounter, e.g., corresponding to particular
maneuvers that a vehicle makes or conditions that it encounters. Events are
characterized by similar waveform patterns re-appearing within one or more
sensors. Further such patterns can be of variable duration. In this work, we
propose a method for detecting such events in time-series data using a novel
feature descriptor motivated by similar ideas in image processing. We define
the shape histogram: a constant dimension descriptor that nevertheless captures
patterns of variable duration. We demonstrate the efficacy of using shape
histograms as features to detect events in an SVM-based, multi-sensor,
supervised learning scenario, i.e., multiple time-series are used to detect an
event. We present results on real-life vehicular sensor data and show that our
technique performs better than available pattern detection implementations on
our data, and that it can also be used to combine features from multiple
sensors resulting in better accuracy than using any single sensor. Since
previous work on pattern detection in time-series has been in the single series
context, we also present results using our technique on multiple standard
time-series datasets and show that it is the most versatile in terms of how it
ranks compared to other published results.",http://arxiv.org/pdf/1408.3733v1,cs.LG
2014-07-14 15:01:57+00:00,Finding Motif Sets in Time Series,"['Anthony Bagnall', 'Jon Hills', 'Jason Lines']","Time-series motifs are representative subsequences that occur frequently in a
time series; a motif set is the set of subsequences deemed to be instances of a
given motif. We focus on finding motif sets. Our motivation is to detect motif
sets in household electricity-usage profiles, representing repeated patterns of
household usage.
  We propose three algorithms for finding motif sets. Two are greedy algorithms
based on pairwise comparison, and the third uses a heuristic measure of set
quality to find the motif set directly. We compare these algorithms on
simulated datasets and on electricity-usage data. We show that Scan MK, the
simplest way of using the best-matching pair to find motif sets, is less
accurate on our synthetic data than Set Finder and Cluster MK, although the
latter is very sensitive to parameter settings. We qualitatively analyse the
outputs for the electricity-usage data and demonstrate that both Scan MK and
Set Finder can discover useful motif sets in such data.",http://arxiv.org/pdf/1407.3685v1,cs.LG
2014-07-11 16:11:58+00:00,Bayesian Model for Multiple Change-points Detection in Multivariate Time Series,"['Flore Harlé', 'Florent Chatelain', 'Cédric Gouy-Pailler', 'Sophie Achard']","This paper addresses the issue of detecting change-points in multivariate
time series. The proposed approach differs from existing counterparts by making
only weak assumptions on both the change-points structure across series, and
the statistical signal distributions. Specifically change-points are not
assumed to occur at simultaneous time instants across series, and no specific
distribution is assumed on the individual signals. It relies on the combination
of a local robust statistical test acting on individual time segments, with a
global Bayesian framework able to optimize configurations from multiple local
statistics (from segments of a unique time series or multiple time series).
Using an extensive experimental set-up, our algorithm is shown to perform well
on Gaussian data, with the same results in term of recall and precision as
classical approaches, such as the fused lasso and the Bernoulli Gaussian model.
Furthermore, it outperforms the reference models in the case of non normal data
with outliers. The control of the False Discovery Rate by an acceptance level
is confirmed. In the case of multivariate data, the probabilities that
simultaneous change-points are shared by some specific time series are learned.
We finally illustrate our algorithm with real datasets from energy monitoring
and genomic. Segmentations are compared to state-of-the-art approaches based on
fused lasso and group fused lasso.",http://arxiv.org/pdf/1407.3206v1,stat.ME
2014-06-18 15:09:21+00:00,An Experimental Evaluation of Nearest Neighbour Time Series Classification,"['Anthony Bagnall', 'Jason Lines']","Data mining research into time series classification (TSC) has focussed on
alternative distance measures for nearest neighbour classifiers. It is standard
practice to use 1-NN with Euclidean or dynamic time warping (DTW) distance as a
straw man for comparison. As part of a wider investigation into elastic
distance measures for TSC~\cite{lines14elastic}, we perform a series of
experiments to test whether this standard practice is valid.
  Specifically, we compare 1-NN classifiers with Euclidean and DTW distance to
standard classifiers, examine whether the performance of 1-NN Euclidean
approaches that of 1-NN DTW as the number of cases increases, assess whether
there is any benefit of setting $k$ for $k$-NN through cross validation whether
it is worth setting the warping path for DTW through cross validation and
finally is it better to use a window or weighting for DTW. Based on experiments
on 77 problems, we conclude that 1-NN with Euclidean distance is fairly easy to
beat but 1-NN with DTW is not, if window size is set through cross validation.",http://arxiv.org/pdf/1406.4757v1,cs.LG
2014-06-17 21:09:39+00:00,Dynamic Principal Components in the Time Domain,"['Daniel Peña', 'Víctor J. Yohai']","We propose a time domain approach to define dynamic principal components
(DPC) using a reconstruction of the original series criterion. This approach to
define DPC was introduced by Brillinger, who gave a very elegant theoretical
solution in the stationary case using the cross spectrum. Our procedure can be
applied under more general conditions including the case ofnon stationary
series and relatively short series. We also present a robust version of our
procedure that allows to estimate the DPC when the series have outlier
contamination. Our non robust and robust procedures are illustrated with real
datasets.",http://arxiv.org/pdf/1406.4543v1,math.ST
2014-06-15 02:39:37+00:00,Interval Forecasting of Electricity Demand: A Novel Bivariate EMD-based Support Vector Regression Modeling Framework,"['Tao Xiong', 'Yukun Bao', 'Zhongyi Hu']","Highly accurate interval forecasting of electricity demand is fundamental to
the success of reducing the risk when making power system planning and
operational decisions by providing a range rather than point estimation. In
this study, a novel modeling framework integrating bivariate empirical mode
decomposition (BEMD) and support vector regression (SVR), extended from the
well-established empirical mode decomposition (EMD) based time series modeling
framework in the energy demand forecasting literature, is proposed for interval
forecasting of electricity demand. The novelty of this study arises from the
employment of BEMD, a new extension of classical empirical model decomposition
(EMD) destined to handle bivariate time series treated as complex-valued time
series, as decomposition method instead of classical EMD only capable of
decomposing one-dimensional single-valued time series. This proposed modeling
framework is endowed with BEMD to decompose simultaneously both the lower and
upper bounds time series, constructed in forms of complex-valued time series,
of electricity demand on a monthly per hour basis, resulting in capturing the
potential interrelationship between lower and upper bounds. The proposed
modeling framework is justified with monthly interval-valued electricity demand
data per hour in Pennsylvania-New Jersey-Maryland Interconnection, indicating
it as a promising method for interval-valued electricity demand forecasting.",http://arxiv.org/pdf/1406.3792v1,cs.LG
2014-06-14 10:21:03+00:00,Dimensionality reduction for time series data,"['Diego Vidaurre', 'Iead Rezek', 'Samuel L. Harrison', 'Stephen S. Smith', 'Mark Woolrich']","Despite the fact that they do not consider the temporal nature of data,
classic dimensionality reduction techniques, such as PCA, are widely applied to
time series data. In this paper, we introduce a factor decomposition specific
for time series that builds upon the Bayesian multivariate autoregressive model
and hence evades the assumption that data points are mutually independent. The
key is to find a low-rank estimation of the autoregressive matrices. As in the
probabilistic version of other factor models, this induces a latent
low-dimensional representation of the original data. We discuss some possible
generalisations and alternatives, with the most relevant being a technique for
simultaneous smoothing and dimensionality reduction. To illustrate the
potential applications, we apply the model on a synthetic data set and
different types of neuroimaging data (EEG and ECoG).",http://arxiv.org/pdf/1406.3711v1,stat.ML
2014-06-04 13:22:29+00:00,Bootstrapping High Dimensional Time Series,"['Xianyang Zhang', 'Guang Cheng']","This article studies bootstrap inference for high dimensional weakly
dependent time series in a general framework of approximately linear
statistics. The following high dimensional applications are covered: (1)
uniform confidence band for mean vector; (2) specification testing on the
second order property of time series such as white noise testing and bandedness
testing of covariance matrix; (3) specification testing on the spectral
property of time series. In theory, we first derive a Gaussian approximation
result for the maximum of a sum of weakly dependent vectors, where the
dimension of the vectors is allowed to be exponentially larger than the sample
size. In particular, we illustrate an interesting interplay between dependence
and dimensionality, and also discuss one type of ""dimension free"" dependence
structure. We further propose a blockwise multiplier (wild) bootstrap that
works for time series with unknown autocovariance structure. These
distributional approximation errors, which are finite sample valid, decrease
polynomially in sample size. A non-overlapping block bootstrap is also studied
as a more flexible alternative. The above results are established under the
general physical/functional dependence framework proposed in Wu (2005). Our
work can be viewed as a substantive extension of Chernozhukov et al. (2013) to
time series based on a variant of Stein's method developed therein.",http://arxiv.org/pdf/1406.1037v2,math.ST
2014-06-03 17:56:26+00:00,The Cepstral Model for Multivariate Time Series: The Vector Exponential Model,"['Scott H. Holan', 'Tucker S. McElroy', 'Guohui Wu']","Vector autoregressive (VAR) models have become a staple in the analysis of
multivariate time series and are formulated in the time domain as difference
equations, with an implied covariance structure. In many contexts, it is
desirable to work with a stable, or at least stationary, representation. To fit
such models, one must impose restrictions on the coefficient matrices to ensure
that certain determinants are nonzero; which, except in special cases, may
prove burdensome. To circumvent these difficulties, we propose a flexible
frequency domain model expressed in terms of the spectral density matrix.
Specifically, this paper treats the modeling of covariance stationary
vector-valued (i.e., multivariate) time series via an extension of the
exponential model for the spectrum of a scalar time series. We discuss the
modeling advantages of the vector exponential model and its computational
facets, such as how to obtain Wold coefficients from given cepstral
coefficients. Finally, we demonstrate the utility of our approach through
simulation as well as two illustrative data examples focusing on multi-step
ahead forecasting and estimation of squared coherence.",http://arxiv.org/pdf/1406.0801v1,stat.ME
2014-05-15 04:32:29+00:00,Effective Bayesian Modeling of Groups of Related Count Time Series,['Nicolas Chapados'],"Time series of counts arise in a variety of forecasting applications, for
which traditional models are generally inappropriate. This paper introduces a
hierarchical Bayesian formulation applicable to count time series that can
easily account for explanatory variables and share statistical strength across
groups of related time series. We derive an efficient approximate inference
technique, and illustrate its performance on a number of datasets from supply
chain planning.",http://arxiv.org/pdf/1405.3738v1,stat.ML
2014-05-14 07:41:06+00:00,Separation of uncorrelated stationary time series using autocovariance matrices,"['Jari Miettinen', 'Katrin Illner', 'Klaus Nordhausen', 'Hannu Oja', 'Sara Taskinen', 'Fabian J. Theis']","Blind source separation (BSS) is a signal processing tool, which is widely
used in various fields. Examples include biomedical signal separation, brain
imaging and economic time series applications. In BSS, one assumes that the
observed $p$ time series are linear combinations of $p$ latent uncorrelated
weakly stationary time series. The aim is then to find an estimate for an
unmixing matrix, which transforms the observed time series back to uncorrelated
latent time series. In SOBI (Second Order Blind Identification) joint
diagonalization of the covariance matrix and autocovariance matrices with
several lags is used to estimate the unmixing matrix. The rows of an unmixing
matrix can be derived either one by one (deflation-based approach) or
simultaneously (symmetric approach). The latter of these approaches is
well-known especially in signal processing literature, however, the rigorous
analysis of its statistical properties has been missing so far. In this paper,
we fill this gap and investigate the statistical properties of the symmetric
SOBI estimate in detail and find its limiting distribution under general
conditions. The asymptotical efficiencies of symmetric SOBI estimate are
compared to those of recently introduced deflation-based SOBI estimate under
general multivariate MA$(\infty)$ processes. The theory is illustrated by some
finite-sample simulation studies as well as a real EEG data example.",http://arxiv.org/pdf/1405.3388v1,math.ST
2014-04-29 06:43:19+00:00,Meteorological time series forecasting based on MLP modelling using heterogeneous transfer functions,"['Cyril Voyant', 'Marie Laure Nivet', 'Christophe Paoli', 'Marc Muselli', 'Gilles Notton']","In this paper, we propose to study four meteorological and seasonal time
series coupled with a multi-layer perceptron (MLP) modeling. We chose to
combine two transfer functions for the nodes of the hidden layer, and to use a
temporal indicator (time index as input) in order to take into account the
seasonal aspect of the studied time series. The results of the prediction
concern two years of measurements and the learning step, eight independent
years. We show that this methodology can improve the accuracy of meteorological
data estimation compared to a classical MLP modelling with a homogenous
transfer function.",http://arxiv.org/pdf/1404.7255v1,cs.LG
2014-04-17 18:44:50+00:00,Quantile Spectral Analysis for Locally Stationary Time Series,"['Stefan Birr', 'Stanislav Volgushev', 'Tobias Kley', 'Holger Dette', 'Marc Hallin']","Classical spectral methods are subject to two fundamental limitations: they
only can account for covariance-related serial dependencies, and they require
second-order stationarity. Much attention has been devoted lately to
quantile-based spectral methods that go beyond covariance-based serial
dependence features. At the same time, covariance-based methods relaxing
stationarity into much weaker {\it local stationarity} conditions have been
developed for a variety of time-series models. Here, we are combining those two
approaches by proposing quantile-based spectral methods for locally stationary
processes. We therefore introduce a time-varying version of the copula spectra
that have been recently proposed in the literature, along with a suitable local
lag-window estimator. We propose a new definition of local {\it strict}
stationarity that allows us to handle completely general non-linear processes
without any moment assumptions, thus accommodating our quantile-based concepts
and methods. We establish a central limit theorem for the new estimators, and
illustrate the power of the proposed methodology by means of a simulation
study. Moreover, in two empirical studies (namely of the Standard \& Poor's 500
series and a temperature dataset recorded in Hohenpeissenberg) we demonstrate
that the new approach detects important variations in serial dependence
structures both across time and across quantiles. Such variations remain
completely undetected, and are actually undetectable, via classical
covariance-based spectral methods.",http://arxiv.org/pdf/1404.4605v3,math.ST
2014-03-27 12:44:32+00:00,Spaghetti prediction: A robust method for forecasting short time series,"['Steven C. Gustafson', 'Leno M. Pedrotti']","A novel method for predicting time series is described and demonstrated. This
method inputs time series data points and outputs multiple ""spaghetti""
functions from which predictions can be made. Spaghetti prediction has
desirable properties that are not realized by classic autoregression, moving
average, spline, Gaussian process, and other methods. It is particularly
appropriate for short time series because it allows asymmetric prediction
distributions and produces prediction functions which are robust in that they
use multiple independent models.",http://arxiv.org/pdf/1403.7001v1,stat.ME
2014-03-22 23:50:24+00:00,Testing for independence between functional time series,"['Lajos Horvath', 'Greg Rice']","Frequently econometricians are interested in verifying a relationship between
two or more time series. Such analysis is typically carried out by causality
and/or independence tests which have been well studied when the data is
univariate or multivariate. Modern data though is increasingly of a high
dimensional or functional nature for which finite dimensional methods are not
suitable. In the present paper we develop methodology to check the assumption
that data obtained from two functional time series are independent. Our
procedure is based on the norms of empirical cross covariance operators and is
asymptotically validated when the underlying populations are assumed to be in a
class of weakly dependent random functions which include the functional ARMA,
ARCH and GARCH processes.",http://arxiv.org/pdf/1403.5710v1,math.ST
2014-03-17 01:16:10+00:00,Causality between time series,['X. San Liang'],"Given two time series, can one tell, in a rigorous and quantitative way, the
cause and effect between them? Based on a recently rigorized physical notion
namely information flow, we arrive at a concise formula and give this
challenging question, which is of wide concern in different disciplines, a
positive answer. Here causality is measured by the time rate of change of
information flowing from one series, say, X2, to another, X1. The measure is
asymmetric between the two parties and, particularly, if the process underlying
X1 does not depend on X2, then the resulting causality from X2 to X1 vanishes.
The formula is tight in form, involving only the commonly used statistics,
sample covariances. It has been validated with touchstone series purportedly
generated with one-way causality. It has also been applied to the investigation
of real world problems; an example presented here is the cause-effect relation
between two climate modes, El Ni\~no and Indian Ocean Dipole, which have been
linked to the hazards in far flung regions of the globe, with important results
that would otherwise be difficult, if not impossible, to obtain.",http://arxiv.org/pdf/1403.6496v1,stat.ME
2014-03-05 03:57:26+00:00,Hierarchical Semi-parametric Duration Models,"['Mingyu Tang', 'Mark Schervish']","This research attempts to model the stochastic process of trades in a limit
order book market as a marked point process. We propose a semi-parametric model
for the conditional distribution given the past, attempting to capture the
effect of the recent past in a nonparametric way and the effect of the more
distant past using a parametric time series model. Our framework provides more
flexibility than the most commonly used family of models, known as
Autoregressive Conditional Duration (ACD), in terms of the shape of the density
of durations and in the form of dependence across time. We also propose an
online learning algorithm for intraday trends that vary from day to day. This
allows us both to do prediction of future trade times and to incorporate the
effects of additional explanatory variables. In this paper, we show that the
framework works better than the ACD family both in the sense of prediction
log-likelihood and according to various diagnostic tests using data from the
New York Stock Exchange. In general, the framework can be used both to estimate
the intensity of a point process, and to estimate a the joint density of a time
series.",http://arxiv.org/pdf/1403.0998v1,stat.ME
2014-02-09 11:30:20+00:00,The Cross-Quantilogram: Measuring Quantile Dependence and Testing Directional Predictability between Time Series,"['Heejoon Han', 'Oliver Linton', 'Tatsushi Oka', 'Yoon-Jae Whang']","This paper proposes the cross-quantilogram to measure the quantile dependence
between two time series. We apply it to test the hypothesis that one time
series has no directional predictability to another time series. We establish
the asymptotic distribution of the cross quantilogram and the corresponding
test statistic. The limiting distributions depend on nuisance parameters. To
construct consistent confidence intervals we employ the stationary bootstrap
procedure; we show the consistency of this bootstrap. Also, we consider the
self-normalized approach, which is shown to be asymptotically pivotal under the
null hypothesis of no predictability. We provide simulation studies and two
empirical applications. First, we use the cross-quantilogram to detect
predictability from stock variance to excess stock return. Compared to existing
tools used in the literature of stock return predictability, our method
provides a more complete relationship between a predictor and stock return.
Second, we investigate the systemic risk of individual financial institutions,
such as JP Morgan Chase, Goldman Sachs and AIG. This article has supplementary
materials online.",http://arxiv.org/pdf/1402.1937v2,math.ST
2014-02-04 13:18:57+00:00,Nonparametric specification for non-stationary time series regression,['Zhou Zhou'],"We investigate the behavior of the Generalized Likelihood Ratio Test (GLRT)
(Fan, Zhang and Zhang [Ann. Statist. 29 (2001) 153-193]) for time varying
coefficient models where the regressors and errors are non-stationary time
series and can be cross correlated. It is found that the GLRT retains the
minimax rate of local alternative detection under weak dependence and
non-stationarity. However, in general, the Wilks phenomenon as well as the
classic residual bootstrap are sensitive to either conditional
heteroscedasticity of the errors, non-stationarity or temporal dependence. An
averaged test is suggested to alleviate the sensitivity of the test to the
choice of bandwidth and is shown to be more powerful than tests based on a
single bandwidth. An alternative wild bootstrap method is proposed and shown to
be consistent when making inference of time varying coefficient models for
non-stationary time series.",http://arxiv.org/pdf/1402.0722v1,math.ST
2014-01-16 12:27:41+00:00,Inference of weighted $V$-statistics for nonstationary time series and its applications,['Zhou Zhou'],"We investigate the behavior of Fourier transforms for a wide class of
nonstationary nonlinear processes. Asymptotic central and noncentral limit
theorems are established for a class of nondegenerate and degenerate weighted
$V$-statistics through the angle of Fourier analysis. The established theory
for $V$-statistics provides a unified treatment for many important time and
spectral domain problems in the analysis of nonstationary time series, ranging
from nonparametric estimation to the inference of periodograms and spectral
densities.",http://arxiv.org/pdf/1401.4007v1,math.ST
2014-01-16 10:21:44+00:00,An Empirical Evaluation of Similarity Measures for Time Series Classification,"['Joan Serrà', 'Josep Lluis Arcos']","Time series are ubiquitous, and a measure to assess their similarity is a
core part of many computational systems. In particular, the similarity measure
is the most essential ingredient of time series clustering and classification
systems. Because of this importance, countless approaches to estimate time
series similarity have been proposed. However, there is a lack of comparative
studies using empirical, rigorous, quantitative, and large-scale assessment
strategies. In this article, we provide an extensive evaluation of similarity
measures for time series classification following the aforementioned
principles. We consider 7 different measures coming from alternative measure
`families', and 45 publicly-available time series data sets coming from a wide
variety of scientific domains. We focus on out-of-sample classification
accuracy, but in-sample accuracies and parameter choices are also discussed.
Our work is based on rigorous evaluation methodologies and includes the use of
powerful statistical significance tests to derive meaningful conclusions. The
obtained results show the equivalence, in terms of accuracy, of a number of
measures, but with one single candidate outperforming the rest. Such findings,
together with the followed methodology, invite researchers on the field to
adopt a more consistent evaluation criteria and a more informed decision
regarding the baseline measures to which new developments should be compared.",http://arxiv.org/pdf/1401.3973v1,cs.LG
2014-01-15 09:41:50+00:00,Highly comparative feature-based time-series classification,"['Ben D. Fulcher', 'Nick S. Jones']","A highly comparative, feature-based approach to time series classification is
introduced that uses an extensive database of algorithms to extract thousands
of interpretable features from time series. These features are derived from
across the scientific time-series analysis literature, and include summaries of
time series in terms of their correlation structure, distribution, entropy,
stationarity, scaling properties, and fits to a range of time-series models.
After computing thousands of features for each time series in a training set,
those that are most informative of the class structure are selected using
greedy forward feature selection with a linear classifier. The resulting
feature-based classifiers automatically learn the differences between classes
using a reduced number of time-series properties, and circumvent the need to
calculate distances between time series. Representing time series in this way
results in orders of magnitude of dimensionality reduction, allowing the method
to perform well on very large datasets containing long time series or time
series of different lengths. For many of the datasets studied, classification
performance exceeded that of conventional instance-based classifiers, including
one nearest neighbor classifiers using Euclidean distances and dynamic time
warping and, most importantly, the features selected provide an understanding
of the properties of the dataset, insight that can guide further scientific
investigation.",http://arxiv.org/pdf/1401.3531v2,cs.LG
2014-01-11 06:14:53+00:00,Multi-Step-Ahead Time Series Prediction using Multiple-Output Support Vector Regression,"['Yukun Bao', 'Tao Xiong', 'Zhongyi Hu']","Accurate time series prediction over long future horizons is challenging and
of great interest to both practitioners and academics. As a well-known
intelligent algorithm, the standard formulation of Support Vector Regression
(SVR) could be taken for multi-step-ahead time series prediction, only relying
either on iterated strategy or direct strategy. This study proposes a novel
multiple-step-ahead time series prediction approach which employs
multiple-output support vector regression (M-SVR) with multiple-input
multiple-output (MIMO) prediction strategy. In addition, the rank of three
leading prediction strategies with SVR is comparatively examined, providing
practical implications on the selection of the prediction strategy for
multi-step-ahead forecasting while taking SVR as modeling technique. The
proposed approach is validated with the simulated and real datasets. The
quantitative and comprehensive assessments are performed on the basis of the
prediction accuracy and computational cost. The results indicate that: 1) the
M-SVR using MIMO strategy achieves the best accurate forecasts with accredited
computational load, 2) the standard SVR using direct strategy achieves the
second best accurate forecasts, but with the most expensive computational cost,
and 3) the standard SVR using iterated strategy is the worst in terms of
prediction accuracy, but with the least computational cost.",http://arxiv.org/pdf/1401.2504v1,cs.LG
2014-01-08 08:47:44+00:00,Fast nonparametric clustering of structured time-series,"['James Hensman', 'Magnus Rattray', 'Neil D. Lawrence']","In this publication, we combine two Bayesian non-parametric models: the
Gaussian Process (GP) and the Dirichlet Process (DP). Our innovation in the GP
model is to introduce a variation on the GP prior which enables us to model
structured time-series data, i.e. data containing groups where we wish to model
inter- and intra-group variability. Our innovation in the DP model is an
implementation of a new fast collapsed variational inference procedure which
enables us to optimize our variationala pproximation significantly faster than
standard VB approaches. In a biological time series application we show how our
model better captures salient features of the data, leading to better
consistency with existing biological classifications, while the associated
inference algorithm provides a twofold speed-up over EM-based variational
inference.",http://arxiv.org/pdf/1401.1605v2,cs.LG
2014-01-06 10:03:14+00:00,A nonstandard empirical likelihood for time series,"['Daniel J. Nordman', 'Helle Bunzel', 'Soumendra N. Lahiri']","Standard blockwise empirical likelihood (BEL) for stationary, weakly
dependent time series requires specifying a fixed block length as a tuning
parameter for setting confidence regions. This aspect can be difficult and
impacts coverage accuracy. As an alternative, this paper proposes a new version
of BEL based on a simple, though nonstandard, data-blocking rule which uses a
data block of every possible length. Consequently, the method does not involve
the usual block selection issues and is also anticipated to exhibit better
coverage performance. Its nonstandard blocking scheme, however, induces
nonstandard asymptotics and requires a significantly different development
compared to standard BEL. We establish the large-sample distribution of
log-ratio statistics from the new BEL method for calibrating confidence regions
for mean or smooth function parameters of time series. This limit law is not
the usual chi-square one, but is distribution-free and can be reproduced
through straightforward simulations. Numerical studies indicate that the
proposed method generally exhibits better coverage accuracy than standard BEL.",http://arxiv.org/pdf/1401.1026v1,math.ST
2014-01-03 17:44:06+00:00,Quantile Regression for Location-Scale Time Series Models with Conditional Heteroscedasticity,"['Jungsik Noh', 'Sangyeol Lee']","This paper considers quantile regression for a wide class of time series
models including ARMA models with asymmetric GARCH (AGARCH) errors. The
classical mean-variance models are reinterpreted as conditional location-scale
models so that the quantile regression method can be naturally geared into the
considered models. The consistency and asymptotic normality of the quantile
regression estimator is established in location-scale time series models under
mild conditions. In the application of this result to ARMA-AGARCH models, more
primitive conditions are deduced to obtain the asymptotic properties. For
illustration, a simulation study and a real data analysis are provided.",http://arxiv.org/pdf/1401.0688v2,stat.ME
2013-12-28 00:14:28+00:00,On the Identifiability Conditions in Some Nonlinear Time Series Models,"['Jungsik Noh', 'Sangyeol Lee']","In this study, we consider the identifiability problem for nonlinear time
series models. Special attention is paid to smooth transition GARCH, nonlinear
Poisson autoregressive, and multiple regime smooth transition autoregressive
models. Some sufficient conditions are obtained to establish the
identifiability of these models.",http://arxiv.org/pdf/1312.7375v2,math.ST
2013-12-25 21:25:41+00:00,Model-based clustering with Hidden Markov Model regression for time series with regime changes,"['Faicel Chamroukhi', 'Allou Samé', 'Patrice Aknin', 'Gérard Govaert']","This paper introduces a novel model-based clustering approach for clustering
time series which present changes in regime. It consists of a mixture of
polynomial regressions governed by hidden Markov chains. The underlying hidden
process for each cluster activates successively several polynomial regimes
during time. The parameter estimation is performed by the maximum likelihood
method through a dedicated Expectation-Maximization (EM) algorithm. The
proposed approach is evaluated using simulated time series and real-world time
series issued from a railway diagnosis application. Comparisons with existing
approaches for time series clustering, including the stand EM for Gaussian
mixtures, $K$-means clustering, the standard mixture of regression models and
mixture of Hidden Markov Models, demonstrate the effectiveness of the proposed
approach.",http://arxiv.org/pdf/1312.7024v1,stat.ML
2013-12-25 13:13:55+00:00,Time series modeling by a regression approach based on a latent process,"['Faicel Chamroukhi', 'Allou Samé', 'Gérard Govaert', 'Patrice Aknin']","Time series are used in many domains including finance, engineering,
economics and bioinformatics generally to represent the change of a measurement
over time. Modeling techniques may then be used to give a synthetic
representation of such data. A new approach for time series modeling is
proposed in this paper. It consists of a regression model incorporating a
discrete hidden logistic process allowing for activating smoothly or abruptly
different polynomial regression models. The model parameters are estimated by
the maximum likelihood method performed by a dedicated Expectation Maximization
(EM) algorithm. The M step of the EM algorithm uses a multi-class Iterative
Reweighted Least-Squares (IRLS) algorithm to estimate the hidden process
parameters. To evaluate the proposed approach, an experimental study on
simulated data and real world data was performed using two alternative
approaches: a heteroskedastic piecewise regression model using a global
optimization algorithm based on dynamic programming, and a Hidden Markov
Regression Model whose parameters are estimated by the Baum-Welch algorithm.
Finally, in the context of the remote monitoring of components of the French
railway infrastructure, and more particularly the switch mechanism, the
proposed approach has been applied to modeling and classifying time series
representing the condition measurements acquired during switch operations.",http://arxiv.org/pdf/1312.6969v1,stat.ME
2013-12-25 13:11:04+00:00,Model-based clustering and segmentation of time series with changes in regime,"['Allou Samé', 'Faicel Chamroukhi', 'Gérard Govaert', 'Patrice Aknin']","Mixture model-based clustering, usually applied to multidimensional data, has
become a popular approach in many data analysis problems, both for its good
statistical properties and for the simplicity of implementation of the
Expectation-Maximization (EM) algorithm. Within the context of a railway
application, this paper introduces a novel mixture model for dealing with time
series that are subject to changes in regime. The proposed approach consists in
modeling each cluster by a regression model in which the polynomial
coefficients vary according to a discrete hidden process. In particular, this
approach makes use of logistic functions to model the (smooth or abrupt)
transitions between regimes. The model parameters are estimated by the maximum
likelihood method solved by an Expectation-Maximization algorithm. The proposed
approach can also be regarded as a clustering approach which operates by
finding groups of time series having common changes in regime. In addition to
providing a time series partition, it therefore provides a time series
segmentation. The problem of selecting the optimal numbers of clusters and
segments is solved by means of the Bayesian Information Criterion (BIC). The
proposed approach is shown to be efficient using a variety of simulated time
series and real-world time series of electrical power consumption from rail
switching operations.",http://arxiv.org/pdf/1312.6967v1,stat.ME
2013-12-23 22:15:59+00:00,Invariant Factorization Of Time-Series,"['Josif Grabocka', 'Lars Schmidt-Thieme']","Time-series classification is an important domain of machine learning and a
plethora of methods have been developed for the task. In comparison to existing
approaches, this study presents a novel method which decomposes a time-series
dataset into latent patterns and membership weights of local segments to those
patterns. The process is formalized as a constrained objective function and a
tailored stochastic coordinate descent optimization is applied. The time-series
are projected to a new feature representation consisting of the sums of the
membership weights, which captures frequencies of local patterns. Features from
various sliding window sizes are concatenated in order to encapsulate the
interaction of patterns from different sizes. Finally, a large-scale
experimental comparison against 6 state of the art baselines and 43 real life
datasets is conducted. The proposed method outperforms all the baselines with
statistically significant margins in terms of prediction accuracy.",http://arxiv.org/pdf/1312.6712v1,cs.LG
2013-12-10 13:03:10+00:00,Long-range dependent time series specification,"['Jiti Gao', 'Qiying Wang', 'Jiying Yin']","In this paper we propose using a nonparametric model specification test for
parametric time series with long-range dependence (LRD). To establish
asymptotic distributions of the proposed test statistic, we develop new central
limit theorems for certain weighted quadratic forms of stationary time series
with LRD. To implement our proposed test in practice, we develop a
computer-intensive parametric bootstrap simulation procedure for finding
simulated critical values. As a result, our finite-sample studies demonstrate
that both the proposed theory and the simulation procedure work well, and that
the proposed test has little size distortion and reasonable power.",http://arxiv.org/pdf/1312.2788v1,math.ST
2013-11-22 17:43:41+00:00,The Splice Bootstrap,['Gerard Keogh'],"This paper proposes a new bootstrap method to compute predictive intervals
for nonlinear autoregressive time series model forecast. This method we call
the splice boobstrap as it involves splicing the last p values of a given
series to a suitably simulated series. This ensures that each simulated series
will have the same set of p time series values in common, a necessary
requirement for computing conditional predictive intervals. Using simulation
studies we show the methods gives 90% intervals intervals that are similar to
those expected from theory for simple linear and SETAR model driven by normal
and non-normal noise. Furthermore, we apply the method to some economic data
and demonstrate the intervals compare favourably with cross-validation based
intervals.",http://arxiv.org/pdf/1311.5828v1,stat.ME
2013-11-17 16:13:31+00:00,Regularized estimation in sparse high-dimensional time series models,"['Sumanta Basu', 'George Michailidis']","Many scientific and economic problems involve the analysis of
high-dimensional time series datasets. However, theoretical studies in
high-dimensional statistics to date rely primarily on the assumption of
independent and identically distributed (i.i.d.) samples. In this work, we
focus on stable Gaussian processes and investigate the theoretical properties
of $\ell _1$-regularized estimates in two important statistical problems in the
context of high-dimensional time series: (a) stochastic regression with
serially correlated errors and (b) transition matrix estimation in vector
autoregressive (VAR) models. We derive nonasymptotic upper bounds on the
estimation errors of the regularized estimates and establish that consistent
estimation under high-dimensional scaling is possible via
$\ell_1$-regularization for a large class of stable processes under sparsity
constraints. A key technical contribution of the work is to introduce a measure
of stability for stationary processes using their spectral properties that
provides insight into the effect of dependence on the accuracy of the
regularized estimates. With this proposed stability measure, we establish some
useful deviation bounds for dependent data, which can be used to study several
important regularized estimates in a time series setting.",http://arxiv.org/pdf/1311.4175v3,math.ST
2013-11-07 12:14:24+00:00,Constructing Time Series Shape Association Measures: Minkowski Distance and Data Standardization,['Ildar Batyrshin'],"It is surprising that last two decades many works in time series data mining
and clustering were concerned with measures of similarity of time series but
not with measures of association that can be used for measuring possible direct
and inverse relationships between time series. Inverse relationships can exist
between dynamics of prices and sell volumes, between growth patterns of
competitive companies, between well production data in oilfields, between wind
velocity and air pollution concentration etc. The paper develops a theoretical
basis for analysis and construction of time series shape association measures.
Starting from the axioms of time series shape association measures it studies
the methods of construction of measures satisfying these axioms. Several
general methods of construction of such measures suitable for measuring time
series shape similarity and shape association are proposed. Time series shape
association measures based on Minkowski distance and data standardization
methods are considered. The cosine similarity and the Pearsons correlation
coefficient are obtained as particular cases of the proposed general methods
that can be used also for construction of new association measures in data
analysis.",http://arxiv.org/pdf/1311.1958v3,cs.LG
2013-11-04 10:17:43+00:00,Real-time covariance estimation for the local level model,['K. Triantafyllopoulos'],"This paper develops on-line inference for the multivariate local level model,
with the focus being placed on covariance estimation of the innovations. We
assess the application of the inverse Wishart prior distribution in this
context and find it too restrictive since the serial correlation structure of
the observation and state innovations is forced to be the same. We generalize
the inverse Wishart distribution to allow for a more convenient correlation
structure, but still retaining approximate conjugacy. We prove some relevant
results for the new distribution and we develop approximate Bayesian inference,
which allows simultaneous forecasting of time series data and estimation of the
covariance of the innovations of the model. We provide results on the steady
state of the level of the time series, which are deployed to achieve
computational savings. Using Monte Carlo experiments, we compare the proposed
methodology with existing estimation procedures. An example with real data
consisting of production data from an industrial process is given.",http://arxiv.org/pdf/1311.0634v1,stat.ME
2013-11-01 06:21:28+00:00,A Bayesian framework for functional time series analysis,['Giovanni Petris'],"The paper introduces a general framework for statistical analysis of
functional time series from a Bayesian perspective. The proposed approach,
based on an extension of the popular dynamic linear model to Banach-space
valued observations and states, is very flexible but also easy to implement in
many cases. For many kinds of data, such as continuous functions, we show how
the general theory of stochastic processes provides a convenient tool to
specify priors and transition probabilities of the model. Finally, we show how
standard Markov chain Monte Carlo methods for posterior simulation can be
employed under consistent discretizations of the data.",http://arxiv.org/pdf/1311.0098v2,stat.ME
2013-10-18 21:34:01+00:00,On the graph-theoretical interpretation of Pearson correlations in a multivariate process and a novel partial correlation measure,['Jakob Runge'],"The dependencies of the lagged (Pearson) correlation function on the
coefficients of multivariate autoregressive models are interpreted in the
framework of time series graphs. Time series graphs are related to the concept
of Granger causality and encode the conditional independence structure of a
multivariate process. The authors show that the complex dependencies of the
Pearson correlation coefficient complicate an interpretation and propose a
novel partial correlation measure with a straightforward graph-theoretical
interpretation. The novel measure has the additional advantage that its
sampling distribution is not affected by serial dependencies like that of the
Pearson correlation coefficient. In an application to climatological time
series the potential of the novel measure is demonstrated.",http://arxiv.org/pdf/1310.5169v1,math.ST
2013-10-18 12:53:20+00:00,Mean-Based Error Measures for Intermittent Demand Forecasting,"['S. D. Prestwich', 'R. Rossi', 'S. A. Tarim', 'B. Hnich']","To compare different forecasting methods on demand series we require an error
measure. Many error measures have been proposed, but when demand is
intermittent some become inapplicable, some give counter-intuitive results, and
there is no agreement on which is best. We argue that almost all known measures
rank forecasters incorrectly on intermittent demand series. We propose several
new error measures with wider applicability, and correct forecaster ranking on
several intermittent demand patterns. We call these ""mean-based"" error measures
because they evaluate forecasts against the (possibly time-dependent) mean of
the underlying stochastic process instead of point demands.",http://arxiv.org/pdf/1310.5663v1,stat.ME
2013-10-08 02:59:08+00:00,"High dimensional stochastic regression with latent factors, endogeneity and nonlinearity","['Jinyuan Chang', 'Bin Guo', 'Qiwei Yao']","We consider a multivariate time series model which represents a high
dimensional vector process as a sum of three terms: a linear regression of some
observed regressors, a linear combination of some latent and serially
correlated factors, and a vector white noise. We investigate the inference
without imposing stationary conditions on the target multivariate time series,
the regressors and the underlying factors. Furthermore we deal with the
endogeneity that there exist correlations between the observed regressors and
the unobserved factors. We also consider the model with nonlinear regression
term which can be approximated by a linear regression function with a large
number of regressors. The convergence rates for the estimators of regression
coefficients, the number of factors, factor loading space and factors are
established under the settings when the dimension of time series and the number
of regressors may both tend to infinity together with the sample size. The
proposed method is illustrated with both simulated and real data examples.",http://arxiv.org/pdf/1310.1990v2,math.ST
2013-09-16 10:46:58+00:00,Multiple Hidden Markov Models for Categorical Time Series,"['Roberto Colombi', 'Sabrina Giordano']","We introduce multiple hidden Markov models (MHMMs) where an observed
multivariate categorical time series depends on an unobservable multivariate
Mar- kov chain. MHMMs provide an elegant framework for specifying various
independence relationships between multiple discrete time processes. These
independencies are interpreted as Markov properties of a mixed graph and a
chain graph associated to the latent and observable components of the MHMM,
respectively. These Markov properties are also translated into zero
restrictions on the parameters of marginal models for the transition
probabilities and the distributions of the observable variables given the
latent states.",http://arxiv.org/pdf/1309.3895v1,stat.ME
2013-09-13 18:31:02+00:00,Mixed Membership Models for Time Series,"['Emily B. Fox', 'Michael I. Jordan']","In this article we discuss some of the consequences of the mixed membership
perspective on time series analysis. In its most abstract form, a mixed
membership model aims to associate an individual entity with some set of
attributes based on a collection of observed data. Although much of the
literature on mixed membership models considers the setting in which
exchangeable collections of data are associated with each member of a set of
entities, it is equally natural to consider problems in which an entire time
series is viewed as an entity and the goal is to characterize the time series
in terms of a set of underlying dynamic attributes or ""dynamic regimes"".
Indeed, this perspective is already present in the classical hidden Markov
model, where the dynamic regimes are referred to as ""states"", and the
collection of states realized in a sample path of the underlying process can be
viewed as a mixed membership characterization of the observed time series. Our
goal here is to review some of the richer modeling possibilities for time
series that are provided by recent developments in the mixed membership
framework.",http://arxiv.org/pdf/1309.3533v1,stat.ME
2013-09-05 11:00:11+00:00,Detection of multiple structural breaks in multivariate time series,"['Philip Preuß', 'Ruprecht Puchstein', 'Holger Dette']","We propose a new nonparametric procedure for the detection and estimation of
multiple structural breaks in the autocovariance function of a multivariate
(second- order) piecewise stationary process, which also identifies the
components of the series where the breaks occur. The new method is based on a
comparison of the estimated spectral distribution on different segments of the
observed time series and consists of three steps: it starts with a consistent
test, which allows to prove the existence of structural breaks at a controlled
type I error. Secondly, it estimates sets containing possible break points and
finally these sets are reduced to identify the relevant structural breaks and
corresponding components which are responsible for the changes in the
autocovariance structure. In contrast to all other methods which have been
proposed in the literature, our approach does not make any parametric
assumptions, is not especially designed for detecting one single change point
and addresses the problem of multiple structural breaks in the autocovariance
function directly with no use of the binary segmentation algorithm. We prove
that the new procedure detects all components and the corresponding locations
where structural breaks occur with probability converging to one as the sample
size increases and provide data-driven rules for the selection of all
regularization parameters. The results are illustrated by analyzing financial
returns, and in a simulation study it is demonstrated that the new procedure
outperforms the currently available nonparametric methods for detecting breaks
in the dependency structure of multivariate time series.",http://arxiv.org/pdf/1309.1309v1,math.ST
2013-09-03 08:03:52+00:00,Segmentation procedure based on Fisher's exact test and its application to foreign exchange rates,"['Aki-Hiro Sato', 'Hideki Takayasu']","This study proposes the segmentation procedure of univariate time series
based on Fisher's exact test. We show that an adequate change point can be
detected as the minimum value of p-value. It is shown that the proposed
procedure can detect change points for an artificial time series. We apply the
proposed method to find segments of the foreign exchange rates recursively. It
is also applied to randomly shuffled time series. It concludes that the
randomly shuffled data can be used as a level to determine the null hypothesis.",http://arxiv.org/pdf/1309.0602v1,stat.ME
2013-08-19 13:47:25+00:00,Variations of singular spectrum analysis for separability improvement: non-orthogonal decompositions of time series,"['Nina Golyandina', 'Alex Shlemov']","Singular spectrum analysis (SSA) as a nonparametric tool for decomposition of
an observed time series into sum of interpretable components such as trend,
oscillations and noise is considered. The separability of these series
components by SSA means the possibility of such decomposition. Two variations
of SSA, which weaken the separability conditions, are proposed. Both proposed
approaches consider inner products corresponding to oblique coordinate systems
instead of the conventional Euclidean inner product. One of the approaches
performs iterations to obtain separating inner products. The other method
changes contributions of the components by involving the series derivative to
avoid component mixing. Performance of the suggested methods is demonstrated on
simulated and real-life data.",http://arxiv.org/pdf/1308.4022v2,stat.ME
2013-08-06 11:21:33+00:00,Asymptotic Distribution of the Delay Time in Page's Sequential Procedure,['Stefan Fremdt'],"In this paper the asymptotic distribution of the stopping time in Page's
sequential cumulative sum (CUSUM) procedure is presented. Page as well as
ordinary cumulative sums are considered as detectors for changes in the mean of
observations satisfying a weak invariance principle. The main results on the
stopping times derived from these detectors extend a series of results on the
asymptotic normality of stopping times of CUSUM-type procedures. In particular
the results quantify the superiority of the Page CUSUM procedure to ordinary
CUSUM procedures in late change scenarios. The theoretical results are
illustrated by a small simulation study, including a comparison of the
performance of ordinary and Page CUSUM detectors.",http://arxiv.org/pdf/1308.1241v1,stat.ME
2013-08-06 11:08:40+00:00,Page's Sequential Procedure for Change-Point Detection in Time Series Regression,['Stefan Fremdt'],"In a variety of different settings cumulative sum (CUSUM) procedures have
been applied for the sequential detection of structural breaks in the
parameters of stochastic models. Yet their performance depends strongly on the
time of change and is best under early-change scenarios. For later changes
their finite sample behavior is rather questionable. We therefore propose
modified CUSUM procedures for the detection of abrupt changes in the regression
parameter of multiple time series regression models, that show a higher
stability with respect to the time of change than ordinary CUSUM procedures.
The asymptotic distributions of the test statistics and the consistency of the
procedures are provided. In a simulation study it is shown that the proposed
procedures behave well in finite samples. Finally the procedures are applied to
a set of capital asset pricing data related to the Fama-French extension of the
capital asset pricing model.",http://arxiv.org/pdf/1308.1237v1,stat.ME
2013-08-03 00:04:00+00:00,"Nonlinear Time Series Modeling: A Unified Perspective, Algorithm, and Application","['Subhadeep Mukhopadhyay', 'Emanuel Parzen']","A new comprehensive approach to nonlinear time series analysis and modeling
is developed in the present paper. We introduce novel data-specific
mid-distribution based Legendre Polynomial (LP) like nonlinear transformations
of the original time series Y(t) that enables us to adapt all the existing
stationary linear Gaussian time series modeling strategy and made it applicable
for non-Gaussian and nonlinear processes in a robust fashion. The emphasis of
the present paper is on empirical time series modeling via the algorithm
LPTime. We demonstrate the effectiveness of our theoretical framework using
daily S&P 500 return data between Jan/2/1963 - Dec/31/2009. Our proposed LPTime
algorithm systematically discovers all the `stylized facts' of the financial
time series automatically all at once, which were previously noted by many
researchers one at a time.",http://arxiv.org/pdf/1308.0642v4,math.ST
2013-07-05 00:37:52+00:00,Heavy tailed time series with extremal independence,"['Rafal Kulik', 'Philippe Soulier']","We consider strictly stationary heavy tailed time series whose
finite-dimensional exponent measures are concentrated on axes, and hence their
extremal properties cannot be tackled using classical multivariate regular
variation that is suitable for time series with extremal dependence. We recover
relevant information about limiting behavior of time series with extremal
independence by introducing a sequence of scaling functions and conditional
scaling exponent. Both quantities provide more information about joint extremes
than a widely used tail dependence coefficient. We calculate the scaling
functions and the scaling exponent for variety of models, including Markov
chains, exponential autoregressive model, stochastic volatility with heavy
tailed innovations or volatility.",http://arxiv.org/pdf/1307.1501v2,math.ST
2013-07-01 14:14:55+00:00,Gaussian Process Conditional Copulas with Applications to Financial Time Series,"['José Miguel Hernández-Lobato', 'James Robert Lloyd', 'Daniel Hernández-Lobato']","The estimation of dependencies between multiple variables is a central
problem in the analysis of financial time series. A common approach is to
express these dependencies in terms of a copula function. Typically the copula
function is assumed to be constant but this may be inaccurate when there are
covariates that could have a large influence on the dependence structure of the
data. To account for this, a Bayesian framework for the estimation of
conditional copulas is proposed. In this framework the parameters of a copula
are non-linearly related to some arbitrary conditioning variables. We evaluate
the ability of our method to predict time-varying dependencies on several
equities and currencies and observe consistent performance gains compared to
static copula models and other time-varying copula methods.",http://arxiv.org/pdf/1307.0373v1,stat.ML
2013-06-30 00:40:09+00:00,Sparse Principal Component Analysis for High Dimensional Vector Autoregressive Models,"['Zhaoran Wang', 'Fang Han', 'Han Liu']","We study sparse principal component analysis for high dimensional vector
autoregressive time series under a doubly asymptotic framework, which allows
the dimension $d$ to scale with the series length $T$. We treat the transition
matrix of time series as a nuisance parameter and directly apply sparse
principal component analysis on multivariate time series as if the data are
independent. We provide explicit non-asymptotic rates of convergence for
leading eigenvector estimation and extend this result to principal subspace
estimation. Our analysis illustrates that the spectral norm of the transition
matrix plays an essential role in determining the final rates. We also
characterize sufficient conditions under which sparse principal component
analysis attains the optimal parametric rate. Our theoretical results are
backed up by thorough numerical studies.",http://arxiv.org/pdf/1307.0164v1,stat.ML
2013-06-20 00:39:14+00:00,A Bayesian changepoint methodology for high dimensional multivariate time series and space-time data: A study of structural change using remotely sensed data,"['Chris Strickland', 'Robert Burdett', 'Robert Denham', 'Robert Kohn', 'Kerrie Mengersen']","A Bayesian approach is developed to analyze change points in multivariate
time series and space-time data. The methodology is used to assess the impact
of extended inundation on the ecosystem of the Gulf Plains bioregion in
northern Australia. The proposed approach can be implemented for dynamic
mixture models that have a conditionally Gaussian state space representation.
Details are given on how to efficiently implement the algorithm for a general
class of multivariate time series and space-time models. This efficient
implementation makes it feasible to analyze high dimensional, but of realistic
size, space-time data sets because our approach can be appreciably faster,
possibly millions of times, than a standard implementation in such cases.",http://arxiv.org/pdf/1306.4723v1,stat.ME
2013-06-14 06:19:28+00:00,Aggregation and long memory: recent developments,"['Remigijus Leipus', 'Anne Philippe', 'Donata Puplinskaite', 'Donatas Surgailis']","It is well-known that the aggregated time series might have very different
properties from those of the individual series, in particular, long memory. At
the present time, aggregation has become one of the main tools for modelling of
long memory processes. We review recent work on contemporaneous aggregation of
random-coefficient AR(1) and related models, with particular focus on various
long memory properties of the aggregated process.",http://arxiv.org/pdf/1306.3301v1,math.ST
2013-06-03 08:42:53+00:00,Online Tracking of a Predictable Drifting Parameter of a Time Series,"['Eduard Belitser', 'Paulo Serra']","We propose an online algorithm for tracking a multidimensional time-varying
parameter of a time series, which is also allowed to be a predictable process
with respect to the underlying time series. The algorithm is driven by a gain
function. Under assumptions on the gain, we derive uniform non-asymptotic error
bounds on the tracking algorithm in terms of chosen step size for the algorithm
and the variation of the parameter of interest. We also outline how appropriate
gain functions can be constructed. We give several examples of different
variational setups for the parameter process where our result can be applied.
The proposed approach covers many frameworks and models (including the
classical Robbins-Monro and Kiefer-Wolfowitz procedures) where stochastic
approximation algorithms comprise the main inference tool for the data
analysis. We treat in some detail a couple of specific models.",http://arxiv.org/pdf/1306.0325v2,math.ST
2013-05-12 22:00:09+00:00,Identifying Pairs in Simulated Bio-Medical Time-Series,['Uri Kartoun'],"The paper presents a time-series-based classification approach to identify
similarities in pairs of simulated human-generated patterns. An example for a
pattern is a time-series representing a heart rate during a specific
time-range, wherein the time-series is a sequence of data points that represent
the changes in the heart rate values. A bio-medical simulator system was
developed to acquire a collection of 7,871 price patterns of financial
instruments. The financial instruments traded in real-time on three American
stock exchanges, NASDAQ, NYSE, and AMEX, simulate bio-medical measurements. The
system simulates a human in which each price pattern represents one bio-medical
sensor. Data provided during trading hours from the stock exchanges allowed
real-time classification. Classification is based on new machine learning
techniques: self-labeling, which allows the application of supervised learning
methods on unlabeled time-series and similarity ranking, which applied on a
decision tree learning algorithm to classify time-series regardless of type and
quantity.",http://arxiv.org/pdf/1306.0541v1,cs.LG
2013-04-17 13:06:59+00:00,Unsupervised model-free representation learning,['Daniil Ryabko'],"Numerous control and learning problems face the situation where sequences of
high-dimensional highly dependent data are available but no or little feedback
is provided to the learner, which makes any inference rather challenging. To
address this challenge, we formulate the following problem. Given a series of
observations $X_0,\dots,X_n$ coming from a large (high-dimensional) space
$\mathcal X$, find a representation function $f$ mapping $\mathcal X$ to a
finite space $\mathcal Y$ such that the series $f(X_0),\dots,f(X_n)$ preserves
as much information as possible about the original time-series dependence in
$X_0,\dots,X_n$. We show that, for stationary time series, the function $f$ can
be selected as the one maximizing a certain information criterion that we call
time-series information. Some properties of this functions are investigated,
including its uniqueness and consistency of its empirical estimates.
  Implications for the problem of optimal control are presented.",http://arxiv.org/pdf/1304.4806v4,cs.LG
2013-03-26 12:35:45+00:00,Partial Transfer Entropy on Rank Vectors,['Dimitris Kugiumtzis'],"For the evaluation of information flow in bivariate time series, information
measures have been employed, such as the transfer entropy (TE), the symbolic
transfer entropy (STE), defined similarly to TE but on the ranks of the
components of the reconstructed vectors, and the transfer entropy on rank
vectors (TERV), similar to STE but forming the ranks for the future samples of
the response system with regard to the current reconstructed vector. Here we
extend TERV for multivariate time series, and account for the presence of
confounding variables, called partial transfer entropy on ranks (PTERV). We
investigate the asymptotic properties of PTERV, and also partial STE (PSTE),
construct parametric significance tests under approximations with Gaussian and
gamma null distributions, and show that the parametric tests cannot achieve the
power of the randomization test using time-shifted surrogates. Using
simulations on known coupled dynamical systems and applying parametric and
randomization significance tests, we show that PTERV performs better than PSTE
but worse than the partial transfer entropy (PTE). However, PTERV, unlike PTE,
is robust to the presence of drifts in the time series and it is also not
affected by the level of detrending.",http://arxiv.org/pdf/1303.6454v1,stat.ME
2013-03-25 23:31:45+00:00,Measures of serial extremal dependence and their estimation,"['Richard A. Davis', 'Thomas Mikosch', 'Yuwei Zhao']","The goal of this paper is two-fold: 1. We review classical and recent
measures of serial extremal dependence in a strictly stationary time series as
well as their estimation. 2. We discuss recent concepts of heavy-tailed time
series, including regular variation and max-stable processes. Serial extremal
dependence is typically characterized by clusters of exceedances of high
thresholds in the series. We start by discussing the notion of extremal index
of a univariate sequence, i.e. the reciprocal of the expected cluster size,
which has attracted major attention in the extremal value literature. Then we
continue by introducing the extremogram which is an asymptotic auto-correlation
function for sequences of extremal events in a time series. In this context, we
discuss regular variation of a time series. This notion has been useful for
describing serial extremal dependence and heavy tails in a strictly stationary
sequence. We briefly discuss the tail process coined by Basrak and Segers to
describe the dependence structure of regularly varying sequences in a
probabilistic way. Max-stable processes with Frechet marginals are an important
class of reg- ularly varying sequences. Recently, this class has attracted
attention for modeling and statistical purposes. We apply the extremogram to
max-stable processes. Finally, we discuss estimation of the extremogram both in
the time and frequency domains.",http://arxiv.org/pdf/1303.6349v1,math.ST
2013-03-25 10:17:41+00:00,"A Robust Bayesian Dynamic Linear Model for Latin-American Economic Time Series: ""The Mexico and Puerto Rico Cases""","['Jairo Fuquene', 'Marta Alvarez', 'Luis Pericchi']","The traditional time series methodology requires at least a preliminary
transformation of the data to get stationarity. On the other hand, Robust
Bayesian Dynamic Models (RBDMs) do not assume a regular pattern or stability of
the underlying system but can include points of statement breaks. In this paper
we use RBDMs in order to account possible outliers and structural breaks in
Latin-American economic time series. We work with important economic time
series from Puerto Rico and Mexico. We show by using a random walk model how
RBDMs can be applied for detecting historic changes in the economic inflation
of Mexico. Also, we model the Consumer Price Index (CPI), the Economic Activity
Index (EAI) and the total number of employments (TNE) economic time series in
Puerto Rico using local linear trend and seasonal RBDMs with observational and
states variances. The results illustrate how the model accounts the structural
breaks for the historic recession periods in Puerto Rico.",http://arxiv.org/pdf/1303.6073v2,stat.ME
2013-03-03 00:16:44+00:00,On Bayesian Nonparametric Continuous Time Series Models,"['George Karabatsos', 'Stephen G. Walker']","This paper is a note on the use of Bayesian nonparametric mixture models for
continuous time series. We identify a key requirement for such models, and then
establish that there is a single type of model which meets this requirement. As
it turns out, the model is well known in multiple change-point problems.",http://arxiv.org/pdf/1303.0439v1,stat.ME
2013-03-01 03:45:42+00:00,Inverse Signal Classification for Financial Instruments,['Uri Kartoun'],"The paper presents new machine learning methods: signal composition, which
classifies time-series regardless of length, type, and quantity; and
self-labeling, a supervised-learning enhancement. The paper describes further
the implementation of the methods on a financial search engine system using a
collection of 7,881 financial instruments traded during 2011 to identify
inverse behavior among the time-series.",http://arxiv.org/pdf/1303.0283v2,cs.LG
2013-02-27 17:14:14+00:00,Online Learning for Time Series Prediction,"['Oren Anava', 'Elad Hazan', 'Shie Mannor', 'Ohad Shamir']","In this paper we address the problem of predicting a time series using the
ARMA (autoregressive moving average) model, under minimal assumptions on the
noise terms. Using regret minimization techniques, we develop effective online
learning algorithms for the prediction problem, without assuming that the noise
terms are Gaussian, identically distributed or even independent. Furthermore,
we show that our algorithm's performances asymptotically approaches the
performance of the best ARMA model in hindsight.",http://arxiv.org/pdf/1302.6927v1,cs.LG
2013-02-26 22:18:55+00:00,An Introductory Study on Time Series Modeling and Forecasting,"['Ratnadip Adhikari', 'R. K. Agrawal']","Time series modeling and forecasting has fundamental importance to various
practical domains. Thus a lot of active research works is going on in this
subject during several years. Many important models have been proposed in
literature for improving the accuracy and effectiveness of time series
forecasting. The aim of this dissertation work is to present a concise
description of some popular time series forecasting models used in practice,
with their salient features. In this thesis, we have described three important
classes of time series models, viz. the stochastic, neural networks and SVM
based models, together with their inherent forecasting strengths and
weaknesses. We have also discussed about the basic issues related to time
series modeling, such as stationarity, parsimony, overfitting, etc. Our
discussion about different time series models is supported by giving the
experimental forecast results, performed on six real time series datasets.
While fitting a model to a dataset, special care is taken to select the most
parsimonious one. To evaluate forecast accuracy as well as to compare among
different models fitted to a time series, we have used the five performance
measures, viz. MSE, MAD, RMSE, MAPE and Theil's U-statistics. For each of the
six datasets, we have shown the obtained forecast diagram which graphically
depicts the closeness between the original and forecasted observations. To have
authenticity as well as clarity in our discussion about time series modeling
and forecasting, we have taken the help of various published research works
from reputed journals and some standard books.",http://arxiv.org/pdf/1302.6613v1,cs.LG
2013-02-22 21:20:22+00:00,Bayes linear variance structure learning for inspection of large scale physical systems,"['David Randell', 'Michael Goldstein', 'Philip Jonathan']","Modelling of inspection data for large scale physical systems is critical to
assessment of their integrity. We present a general method for inference about
system state and associated model variance structure from spatially distributed
time series which are typically short, irregular, incomplete and not directly
observable. Bayes linear analysis simplifies parameter estimation and avoids
often-unrealistic distributional assumptions. Second-order exchangeability
judgements facilitate variance learning for sparse inspection time-series. The
model is applied to inspection data for minimum wall thickness from corroding
pipe-work networks on a full-scale offshore platform, and shown to give
materially different forecasts of remnant life compared to an equivalent model
neglecting variance learning.",http://arxiv.org/pdf/1302.5714v1,stat.ME
2013-02-18 09:37:56+00:00,Nonparametric regression for locally stationary time series,['Michael Vogt'],"In this paper, we study nonparametric models allowing for locally stationary
regressors and a regression function that changes smoothly over time. These
models are a natural extension of time series models with time-varying
coefficients. We introduce a kernel-based method to estimate the time-varying
regression function and provide asymptotic theory for our estimates. Moreover,
we show that the main conditions of the theory are satisfied for a large class
of nonlinear autoregressive processes with a time-varying regression function.
Finally, we examine structured models where the regression function splits up
into time-varying additive components. As will be seen, estimation in these
models does not suffer from the curse of dimensionality.",http://arxiv.org/pdf/1302.4198v1,math.ST
2013-02-14 22:12:40+00:00,A Latent Source Model for Nonparametric Time Series Classification,"['George H. Chen', 'Stanislav Nikolov', 'Devavrat Shah']","For classifying time series, a nearest-neighbor approach is widely used in
practice with performance often competitive with or better than more elaborate
methods such as neural networks, decision trees, and support vector machines.
We develop theoretical justification for the effectiveness of
nearest-neighbor-like classification of time series. Our guiding hypothesis is
that in many applications, such as forecasting which topics will become trends
on Twitter, there aren't actually that many prototypical time series to begin
with, relative to the number of time series we have access to, e.g., topics
become trends on Twitter only in a few distinct manners whereas we can collect
massive amounts of Twitter data. To operationalize this hypothesis, we propose
a latent source model for time series, which naturally leads to a ""weighted
majority voting"" classification rule that can be approximated by a
nearest-neighbor classifier. We establish nonasymptotic performance guarantees
of both weighted majority voting and nearest-neighbor classification under our
model accounting for how much of the time series we observe and the model
complexity. Experimental results on synthetic data show weighted majority
voting achieving the same misclassification rate as nearest-neighbor
classification while observing less of the time series. We then use weighted
majority to forecast which news topics on Twitter become trends, where we are
able to detect such ""trending topics"" in advance of Twitter 79% of the time,
with a mean early advantage of 1 hour and 26 minutes, a true positive rate of
95%, and a false positive rate of 4%.",http://arxiv.org/pdf/1302.3639v5,stat.ML
2013-02-09 22:56:45+00:00,A Time Series Forest for Classification and Feature Extraction,"['Houtao Deng', 'George Runger', 'Eugene Tuv', 'Martyanov Vladimir']","We propose a tree ensemble method, referred to as time series forest (TSF),
for time series classification. TSF employs a combination of the entropy gain
and a distance measure, referred to as the Entrance (entropy and distance)
gain, for evaluating the splits. Experimental studies show that the Entrance
gain criterion improves the accuracy of TSF. TSF randomly samples features at
each tree node and has a computational complexity linear in the length of a
time series and can be built using parallel computing techniques such as
multi-core computing used here. The temporal importance curve is also proposed
to capture the important temporal characteristics useful for classification.
Experimental studies show that TSF using simple features such as mean,
deviation and slope outperforms strong competitors such as one-nearest-neighbor
classifiers with dynamic time warping, is computationally efficient, and can
provide insights into the temporal characteristics.",http://arxiv.org/pdf/1302.2277v2,cs.LG
2012-12-12 11:54:11+00:00,Clustering of functional boxplots for multiple streaming time series,"['Elvira Romano', 'Antonio Balzanella']","In this paper we introduce a micro-clustering strategy for Functional
Boxplots. The aim is to summarize a set of streaming time series splitted in
non overlapping windows. It is a two step strategy which performs at first, an
on-line summarization by means of functional data structures, named Functional
Boxplot micro-clusters; then it reveals the final summarization by processing,
off-line, the functional data structures. Our main contribute consists in
providing a new definition of micro-cluster based on Functional Boxplots and,
in defining a proximity measure which allows to compare and update them. This
allows to get a finer graphical summarization of the streaming time series by
five functional basic statistics of data. The obtained synthesis will be able
to keep track of the dynamic evolution of the multiple streams.",http://arxiv.org/pdf/1212.2784v1,stat.ME
2012-12-11 00:49:27+00:00,Bag-of-Words Representation for Biomedical Time Series Classification,"['Jin Wang', 'Ping Liu', 'Mary F. H. She', 'Saeid Nahavandi', 'and Abbas Kouzani']","Automatic analysis of biomedical time series such as electroencephalogram
(EEG) and electrocardiographic (ECG) signals has attracted great interest in
the community of biomedical engineering due to its important applications in
medicine. In this work, a simple yet effective bag-of-words representation that
is able to capture both local and global structure similarity information is
proposed for biomedical time series representation. In particular, similar to
the bag-of-words model used in text document domain, the proposed method treats
a time series as a text document and extracts local segments from the time
series as words. The biomedical time series is then represented as a histogram
of codewords, each entry of which is the count of a codeword appeared in the
time series. Although the temporal order of the local segments is ignored, the
bag-of-words representation is able to capture high-level structural
information because both local and global structural information are well
utilized. The performance of the bag-of-words model is validated on three
datasets extracted from real EEG and ECG signals. The experimental results
demonstrate that the proposed method is not only insensitive to parameters of
the bag-of-words model such as local segment length and codebook size, but also
robust to noise.",http://arxiv.org/pdf/1212.2262v1,cs.LG
2012-11-23 14:22:35+00:00,Inference of seasonal long-memory aggregate time series,"['Kung-Sik Chan', 'Henghsiu Tsai']","Time-series data with regular and/or seasonal long-memory are often
aggregated before analysis. Often, the aggregation scale is large enough to
remove any short-memory components of the underlying process but too short to
eliminate seasonal patterns of much longer periods. In this paper, we
investigate the limiting correlation structure of aggregate time series within
an intermediate asymptotic framework that attempts to capture the
aforementioned sampling scheme. In particular, we study the autocorrelation
structure and the spectral density function of aggregates from a discrete-time
process. The underlying discrete-time process is assumed to be a stationary
Seasonal AutoRegressive Fractionally Integrated Moving-Average (SARFIMA)
process, after suitable number of differencing if necessary, and the seasonal
periods of the underlying process are multiples of the aggregation size. We
derive the limit of the normalized spectral density function of the aggregates,
with increasing aggregation. The limiting aggregate (seasonal) long-memory
model may then be useful for analyzing aggregate time-series data, which can be
estimated by maximizing the Whittle likelihood. We prove that the maximum
Whittle likelihood estimator (spectral maximum likelihood estimator) is
consistent and asymptotically normal, and study its finite-sample properties
through simulation. The efficacy of the proposed approach is illustrated by a
real-life internet traffic example.",http://arxiv.org/pdf/1211.5513v1,math.ST
2012-11-20 13:05:08+00:00,TFT-bootstrap: Resampling time series in the frequency domain to obtain replicates in the time domain,"['Claudia Kirch', 'Dimitris N. Politis']","A new time series bootstrap scheme, the time frequency toggle
(TFT)-bootstrap, is proposed. Its basic idea is to bootstrap the Fourier
coefficients of the observed time series, and then to back-transform them to
obtain a bootstrap sample in the time domain. Related previous proposals, such
as the ""surrogate data"" approach, resampled only the phase of the Fourier
coefficients and thus had only limited validity. By contrast, we show that the
appropriate resampling of phase and magnitude, in addition to some smoothing of
Fourier coefficients, yields a bootstrap scheme that mimics the correct
second-order moment structure for a large class of time series processes. As a
main result we obtain a functional limit theorem for the TFT-bootstrap under a
variety of popular ways of frequency domain bootstrapping. Possible
applications of the TFT-bootstrap naturally arise in change-point analysis and
unit-root testing where statistics are frequently based on functionals of
partial sums. Finally, a small simulation study explores the potential of the
TFT-bootstrap for small samples showing that for the discussed tests in
change-point analysis as well as unit-root testing, it yields better results
than the corresponding asymptotic tests if measured by size and power.",http://arxiv.org/pdf/1211.4732v1,math.ST
2012-11-13 14:54:47+00:00,Time-series Scenario Forecasting,['Sriharsha Veeramachaneni'],"Many applications require the ability to judge uncertainty of time-series
forecasts. Uncertainty is often specified as point-wise error bars around a
mean or median forecast. Due to temporal dependencies, such a method obscures
some information. We would ideally have a way to query the posterior
probability of the entire time-series given the predictive variables, or at a
minimum, be able to draw samples from this distribution. We use a Bayesian
dictionary learning algorithm to statistically generate an ensemble of
forecasts. We show that the algorithm performs as well as a physics-based
ensemble method for temperature forecasts for Houston. We conclude that the
method shows promise for scenario forecasting where physics-based methods are
absent.",http://arxiv.org/pdf/1211.3010v1,stat.ML
2012-11-12 07:01:00+00:00,Identifying the finite dimensionality of curve time series,"['Neil Bathia', 'Qiwei Yao', 'Flavio Ziegelmann']","The curve time series framework provides a convenient vehicle to accommodate
some nonstationary features into a stationary setup. We propose a new method to
identify the dimensionality of curve time series based on the dynamical
dependence across different curves. The practical implementation of our method
boils down to an eigenanalysis of a finite-dimensional matrix. Furthermore, the
determination of the dimensionality is equivalent to the identification of the
nonzero eigenvalues of the matrix, which we carry out in terms of some
bootstrap tests. Asymptotic properties of the proposed method are investigated.
In particular, our estimators for zero-eigenvalues enjoy the fast convergence
rate n while the estimators for nonzero eigenvalues converge at the standard
$\sqrt{n}$-rate. The proposed methodology is illustrated with both simulated
and real data sets.",http://arxiv.org/pdf/1211.2522v1,math.ST
2012-11-08 13:39:25+00:00,Prediction of time series by statistical learning: general losses and fast rates,"['Pierre Alquier', 'Xiaoyin Li', 'Olivier Wintenberger']","We establish rates of convergences in time series forecasting using the
statistical learning approach based on oracle inequalities. A series of papers
extends the oracle inequalities obtained for iid observations to time series
under weak dependence conditions. Given a family of predictors and $n$
observations, oracle inequalities state that a predictor forecasts the series
as well as the best predictor in the family up to a remainder term $\Delta_n$.
Using the PAC-Bayesian approach, we establish under weak dependence conditions
oracle inequalities with optimal rates of convergence. We extend previous
results for the absolute loss function to any Lipschitz loss function with
rates $\Delta_n\sim\sqrt{c(\Theta)/ n}$ where $c(\Theta)$ measures the
complexity of the model. We apply the method for quantile loss functions to
forecast the french GDP. Under additional conditions on the loss functions
(satisfied by the quadratic loss function) and on the time series, we refine
the rates of convergence to $\Delta_n \sim c(\Theta)/n$. We achieve for the
first time these fast rates for uniformly mixing processes. These rates are
known to be optimal in the iid case and for individual sequences. In
particular, we generalize the results of Dalalyan and Tsybakov on sparse
regression estimation to the case of autoregression.",http://arxiv.org/pdf/1211.1847v1,math.ST
2012-10-31 18:24:10+00:00,Anomaly Detection in Time Series of Graphs using Fusion of Graph Invariants,"['Youngser Park', 'Carey E. Priebe', 'Abdou Youssef']","Given a time series of graphs G(t) = (V, E(t)), t = 1, 2, ..., where the
fixed vertex set V represents ""actors"" and an edge between vertex u and vertex
v at time t (uv \in E(t)) represents the existence of a communications event
between actors u and v during the tth time period, we wish to detect anomalies
and/or change points. We consider a collection of graph features, or
invariants, and demonstrate that adaptive fusion provides superior inferential
efficacy compared to naive equal weighting for a certain class of anomaly
detection problems. Simulation results using a latent process model for time
series of graphs, as well as illustrative experimental results for a time
series of graphs derived from the Enron email data, show that a fusion
statistic can provide superior inference compared to individual invariants
alone. These results also demonstrate that an adaptive weighting scheme for
fusion of invariants performs better than naive equal weighting.",http://arxiv.org/pdf/1210.8429v1,stat.ML
2012-10-26 16:57:25+00:00,Dynamic Functional Principal Component,"['Siegfried Hörmann', 'Łukasz Kidziński', 'Marc Hallin']","In this paper, we address the problem of dimension reduction for time series
of functional data $(X_t\colon t\in\mathbb{Z})$. Such {\it functional time
series} frequently arise, e.g., when a continuous-time process is segmented
into some smaller natural units, such as days. Then each~$X_t$ represents one
intraday curve. We argue that functional principal component analysis (FPCA),
though a key technique in the field and a benchmark for any competitor, does
not provide an adequate dimension reduction in a time-series setting. FPCA
indeed is a {\it static} procedure which ignores the essential information
provided by the serial dependence structure of the functional data under study.
Therefore, inspired by Brillinger's theory of {\it dynamic principal
components}, we propose a {\it dynamic} version of FPCA, which is based on a
frequency-domain approach. By means of a simulation study and an empirical
illustration, we show the considerable improvement the dynamic approach entails
when compared to the usual static procedure.",http://arxiv.org/pdf/1210.7192v5,math.ST
2012-10-22 19:02:21+00:00,Reducing statistical time-series problems to binary classification,"['Daniil Ryabko', 'Jérémie Mary']","We show how binary classification methods developed to work on i.i.d. data
can be used for solving statistical problems that are seemingly unrelated to
classification and concern highly-dependent time series. Specifically, the
problems of time-series clustering, homogeneity testing and the three-sample
problem are addressed. The algorithms that we construct for solving these
problems are based on a new metric between time-series distributions, which can
be evaluated using binary classification methods. Universal consistency of the
proposed algorithms is proven under most general assumptions. The theoretical
results are illustrated with experiments on synthetic and real-world data.",http://arxiv.org/pdf/1210.6001v3,cs.LG
2012-10-17 13:41:51+00:00,Ergodicity of observation-driven time series models and consistency of the maximum likelihood estimator,"['Randal Douc', 'Paul Doukhan', 'Eric Moulines']","This paper deals with a general class of observation-driven time series
models with a special focus on time series of counts. We provide conditions
under which there exist strict-sense stationary and ergodic versions of such
processes. The consistency of the maximum likelihood estimators is then derived
for well- specified and misspecified models.",http://arxiv.org/pdf/1210.4739v2,math.ST
2012-10-16 17:51:29+00:00,Detecting Change-Points in Time Series by Maximum Mean Discrepancy of Ordinal Pattern Distributions,"['Mathieu Sinn', 'Ali Ghodsi', 'Karsten Keller']","As a new method for detecting change-points in high-resolution time series,
we apply Maximum Mean Discrepancy to the distributions of ordinal patterns in
different parts of a time series. The main advantage of this approach is its
computational simplicity and robustness with respect to (non-linear) monotonic
transformations, which makes it particularly well-suited for the analysis of
long biophysical time series where the exact calibration of measurement devices
is unknown or varies with time. We establish consistency of the method and
evaluate its performance in simulation studies. Furthermore, we demonstrate the
application to the analysis of electroencephalography (EEG) and
electrocardiography (ECG) recordings.",http://arxiv.org/pdf/1210.4903v1,stat.ME
2012-10-09 06:36:09+00:00,Gaussian process modelling of multiple short time series,"['Hande Topa', 'Antti Honkela']","We present techniques for effective Gaussian process (GP) modelling of
multiple short time series. These problems are common when applying GP models
independently to each gene in a gene expression time series data set. Such sets
typically contain very few time points. Naive application of common GP
modelling techniques can lead to severe over-fitting or under-fitting in a
significant fraction of the fitted models, depending on the details of the data
set. We propose avoiding over-fitting by constraining the GP length-scale to
values that focus most of the energy spectrum to frequencies below the Nyquist
frequency corresponding to the sampling frequency in the data set.
Under-fitting can be avoided by more informative priors on observation noise.
Combining these methods allows applying GP methods reliably automatically to
large numbers of independent instances of short time series. This is
illustrated with experiments with both synthetic data and real gene expression
data.",http://arxiv.org/pdf/1210.2503v1,stat.ML
2012-09-23 07:50:42+00:00,Fast Randomized Model Generation for Shapelet-Based Time Series Classification,"['Daniel Gordon', 'Danny Hendler', 'Lior Rokach']","Time series classification is a field which has drawn much attention over the
past decade. A new approach for classification of time series uses
classification trees based on shapelets. A shapelet is a subsequence extracted
from one of the time series in the dataset. A disadvantage of this approach is
the time required for building the shapelet-based classification tree. The
search for the best shapelet requires examining all subsequences of all lengths
from all time series in the training set.
  A key goal of this work was to find an evaluation order of the shapelets
space which enables fast convergence to an accurate model. The comparative
analysis we conducted clearly indicates that a random evaluation order yields
the best results. Our empirical analysis of the distribution of high-quality
shapelets within the shapelets space provides insights into why randomized
shapelets sampling is superior to alternative evaluation orders.
  We present an algorithm for randomized model generation for shapelet-based
classification that converges extremely quickly to a model with surprisingly
high accuracy after evaluating only an exceedingly small fraction of the
shapelets space.",http://arxiv.org/pdf/1209.5038v1,cs.LG
2012-09-18 16:17:14+00:00,Diagnostic Tests for Non-causal Time Series with Infinite Variance,"['Yunwei Cui', 'Rongning Wu', 'Thomas J. Fisher']","We study goodness-of-fit testing for non-causal autoregressive time series
with non-Gaussian stable noise. To model time series exhibiting sharp spikes or
occasional bursts of outlying observations, the exponent of the non-Gaussian
stable variables is assumed to be less than two. Under such conditions, the
innovation variables have no finite second moment. We proved that the sample
autocorrelation functions of the trimmed residuals are asymptotically normal.
Nonparametric tests are also investigated. The rank correlations of the
residuals or the squared residuals are shown to be asymptotically normal. Thus,
an assortment of portmanteau statistics are available for model assessment.",http://arxiv.org/pdf/1209.4013v1,math.ST
2012-08-14 15:00:32+00:00,On the prediction of stationary functional time series,"['Alexander Aue', 'Diogo Dubart Norinho', 'Siegfried Hörmann']","This paper addresses the prediction of stationary functional time series.
Existing contributions to this problem have largely focused on the special case
of first-order functional autoregressive processes because of their technical
tractability and the current lack of advanced functional time series
methodology. It is shown here how standard multivariate prediction techniques
can be utilized in this context. The connection between functional and
multivariate predictions is made precise for the important case of vector and
functional autoregressions. The proposed method is easy to implement, making
use of existing statistical software packages, and may therefore be attractive
to a broader, possibly non-academic, audience. Its practical applicability is
enhanced through the introduction of a novel functional final prediction error
model selection criterion that allows for an automatic determination of the lag
structure and the dimensionality of the model. The usefulness of the proposed
methodology is demonstrated in a simulation study and an application to
environmental data, namely the prediction of daily pollution curves describing
the concentration of particulate matter in ambient air. It is found that the
proposed prediction method often significantly outperforms existing methods.",http://arxiv.org/pdf/1208.2892v4,stat.ME
2012-07-24 11:09:14+00:00,Comparing spectral densities of stationary time series with unequal sample sizes,"['Philip Preuß', 'Thimo Hildebrandt']","This paper deals with the comparison of several stationary processes with
unequal sample sizes. We provide a detailed theoretical framework on the
testing problem for equality of spectral densities in the bivariate case, after
which the generalization of our approach to the m dimensional case and to other
statistical applications (like testing for zero correlation or clustering of
time series data with different length) is straightforward. We prove asymptotic
normality of an appropriately standardized version of the test statistic both
under the null and the alternative and investigate the finite sample properties
of our method in a simulation study. Furthermore we apply our approach to
cluster financial time series data with different sample length.",http://arxiv.org/pdf/1207.5659v1,math.ST
2012-07-21 13:31:56+00:00,Causal Inference on Time Series using Structural Equation Models,"['Jonas Peters', 'Dominik Janzing', 'Bernhard Schölkopf']","Causal inference uses observations to infer the causal structure of the data
generating system. We study a class of functional models that we call Time
Series Models with Independent Noise (TiMINo). These models require independent
residual time series, whereas traditional methods like Granger causality
exploit the variance of residuals. There are two main contributions: (1)
Theoretical: By restricting the model class (e.g. to additive noise) we can
provide a more general identifiability result than existing ones. This result
incorporates lagged and instantaneous effects that can be nonlinear and do not
need to be faithful, and non-instantaneous feedbacks between the time series.
(2) Practical: If there are no feedback loops between time series, we propose
an algorithm based on non-linear independence tests of time series. When the
data are causally insufficient, or the data generating process does not satisfy
the model assumptions, this algorithm may still give partial results, but
mostly avoids incorrect answers. An extension to (non-instantaneous) feedbacks
is possible, but not discussed. It outperforms existing methods on artificial
and real data. Code can be provided upon request.",http://arxiv.org/pdf/1207.5136v1,stat.ML
2012-06-27 16:19:31+00:00,Fitting Graphical Interaction Models to Multivariate Time Series,['Michael Eichler'],"Graphical interaction models have become an important tool for analysing
multivariate time series. In these models, the interrelationships among the
components of a time series are described by undirected graphs in which the
vertices depict the components while the edges indictate possible dependencies
between the components. Current methods for the identification of the graphical
structure are based on nonparametric spectral stimation, which prevents
application of common model selection strategies. In this paper, we present a
parametric approach for graphical interaction modelling of multivariate
stationary time series. The proposed models generalize covariance selection
models to the time series setting and are formulated in terms of inverse
covariances. We show that these models correspond to vector autoregressive
models under conditional independence constraints encoded by undirected graphs.
Furthermore, we discuss maximum likelihood estimation based on Whittle's
approximation to the log-likelihood function and propose an iterative method
for solving the resulting likelihood equations. The concepts are illustrated by
an example.",http://arxiv.org/pdf/1206.6839v1,stat.ME
2012-06-27 07:44:15+00:00,Discrete Elastic Inner Vector Spaces with Application in Time Series and Sequence Mining,"['Pierre-François Marteau', 'Nicolas Bonnel', 'Gilbas Ménier']","This paper proposes a framework dedicated to the construction of what we call
discrete elastic inner product allowing one to embed sets of non-uniformly
sampled multivariate time series or sequences of varying lengths into inner
product space structures. This framework is based on a recursive definition
that covers the case of multiple embedded time elastic dimensions. We prove
that such inner products exist in our general framework and show how a simple
instance of this inner product class operates on some prospective applications,
while generalizing the Euclidean inner product. Classification experimentations
on time series and symbolic sequences datasets demonstrate the benefits that we
can expect by embedding time series or sequences into elastic inner spaces
rather than into classical Euclidean spaces. These experiments show good
accuracy when compared to the euclidean distance or even dynamic programming
algorithms while maintaining a linear algorithmic complexity at exploitation
stage, although a quadratic indexing phase beforehand is required.",http://arxiv.org/pdf/1206.6196v1,cs.LG
2012-06-26 23:39:00+00:00,Directed Time Series Regression for Control,"['Yi-Hao Kao', 'Benjamin Van Roy']","We propose directed time series regression, a new approach to estimating
parameters of time-series models for use in certainty equivalent model
predictive control. The approach combines merits of least squares regression
and empirical optimization. Through a computational study involving a
stochastic version of a well known inverted pendulum balancing problem, we
demonstrate that directed time series regression can generate significant
improvements in controller performance over either of the aforementioned
alternatives.",http://arxiv.org/pdf/1206.6141v1,cs.LG
2012-06-20 14:54:25+00:00,Causal Reasoning in Graphical Time Series Models,"['Michael Eichler', 'Vanessa Didelez']","We propose a definition of causality for time series in terms of the effect
of an intervention in one component of a multivariate time series on another
component at some later point in time. Conditions for identifiability,
comparable to the back-door and front-door criteria, are presented and can also
be verified graphically. Computation of the causal effect is derived and
illustrated for the linear case.",http://arxiv.org/pdf/1206.5246v1,stat.ME
2012-06-18 15:42:15+00:00,Sparse-GEV: Sparse Latent Space Model for Multivariate Extreme Value Time Serie Modeling,"['Yan Liu', 'Taha Bahadori', 'Hongfei Li']","In many applications of time series models, such as climate analysis and
social media analysis, we are often interested in extreme events, such as
heatwave, wind gust, and burst of topics. These time series data usually
exhibit a heavy-tailed distribution rather than a Gaussian distribution. This
poses great challenges to existing approaches due to the significantly
different assumptions on the data distributions and the lack of sufficient past
data on extreme events. In this paper, we propose the Sparse-GEV model, a
latent state model based on the theory of extreme value modeling to
automatically learn sparse temporal dependence and make predictions. Our model
is theoretically significant because it is among the first models to learn
sparse temporal dependencies among multivariate extreme value time series. We
demonstrate the superior performance of our algorithm to the state-of-art
methods, including Granger causality, copula approach, and transfer entropy, on
one synthetic dataset, one climate dataset and two Twitter datasets.",http://arxiv.org/pdf/1206.4685v1,stat.ME
2012-06-12 14:59:34+00:00,Detecting changes in cross-sectional dependence in multivariate time series,"['Axel Bücher', 'Ivan Kojadinovic', 'Tom Rohmer', 'Johan Segers']","Classical and more recent tests for detecting distributional changes in
multivariate time series often lack power against alternatives that involve
changes in the cross-sectional dependence structure. To be able to detect such
changes better, a test is introduced based on a recently studied variant of the
sequential empirical copula process. In contrast to earlier attempts, ranks are
computed with respect to relevant subsamples, with beneficial consequences for
the sensitivity of the test. For the computation of p-values we propose a
multiplier resampling scheme that takes the serial dependence into account. The
large-sample theory for the test statistic and the resampling scheme is
developed. The finite-sample performance of the procedure is assessed by Monte
Carlo simulations. Two case studies involving time series of financial returns
are presented as well.",http://arxiv.org/pdf/1206.2557v4,math.ST
2012-06-11 21:33:53+00:00,Stochastic Equicontinuity in Nonlinear Time Series Models,['Andreas Hagemann'],"In this paper I provide simple and easily verifiable conditions under which a
strong form of stochastic equicontinuity holds in a wide variety of modern time
series models. In contrast to most results currently available in the
literature, my methods avoid mixing conditions. I discuss several applications
in detail.",http://arxiv.org/pdf/1206.2385v2,math.ST
2012-06-05 06:10:59+00:00,A specification test for nonlinear nonstationary models,"['Qiying Wang', 'Peter C. B. Phillips']","We provide a limit theory for a general class of kernel smoothed U-statistics
that may be used for specification testing in time series regression with
nonstationary data. The test framework allows for linear and nonlinear models
with endogenous regressors that have autoregressive unit roots or near unit
roots. The limit theory for the specification test depends on the
self-intersection local time of a Gaussian process. A new weak convergence
result is developed for certain partial sums of functions involving
nonstationary time series that converges to the intersection local time
process. This result is of independent interest and is useful in other
applications. Simulations examine the finite sample performance of the test.",http://arxiv.org/pdf/1206.0825v1,math.ST
2012-06-04 13:37:12+00:00,Factor modeling for high-dimensional time series: Inference for the number of factors,"['Clifford Lam', 'Qiwei Yao']","This paper deals with the factor modeling for high-dimensional time series
based on a dimension-reduction viewpoint. Under stationary settings, the
inference is simple in the sense that both the number of factors and the factor
loadings are estimated in terms of an eigenanalysis for a nonnegative definite
matrix, and is therefore applicable when the dimension of time series is on the
order of a few thousands. Asymptotic properties of the proposed method are
investigated under two settings: (i) the sample size goes to infinity while the
dimension of time series is fixed; and (ii) both the sample size and the
dimension of time series go to infinity together. In particular, our estimators
for zero-eigenvalues enjoy faster convergence (or slower divergence) rates,
hence making the estimation for the number of factors easier. In particular,
when the sample size and the dimension of time series go to infinity together,
the estimators for the eigenvalues are no longer consistent. However, our
estimator for the number of the factors, which is based on the ratios of the
estimated eigenvalues, still works fine. Furthermore, this estimation shows the
so-called ""blessing of dimensionality"" property in the sense that the
performance of the estimation may improve when the dimension of time series
increases. A two-step procedure is investigated when the factors are of
different degrees of strength. Numerical illustration with both simulated and
real data is also reported.",http://arxiv.org/pdf/1206.0613v1,math.ST
2012-05-21 13:17:46+00:00,Forecastable Component Analysis (ForeCA),['Georg M. Goerg'],"I introduce Forecastable Component Analysis (ForeCA), a novel dimension
reduction technique for temporally dependent signals. Based on a new
forecastability measure, ForeCA finds an optimal transformation to separate a
multivariate time series into a forecastable and an orthogonal white noise
space. I present a converging algorithm with a fast eigenvector solution.
Applications to financial and macro-economic time series show that ForeCA can
successfully discover informative structure, which can be used for forecasting
as well as classification. The R package ForeCA
(http://cran.r-project.org/web/packages/ForeCA/index.html) accompanies this
work and is publicly available on CRAN.",http://arxiv.org/pdf/1205.4591v3,stat.ME
2012-04-29 20:35:21+00:00,Detection of additive outliers in Poisson INteger-valued AutoRegressive time series,"['Maria Eduarda Silva', 'Isabel Pereira']","Outlying observations are commonly encountered in the analysis of time
series. In this paper the problem of detecting additive outliers in
integer-valued time series is considered. We show how Gibbs sampling can be
used to detect outlying observations in INAR(1) processes. The methodology
proposed is illustrated using examples as well as an observed data set.",http://arxiv.org/pdf/1204.6516v1,stat.ME
2012-03-15 11:38:16+00:00,COPAR - Multivariate time series modeling using the COPula AutoRegressive model,"['Eike Christian Brechmann', 'Claudia Czado']","Analysis of multivariate time series is a common problem in areas like
finance and economics. The classical tool for this purpose are vector
autoregressive models. These however are limited to the modeling of linear and
symmetric dependence. We propose a novel copula-based model which allows for
non-linear and asymmetric modeling of serial as well as between-series
dependencies. The model exploits the flexibility of vine copulas which are
built up by bivariate copulas only. We describe statistical inference
techniques for the new model and demonstrate its usefulness in three relevant
applications: We analyze time series of macroeconomic indicators, of
electricity load demands and of bond portfolio returns.",http://arxiv.org/pdf/1203.3328v3,stat.ME
2012-03-05 17:07:10+00:00,Infinite Shift-invariant Grouped Multi-task Learning for Gaussian Processes,"['Yuyang Wang', 'Roni Khardon', 'Pavlos Protopapas']","Multi-task learning leverages shared information among data sets to improve
the learning performance of individual tasks. The paper applies this framework
for data where each task is a phase-shifted periodic time series. In
particular, we develop a novel Bayesian nonparametric model capturing a mixture
of Gaussian processes where each task is a sum of a group-specific function and
a component capturing individual variation, in addition to each task being
phase shifted. We develop an efficient \textsc{em} algorithm to learn the
parameters of the model. As a special case we obtain the Gaussian mixture model
and \textsc{em} algorithm for phased-shifted periodic time series. Furthermore,
we extend the proposed model by using a Dirichlet Process prior and thereby
leading to an infinite mixture model that is capable of doing automatic model
selection. A Variational Bayesian approach is developed for inference in this
model. Experiments in regression, classification and class discovery
demonstrate the performance of the proposed models using both synthetic data
and real-world time series data from astrophysics. Our methods are particularly
useful when the time series are sparsely and non-synchronously sampled.",http://arxiv.org/pdf/1203.0970v2,cs.LG
2012-03-02 13:12:03+00:00,Change-Point Detection in Time-Series Data by Relative Density-Ratio Estimation,"['Song Liu', 'Makoto Yamada', 'Nigel Collier', 'Masashi Sugiyama']","The objective of change-point detection is to discover abrupt property
changes lying behind time-series data. In this paper, we present a novel
statistical change-point detection algorithm based on non-parametric divergence
estimation between time-series samples from two retrospective segments. Our
method uses the relative Pearson divergence as a divergence measure, and it is
accurately and efficiently estimated by a method of direct density-ratio
estimation. Through experiments on artificial and real-world datasets including
human-activity sensing, speech, and Twitter messages, we demonstrate the
usefulness of the proposed method.",http://arxiv.org/pdf/1203.0453v2,stat.ML
2012-02-20 10:26:28+00:00,Fast rates in learning with dependent observations,"['Pierre Alquier', 'Olivier Wintenberger']","In this paper we tackle the problem of fast rates in time series forecasting
from a statistical learning perspective. In a serie of papers (e.g. Meir 2000,
Modha and Masry 1998, Alquier and Wintenberger 2012) it is shown that the main
tools used in learning theory with iid observations can be extended to the
prediction of time series. The main message of these papers is that, given a
family of predictors, we are able to build a new predictor that predicts the
series as well as the best predictor in the family, up to a remainder of order
$1/\sqrt{n}$. It is known that this rate cannot be improved in general. In this
paper, we show that in the particular case of the least square loss, and under
a strong assumption on the time series (phi-mixing) the remainder is actually
of order $1/n$. Thus, the optimal rate for iid variables, see e.g. Tsybakov
2003, and individual sequences, see \cite{lugosi} is, for the first time,
achieved for uniformly mixing processes. We also show that our method is
optimal for aggregating sparse linear combinations of predictors.",http://arxiv.org/pdf/1202.4283v1,math.ST
2012-01-16 13:08:15+00:00,Space-time modelling of extreme events,"['Raphaël Huser', 'A. C. Davison']","Max-stable processes are the natural analogues of the generalized
extreme-value distribution for the modelling of extreme events in space and
time. Under suitable conditions, these processes are asymptotically justified
models for maxima of independent replications of random fields, and they are
also suitable for the modelling of joint individual extreme measurements over
high thresholds. This paper extends a model of Schlather (2001) to the
space-time framework, and shows how a pairwise censored likelihood can be used
for consistent estimation under mild mixing conditions. Estimator efficiency is
also assessed and the choice of pairs to be included in the pairwise likelihood
is discussed based on computations for simple time series models. The ideas are
illustrated by an application to hourly precipitation data over Switzerland.",http://arxiv.org/pdf/1201.3245v1,stat.ME
2012-01-12 17:06:23+00:00,Short-Term Load Forecasting: The Similar Shape Functional Time Series Predictor,"['Efstathios Paparoditis', 'Theofanis Sapatinas']","We introduce a novel functional time series methodology for short-term load
forecasting. The prediction is performed by means of a weighted average of past
daily load segments, the shape of which is similar to the expected shape of the
load segment to be predicted. The past load segments are identified from the
available history of the observed load segments by means of their closeness to
a so-called reference load segment, the later being selected in a manner that
captures the expected qualitative and quantitative characteristics of the load
segment to be predicted. Weak consistency of the suggested functional similar
shape predictor is established. As an illustration, we apply the suggested
functional time series forecasting methodology to historical daily load data in
Cyprus and compare its performance to that of a recently proposed alternative
functional time series methodology for short-term load forecasting.",http://arxiv.org/pdf/1201.2617v1,math.ST
2012-01-06 09:33:44+00:00,"Rejoinder to ""Feature Matching in Time Series Modeling""","['Yingcun Xia', 'Howell Tong']","Rejoinder to ""Feature Matching in Time Series Modeling"" by Y. Xia and H. Tong
[arXiv:1104.3073]",http://arxiv.org/pdf/1201.1379v1,stat.ME
2012-01-06 09:09:51+00:00,"Discussion of ""Feature Matching in Time Series Modeling"" by Y. Xia and H. Tong",['Qiwei Yao'],"Discussion of ""Feature Matching in Time Series Modeling"" by Y. Xia and H.
Tong [arXiv:1104.3073]",http://arxiv.org/pdf/1201.1376v1,stat.ME
2012-01-06 09:01:17+00:00,"Discussion of ""Feature Matching in Time Series Modeling"" by Y. Xia and H. Tong",['Edward L. Ionides'],"Discussion of ""Feature Matching in Time Series Modeling"" by Y. Xia and H.
Tong [arXiv:1104.3073]",http://arxiv.org/pdf/1201.1373v1,stat.ME
2012-01-06 08:24:26+00:00,"Discussion of ""Feature Matching in Time Series Modeling"" by Y. Xia and H. Tong","['Kung-Sik Chan', 'Ruey S. Tsay']","Discussion of ""Feature Matching in Time Series Modeling"" by Y. Xia and H.
Tong [arXiv:1104.3073]",http://arxiv.org/pdf/1201.1367v1,stat.ME
2012-01-06 06:59:24+00:00,"Discussion of ""Feature Matching in Time Series Modeling"" by Y. Xia and H. Tong",['Bruce E. Hansen'],"Discussion of ""Feature Matching in Time Series Modeling"" by Y. Xia and H.
Tong [arXiv:1104.3073]",http://arxiv.org/pdf/1201.1356v1,stat.ME
2012-01-05 13:26:40+00:00,Resampling in Time Series Models,"['Abhishek Bhattacharya', 'Arup Bose']","This project revolves around studying estimators for parameters in different
Time Series models and studying their assymptotic properties. We introduce
various bootstrap techniques for the estimators obtained. Our special emphasis
is on Weighted Bootstrap. We establish the consistency of this scheme in a AR
model and its variations. Numerical calculations lend further support to our
consistency results. Next we analyze ARCH models, and study various estimators
used for different error distributions. We also present resampling techniques
for estimating the distribution of the estimators. Finally by simulating data,
we analyze the numerical properties of the estimators.",http://arxiv.org/pdf/1201.1166v1,math.ST
2011-12-29 13:40:43+00:00,Robust estimation in time series with long and short memory properties,"['Valderio A. Reisen', 'Fabio A. Fajardo']","This paper reviews recent developments of robust estimation in linear time
series models, with short and long memory correlation structures, in the
presence of additive outliers. Based on the manuscripts Fajardo et al. (2009)
and L\'evy-Leduc et al. (2011a), the emphasis in this paper is given in the
following directions; the influence of additive outliers in the estimation of a
time series, the asymptotic properties of a robust autocovariance function and
a robust semiparametric estimation method of the fractional parameter d in
ARFIMA(p, d, q) models. Some simulations are used to support the use of the
robust method when a time series has additive outliers. The invariance property
of the estimators for the first difference in ARFIMA model with outliers is
also discussed. In general, the robust long-memory estimator leads to be
outlier resistant and is invariant to first differencing.",http://arxiv.org/pdf/1112.6308v1,stat.ME
2011-12-20 03:33:24+00:00,Binomial ARMA count series from renewal processes,"['Sergiy Koshkin', 'Yunwei Cui']","This paper describes a new method for generating stationary integer-valued
time series from renewal processes. We prove that if the lifetime distribution
of renewal processes is nonlattice and the probability generating function is
rational, then the generated time series satisfy causal and invertible ARMA
type stochastic difference equations. The result provides an easy method for
generating integer-valued time series with ARMA type autocovariance functions.
Examples of generating binomial ARMA(p,p-1) series from lifetime distributions
with constant hazard rates after lag p are given as an illustration. An
estimation method is developed for the AR(p) cases.",http://arxiv.org/pdf/1112.4554v1,math.ST
2011-12-13 00:28:37+00:00,The quantile spectral density and comparison based tests for nonlinear time series,"['Junbum Lee', 'Suhasini Subba Rao']","In this paper we consider tests for nonlinear time series, which are
motivated by the notion of serial dependence. The proposed tests are based on
comparisons with the quantile spectral density, which can be considered as a
quantile version of the usual spectral density function. The quantile spectral
density 'measures' sequential dependence structure of a time series, and is
well defined under relatively weak mixing conditions. We propose an estimator
for the quantile spectral density and derive its asympototic sampling
properties. We use the quantile spectral density to construct a goodness of fit
test for time series and explain how this test can also be used for comparing
the sequential dependence structure of two time series. The method is
illustrated with simulations and some real data examples.",http://arxiv.org/pdf/1112.2759v2,math.ST
2011-11-08 16:42:06+00:00,Robust Spectral Analysis,['Andreas Hagemann'],"In this paper I introduce quantile spectral densities that summarize the
cyclical behavior of time series across their whole distribution by analyzing
periodicities in quantile crossings. This approach can capture systematic
changes in the impact of cycles on the distribution of a time series and allows
robust spectral estimation and inference in situations where the dependence
structure is not accurately captured by the auto-covariance function. I study
the statistical properties of quantile spectral estimators in a large class of
nonlinear time series models and discuss inference both at fixed and across all
frequencies. Monte Carlo experiments illustrate the advantages of quantile
spectral analysis over classical methods when standard assumptions are
violated.",http://arxiv.org/pdf/1111.1965v2,math.ST
2011-10-24 05:59:09+00:00,Detection of non-constant long memory parameter,"['Frédéric Lavancier', 'Remigijus Leipus', 'Anne Philippe', 'Donatas Surgailis']","This article deals with detection of nonconstant long memory parameter in
time series. The null hypothesis presumes stationary or nonstationary time
series with constant long memory parameter, typically an I(d) series with
d>-.5. The alternative corresponds to an increase in persistence and includes
in particular an abrupt or gradual change from I(d_1) to I(d_2).",http://arxiv.org/pdf/1110.5138v3,math.ST
2011-09-22 11:32:31+00:00,Beta-Product Poisson-Dirichlet Processes,"['Federico Bassetti', 'Roberto Casarin', 'Fabrizio Leisen']","Time series data may exhibit clustering over time and, in a multiple time
series context, the clustering behavior may differ across the series. This
paper is motivated by the Bayesian non--parametric modeling of the dependence
between the clustering structures and the distributions of different time
series. We follow a Dirichlet process mixture approach and introduce a new
class of multivariate dependent Dirichlet processes (DDP). The proposed DDP are
represented in terms of vector of stick-breaking processes with dependent
weights. The weights are beta random vectors that determine different and
dependent clustering effects along the dimension of the DDP vector. We discuss
some theoretical properties and provide an efficient Monte Carlo Markov Chain
algorithm for posterior computation. The effectiveness of the method is
illustrated with a simulation study and an application to the United States and
the European Union industrial production indexes.",http://arxiv.org/pdf/1109.4777v1,math.ST
2011-09-22 10:44:51+00:00,Clustering of time-course gene expression profiles using normal mixture models with AR(1) random effects,"['K. Wang', 'S. K. Ng', 'G. J. McLachlan']","Time-course gene expression data such as yeast cell cycle data may be
periodically expressed. To cluster such data, currently used Fourier series
approximations of periodic gene expressions have been found not to be
sufficiently adequate to model the complexity of the time-course data, partly
due to their ignoring the dependence between the expression measurements over
time and the correlation among gene expression profiles. We further investigate
the advantages and limitations of available models in the literature and
propose a new mixture model with AR(1) random effects for the clustering of
time-course gene-expression profiles. Some simulations and real examples are
given to demonstrate the usefulness of the proposed models.",http://arxiv.org/pdf/1109.4764v1,stat.ME
2011-09-19 21:08:56+00:00,Locally Stationary Processes,['Rainer Dahlhaus'],"The article contains an overview over locally stationary processes. At the
beginning time varying autoregressive processes are discussed in detail - both
as as a deep example and an important class of locally stationary processes. In
the next section a general framework for time series with time varying finite
dimensional parameters is discussed with special emphasis on nonlinear locally
stationary processes. Then the paper focusses on linear processes where a more
general theory is possible. First a general definition for linear processes is
given and time varying spectral densities are discussed in detail. Then the
Gaussian likelihood theory is presented for locally stationary processes. In
the next section the relevance of empirical spectral processes for locally
stationary time series is discussed. Empirical spectral processes play a major
role in proving theoretical results and provide a deeper understanding of many
techniques. The article concludes with an overview of other results for locally
stationary processes.",http://arxiv.org/pdf/1109.4174v2,math.ST
2011-09-16 21:51:44+00:00,On the Convergence of Finite Order Approximations of Stationary Time Series,"['Symantak Datta Gupta', 'Ravi R. Mazumdar', 'Peter W. Glynn']","The approximation of a stationary time-series by finite order autoregressive
(AR) and moving averages (MA) is a problem that occurs in many applications. In
this paper we study asymptotic behavior of the spectral density of finite order
approximations of wide sense stationary time series. It is shown that when the
on the spectral density is non-vanishing in $[-\pi,\pi]$ and the covariance is
summable, the spectral density of the approximating autoregressive sequence
converges at the origin. Under additional mild conditions on the coefficients
of the Wold decomposition it is also shown that the spectral densities of both
moving average and autoregressive approximations converge in $L_2$ as the order
of approximation increases.",http://arxiv.org/pdf/1109.3732v1,math.ST
2011-09-08 01:39:39+00:00,A note on a Marčenko-Pastur type theorem for time series,['Jianfeng Yao'],"In this note we develop an extension of the Mar\v{c}enko-Pastur theorem to
time series model with temporal correlations. The limiting spectral
distribution (LSD) of the sample covariance matrix is characterised by an
explicit equation for its Stieltjes transform depending on the spectral density
of the time series. A numerical algorithm is then given to compute the density
functions of these LSD's.",http://arxiv.org/pdf/1109.1612v1,math.ST
2011-08-16 14:55:20+00:00,A review and comparison of strategies for multi-step ahead time series forecasting based on the NN5 forecasting competition,"['Souhaib Ben Taieb', 'Gianluca Bontempi', 'Amir Atiya', 'Antti Sorjamaa']","Multi-step ahead forecasting is still an open challenge in time series
forecasting. Several approaches that deal with this complex problem have been
proposed in the literature but an extensive comparison on a large number of
tasks is still missing. This paper aims to fill this gap by reviewing existing
strategies for multi-step ahead forecasting and comparing them in theoretical
and practical terms. To attain such an objective, we performed a large scale
comparison of these different strategies using a large experimental benchmark
(namely the 111 series from the NN5 forecasting competition). In addition, we
considered the effects of deseasonalization, input variable selection, and
forecast combination on these strategies and on multi-step ahead forecasting at
large. The following three findings appear to be consistently supported by the
experimental results: Multiple-Output strategies are the best performing
approaches, deseasonalization leads to uniformly improved forecast accuracy,
and input selection is more effective when performed in conjunction with
deseasonalization.",http://arxiv.org/pdf/1108.3259v1,stat.ML
2011-07-27 20:54:26+00:00,Estimating Extremal Dependence in Univariate and Multivariate Time Series via the Extremogram,"['Richard A. Davis', 'Thomas Mikosch', 'Ivor Cribben']","Davis and Mikosch [7] introduced the extremogram as a flexible quantitative
tool for measuring various types of extremal dependence in a stationary time
series. There we showed some standard statistical properties of the sample
extremogram. A major difficulty was the construction of credible confidence
bands for the extremogram. In this paper, we employ the stationary bootstrap to
overcome this problem. Moreover, we introduce the cross extremogram as a
measure of extremal serial dependence between two or more time series. We also
study the extremogram for return times between extremal events. The use of the
stationary bootstrap for the extremogram and the resulting interpretations are
illustrated in several univariate and multivariate financial time series
examples.",http://arxiv.org/pdf/1107.5592v1,stat.ME
2011-06-20 14:35:52+00:00,Dynamic Large Spatial Covariance Matrix Estimation in Application to Semiparametric Model Construction via Variable Clustering: the SCE approach,['Song Song'],"To better understand the spatial structure of large panels of economic and
financial time series and provide a guideline for constructing semiparametric
models, this paper first considers estimating a large spatial covariance matrix
of the generalized $m$-dependent and $\beta$-mixing time series (with $J$
variables and $T$ observations) by hard thresholding regularization as long as
${{\log J \, \cx^*(\ct)}}/{T} = \Co(1)$ (the former scheme with some time
dependence measure $\cx^*(\ct)$) or $\log J /{T} = \Co(1)$ (the latter scheme
with some upper bounded mixing coefficient). We quantify the interplay between
the estimators' consistency rate and the time dependence level, discuss an
intuitive resampling scheme for threshold selection, and also prove a general
cross-validation result justifying this. Given a consistently estimated
covariance (correlation) matrix, by utilizing its natural links with graphical
models and semiparametrics, after ""screening"" the (explanatory) variables, we
implement a novel forward (and backward) label permutation procedure to cluster
the ""relevant"" variables and construct the corresponding semiparametric model,
which is further estimated by the groupwise dimension reduction method with
sign constraints. We call this the SCE (screen - cluster - estimate) approach
for modeling high dimensional data with complex spatial structure. Finally we
apply this method to study the spatial structure of large panels of economic
and financial time series and find the proper semiparametric structure for
estimating the consumer price index (CPI) to illustrate its superiority over
the linear models.",http://arxiv.org/pdf/1106.3921v2,stat.ML
2011-06-03 19:09:31+00:00,Rademacher complexity of stationary sequences,"['Daniel J. McDonald', 'Cosma Rohilla Shalizi']","We show how to control the generalization error of time series models wherein
past values of the outcome are used to predict future values. The results are
based on a generalization of standard i.i.d. concentration inequalities to
dependent data without the mixing assumptions common in the time series
setting. Our proof and the result are simpler than previous analyses with
dependent data or stochastic adversaries which use sequential Rademacher
complexities rather than the expected Rademacher complexity for i.i.d.
processes. We also derive empirical Rademacher results without mixing
assumptions resulting in fully calculable upper bounds.",http://arxiv.org/pdf/1106.0730v2,stat.ML
2011-05-12 16:38:17+00:00,Deconvolution of mixing time series on a graph,"['Alexander W. Blocker', 'Edoardo M. Airoldi']","In many applications we are interested in making inference on latent time
series from indirect measurements, which are often low-dimensional projections
resulting from mixing or aggregation. Positron emission tomography,
super-resolution, and network traffic monitoring are some examples. Inference
in such settings requires solving a sequence of ill-posed inverse problems,
y_t= A x_t, where the projection mechanism provides information on A. We
consider problems in which A specifies mixing on a graph of times series that
are bursty and sparse. We develop a multilevel state-space model for mixing
times series and an efficient approach to inference. A simple model is used to
calibrate regularization parameters that lead to efficient inference in the
multilevel state-space model. We apply this method to the problem of estimating
point-to-point traffic flows on a network from aggregate measurements. Our
solution outperforms existing methods for this problem, and our two-stage
approach suggests an efficient inference strategy for multilevel models of
dependent time series.",http://arxiv.org/pdf/1105.2526v2,stat.ME
2011-04-29 20:43:33+00:00,Estimation of the mean of functional time series and a two sample problem,"['Lajos Horvath', 'Piotr Kokoszka', 'Ron Reeder']","This paper is concerned with inference based on the mean function of a
functional time series, which is defined as a collection of curves obtained by
splitting a continuous time record, e.g. into daily or annual curves. We
develop a normal approximation for the functional sample mean, and then focus
on the estimation of the asymptotic variance kernel. Using these results, we
develop and asymptotically justify a testing procedure for the equality of
means in two functional samples exhibiting temporal dependence. Evaluated by
means of a simulations study and application to real data sets, this two sample
procedure enjoys good size and power in finite samples. We provide the details
of its numerical implementation.",http://arxiv.org/pdf/1105.0019v1,math.ST
2011-04-15 14:37:22+00:00,Feature Matching in Time Series Modeling,"['Yingcun Xia', 'Howell Tong']","Using a time series model to mimic an observed time series has a long
history. However, with regard to this objective, conventional estimation
methods for discrete-time dynamical models are frequently found to be wanting.
In fact, they are characteristically misguided in at least two respects: (i)
assuming that there is a true model; (ii) evaluating the efficacy of the
estimation as if the postulated model is true. There are numerous examples of
models, when fitted by conventional methods, that fail to capture some of the
most basic global features of the data, such as cycles with good matching
periods, singularities of spectral density functions (especially at the origin)
and others. We argue that the shortcomings need not always be due to the model
formulation but the inadequacy of the conventional fitting methods. After all,
all models are wrong, but some are useful if they are fitted properly. The
practical issue becomes one of how to best fit the model to data. Thus, in the
absence of a true model, we prefer an alternative approach to conventional
model fitting that typically involves one-step-ahead prediction errors. Our
primary aim is to match the joint probability distribution of the observable
time series, including long-term features of the dynamics that underpin the
data, such as cycles, long memory and others, rather than short-term
prediction. For want of a better name, we call this specific aim feature
matching.",http://arxiv.org/pdf/1104.3073v2,math.ST
2011-03-16 21:31:17+00:00,A Nonparametric Frequency Domain EM Algorithm for Time Series Classification with Applications to Spike Sorting and Macro-Economics,['Georg M. Goerg'],"I propose a frequency domain adaptation of the Expectation Maximization (EM)
algorithm to group a family of time series in classes of similar dynamic
structure. It does this by viewing the magnitude of the discrete Fourier
transform (DFT) of each signal (or power spectrum) as a probability
density/mass function (pdf/pmf) on the unit circle: signals with similar
dynamics have similar pdfs; distinct patterns have distinct pdfs. An advantage
of this approach is that it does not rely on any parametric form of the dynamic
structure, but can be used for non-parametric, robust and model-free
classification. This new method works for non-stationary signals of similar
shape as well as stationary signals with similar auto-correlation structure.
Applications to neural spike sorting (non-stationary) and pattern-recognition
in socio-economic time series (stationary) demonstrate the usefulness and wide
applicability of the proposed method.",http://arxiv.org/pdf/1103.3300v3,stat.ML
2011-02-26 17:55:44+00:00,Testing for change in mean of heteroskedastic time series,['Mohamed Boutahar'],"In this paper we consider a Lagrange Multiplier-type test (LM) to detect
change in the mean of time series with heteroskedasticity of unknown form. We
derive the limiting distribution under the null, and prove the consistency of
the test against the alternative of either an abrupt or smooth changes in the
mean. We perform also some Monte Carlo simulations to analyze the size
distortion and the power of the proposed test. We conclude that for moderate
sample size, the test has a good performance. We finally carry out an empirical
application using the daily closing level of the S&P 500 stock index, in order
to illustrate the usefulness of the proposed test.",http://arxiv.org/pdf/1102.5431v1,stat.ME
2011-02-10 09:42:49+00:00,Asymptotic distributions and subsampling in spectral analysis for almost periodically correlated time series,['Łukasz Lenart'],"The aim of this article is to establish asymptotic distributions and
consistency of subsampling for spectral density and for magnitude of coherence
for non-stationary, almost periodically correlated time series. We show the
asymptotic normality of the spectral density estimator and the limiting
distribution of a magnitude of coherence statistic for all points from the
bifrequency square. The theoretical results hold under $\alpha$-mixing and
moment conditions.",http://arxiv.org/pdf/1102.2064v1,math.ST
2011-01-04 08:44:14+00:00,Autoregressive Kernels For Time Series,"['Marco Cuturi', 'Arnaud Doucet']","We propose in this work a new family of kernels for variable-length time
series. Our work builds upon the vector autoregressive (VAR) model for
multivariate stochastic processes: given a multivariate time series x, we
consider the likelihood function p_{\theta}(x) of different parameters \theta
in the VAR model as features to describe x. To compare two time series x and
x', we form the product of their features p_{\theta}(x) p_{\theta}(x') which is
integrated out w.r.t \theta using a matrix normal-inverse Wishart prior. Among
other properties, this kernel can be easily computed when the dimension d of
the time series is much larger than the lengths of the considered time series x
and x'. It can also be generalized to time series taking values in arbitrary
state spaces, as long as the state space itself is endowed with a kernel
\kappa. In that case, the kernel between x and x' is a a function of the Gram
matrices produced by \kappa on observations and subsequences of observations
enumerated in x and x'. We describe a computationally efficient implementation
of this generalization that uses low-rank matrix factorization techniques.
These kernels are compared to other known kernels using a set of benchmark
classification tasks carried out with support vector machines.",http://arxiv.org/pdf/1101.0673v1,stat.ML
2010-12-15 18:01:25+00:00,Translating biomarkers between multi-way time-series experiments,"['Ilkka Huopaniemi', 'Tommi Suvitaival', 'Matej Orešič', 'Samuel Kaski']","Translating potential disease biomarkers between multi-species 'omics'
experiments is a new direction in biomedical research. The existing methods are
limited to simple experimental setups such as basic healthy-diseased
comparisons. Most of these methods also require an a priori matching of the
variables (e.g., genes or metabolites) between the species. However, many
experiments have a complicated multi-way experimental design often involving
irregularly-sampled time-series measurements, and for instance metabolites do
not always have known matchings between organisms. We introduce a Bayesian
modelling framework for translating between multiple species the results from
'omics' experiments having a complex multi-way, time-series experimental
design. The underlying assumption is that the unknown matching can be inferred
from the response of the variables to multiple covariates including time.",http://arxiv.org/pdf/1012.3407v1,stat.ML
2010-10-10 16:23:23+00:00,Testing for Parallelism Between Trends in Multiple Time Series,"['David Degras', 'Zhiwei Xu', 'Ting Zhang', 'Wei Biao Wu']","This paper considers the inference of trends in multiple, nonstationary time
series. To test whether trends are parallel to each other, we use a parallelism
index based on the L2-distances between nonparametric trend estimators and
their average. A central limit theorem is obtained for the test statistic and
the test's consistency is established. We propose a simulation-based
approximation to the distribution of the test statistic, which significantly
improves upon the normal approximation. The test is also applied to devise a
clustering algorithm. Finally, the finite-sample properties of the test are
assessed through simulations and the test methodology is illustrated with time
series from Motorola cell phone activity in the United States.",http://arxiv.org/pdf/1010.1935v2,stat.ME
2010-10-07 19:48:23+00:00,Time Series Classification by Class-Specific Mahalanobis Distance Measures,"['Zoltán Prekopcsák', 'Daniel Lemire']","To classify time series by nearest neighbors, we need to specify or learn one
or several distance measures. We consider variations of the Mahalanobis
distance measures which rely on the inverse covariance matrix of the data.
Unfortunately --- for time series data --- the covariance matrix has often low
rank. To alleviate this problem we can either use a pseudoinverse, covariance
shrinking or limit the matrix to its diagonal. We review these alternatives and
benchmark them against competitive methods such as the related Large Margin
Nearest Neighbor Classification (LMNN) and the Dynamic Time Warping (DTW)
distance. As we expected, we find that the DTW is superior, but the Mahalanobis
distance measures are one to two orders of magnitude faster. To get best
results with Mahalanobis distance measures, we recommend learning one distance
measure per class using either covariance shrinking or the diagonal approach.",http://arxiv.org/pdf/1010.1526v6,cs.LG
2010-10-05 08:08:17+00:00,Weakly dependent functional data,"['Siegfried Hörmann', 'Piotr Kokoszka']","Functional data often arise from measurements on fine time grids and are
obtained by separating an almost continuous time record into natural
consecutive intervals, for example, days. The functions thus obtained form a
functional time series, and the central issue in the analysis of such data
consists in taking into account the temporal dependence of these functional
observations. Examples include daily curves of financial transaction data and
daily patterns of geophysical and environmental data. For scalar and vector
valued stochastic processes, a large number of dependence notions have been
proposed, mostly involving mixing type distances between $\sigma$-algebras. In
time series analysis, measures of dependence based on moments have proven most
useful (autocovariances and cumulants). We introduce a moment-based notion of
dependence for functional time series which involves $m$-dependence. We show
that it is applicable to linear as well as nonlinear functional time series.
Then we investigate the impact of dependence thus quantified on several
important statistical procedures for functional data. We study the estimation
of the functional principal components, the long-run covariance matrix, change
point detection and the functional linear model. We explain when temporal
dependence affects the results obtained for i.i.d. functional observations and
when these results are robust to weak dependence.",http://arxiv.org/pdf/1010.0792v1,math.ST
2010-09-04 05:16:40+00:00,Subsampling weakly dependent times series and application to extremes,"['Paul Doukhan', 'Silika Prohl', 'Christian Y. Robert']","This paper provides extensions of the work on subsampling by Bertail et al.
(2004) for strongly mixing case to weakly dependent case by application of the
results of Doukhan and Louhichi (1999). We investigate properties of smooth and
rough subsampling estimators for distributions of converging and extreme
statistics when the underlying time series is {\eta} or {\lambda}-weakly
dependent.",http://arxiv.org/pdf/1009.0805v1,math.ST
2010-09-04 01:26:31+00:00,"Dynamic interactions in terms of senders, hubs, and receivers (SHR) using the singular value decomposition of time series: Theory and brain connectivity applications","['Roberto D. Pascual-Marqui', 'Rolando J. Biscay-Lirio']","Understanding of normal and pathological brain function requires the
identification and localization of functional connections between specialized
regions. The availability of high time resolution signals of electric neuronal
activity at several regions offers information for quantifying the connections
in terms of information flow. When the signals cover the whole cortex, the
number of connections is very large, making visualization and interpretation
very difficult. We introduce here the singular value decomposition of
time-lagged multiple signals, which localizes the senders, hubs, and receivers
(SHR) of information transmission. Unlike methods that operate on large
connectivity matrices, such as correlation thresholding and graph-theoretic
analyses, this method operates on the multiple time series directly, providing
3D brain images that assign a score to each location in terms of its sending,
relaying, and receiving capacity. The scope of the method is general and
encompasses other applications outside the field of brain connectivity.",http://arxiv.org/pdf/1009.0796v2,stat.ME
2010-08-12 00:41:23+00:00,Discovering shared and individual latent structure in multiple time series,"['Suchi Saria', 'Daphne Koller', 'Anna Penn']","This paper proposes a nonparametric Bayesian method for exploratory data
analysis and feature construction in continuous time series. Our method focuses
on understanding shared features in a set of time series that exhibit
significant individual variability. Our method builds on the framework of
latent Diricihlet allocation (LDA) and its extension to hierarchical Dirichlet
processes, which allows us to characterize each series as switching between
latent ``topics'', where each topic is characterized as a distribution over
``words'' that specify the series dynamics. However, unlike standard
applications of LDA, we discover the words as we learn the model. We apply this
model to the task of tracking the physiological signals of premature infants;
our model obtains clinically significant insights as well as useful features
for supervised learning tasks.",http://arxiv.org/pdf/1008.2028v1,stat.ML
2010-07-23 16:23:35+00:00,Assessing Characteristic Scales Using Wavelets,"['Michael J. Keim', 'Donald B. Percival']","Characteristic scale is a notion that pervades the geophysical sciences, but
it has no widely accepted precise definition. The wavelet transform decomposes
a time series into coefficients that are associated with different scales. The
variance of these coefficients can be used to decompose the variance of the
time series across different scales. A practical definition for characteristic
scale can be formulated in terms of peaks in plots of the wavelet variance
versus scale. This paper presents basic theory for characteristic scales based
upon the discrete wavelet transform, proposes a natural estimator for these
scales and provides a large sample theory for this estimator that permits the
construction of confidence intervals for a true unknown characteristic scale.
Computer experiments are presented that demonstrate the efficacy of the large
sample theory for finite sample sizes. Examples of characteristic scale
estimation are given for global temperature records, coherent structures in
river flows, the Madden-Julian oscillation in an atmospheric time series and
transects of one type of Arctic sea ice.",http://arxiv.org/pdf/1007.4169v1,stat.ME
2010-06-17 11:47:50+00:00,On signal and extraneous roots in Singular Spectrum Analysis,['Konstantin Usevich'],"In the present paper we study properties of roots of characteristic
polynomials for the linear recurrent formulae (LRF) that govern time series. We
also investigate how the values of these roots affect Singular Spectrum
Analysis implications, in what concerns separation of components, SSA
forecasting and related signal parameter estimation methods. The roots of the
characteristic polynomial for an LRF comprise the signal roots, which determine
the structure of the time series, and extraneous roots. We show how the
separability of two time series can be characterized in terms of their signal
roots. All possible cases of exact separability are enumerated. We also examine
properties of extraneous roots of the LRF used in SSA forecasting algorithms,
which is equivalent to the Min-Norm vector in subspace-based estimation
methods. We apply recent theoretical results for orthogonal polynomials on the
unit circle, which enable us to precisely describe the asymptotic distribution
of extraneous roots relative to the position of the signal roots.",http://arxiv.org/pdf/1006.3436v1,stat.ME
2010-05-24 14:01:05+00:00,On the Estimation of the Heavy-Tail Exponent in Time Series using the Max-Spectrum,"['Stilian A Stoev', 'George Michailidis']","This paper addresses the problem of estimating the tail index of
distributions with heavy, Pareto-type tails for dependent data, that is of
interest in the areas of finance, insurance, environmental monitoring and
teletraffic analysis. A novel approach based on the max self-similarity scaling
behavior of block maxima is introduced. The method exploits the increasing lack
of dependence of maxima over large size blocks, which proves useful for time
series data. We establish the consistency and asymptotic normality of the
proposed max-spectrum estimator for a large class of m-dependent time series,
in the regime of intermediate block-maxima. In the regime of large
block-maxima, we demonstrate the distributional consistency of the estimator
for a broad range of time series models including linear processes. The
max-spectrum estimator is a robust and computationally efficient tool, which
provides a novel time-scale perspective to the estimation of the
tail--exponents. Its performance is illustrated over synthetic and real data
sets.",http://arxiv.org/pdf/1005.4329v1,stat.ME
2010-04-13 10:16:29+00:00,Estimation for Latent Factor Models for High-Dimensional Time Series,"['Clifford Lam', 'Qiwei Yao', 'Neil Bathia']","This paper deals with the dimension reduction for high-dimensional time
series based on common factors. In particular we allow the dimension of time
series $p$ to be as large as, or even larger than, the sample size $n$. The
estimation for the factor loading matrix and the factor process itself is
carried out via an eigenanalysis for a $p\times p$ non-negative definite
matrix. We show that when all the factors are strong in the sense that the norm
of each column in the factor loading matrix is of the order $p^{1/2}$, the
estimator for the factor loading matrix, as well as the resulting estimator for
the precision matrix of the original $p$-variant time series, are weakly
consistent in $L_2$-norm with the convergence rates independent of $p$. This
result exhibits clearly that the `curse' is canceled out by the `blessings' in
dimensionality. We also establish the asymptotic properties of the estimation
when not all factors are strong. For the latter case, a two-step estimation
procedure is preferred accordingly to the asymptotic theory. The proposed
methods together with their asymptotic properties are further illustrated in a
simulation study. An application to a real data set is also reported.",http://arxiv.org/pdf/1004.2138v3,math.ST
2010-03-22 13:01:30+00:00,Off-line detection of multiple change points with the Filtered Derivative with p-Value method,"['Pierre R. Bertrand', 'Mehdi Fhima', 'Arnaud Guillin']","This paper deals with off-line detection of change points for time series of
independent observations, when the number of change points is unknown. We
propose a sequential analysis like method with linear time and memory
complexity. Our method is based at first step, on Filtered Derivative method
which detects the right change points but also false ones. We improve Filtered
Derivative method by adding a second step in which we compute the p-values
associated to each potential change points. Then we eliminate as false alarms
the points which have p-value smaller than a given critical level. Next, our
method is compared with the Penalized Least Square Criterion procedure on
simulated data sets. Eventually, we apply Filtered Derivative with p-Value
method to segmentation of heartbeat time series, and detection of change points
in the average daily volume of financial time series.",http://arxiv.org/pdf/1003.4148v2,math.ST
2010-03-14 23:12:56+00:00,A note on the Berman condition,"['Rolf Turner', 'Patrick Chareka']","It is established that if a time series satisfies the Berman condition, and
another related (summability) condition, the result of filtering that series
through a certain type of filter also satisfies the two conditions. In
particular it follows that if $X_t$ satisfies the two conditions and if $X_t$
and $a_t$ are related by an invertible ARMA model, then the $a_t$ satisfy the
two conditions.",http://arxiv.org/pdf/1003.2831v1,stat.ME
2010-01-31 20:21:44+00:00,Estimation error for blind Gaussian time series prediction,"['Thibault Espinasse', 'Fabrice Gamboa', 'Jean-Michel Loubes']","We tackle the issue of the blind prediction of a Gaussian time series. For
this, we construct a projection operator build by plugging an empirical
covariance estimation into a Schur complement decomposition of the projector.
This operator is then used to compute the predictor. Rates of convergence of
the estimates are given.",http://arxiv.org/pdf/1002.0152v2,stat.ME
2010-01-12 09:45:20+00:00,Monitoring Procedures to Detect Unit Roots and Stationarity,['Ansgar Steland'],"When analysing time series an important issue is to decide whether the time
series is stationary or a random walk. Relaxing these notions, we consider the
problem to decide in favor of the I(0)- or I(1)-property. Fixed-sample
statistical tests for that problem are well studied in the literature. In this
paper we provide first results for the problem to monitor sequentially a time
series. Our stopping times are based on a sequential version of a
kernel-weighted variance-ratio statistic. The asymptotic distributions are
established for I(1) processes, a rich class of stationary processes, possibly
affected by local nonpara- metric alternatives, and the local-to-unity model.
Further, we consider the two interesting change-point models where the time
series changes its behaviour after a certain fraction of the observations and
derive the associated limiting laws. Our Monte-Carlo studies show that the
proposed detection procedures have high power when interpreted as a hypothesis
test, and that the decision can often be made very early.",http://arxiv.org/pdf/1001.1831v1,math.ST
2009-11-25 01:02:36+00:00,A test for second order stationarity of a time series based on the Discrete Fourier Transform (Technical Report),"['Yogesh Dwivedi', 'Suhasini Subba Rao']","We consider a zero mean discrete time series, and define its discrete Fourier
transform at the canonical frequencies. It is well known that the discrete
Fourier transform is asymptotically uncorrelated at the canonical frequencies
if and if only the time series is second order stationary. Exploiting this
important property, we construct a Portmanteau type test statistic for testing
stationarity of the time series. It is shown that under the null of
stationarity, the test statistic is approximately a chi square distribution. To
examine the power of the test statistic, the asymptotic distribution under the
locally stationary alternative is established. It is shown to be a type of
noncentral chi-square, where the noncentrality parameter measures the deviation
from stationarity. The test is illustrated with simulations, where is it shown
to have good power. Some real examples are also included to illustrate the
test.",http://arxiv.org/pdf/0911.4744v1,stat.ME
2009-09-02 13:57:52+00:00,On nonparametric and semiparametric testing for multivariate linear time series,"['Yoshihiro Yajima', 'Yasumasa Matsuda']","We formulate nonparametric and semiparametric hypothesis testing of
multivariate stationary linear time series in a unified fashion and propose new
test statistics based on estimators of the spectral density matrix. The
limiting distributions of these test statistics under null hypotheses are
always normal distributions, and they can be implemented easily for practical
use. If null hypotheses are false, as the sample size goes to infinity, they
diverge to infinity and consequently are consistent tests for any alternative.
The approach can be applied to various null hypotheses such as the independence
between the component series, the equality of the autocovariance functions or
the autocorrelation functions of the component series, the separability of the
covariance matrix function and the time reversibility. Furthermore, a null
hypothesis with a nonlinear constraint like the conditional independence
between the two series can be tested in the same way.",http://arxiv.org/pdf/0909.0433v1,math.ST
2009-08-18 07:16:28+00:00,Sequential Quantile Prediction of Time Series,"['Gérard Biau', 'Benoît Patra']","Motivated by a broad range of potential applications, we address the quantile
prediction problem of real-valued time series. We present a sequential quantile
forecasting model based on the combination of a set of elementary nearest
neighbor-type predictors called ""experts"" and show its consistency under a
minimum of conditions. Our approach builds on the methodology developed in
recent years for prediction of individual sequences and exploits the quantile
structure as a minimizer of the so-called pinball loss function. We perform an
in-depth analysis of real-world data sets and show that this nonparametric
strategy generally outperforms standard quantile prediction methods",http://arxiv.org/pdf/0908.2503v2,stat.ME
2009-05-21 03:05:38+00:00,Finding Anomalous Periodic Time Series: An Application to Catalogs of Periodic Variable Stars,"['Umaa Rebbapragada', 'Pavlos Protopapas', 'Carla E. Brodley', 'Charles Alcock']","Catalogs of periodic variable stars contain large numbers of periodic
light-curves (photometric time series data from the astrophysics domain).
Separating anomalous objects from well-known classes is an important step
towards the discovery of new classes of astronomical objects. Most anomaly
detection methods for time series data assume either a single continuous time
series or a set of time series whose periods are aligned. Light-curve data
precludes the use of these methods as the periods of any given pair of
light-curves may be out of sync. One may use an existing anomaly detection
method if, prior to similarity calculation, one performs the costly act of
aligning two light-curves, an operation that scales poorly to massive data
sets. This paper presents PCAD, an unsupervised anomaly detection method for
large sets of unsynchronized periodic time-series data, that outputs a ranked
list of both global and local anomalies. It calculates its anomaly score for
each light-curve in relation to a set of centroids produced by a modified
k-means clustering algorithm. Our method is able to scale to large data sets
through the use of sampling. We validate our method on both light-curve data
and other time series data sets. We demonstrate its effectiveness at finding
known anomalies, and discuss the effect of sample size and number of centroids
on our results. We compare our method to naive solutions and existing time
series anomaly detection methods for unphased data, and show that PCAD's
reported anomalies are comparable to or better than all other methods. Finally,
astrophysicists on our team have verified that PCAD finds true anomalies that
might be indicative of novel astrophysical phenomena.",http://arxiv.org/pdf/0905.3428v1,cs.LG
2009-02-17 13:40:29+00:00,Model selection for weakly dependent time series forecasting,"['Pierre Alquier', 'Olivier Wintenberger']","Observing a stationary time series, we propose a two-step procedure for the
prediction of the next value of the time series. The first step follows machine
learning theory paradigm and consists in determining a set of possible
predictors as randomized estimators in (possibly numerous) different predictive
models. The second step follows the model selection paradigm and consists in
choosing one predictor with good properties among all the predictors of the
first steps. We study our procedure for two different types of bservations:
causal Bernoulli shifts and bounded weakly dependent processes. In both cases,
we give oracle inequalities: the risk of the chosen predictor is close to the
best prediction risk in all predictive models that we consider. We apply our
procedure for predictive models such as linear predictors, neural networks
predictors and non-parametric autoregressive.",http://arxiv.org/pdf/0902.2924v4,stat.ME
2009-02-09 15:04:32+00:00,Empirical spectral processes for locally stationary time series,"['Rainer Dahlhaus', 'Wolfgang Polonik']","A time-varying empirical spectral process indexed by classes of functions is
defined for locally stationary time series. We derive weak convergence in a
function space, and prove a maximal exponential inequality and a
Glivenko--Cantelli-type convergence result. The results use conditions based on
the metric entropy of the index class. In contrast to related earlier work, no
Gaussian assumption is made. As applications, quasi-likelihood estimation,
goodness-of-fit testing and inference under model misspecification are
discussed. In an extended application, uniform rates of convergence are derived
for local Whittle estimates of the parameter curves of locally stationary time
series models.",http://arxiv.org/pdf/0902.1448v1,math.ST
2009-02-09 10:50:56+00:00,On continuous-time autoregressive fractionally integrated moving average processes,['Henghsiu Tsai'],"In this paper, we consider a continuous-time autoregressive fractionally
integrated moving average (CARFIMA) model, which is defined as the stationary
solution of a stochastic differential equation driven by a standard fractional
Brownian motion. Like the discrete-time ARFIMA model, the CARFIMA model is
useful for studying time series with short memory, long memory and
antipersistence. We investigate the stationarity of the model and derive its
covariance structure. In addition, we derive the spectral density function of a
stationary CARFIMA process.",http://arxiv.org/pdf/0902.1403v1,math.ST
2009-01-15 11:21:33+00:00,Sparse Causal Discovery in Multivariate Time Series,"['Stefan Haufe', 'Guido Nolte', 'Klaus-Robert Mueller', 'Nicole Kraemer']","Our goal is to estimate causal interactions in multivariate time series.
Using vector autoregressive (VAR) models, these can be defined based on
non-vanishing coefficients belonging to respective time-lagged instances. As in
most cases a parsimonious causality structure is assumed, a promising approach
to causal discovery consists in fitting VAR models with an additional
sparsity-promoting regularization. Along this line we here propose that
sparsity should be enforced for the subgroups of coefficients that belong to
each pair of time series, as the absence of a causal relation requires the
coefficients for all time-lags to become jointly zero. Such behavior can be
achieved by means of l1-l2-norm regularized regression, for which an efficient
active set solver has been proposed recently. Our method is shown to outperform
standard methods in recovering simulated causality graphs. The results are on
par with a second novel approach which uses multiple statistical testing.",http://arxiv.org/pdf/0901.2234v1,stat.ME
2009-01-07 06:57:19+00:00,Estimators for Long Range Dependence: An Empirical Study,"['William Rea', 'Les Oxley', 'Marco Reale', 'Jennifer Brown']","We present the results of a simulation study into the properties of 12
different estimators of the Hurst parameter, $H$, or the fractional integration
parameter, $d$, in long memory time series. We compare and contrast their
performance on simulated Fractional Gaussian Noises and fractionally integrated
series with lengths between 100 and 10,000 data points and $H$ values between
0.55 and 0.90 or $d$ values between 0.05 and 0.40. We apply all 12 estimators
to the Campito Mountain data and estimate the accuracy of their estimates using
the Beran goodness of fit test for long memory time series. MCS code: 37M10",http://arxiv.org/pdf/0901.0762v1,stat.ME
2008-12-02 09:16:18+00:00,Locally adaptive estimation methods with application to univariate time series,['Mstislav Elagin'],"The paper offers a unified approach to the study of three locally adaptive
estimation methods in the context of univariate time series from both
theoretical and empirical points of view. A general procedure for the
computation of critical values is given. The underlying model encompasses all
distributions from the exponential family providing for great flexibility. The
procedures are applied to simulated and real financial data distributed
according to the Gaussian, volatility, Poisson, exponential and Bernoulli
models. Numerical results exhibit a very reasonable performance of the methods.",http://arxiv.org/pdf/0812.0449v1,math.ST
2008-11-06 14:03:08+00:00,Multiple local whittle estimation in stationary systems,['P. M. Robinson'],"Moving from univariate to bivariate jointly dependent long-memory time series
introduces a phase parameter $(\gamma)$, at the frequency of principal
interest, zero; for short-memory series $\gamma=0$ automatically. The latter
case has also been stressed under long memory, along with the ``fractional
differencing'' case $\gamma=(\delta_2-\delta_1)\pi /2$, where $\delta_1$,
$\delta_2$ are the memory parameters of the two series. We develop time domain
conditions under which these are and are not relevant, and relate the
consequent properties of cross-autocovariances to ones of the (possibly
bilateral) moving average representation which, with martingale difference
innovations of arbitrary dimension, is used in asymptotic theory for local
Whittle parameter estimates depending on a single smoothing number.
Incorporating also a regression parameter $(\beta)$ which, when nonzero,
indicates cointegration, the consistency proof of these implicitly defined
estimates is nonstandard due to the $\beta$ estimate converging faster than the
others. We also establish joint asymptotic normality of the estimates, and
indicate how this outcome can apply in statistical inference on several
questions of interest. Issues of implemention are discussed, along with
implications of knowing $\beta$ and of correct or incorrect specification of
$\gamma$, and possible extensions to higher-dimensional systems and
nonstationary series.",http://arxiv.org/pdf/0811.0948v1,math.ST
2008-10-22 06:51:49+00:00,Marginal likelihood for parallel series,['Peter McCullagh'],"Suppose that $k$ series, all having the same autocorrelation function, are
observed in parallel at $n$ points in time or space. From a single series of
moderate length, the autocorrelation parameter $\beta$ can be estimated with
limited accuracy, so we aim to increase the information by formulating a
suitable model for the joint distribution of all series. Three Gaussian models
of increasing complexity are considered, two of which assume that the series
are independent. This paper studies the rate at which the information for
$\beta$ accumulates as $k$ increases, possibly even beyond $n$. The profile log
likelihood for the model with $k(k+1)/2$ covariance parameters behaves
anomalously in two respects. On the one hand, it is a log likelihood, so the
derivatives satisfy the Bartlett identities. On the other hand, the Fisher
information for $\beta$ increases to a maximum at $k=n/2$, decreasing to zero
for $k\ge n$. In any parametric statistical model, one expects the Fisher
information to increase with additional data; decreasing Fisher information is
an anomaly demanding an explanation.",http://arxiv.org/pdf/0810.3978v1,math.ST
2008-10-13 17:34:10+00:00,A generalized portmanteau test of independence between two stationary time series,['Xiaofeng Shao'],"We propose generalized portmanteau-type test statistics in the frequency
domain to test independence between two stationary time series. The test
statistics are formed analogous to the one in Chen and Deo (2004, Econometric
Theory 20, 382-416), who extended the applicability of portmanteau
goodness-of-fit test to the long memory case. Under the null hypothesis of
independence, the asymptotic standard normal distributions of the proposed
statistics are derived under fairly mild conditions. In particular, each time
series is allowed to possess short memory, long memory or anti-persistence. A
simulation study shows that the tests have reasonable size and power
properties.",http://arxiv.org/pdf/0810.2276v1,math.ST
2008-05-25 15:00:22+00:00,Missing observation analysis for matrix-variate time series data,['K. Triantafyllopoulos'],"Bayesian inference is developed for matrix-variate dynamic linear models
(MV-DLMs), in order to allow missing observation analysis, of any sub-vector or
sub-matrix of the observation time series matrix. We propose modifications of
the inverted Wishart and matrix $t$ distributions, replacing the scalar degrees
of freedom by a diagonal matrix of degrees of freedom. The MV-DLM is then
re-defined and modifications of the updating algorithm for missing observations
are suggested.",http://arxiv.org/pdf/0805.3831v1,stat.ME
2008-04-07 14:31:30+00:00,On the Spectral Properties of Matrices Associated with Trend Filters,"['Alessandra Luati', 'Tommaso Proietti']","This paper is concerned with the spectral properties of matrices associated
with linear filters for the estimation of the underlying trend of a time
series. The interest lies in the fact that the eigenvectors can be interpreted
as the latent components of any time series that the filter smooths through the
corresponding eigenvalues. A difficulty arises because matrices associated with
trend filters are finite approximations of Toeplitz operators and therefore
very little is known about their eigenstructure, which also depends on the
boundary conditions or, equivalently, on the filters for trend estimation at
the end of the sample. Assuming reflecting boundary conditions, we derive a
time series decomposition in terms of periodic latent components and
corresponding smoothing eigenvalues. This decomposition depends on the local
polynomial regression estimator chosen for the interior. Otherwise, the
eigenvalue distribution is derived with an approximation measured by the size
of the perturbation that different boundary conditions apport to the
eigenvalues of matrices belonging to algebras with known spectral properties,
such as the Circulant or the Cosine. The analytical form of the eigenvectors is
then derived with an approximation that involves the extremes only. A further
topic investigated in the paper concerns a strategy for a filter design in the
time domain. Based on cut-off eigenvalues, new estimators are derived, that are
less variable and almost equally biased as the original estimator, based on all
the eigenvalues. Empirical examples illustrate the effectiveness of the method.",http://arxiv.org/pdf/0804.1040v2,math.ST
2008-02-01 22:18:34+00:00,Posterior mean and variance approximation for regression and time series problems,"['K. Triantafyllopoulos', 'P. J. Harrison']","This paper develops a methodology for approximating the posterior first two
moments of the posterior distribution in Bayesian inference. Partially
specified probability models, which are defined only by specifying means and
variances, are constructed based upon second-order conditional independence, in
order to facilitate posterior updating and prediction of required
distributional quantities. Such models are formulated particularly for
multivariate regression and time series analysis with unknown observational
variance-covariance components. The similarities and differences of these
models with the Bayes linear approach are established. Several subclasses of
important models, including regression and time series models with errors
following multivariate $t$, inverted multivariate $t$ and Wishart
distributions, are discussed in detail. Two numerical examples consisting of
simulated data and of US investment and change in inventory data illustrate the
proposed methodology.",http://arxiv.org/pdf/0802.0213v1,stat.ME
2008-02-01 19:48:03+00:00,Covariance estimation for multivariate conditionally Gaussian dynamic linear models,['K. Triantafyllopoulos'],"In multivariate time series, the estimation of the covariance matrix of the
observation innovations plays an important role in forecasting as it enables
the computation of the standardized forecast error vectors as well as it
enables the computation of confidence bounds of the forecasts. We develop an
on-line, non-iterative Bayesian algorithm for estimation and forecasting. It is
empirically found that, for a range of simulated time series, the proposed
covariance estimator has good performance converging to the true values of the
unknown observation covariance matrix. Over a simulated time series, the new
method approximates the correct estimates, produced by a non-sequential Monte
Carlo simulation procedure, which is used here as the gold standard. The
special, but important, vector autoregressive (VAR) and time-varying VAR models
are illustrated by considering London metal exchange data consisting of spot
prices of aluminium, copper, lead and zinc.",http://arxiv.org/pdf/0802.0191v1,stat.ME
2008-01-02 02:00:15+00:00,Nonparametric sequential prediction of time series,"['Gérard Biau', 'Kevin Bleakley', 'László Györfi', 'György Ottucsák']","Time series prediction covers a vast field of every-day statistical
applications in medical, environmental and economic domains. In this paper we
develop nonparametric prediction strategies based on the combination of a set
of 'experts' and show the universal consistency of these strategies under a
minimum of conditions. We perform an in-depth analysis of real-world data sets
and show that these nonparametric strategies are more flexible, faster and
generally outperform ARMA methods in terms of normalized cumulative prediction
error.",http://arxiv.org/pdf/0801.0327v1,stat.ME
2007-12-11 10:17:30+00:00,Estimation in a class of nonlinear heteroscedastic time series models,['Joseph Ngatchou-Wandji'],"Parameter estimation in a class of heteroscedastic time series models is
investigated. The existence of conditional least-squares and conditional
likelihood estimators is proved. Their consistency and their asymptotic
normality are established. Kernel estimators of the noise's density and its
derivatives are defined and shown to be uniformly consistent. A simulation
experiment conducted shows that the estimators perform well for large sample
size.",http://arxiv.org/pdf/0712.1673v2,math.ST
2007-12-07 15:19:36+00:00,Detecting changes in the fluctuations of a Gaussian process and an application to heartbeat time series,"['Jean-Marc Bardet', 'Imen Kammoun']","The aim of this paper is first the detection of multiple abrupt changes of
the long-range dependence (respectively self-similarity, local fractality)
parameters from a sample of a Gaussian stationary times series (respectively
time series, continuous-time process having stationary increments). The
estimator of the $m$ change instants (the number $m$ is supposed to be known)
is proved to satisfied a limit theorem with an explicit convergence rate.
Moreover, a central limit theorem is established for an estimator of each
long-range dependence (respectively self-similarity, local fractality)
parameter. Finally, a goodness-of-fit test is also built in each time domain
without change and proved to asymptotically follow a Khi-square distribution.
Such statistics are applied to heart rate data of marathon's runners and lead
to interesting conclusions.",http://arxiv.org/pdf/0712.1157v1,math.ST
2007-11-28 13:20:10+00:00,Consistency and application of moving block bootstrap for non-stationary time series with periodic and almost periodic structure,['Rafal Synowiecki'],"The aim of this paper it to establish sufficient conditions for consistency
of moving block bootstrap for non-stationary time series with periodic and
almost periodic structure. The parameter of the study is the mean value of the
expectation function. Consistency holds in quite general situations: if all
joint distributions of the series are periodic, then it suffices to assume the
central limit theorem and strong mixing property, together with summability of
the autocovariance function. In the case where the mean function is almost
periodic, we additionally need uniform boundedness of the fourth moments of the
root statistics. It is shown that these theoretical results can be applied in
statistical inference concerning the Fourier coefficients of periodically (PC)
and almost periodically (APC) correlated time series. A simulation example
shows how to use a graphical diagnostic test for significant frequencies and
stationarity within these classes of time series.",http://arxiv.org/pdf/0711.4493v1,math.ST
2007-11-09 19:32:16+00:00,Instantaneous and lagged measurements of linear and nonlinear dependence between groups of multivariate time series: frequency decomposition,['Roberto D. Pascual-Marqui'],"Measures of linear dependence (coherence) and nonlinear dependence (phase
synchronization) between any number of multivariate time series are defined.
The measures are expressed as the sum of lagged dependence and instantaneous
dependence. The measures are non-negative, and take the value zero only when
there is independence of the pertinent type. These measures are defined in the
frequency domain and are applicable to stationary and non-stationary time
series. These new results extend and refine significantly those presented in a
previous technical report (Pascual-Marqui 2007, arXiv:0706.1776 [stat.ME],
http://arxiv.org/abs/0706.1776), and have been largely motivated by the seminal
paper on linear feedback by Geweke (1982 JASA 77:304-313). One important field
of application is neurophysiology, where the time series consist of electric
neuronal activity at several brain locations. Coherence and phase
synchronization are interpreted as ""connectivity"" between locations. However,
any measure of dependence is highly contaminated with an instantaneous,
non-physiological contribution due to volume conduction and low spatial
resolution. The new techniques remove this confounding factor considerably.
Moreover, the measures of dependence can be applied to any number of brain
areas jointly, i.e. distributed cortical networks, whose activity can be
estimated with eLORETA (Pascual-Marqui 2007, arXiv:0710.3341 [math-ph]).",http://arxiv.org/pdf/0711.1455v1,stat.ME
2007-10-19 11:25:46+00:00,Outliers in dynamic factor models,"['Roberto Baragona', 'Francesco Battaglia']","Dynamic factor models have a wide range of applications in econometrics and
applied economics. The basic motivation resides in their capability of reducing
a large set of time series to only few indicators (factors). If the number of
time series is large compared to the available number of observations then most
information may be conveyed to the factors. This way low dimension models may
be estimated for explaining and forecasting one or more time series of
interest. It is desirable that outlier free time series be available for
estimation. In practice, outlying observations are likely to arise at unknown
dates due, for instance, to external unusual events or gross data entry errors.
Several methods for outlier detection in time series are available. Most
methods, however, apply to univariate time series while even methods designed
for handling the multivariate framework do not include dynamic factor models
explicitly. A method for discovering outliers occurrences in a dynamic factor
model is introduced that is based on linear transforms of the observed data.
Some strategies to separate outliers that add to the model and outliers within
the common component are discussed. Applications to simulated and real data
sets are presented to check the effectiveness of the proposed method.",http://arxiv.org/pdf/0710.3676v1,math.ST
2007-08-17 14:00:25+00:00,Testing for change points in time series models and limiting theorems for NED sequences,['Shiqing Ling'],"This paper first establishes a strong law of large numbers and a strong
invariance principle for forward and backward sums of near-epoch dependent
sequences. Using these limiting theorems, we develop a general asymptotic
theory on the Wald test for change points in a general class of time series
models under the no change-point hypothesis. As an application, we verify our
assumptions for the long-memory fractional ARIMA model.",http://arxiv.org/pdf/0708.2369v1,math.ST
2007-06-12 19:48:30+00:00,"Coherence and phase synchronization: generalization to pairs of multivariate time series, and removal of zero-lag contributions",['Roberto D. Pascual-Marqui'],"Coherence and phase synchronization between time series corresponding to
different spatial locations are usually interpreted as indicators of the
connectivity between locations. In neurophysiology, time series of electric
neuronal activity are essential for studying brain interconnectivity. Such
signals can either be invasively measured from depth electrodes, or computed
from very high time resolution, non-invasive, extracranial recordings of scalp
electric potential differences (EEG: electroencephalogram) and magnetic fields
(MEG: magnetoencephalogram) by means of a tomography such as sLORETA
(standardized low resolution brain electromagnetic tomography). There are two
problems in this case. First, in the usual situation of unknown cortical
geometry, the estimated signal at each brain location is a vector with three
components (i.e. a current density vector), which means that coherence and
phase synchronization must be generalized to pairs of multivariate time series.
Second, the inherent low spatial resolution of the EEG/MEG tomography
introduces artificially high zero-lag coherence and phase synchronization. In
this report, solutions to both problems are presented. Two additional
generalizations are briefly mentioned: (1) conditional coherence and phase
synchronization; and (2) non-stationary time-frequency analysis. Finally, a
non-parametric randomization method for connectivity significance testing is
outlined. The new connectivity measures proposed here can be applied to pairs
of univariate EEG/MEG signals, as is traditional in the published literature.
However, these calculations cannot be interpreted as connectivity, since it is
in general incorrect to associate an extracranial electrode or sensor to the
underlying cortex.",http://arxiv.org/pdf/0706.1776v3,stat.ME
2007-06-11 14:32:13+00:00,Bootstrapping confidence intervals for the change-point of time series,"['Marie Huskova', 'Claudia Kirch']","We study an AMOC time series model with an abrupt change in the mean and
dependent errors that fulfill certain mixing conditions. We obtain confidence
intervals for the unknown change-point via bootstrapping methods.
  Precisely we use a block bootstrap of the estimated centered error sequence.
Then we reconstruct a sequence with a change in the mean using the same
estimators as before. The difference between the change-point estimator of the
resampled sequence and the one for the original sequence can be use as an
approximation of the difference between the real change-point and its
estimator. This enables us to construct confidence intervals using the
empirical distribution of the resampled time series.
  A simulation study shows that the resampled confidence intervals are usually
closer to their target levels and at the same time smaller than the asymptotic
intervals.",http://arxiv.org/pdf/0706.1485v1,math.ST
2007-05-14 12:28:03+00:00,Linear Prediction of Long-Memory Processes: Asymptotic Results on Mean-squared Errors,['Fanny Godet'],"We present two approaches for linear prediction of long-memory time series.
The first approach consists in truncating the Wiener-Kolmogorov predictor by
restricting the observations to the last $k$ terms, which are the only
available values in practice. We derive the asymptotic behaviour of the
mean-squared error as $k$ tends to $ + \infty$. By contrast, the second
approach is non-parametric. An AR($k$) model is fitted to the long-memory time
series and we study the error that arises in this misspecified model.",http://arxiv.org/pdf/0705.1927v1,math.ST
2007-03-02 07:38:12+00:00,Time Series and Related Topics. In Memory of Ching-Zong Wei,"['Hwai-Chung Ho', 'Ching-Kang Ing', 'Tze Leung Lai']","A major research area of Ching-Zong Wei (1949--2004) was time series models
and their applications in econometrics and engineering, to which he made many
important contributions. A conference on time series and related topics in
memory of him was held on December 12--14, 2005, at Academia Sinica in Taipei,
where he was Director of the Institute of Statistical Science from 1993 to
1999. Of the forty-two speakers at the conference, twenty contributed to this
volume. These papers are listed under the following three headings.",http://arxiv.org/pdf/math/0703053v1,math.ST
2007-02-27 16:04:22+00:00,Modeling macroeconomic time series via heavy tailed distributions,['J. A. D. Aston'],"It has been shown that some macroeconomic time series, especially those where
outliers could be present, can be well modelled using heavy tailed
distributions for the noise components. Methods for deciding when and where
heavy-tailed models should be preferred are investigated. These investigations
primarily focus on automatic methods for model identification and selection.
Current methods are extended to incorporate a non-Gaussian selection element,
and various different criteria for deciding on which overall model should be
used are examined.",http://arxiv.org/pdf/math/0702844v1,math.ST
2007-02-27 08:51:35+00:00,Combining domain knowledge and statistical models in time series analysis,"['Tze Leung Lai', 'Samuel Po-Shing Wong']","This paper describes a new approach to time series modeling that combines
subject-matter knowledge of the system dynamics with statistical techniques in
time series analysis and regression. Applications to American option pricing
and the Canadian lynx data are given to illustrate this approach.",http://arxiv.org/pdf/math/0702814v1,math.ST
2007-02-27 08:23:57+00:00,Cowles commission structural equation approach in light of nonstationary time series analysis,['Cheng Hsiao'],"We review the advancement of nonstationary time series analysis from the
perspective of Cowles Commission structural equation approach. We argue that
despite the rich repertoire nonstationary time series analysis provides to
analyze how do variables respond dynamically to shocks through the
decomposition of a dynamic system into long-run and short-run relations,
nonstationarity does not invalid the classical concerns of structural equation
modeling -- identification and simultaneity bias. The same rank condition for
identification holds for stationary and nonstationary data and some sort of
instrumental variable estimators will have to be employed to yield consistency.
However, nonstationarity does raise issues of inference if the rank of
cointegration or direction of nonstationarity is not known a priori. The usual
test statistics may not be chi-square distributed because of the presence of
unit roots distributions. Classical instrumental variable estimators have to be
modified to ensure valid inference.",http://arxiv.org/pdf/math/0702813v1,math.ST
2007-02-26 14:38:54+00:00,Conditional-sum-of-squares estimation of models for stationary time series with long memory,['P. M. Robinson'],"Employing recent results of Robinson (2005) we consider the asymptotic
properties of conditional-sum-of-squares (CSS) estimates of parametric models
for stationary time series with long memory. CSS estimation has been considered
as a rival to Gaussian maximum likelihood and Whittle estimation of time series
models. The latter kinds of estimate have been rigorously shown to be
asymptotically normally distributed in case of long memory. However, CSS
estimates, which should have the same asymptotic distributional properties
under similar conditions, have not received comparable treatment: the
truncation of the infinite autoregressive representation inherent in CSS
estimation has been essentially ignored in proofs of asymptotic normality.
Unlike in short memory models it is not straightforward to show the truncation
has negligible effect.",http://arxiv.org/pdf/math/0702782v1,math.ST
2007-02-26 10:35:20+00:00,Pile-up probabilities for the Laplace likelihood estimator of a non-invertible first order moving average,"['F. Jay Breidt', 'Richard A. Davis', 'Nan-Jung Hsu', 'Murray Rosenblatt']","The first-order moving average model or MA(1) is given by
$X_t=Z_t-\theta_0Z_{t-1}$, with independent and identically distributed
$\{Z_t\}$. This is arguably the simplest time series model that one can write
down. The MA(1) with unit root ($\theta_0=1$) arises naturally in a variety of
time series applications. For example, if an underlying time series consists of
a linear trend plus white noise errors, then the differenced series is an MA(1)
with unit root. In such cases, testing for a unit root of the differenced
series is equivalent to testing the adequacy of the trend plus noise model. The
unit root problem also arises naturally in a signal plus noise model in which
the signal is modeled as a random walk. The differenced series follows a MA(1)
model and has a unit root if and only if the random walk signal is in fact a
constant. The asymptotic theory of various estimators based on Gaussian
likelihood has been developed for the unit root case and nearly unit root case
($\theta=1+\beta/n,\beta\le0$). Unlike standard $1/\sqrt{n}$-asymptotics, these
estimation procedures have $1/n$-asymptotics and a so-called pile-up effect, in
which P$(\hat{\theta}=1)$ converges to a positive value. One explanation for
this pile-up phenomenon is the lack of identifiability of $\theta$ in the
Gaussian case. That is, the Gaussian likelihood has the same value for the two
sets of parameter values $(\theta,\sigma^2)$ and $(1/\theta,\theta^2\sigma^2$).
It follows that $\theta=1$ is always a critical point of the likelihood
function. In contrast, for non-Gaussian noise, $\theta$ is identifiable for all
real values. Hence it is no longer clear whether or not the same pile-up
phenomenon will persist in the non-Gaussian case. In this paper, we focus on
limiting pile-up probabilities for estimates of $\theta_0$ based on a Laplace
likelihood. In some cases, these estimates can be viewed as Least Absolute
Deviation (LAD) estimates. Simulation results illustrate the limit theory.",http://arxiv.org/pdf/math/0702762v1,math.ST
2007-02-23 15:23:19+00:00,A comparison of statistical models for short categorical or ordinal time series with applications in ecology,"['Noëlle Bru', 'Laurence Despres', 'Christian Paroissin']","We study two statistical models for short-length categorical (or ordinal)
time series. The first one is a regression model based on generalized linear
model. The second one is a parametrized Markovian model, particularizing the
discrete autoregressive model to the case of categorical data. These models are
used to analyze two data-sets: annual larch cone production and weekly
planktonic abundance.",http://arxiv.org/pdf/math/0702706v1,math.ST
2007-02-23 11:54:40+00:00,Quasi-maximum-likelihood estimation in conditionally heteroscedastic time series: A stochastic recurrence equations approach,"['Daniel Straumann', 'Thomas Mikosch']","This paper studies the quasi-maximum-likelihood estimator (QMLE) in a general
conditionally heteroscedastic time series model of multiplicative form
$X_t=\sigma_tZ_t$, where the unobservable volatility $\sigma_t$ is a parametric
function of $(X_{t-1},...,X_{t-p},\sigma_{t-1},... ,\sigma_{t-q})$ for some
$p,q\ge0$, and $(Z_t)$ is standardized i.i.d. noise. We assume that these
models are solutions to stochastic recurrence equations which satisfy a
contraction (random Lipschitz coefficient) property. These assumptions are
satisfied for the popular GARCH, asymmetric GARCH and exponential GARCH
processes. Exploiting the contraction property, we give conditions for the
existence and uniqueness of a strictly stationary solution $(X_t)$ to the
stochastic recurrence equation and establish consistency and asymptotic
normality of the QMLE. We also discuss the problem of invertibility of such
time series models.",http://arxiv.org/pdf/math/0702692v1,math.ST
2007-02-16 15:51:13+00:00,Linear Prediction of Long-Range Dependent Time Series,['Fanny Godet'],"We present two approaches for next step linear prediction of long memory time
series. The first is based on the truncation of the Wiener-Kolmogorov predictor
by restricting the observations to the last $k$ terms, which are the only
available values in practice. Part of the mean squared prediction error comes
from the truncation, and another part comes from the parametric estimation of
the parameters of the predictor. By contrast, the second approach is
non-parametric. An AR($k$) model is fitted to the long memory time series and
we study the error made with this misspecified model.",http://arxiv.org/pdf/math/0702485v2,math.ST
2007-01-25 13:14:25+00:00,Uniform limit theorems for the integrated periodogram of weakly dependent time series and their applications to Whittle's estimate,"['Jean-Marc Bardet', 'Paul Doukhan', 'José Rafael León']","We prove uniform convergence results for the integrated periodogram of a
weakly dependent time series, namely a law of large numbers and a central limit
theorem. These results are applied to Whittle's parametric estimation. Under
general weak-dependence assumptions we derive uniform limit theorems and
asymptotic normality of Whittle's estimate for a large class of models. For
instance the causal $\theta$-weak dependence property allows a new and unified
proof of those results for ARCH($\infty$) and bilinear processes. Non causal
$\eta$-weak dependence yields the same limit theorems for two-sided linear
(with dependent inputs) or Volterra processes.",http://arxiv.org/pdf/math/0701739v1,math.ST
2007-01-08 17:03:31+00:00,Time Series Forecasting: Obtaining Long Term Trends with Self-Organizing Maps,"['Geoffroy Simon', 'Amaury Lendasse', 'Marie Cottrell', 'Jean-Claude Fort', 'Michel Verleysen']","Kohonen self-organisation maps are a well know classification tool, commonly
used in a wide variety of problems, but with limited applications in time
series forecasting context. In this paper, we propose a forecasting method
specifically designed for multi-dimensional long-term trends prediction, with a
double application of the Kohonen algorithm. Practical applications of the
method are also presented.",http://arxiv.org/pdf/cs/0701052v1,cs.LG
2006-12-22 19:49:28+00:00,Spline-backfitted kernel smoothing of nonlinear additive autoregression model,"['Li Wang', 'Lijian Yang']","Application of nonparametric and semiparametric regression techniques to
high-dimensional time series data has been hampered due to the lack of
effective tools to address the ``curse of dimensionality.'' Under rather weak
conditions, we propose spline-backfitted kernel estimators of the component
functions for the nonlinear additive time series data that are both
computationally expedient so they are usable for analyzing very
high-dimensional time series, and theoretically reliable so inference can be
made on the component functions with confidence. Simulation experiments have
provided strong evidence that corroborates the asymptotic theory.",http://arxiv.org/pdf/math/0612677v5,math.ST
2006-11-22 13:40:16+00:00,A non-linear Renewal Theorem with stationary and slowly changing perturbations,"['Dong-Yun Kim', 'Michael Woodroofe']","Non-linear renewal theory is extended to include random walks perturbed by
both a slowly changing sequence and a stationary one. Main results include a
version of the Key Renewal Theorem, a derivation of the limiting distribution
of the excess over a boundary, and an expansion for the expected first passage
time. The formulation is motivated by problems in sequential analysis with
staggered entry, where subjects enter a study at random times.",http://arxiv.org/pdf/math/0611695v1,math.ST
2006-11-07 09:28:56+00:00,On competing risk and degradation processes,['Nozer D. Singpurwalla'],"Lehmann's ideas on concepts of dependence have had a profound effect on
mathematical theory of reliability. The aim of this paper is two-fold. The
first is to show how the notion of a ``hazard potential'' can provide an
explanation for the cause of dependence between life-times. The second is to
propose a general framework under which two currently discussed issues in
reliability and in survival analysis involving interdependent stochastic
processes, can be meaningfully addressed via the notion of a hazard potential.
The first issue pertains to the failure of an item in a dynamic setting under
multiple interdependent risks. The second pertains to assessing an item's life
length in the presence of observable surrogates or markers. Here again the
setting is dynamic and the role of the marker is akin to that of a leading
indicator in multiple time series.",http://arxiv.org/pdf/math/0611170v1,math.ST
2006-11-01 20:40:22+00:00,Asymptotic spectral theory for nonlinear time series,"['Xiaofeng Shao', 'Wei Biao Wu']","We consider asymptotic problems in spectral analysis of stationary causal
processes. Limiting distributions of periodograms and smoothed periodogram
spectral density estimates are obtained and applications to the spectral domain
bootstrap are given. Instead of the commonly used strong mixing conditions, in
our asymptotic spectral theory we impose conditions only involving
(conditional) moments, which are easily verifiable for a variety of nonlinear
time series.",http://arxiv.org/pdf/math/0611029v2,math.ST
2006-10-22 00:45:30+00:00,Graphical modelling of multivariate time series,['Michael Eichler'],"We introduce graphical time series models for the analysis of dynamic
relationships among variables in multivariate time series. The modelling
approach is based on the notion of strong Granger causality and can be applied
to time series with non-linear dependencies. The models are derived from
ordinary time series models by imposing constraints that are encoded by mixed
graphs. In these graphs each component series is represented by a single vertex
and directed edges indicate possible Granger-causal relationships between
variables while undirected edges are used to map the contemporaneous dependence
structure. We introduce various notions of Granger-causal Markov properties and
discuss the relationships among them and to other Markov properties that can be
applied in this context.",http://arxiv.org/pdf/math/0610654v2,math.ST
2006-07-31 12:04:53+00:00,On discriminating between long-range dependence and changes in mean,"['István Berkes', 'Lajos Horváth', 'Piotr Kokoszka', 'Qi-Man Shao']","We develop a testing procedure for distinguishing between a long-range
dependent time series and a weakly dependent time series with change-points in
the mean. In the simplest case, under the null hypothesis the time series is
weakly dependent with one change in mean at an unknown point, and under the
alternative it is long-range dependent. We compute the CUSUM statistic $T_n$,
which allows us to construct an estimator $\hat{k}$ of a change-point. We then
compute the statistic $T_{n,1}$ based on the observations up to time $\hat{k}$
and the statistic $T_{n,2}$ based on the observations after time $\hat{k}$. The
statistic $M_n=\max[T_{n,1},T_{n,2}]$ converges to a well-known distribution
under the null, but diverges to infinity if the observations exhibit long-range
dependence. The theory is illustrated by examples and an application to the
returns of the Dow Jones index.",http://arxiv.org/pdf/math/0607803v1,math.ST
2006-03-10 17:32:29+00:00,Convergence rates for density estimators of weakly dependent time series,"['Nicolas Ragache', 'Olivier Wintenberger']","Assuming that $(X_t)_{t\in\Z}$ is a vector valued time series with a common
marginal distribution admitting a density $f$, our aim is to provide a wide
range of consistent estimators of $f$. We consider different methods of
estimation of the density as kernel, projection or wavelets ones. Various cases
of weakly dependent series are investigated including the Doukhan & Louhichi
(1999)'s $\eta$-weak dependence condition, and the $\tilde \phi$-dependence of
Dedecker & Prieur (2005). We thus obtain results for Markov chains, dynamical
systems, bilinear models, non causal Moving Average... From a moment inequality
of Doukhan & Louhichi (1999), we provide convergence rates of the term of error
for the estimation with the $\L^q$ loss or almost surely, uniformly on compact
subsets.",http://arxiv.org/pdf/math/0603254v2,math.ST
2006-01-04 16:29:30+00:00,A Wavelet Whittle estimator of the memory parameter of a non-stationary Gaussian time series,"['Eric Moulines', 'François Roueff', 'Murad S. Taqqu']","We consider a time series $X=\{X_k, k\in\mathbb{Z}\}$ with memory parameter
$d\in\mathbb{R}$. This time series is either stationary or can be made
stationary after differencing a finite number of times. We study the ""Local
Whittle Wavelet Estimator"" of the memory parameter $d$. This is a wavelet-based
semiparametric pseudo-likelihood maximum method estimator. The estimator may
depend on a given finite range of scales or on a range which becomes infinite
with the sample size. We show that the estimator is consistent and rate optimal
if $X$ is a linear process and is asymptotically normal if $X$ is Gaussian.",http://arxiv.org/pdf/math/0601070v4,math.ST
2005-08-16 10:53:52+00:00,Efficiency improvements in inference on stationary and nonstationary fractional time series,['P. M. Robinson'],"We consider a time series model involving a fractional stochastic component,
whose integration order can lie in the stationary/invertible or nonstationary
regions and be unknown, and an additive deterministic component consisting of a
generalized polynomial. The model can thus incorporate competing descriptions
of trending behavior. The stationary input to the stochastic component has
parametric autocorrelation, but innovation with distribution of unknown form.
The model is thus semiparametric, and we develop estimates of the parametric
component which are asymptotically normal and achieve an M-estimation
efficiency bound, equal to that found in work using an adaptive LAM/LAN
approach. A major technical feature which we treat is the effect of truncating
the autoregressive representation in order to form innovation proxies. This is
relevant also when the innovation density is parameterized, and we provide a
result for that case also. Our semiparametric estimates employ nonparametric
series estimation, which avoids some complications and conditions in kernel
approaches featured in much work on adaptive estimation of time series models;
our work thus also contributes to methods and theory for nonfractional time
series models, such as autoregressive moving averages. A Monte Carlo study of
finite sample performance of the semiparametric estimates is included.",http://arxiv.org/pdf/math/0508284v1,math.ST
2005-05-25 04:46:35+00:00,zoo: S3 Infrastructure for Regular and Irregular Time Series,"['A. Zeileis', 'G. Grothendieck']","zoo is an R package providing an S3 class with methods for indexed totally
ordered observations, such as discrete irregular time series. Its key design
goals are independence of a particular index/time/date class and consistency
with base R and the ""ts"" class for regular time series. This paper describes
how these are achieved within zoo and provides several illustrations of the
available methods for ""zoo"" objects which include plotting, merging and
binding, several mathematical operations, extracting and replacing data and
index, coercion and NA handling. A subclass ""zooreg"" embeds regular time series
into the ""zoo"" framework and thus bridges the gap between regular and irregular
time series classes in R.",http://arxiv.org/pdf/math/0505527v1,math.ST
2005-05-10 10:01:59+00:00,A Functional Wavelet-Kernel Approach for Continuous-time Prediction,"['Anestis Antoniadis', 'Efstathios Paparoditis', 'Theofanis Sapatinas']","We consider the prediction problem of a continuous-time stochastic process on
an entire time-interval in terms of its recent past. The approach we adopt is
based on functional kernel nonparametric regression estimation techniques where
observations are segments of the observed process considered as curves. These
curves are assumed to lie within a space of possibly inhomogeneous functions,
and the discretized times series dataset consists of a relatively small,
compared to the number of segments, number of measurements made at regular
times. We thus consider only the case where an asymptotically non-increasing
number of measurements is available for each portion of the times series. We
estimate conditional expectations using appropriate wavelet decompositions of
the segmented sample paths. A notion of similarity, based on wavelet
decompositions, is used in order to calibrate the prediction. Asymptotic
properties when the number of segments grows to infinity are investigated under
mild conditions, and a nonparametric resampling procedure is used to generate,
in a flexible way, valid asymptotic pointwise confidence intervals for the
predicted trajectories. We illustrate the usefulness of the proposed functional
wavelet-kernel methodology in finite sample situations by means of three
real-life datasets that were collected from different arenas.",http://arxiv.org/pdf/math/0505172v1,math.ST
2004-12-01 16:32:49+00:00,Mining Heterogeneous Multivariate Time-Series for Learning Meaningful Patterns: Application to Home Health Telecare,"['Florence Duchene', 'Catherine Garbay', 'Vincent Rialle']","For the last years, time-series mining has become a challenging issue for
researchers. An important application lies in most monitoring purposes, which
require analyzing large sets of time-series for learning usual patterns. Any
deviation from this learned profile is then considered as an unexpected
situation. Moreover, complex applications may involve the temporal study of
several heterogeneous parameters. In that paper, we propose a method for mining
heterogeneous multivariate time-series for learning meaningful patterns. The
proposed approach allows for mixed time-series -- containing both pattern and
non-pattern data -- such as for imprecise matches, outliers, stretching and
global translating of patterns instances in time. We present the early results
of our approach in the context of monitoring the health status of a person at
home. The purpose is to build a behavioral profile of a person by analyzing the
time variations of several quantitative or qualitative parameters recorded
through a provision of sensors installed in the home.",http://arxiv.org/pdf/cs/0412003v1,cs.LG
